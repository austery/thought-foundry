---
title: A/B 实验：揭秘不为人知的核心价值与统计误区
summary: 本文深入探讨A/B实验的真正价值，强调其从“惊喜”中发现机会，并纠正常见的统计误解。文章详细介绍了实验体系的设计、核心统计知识，以及CUPED、贝叶斯方法和序贯检验等高级测试，旨在帮助读者构建更严谨、高效的实验流程。
area: null
category: null
project: []
tags:
- ab-testing
- data-science
- experimentation
- statistics
people: []
companies_orgs: []
products_models: []
media_books: []
date: '2025-10-08'
author: 课代表立正
speaker: 课代表立正
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=9kh1YvzZYks
status: evergreen
---
### A/B 实验的真正价值：源于“惊喜”而非“证实”

大家好！今天我们来系统、完整地探讨A/B实验，力求达到最顶级的认知。我曾在美国亚马逊和Meta工作，很早就意识到了A/B实验的重要性，并撰写了许多相关内容。目前我所在的公司Statsig是业界领先的A/B实验平台提供商，客户包括OpenAI、Anthropic、Atlassian、Notion、Figma等知名公司。作为公司的evangelist（布道师），我与众多业界领袖（包括非客户如Lyft、DoorDash、Netflix）都有深度交流，因此非常了解行业现状和技术水平。

那么，我们为什么要进行实验？很多人存在一个误解，认为做实验是为了验证一个已有的好想法，并决定是否上线。然而，实验的真正价值恰恰来自于“惊喜”。也就是说，当你一个好想法被实验验证时，实验本身并没有提供太多价值，其价值在于你的好想法。而当你发现一个你以为的好想法实际上是个坏想法，或者一个你认为平平无奇的想法却被实验证明非常棒时，这才是实验的核心价值所在。

Ron Kohavi在其著作中提到，必应搜索（Bing search）曾进行一个微小的改动，却带来了数亿美元的销售提升。这说明，无论是正向还是反向的惊喜，都体现了实验的价值。在他的研究中，早期实验的假设（hypothesis）成功率仅在3%-30%之间，通常在20%左右。这意味着，你在80%的情况下都会遇到“惊喜”，即实验结果与预期不符。

理解这一点至关重要。如果我们不了解哪些功能上线后是正向或负向影响，指标的增长就会像过山车一样波动，难以实现复利增长。而通过实验，即使不做其他优化，仅仅是砍掉那些带有负面影响的功能，就能实现更高的指数级增长。因此，实验的根本意义在于“value of experimentation come from surprises”（实验的价值源于惊喜）。

### 提升实验覆盖率：功能开关与实验设计的整合

我们应该想方设法提高实验的覆盖率，确保每一个新功能都经过实验验证，而不是仅仅基于个人信心。许多公司存在“ad hoc”（临时）做实验的情况，只对那些有信心的想法进行实验，这其实意义不大。

实现100%的实验覆盖率是完全可能的。Meta公司以及Statsig的许多客户，包括OpenAI等，都做到了这一点。我所知道的一个例子是Canva。实现这一目标的核心技术洞察在于，将“功能开关”（feature gate）与“实验”（experiment）设计成同一个对象。

在Meta，这分别被称为Gatekeeper（看门人）和Delta（增量测试）。功能开关是一种条件规则，用于决定用户是否能看到某个功能。你可以设置各种条件，比如仅对内部员工可见，或者在特定地区上线10%或50%。本质上，所有用户都会收到代码，但功能开关作为上层的配置，控制着用户能否看到对应功能。在美国公司，这已成为标配，用于新功能的“分阶段发布”（stage roll out），即先上线给1%的用户，观察是否有bug，再逐步增加到10%、100%。去年CrowdStrike的机场蓝屏事故，就因未能使用功能开关而受到广泛批评，这在2024年已是基本的操作。

在此基础上，加入随机化（randomization）就构成了A/B实验。因此，在底层系统设计时，将功能开关和实验视为同一对象，只需在此之上加上随机化和统计引擎，就能实现100%的功能实验覆盖。工程师在发布功能时使用功能开关，就自然而然地免费获得了对应的实验。只需后续接入统计引擎，即可选择对任何通过功能开关发布的功能进行实验效果的读出（readout）。这种基础设施的设计，是Meta A/B实验体系强大的原因之一。

### 实验驱动的文化：赋能工程师与数据驱动决策

这种底层基础设施的建设，还带来了A/B实验重要的文化属性——赋能底层工程师，无需达成广泛共识即可进行构建。在不进行实验的公司，通常需要先进行长时间的讨论，达成共识或规划后，工程师才能动手。而实验可以让你控制功能的发布范围。

绝大多数公司会选择“在开关后测试”或“在实验后测试”的路径：先做出功能的演示（demo），然后内部测试，逐步开放给1%的用户观察负面效果，再到10%，收集足够的用户数据来判断指标变化。一旦确认功能有积极影响，才将其上线给100%的用户。

这样的好处是，在讨论功能上线与否或上线比例时，我们是带着数据和实际功能来的，无需过多无效讨论。正如MIT教授Kevin所言，他们90%的实验假设也是错误的，因为产品越成熟、生态越复杂，改进就越难，人的大脑难以在事前预测所有情况。

我在为客户进行案例研究时，曾发现一个公司（Rec Room）的UI（用户界面）改版后，关键指标“创建的聊天线程数”大幅下降。通过数据发现问题后，回看UI，会发现原本显著的“消息”按钮被移到角落，不易找到。在看到数据之前，没有人能预见到这个问题。

这正是“智识诚实”（intellectual honesty）的体现。人的认知是狭隘的、浅层的，大脑并不适合应对复杂环境。因此，实验的必要性在于它提供了智识诚实，通过事实验证帮助我们发现想法的不足，并带来价值。同时，它也促进了一种更具自主权、更快的工程师文化，避免将时间耗费在无休止的争论上。

### 构建实验体系：从自动化到可扩展的基础设施

围绕实验目标，我们应该如何构建实验体系？

第一，如前所述，功能开关和实验应设计成同一个对象。构建实验系统通常分三步。A/B实验是易于开始但难于扩展的系统之一。

*   **第一步（最基础）：** 数据科学家提供笔记本（notebook）或电子表格，手动进行实验。但这容易出错，且结果不一致。
*   **第二步（自动化）：** 自动化数据计算和流水线，使公司一年能从5个实验扩展到50个。
*   **第三步（可扩展的基础设施）：** 整合功能开关和实验，实现“实验默认开启”（experiments are default on）。工程师无需额外设置实验，实验成本趋近于零。公司可以从50个实验扩展到5千、5万、50万个，实验本身不再构成约束，瓶颈在于新想法的数量。

在这一阶段，数据质量至关重要。数据的可信度是实验过程的基础。随着时间推移，数据质量会下降，因为日志表（logging table）和指标（metrics）之间的复杂流水线代码难以维护，数据碎片化。分析师的任期通常较短，导致代码无人维护，层层累积的改动可能导致数据不一致。

我们的产品提供了一个“指标目录”（metrics catalog），通过可视化拖拽方式，定义日志表后可进行各种聚合、分组、过滤，甚至设置时间窗口。这些基本操作可满足绝大多数公司从日志记录到指标计算的需求。所有指标集中定义后，可实现端到端可追溯。任何人都能清晰地看到指标的来源、计算方式、聚合逻辑等，确保数据的可信度。

拥有简单的实验定义和可信的数据，我们就能最大限度地提高实验覆盖率，从而加速开发，更客观、定量地指导产品发展。

### 警惕“学究式”数据科学家：简化而非复杂化实验

需要警惕的是，一些“学究式”（pedantic）数据科学家，特别是初级或学院派的，倾向于将事情复杂化以凸显自身价值。然而，真正有价值的是将事情做得更简单、更标准化，从而提高实验的可扩展性。

如果实验的复杂性导致他人难以理解、降低了实验速度、增加了沟通难度，并且难以获得业务方的支持，那么就不应进行。除非这种复杂性解决了真实存在的问题。

许多数据科学家一上来就考虑非参数检验、各种论文中的新方法、强化学习或生成式AI。他们并未真正认识到实验的价值，而是拿着“锤子”（新技术）去寻找“钉子”（问题）。“越难越有价值”是一个巨大的误解，源于学校教育。更有价值的是那些真正能带来价值的事物，即通过实验覆盖新功能开发，不断获得“惊喜”，并用因果数据指导产品发展。

### 统计基础：假设检验、功效与样本量

接下来，我们聊聊统计知识，帮助数据科学家在追求“更快更多”的同时，保持严谨并提高决策质量。

1.  **理解假设检验（Hypothesis Testing）、功效（Power）、最小可检测差异（Minimum Detectable Delta）和样本量（Sample Size）：** 实验永远面临权衡。样本量通常由业务决定。实验跑得越久，能检测到越小的效应，结果越准确，信号越强。
    *   如果一个功能影响巨大（如10%增量），跑几天就能知道。
    *   但对于Meta这样的公司，可能需要检测0.1%-0.2%的效应；普通公司则需要0.5%-1%-2%。
    *   通过优化，可以在一周或两周内检测到，而非五到六周。

2.  **并行实验（Concurrent Experiments）：** 运行多个实验是允许的，交互效应（interaction effects）通常不是大问题。学术界对此十分在意，但实际数据显示问题极少。只要实验是正交的，可以同时运行成千上万个实验。即使担心交互效应，也有相应的检测方法。不要因为极少数极端情况而不进行并行实验，这将极大提高实验速度。

3.  **方差缩减（Variance Reduction）：** 这是数据科学家唯一能做的，以降低最小可检测差异，缩短实验时间或降低样本量要求。
    *   **回归调整（Regression Adjustment）/ CUPED（通过回归调整的方差缩减方法）：** 这是最有效的方法。CUPED利用实验前数据预测实验后数据，从而降低方差。更高级的CURE（我们的产品名称）还可利用用户或其他单元的属性进行回归拟合。
    *   CUPED能帮助降低80%本应降低的方差。如果未做CUPED，应尽快实施。即使做了CUPED，也不必花费过多精力去追求更花哨的技术（如深度学习）来进一步降低方差。

4.  **贝叶斯（Bayesian）与频率学派（Frequentist）：** 这两者是解释同一数据的不同哲学，不会改变数据本身。无先验（no prior）的贝叶斯方法与频率学派在数据和决策规则上基本一致。带有先验（Bayesian with priors）的方法，尤其是在点估计（point estimation）上设置先验，可能存在被滥用的风险。而关于置信区间（confidence interval）的先验则有意义，可以避免过度上线数据。

5.  **序贯检验（Sequential Testing）：** 这是减少错误发现率（False Discovery Rate, FDR）的关键。上线一个功能比运行实验的成本高得多。错误上线一个不好的功能危害更大。
    *   **Peeking（偷看数据）：** 在实验过程中频繁查看结果并提前决定上线，会显著提高FDR。
    *   **序贯检验：** 通过一开始提供更宽的置信区间，让结果更难达到统计显著。随着实验进行，置信区间逐渐收窄。实验时长结束后，调整后的置信区间与未调整的会一致。
    *   **核心哲学：** 假设无限次偷看，使调整更保守。实验不应过早上线，但可以尽早终止（abandon early）。当结果显著负向时，可以终止实验。但不必过早庆祝早期正向结果，等待实验结束再做决策。这种保守的序贯检验方法，能系统性地降低FDR。

### 其他测试与总结

此外，还有如Switchback test（轮换实验）、Grid search（网格搜索）、Search interleaving（搜索交错）等测试方法。如果大家感兴趣，欢迎留言，我们有机会再深入探讨。

今天我们讲解了A/B实验的核心价值、体系设计、统计知识以及CUPED、贝叶斯和序贯检验等重要测试。这些内容对于实验数据科学家、产品经理和工程师都非常有价值。