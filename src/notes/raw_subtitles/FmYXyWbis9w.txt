 So, stop me if you've heard this one before.
 Humanity gets better and better technology
 until, one day, while humanity is too busy
 fighting amongst itself to pay attention, the
 machine takes over.
 Then, finally united against a common enemy, a
 group of rebels, bands together to overthrow
 The Machine, could be Skynet from the
 Terminator series, The Machines from the Matrix
 series,
 Ultron from Marvel.
 If you're old like me, it could be WOPR from
 War Games.
 Most of the time, The Machines start by
 triggering a nuclear war, or they're stopped
 from doing
 so at the last minute.
 Now, usually the story starts after the humans
 have already lost.
 Fiction rarely shows us the run up to the
 machines taking over.
 Closest I can think of would be the last couple
 of seasons of the Person of Interest TV series.
 Now, given the current state of discourse about
 ChatGPT, and this video's title, you're
 probably almost certainly expecting me to start
 talking about the dangers of generative AI,
 or AGI, or artificial super intelligence, about
 how we have to act right now to stop AI,
 to prevent the coming war, but I'm about to
 argue that in virtually every way that matters,
 it's far too late to stop The Machine from
 taking over.
 And before you say that ChatGPT hasn't gotten
 that advanced, or it's nowhere near
 taking over, I'm not talking about that.
 I would argue that The Machines took over, for
 at least most practical purposes, more
 than a decade before ChatGPT, and all that sci-fi
 failed to prepare us for it.
 Well, maybe Black Mirror, but only after it was
 already far too late.
 And it wasn't a big war against The Machine.
 It was gradual.
 It is not a centralized, all-knowing self-aware
 super intelligence. The same way that what
 we call The Internet is really a collection of
 computers and networks that are united
 by common protocols,
 The Machine is a collection of a whole bunch of
 interconnected, smaller installations and
 components united by common technological
 features and a set of perverse incentives that
 I'm going to talk about today.
 And it is arguably decided, without deliberately
 intending to,
 most of the major elections in the last 15 or
 so years, it picks which policies do or don't
 get adopted, who gets famous and who gets
 canceled, who exits the EU and who remains
 which products go viral and which get boycotted,
 it even dictates which victims of violence
 become martyrs for cause and which just becomes
 statistics.
 And if that wasn't bad enough, and it's bad,
 modern generative AI is making it worse.
 Fast.
 Really fast.
 And the worst part is that we, the humans, not
 only didn't form an organized resistance,
 but we're ignoring it completely, because it
 tricked us into fighting with each other
 and thinking that we're so in charge and we,
 the human race, better get our act together.
 Cause otherwise we are F-----
 Welcome to the Internet of Bugs.
 My name is Carl.
 I've been a software professional for more than
 35 years now and today I'm going to tell
 you a story about where we are, how we got here
 and how it's about to get a whole lot
 worse unless we do something.
 So I live in the United States where research
 says that we are more polarized as a society
 than any time since the US Civil War in the
 1860s.
 Whether we're on the liberal side or the
 conservative side, most of us have family
members
or friends that either we no longer have
 contact with or that we can only talk to if we
walk
on edge shells and go out of our way to avoid
 any kind of political subject.
 It's made us as a society largely non-functional
 and largely unable to even have substantive
 conversations with each other because, given a
 random selection of Americans, you're likely
 to end up with a group of people that can't
 even agree on basic facts.
 And it's not even that they're going to end up
 in two groups.
 There are a number of issues that divide
 conservatives and a number of issues that
liberals.
divide
 Now, I've read a bunch of books on why we're
 polarized, including this book: Why We're
 Polarized and a bunch of others.
 And I have to say, I don't think I've ever been
 as disappointed and journalist as I am
 over this.
 I don't have time to get into a point-by-point
 breakdown of this literature.
 Just let me tell you what I think they all
 missed because no one has explained or from
 what I've seen even proposed any answer to the
 question: "So why now?"
 Sure, there are issues that divide us.
 But that's always been true.
 If we're more polarized now than any time since
 the Civil War, then that means that
 there's something now that's more impactful
 than anything that existed during the Great
 Depression, whether Vietnam War or Watergate or
 any other period of strife.
 But there's no such issue with these books.
 When people talk about why we're polarized, it's
 a laundry list of reasons ranging from
 inequality, which was a lot worse in the 1920s
 leading up to the Great Depression, but
 polarization
 apparently wasn't.
 The crumbling institutions, the deep state,
 loss of values, 24 by 7 news cycles,
 disinformation
 or social media, or a bunch of other books that
 I could pull out.
 And that is to even include the ones that I've
 only read electronically.
 Now, all those factors are bad, but they're all
 just small pieces of the picture.
 Then I haven't found anyone who has tied them
 all together into a coherent narrative,
 even though the underlying structure seems
 pretty clear to me from where I'm sitting.
 The Machine is what ties it all together.
 It both provides the tools that are being used
 to isolate us from each other, and at
 the same time, it pays the unscrupulous humans
 among us to do just that.
 Unlike the Civil War, the polarization now isn't
 a side effect of a cultural divide
 over a particular issue.
 The opposite in fact, the cultural divide over
 a bunch of issues is a result of the
 polarization,
 and the polarization is being created
 deliberately because the more polarized we get,
 the more
 money they make.
 The story of The Machine, as I said earlier,
 does not begin with ChatGPT.
 It actually starts in the 1950s, more than 20
 years before I was born.
 The best source I found about the humble
 origins of The Machine is this book: "Selling
 the American people: Advertising Optimization,
 and the Origins of AdTech".
 It's released under a Creative Commons license,
 and the content is available for free from
 MIT Press.
 Link below.
 It's not the easiest book for a casual reader,
 as it appears to be done life as a PhD
 dissertation,
 but it's incredibly well researched, and its bibliography
 was a jumping off point for
 a bunch of other stuff I had to read to
 understand the background of what happened
 before I got
 involved in all this.
 I've also linked a YouTube video of the author
 giving a presentation about the book, and that
 video is a lot more approachable for people who
 haven't spent as many years reading academic
 papers as I have.
 What started in the 50s was something called
 the Nielsen ratings, which is a feedback loop
 between what content was being produced and
 what people were watching it, where the content
 at the time would have been TV and radio
 broadcasts.
 So instead of knowing more people bought the
 newspaper today than yesterday or last week,
 they now move down to the individual show, and
 they knew more or less the age ranges
 of the people who were watching or listening to
 each show.
 And as more and more shows were produced, and
 the industry collected more and more data
 about who was watching them, it required more
 sophisticated information technology to keep
 track of all of it, and that's where, albeit in
 a really primitive incarnation, The Machine
 was born.
 And as The Machine collected that information,
 it was being put to other purposes.
 The list of advertising firms and other players
 in selling the American people who figured
 out how to collect and understand the data has
 quite a bit of overlap with the list of
 firms and other players in this book: "Golden
 Holocaust", which is all about how, around
 the same time frame, the tobacco industry, with
 the help of the advertising and public
 relations experts, lied and manipulated the
 public to push more addictive cigarettes on
 the population and made tons of money in the
 process and sent countless numbers of lung
 cancer patients early graves.
 The learning from the one enabled the other.
 Fast forward to the 1980s to the birth of the
 24-hour news channels.
 Now news was also competing for ratings and
 therefore advertising dollars.
 Sensational journalism had always sold
 newspapers, but now, by having shows with
 different personalities
 and different takes on current events, figuring
 out how to tailor the news content to attract
 more viewers was getting easier and more
 lucrative, and The Machine grew bigger, this
 time facilitating,
 among other things,
 the US invasion of Iraq under false pretenses
 which left countless numbers of Iraqi civilians
 said in its wake.
 Fast forward again, now to analytics and
 advertising on the web that tracked exactly
 what web
 pages were seen by exactly what people, and
 built up profiles of those people so that
 knew who was reading what, and now it was
 possible to know not only what sites people
 were watching, but exactly which stories people
 were paying attention to and exactly
 what kinds of people were paying attention to
 them.
 Around this time, I was working at a startup
 here in Austin that provided comments and
 ratings and engagement tracking on stories at
 websites from USAToday to San Francisco
 Chronicle to Better Homes and Gardens.
 There, not realizing the consequences, I made
 some of my personal contributions to
 the technology that made up The Machine, but
 unfortunately, it wasn't the last time in
 my career I would do so.
 This is around the timeline where "Selling the
 American People" ends and "The Age of
 Surveillance
 Capitalism" picks up.
 I'm guessing you have an idea of what happened
 next.
 It was social media and the smartphone.
 Now, everything about you could be tracked from
 your shopping habits to your GPS coordinates,
 and that could all be correlated with
 everything that you clicked on.
 More information was being collected and
 processed than ever before, and The Machine
that was
processing all that information was getting
 incredibly sophisticated.
 So much so that there were cases where the
 machine could deduce that a teenage girl was
 pregnant even before her father knew. Link to
 that story below.
 It was a doozey.
 And the more The Machine knows about what
 content draws more attention and traffic, the
better
it can help people predict what new content to
 create to get even more attention and traffic.
 Analytics continued to inform the science of
 psychology and behavioral manipulation.
 Now, in addition to huge expensive PR campaigns,
 like the ones that kept cigarettes everywhere
 long after the science was clear that they were
 killing people, millions of tiny experiments
 could be run every day to see who would read
 what story, who would share what headline,
 and so on.
 The more The Machine knew about people, the
 better it got at predicting and manipulating
 them.
 And the better it got at manipulating people,
 the more effective the ads became, and the
 more money flowed through the system, funding
 The Machine.
 Now, you've probably heard people complain
 about the algorithm as the thing that they
 hated about social media.
 This is the time period where the algorithm was
 created, and it's just another component
 of that machine.
 Now that we've had a very abbreviated version
 of what led us here, let's talk about where
 we actually are.
 And then, *Sigh*, we'll talk about where it looks like
 we're headed.
 So if you're watching this, and I don't need to
 tell you what social media is, and
 I assume you've heard people complaining about
 how social media has damaged public discourse.
 But there's another side of social media that
 people don't see, and it's a critical
 piece of the puzzle.
 Although there's been a lot of talk about how
 the algorithms the social media companies
 train will route people to extreme opinions and
 falsehoods and conspiracy theories to
 increase people's social media time.
 There hasn't been nearly enough discussion of
 the fact that the algorithm doesn't just
 create polarizing content from nowhere.
 All it does is amplify it, and the algorithm
 can't amplify crazy, completely fabricated
 conspiracy theories until somebody posts a
 conspiracy theory in the first place.
 How and why that happens?
 See, that's another real problem.
 Let me give you a peek behind the curtain of
 the creator economy.
 There is an insane amount of advertising money
 up for grabs for the people that can capture
 the attention of the right demographics.
 As with most of the distribution of insane
 amounts of money, the vast majority of the
 money goes to the people at the very top, the
 Mr. Beast's and Joe Rogan's of the world,
 and the vast majority of the people making
 content earn very little or most likely nothing
 at all.
 But unlike a lot of professions, there's
 technically nothing to stop any random creator
 from getting as big as Mr. Beast.
 There aren't as many gatekeepers as there has
 always been before, and so a large fraction
 of those content creators probably want to get
 that big, and far too many of them think
 that they can, and a lot of those are willing
 to do absolutely anything to do so.
 And this created a whole other industry, the
 social media gurus, a number of groups and
 sites where people share or sell techniques for
 trying to get more clicks, more traffic.
 Sometimes this was just "how to troll the most
 people" threads on forums.
 Sometimes it was classes like "how to make
 guaranteed money from social media using this
 proven five-step secret formula" or the ever-present,
 "how to make thousands of dollars
 a month with a faceless AI YouTube channel" grift.
 But more about that one later.
 And the rules are simple.
 There's an insane amount of money that any
 creator can have if only they can get people
 to interact with their content instead of other
 people's content.
 And to go along with the same amount of money,
 there's also an insane amount of analytics
 data available to help content creators figure
 out what content gets used and what doesn't.
 And there are lots of books and literature from
 the 75 years of psychological manipulation
 experimentation that has run through the
 machine since its inception.
 This is a recipe for a disaster. And for
 polarization.
 We didn't realize it was happening, but we have
 built the world's largest experimental
 psychology platform and it is being used to
 manipulate the vast majority of the human
 race and it has been getting better and better
 at manipulating people day after day, month
 after month for 15 or 20 years now.
 And for those of you that insist on saying, "I
 don't care if they try my every move, I
 have nothing to hide."
 Understand that you, just by interacting with
 or avoiding or ignoring certain content,
 are giving the bad guys a ton of information
 that, when combined with enough other people
 to be statistically significant, allows the
 machine to fine tune different messages to
 get better and better at understanding the
 science of manipulating human psychology.
 You might not think it affects you. You might
 insist that you're immune and you never click
 on anything.
 And even if that were true, and let's be honest,
 it probably isn't,
 just by timing how long it takes you to scroll
 past different content, gives them information
 on how much or how little that item caught your
attention.
And if you have a smartwatch or a front-facing
 camera that scans your face and can see facial
 expression and track your eyes or wireless earbuds,
 it's in your pulse, imagine how valuable
 that info is.
 And when combined with measurements taken from
 enough other people, the mountain of data
 they've collected from you and others has been
 weaponized against your fellow humans.
 And just by participating on those platforms,
 we all contribute to that.
 Now, that said, individuals opting out one at a
 time are not going to make enough of
 a dent to matter.
 If this is going to get better, it's going to
 take a concentrated effort, but that'll
 have to be a later video.
 At this point in time, media properties and
 content creators are no longer being rewarded
 for informing or educating or being trusted.
 They're only get rewarded for taking up your
 time so you can look at ads, and the race is
 on to make the most money by getting the most
traffic.
Because you know what they can do with the
 machine once they're getting paid solely based
 on likes and shares and clicks?
 They can just start making things up.
 Create conspiracy theories out of whole clock
 and throw them at different groups of people
 and see if they stick.
 Make up a story that there's a child abduction
 ring located in a basement of a pizzeria in
 Washington, D.C. that doesn't even have a
 basement.
 And if enough people click on the story, cool,
 they make money.
 And they can double down and make up more
 stories about that basement and more stories
 about child abduction rings and see if they can
 make money from that, too.
 And if people don't click on it, they just
 cross that one off the list and make something
 else up.
 Lather and repeat until something works.
 There's been a lot of discourse about ads that
 push political misinformation on social
 media, especially with respect to the Brexit
 referendum in the U.S. presidential elections.
 And intentionally misleading political ads are
 a problem.
 But only during election season which, despite
 how it feels, is only a fraction of the time.
 And without the infrastructure of The Machine,
 those ads wouldn't be able to find the right
 audience.
 Before you get upset at the mention of politics,
 though, I'm not here to tell you whether you
 should be liberal or conservative or what
 stance you'd shake on any of the issues or
 what ads are or aren't misleading.
 This isn't about what issues we're fighting
 about or what side of them people should be
 on.
 It's about how the fighting itself has become
 more important than the actual issues.
 Both sides routinely lie to their supporters.
 Like last year here in the U.S., one side was
 lying about who would pay the tariffs and
 the other side was lying about how healthy and
 mentally capable their elderly candidate
 wasn't.
 And what sad is from that description, either
 lie could apply to either side.
 Now, I'm trying to get you to realize that
 politicians aren't the problem.
 Well, okay, politicians are always a problem,
 but they aren't the worst problem or the
 main problem.
 This goes far beyond politics.
 People's entire identities, values, and worldviews
 are being overridden.
 I've had conversations with members of my
 extended family where there are basically no
 facts related to news or politics that we can
 agree on.
 And I don't mean disagreeing about whether
 something was good or bad or whether we like
 a person or not.
 I mean, we've had entire conversations where
 they've had a list of facts, events &
 statistics
 that they got from their information bubble.
 And I've had a list of facts and events and
 statistics that I got from my information
bubble
on the same topic and their list and my list
 have nothing whatsoever in common.
 There's just no way to have a meaningful
 conversation out of those circumstances.
 You either have to stop talking or you have to
 change the subject.
 It's like "Invasion of the Body Snatchers" was a
 documentary.
 People are going to get mad at me for saying
 this, but the current political crisis, despite
 it being a matter of life and death for many
 people, is not itself the problem.
 If we don't figure out how to resolve our
 societal fragmentation, it's going to be crisis
 after crisis after crisis.
 And anyone who thinks that we become a
 functional society, again, if we could just get
rid of
any particular politician or come to agreement
 on any particular hot button issue is believing
 the lie that The Machine is pushing.
 You see, The Machine doesn't just tell people
 what to believe.
 It also tells them who to hate. Unscrupulous
 content creators run experiments on the other
 side of social media too.
 They make it fake social media users. Bots. Lots
 of them. And they make the bots act the
 way that a certain group of people act
 according to their data.
 They see what pieces of content that their
 competitors are serving to use in that group
 so they can adjust their output accordingly.
 And this has been happening for much, much
 longer than ChatGPT has been around at least
 since 2017.
 And scrupulous content creators don't want
 competitors serving content to people that
 they're targeting because they don't want to
 share ad revenue. See, what they can
 do next.
 When the bots uncover what content is popular
 from the same other stories, they just invent
 stories about why those things are false,
 harmful, even dangerous to children, even,
 and they have their bots reinforce those
 stories.
 They shout from the rooftops of the crap that
 they made up is vitally important for your
 future and the safety of children and the stuff
 that the anyone else made up.
 They say that that's all lies and it's all paid
 for by George Soros or the Koch brothers
 or some other source
 they've cast as a political villain.
 And this is where things get really scary
 because the easiest way for them to convince
 the people to believe that their content is
 true and other content is lies is to get the
 people who are watching their content to
 dislike and distrust and potentially even hate
other
content creators, other news outlets, other
 brands, other narratives, other political
 parties,
 even other family members, pretty much anyone
 and any content outside the information bubble
 that they've been pigeonholed into, which just
 further isolates them so the only "facts"
 they ever see on their feed are intended only
 to enrage them and anything contains "facts"
 outside that bubble they've been conditioned to
 despise and to distrust. And if those people
 as a side effect end up with nonsensical,
 radically false ideas about what's going on in
 politics
 in a way that affects their vote, or they're incited
 to violence on a college campus,
 As far as the people that are making the
 content are concerned, it's just incidental.
 They only care about ad revenue and they will
 do almost anything to make more of it and
 they don't care about any fallout. Understand
 that there are hundreds, or thousands, or maybe
 even tens of thousands of these video, podcast
 and other content creation operations who
 have acquired sophisticated software that they
 are using to track as many different types
 of users as they can and they are trying to find
 and push pieces of content that are optimized
 to attract the attention of each different user
 type they're tracking and also optimize
 to get those users to hate the kinds of content
 from other sources. And I as a content creator
 get inundated with proposals from people who
 want me to pay them to help make my content
 go viral and what I would get for my money is
 their special software and algorithms and
 skills and techniques and yada yada yada and
 those people don't want to sell just to me
 they want to sell to everyone that they can. So,
 now we have another piece of The Machine:
 a few groups of very experienced coders who are
 each building their own software suites
 that track users and make up content to
 optimize for user types and all that other
 stuff that
 I've been talking about and they sell access to
 those tools to a bunch of content creators
 who then use those tools try and get as much of
 each social media networks ad revenue as
 they can and those tools builders are competing
 with each other to be the group that get the
 biggest number of content creators paying them
 for tools even if all or most of the content
 creators competing with each other are all
 paying the same tools company for the same
 set of tools to use against each other 404media
 404media has done a lot of great work exposing
 this, link on that below. Which brings us to the
 one major piece of the puzzle left: where
 we're headed from here. I told you we come back
 to it, and that's ChatGPT and the other
 new AIs that compete with ChatGPT with respect
 to this decade old interconnected network
 of people trying to monopolize social media ad
 dollars, ChatGPT is a new shiny toy they
 are, relatively speaking, just learning what they
 can do with. The biggest uses at the moment
 are generating AI swap like Shrimp Jesus and
 Bread Horse pictures, bots that write inanely
 worried Tweets and Facebook posts, and some faceless
 YouTube channels, but that's not going
 to last long and the better they get it using 
 AIs like ChatGPT and Sora and the cheaper
 and faster those AIs get in general the easier
 will be for them to split us into more groups
 and monopolize more of our attention to collect
 more of the ad revenue. And AIs are powerful
 tools for manipulating humans. We've already
 seen reports of people harming themselves
 after being encouraged by chatbots to do so. I'm
 telling you you only <i>think</i> we're polarized
 now don't forget the generative AI video is
 still in its infancy but it's getting better
 almost by the week. For short heavily compressed
 video clips like you see on social media, soon
 it will become almost impossible to tell real
 footage from a good fake and trust me
 you haven't seen anything yet. Just wait until it
 can create virtual people that can be
 animated
 fast enough to keep up with generative AI
 output in real time with synchronized lip
 movements.
 And, as these new AI data centers get built, the
 bad guys will no longer have to manipulate
 us into small bubble groups but, every bad actor
 will be able to spin up their own dedicated
 AI agent process specifically to monitor
 manipulate and target you, specifically, and each
and
every one of us individually. And that is going
 to be way worse. And all the talk of AI safety
 is just a smokescreen fairy tale distraction.
 Remember the industry telling us that they're
 working on AI safety is the same industry that
 already built this machine and turned
 it loose on us so they can make more money. Do
 you think for a second that they would
 let any hypothetical safety work stand between
 them and doing whatever they can to make
 even more money at our expense? See this book: "Empire
 of AI" if you wanted more information on how
 likely the AI industry is to slow down or stop
 on their own. Now there's a ton of stuff I've
 had to skip over in this video for a length and
 time, like any discussion of the tons of
 discoveries in psychology and psychological
 manipulation that were started in the Mad Men
 era and accelerated as the number of people that
 could be experimented on simultaneously grew
 to Internet scale. How certain educational
 organizations have been built their content
 on foundations built by these bubbles, like the
 ones that make hours long algorithmically
 generated videos into preschool children. The
 data brokers that package up all this data
 and sell up to content creators and advertisers
 and tool makers. And I've had to omit a whole
 bunch of supporting evidence and research
 citations. This video in fact is basically the
"Too Long;
Didn't Read" (TL;DR) version, or what my generation used
 to call the "Cliff Notes" version of a much
 more detailed book about this stuff. Now I can't
 give you a link to that book, and I'm
 not surprised you haven't read it because I
 haven't finished writing yet. But I'm making
 this video now anyway, because the further I get
 into this, and the more research I do, and
 the more I see how this is affecting the world
 that I and my family are living in, the less
 I'm willing to wait until I'm done writing to
 go public. And if the feedback from this video
 lights a fire under me to finish and/or gives
 me information that I didn't have, relevant
 sources that I haven't found, or things I need
 to clarify, then so much the better. It's time
 for us to start forming that scrappy group of
 rebels the sci-fi shows always have fighting
 back against The Machine. But it has to be done
 in such a way that the different anti-machine
 groups don't end up fighting each other. And
 that's the hard part because The Machine's
 greatest defense is having made us almost
 incapable of working together against it. It's
like the
biblical story of The Tower of Babel, if the God
 in the story was an evil machine and it
 gave everyone different worldviews instead of
 different languages. There's a huge amount
 of work we're all going to have to do to get
 out of this nightmare, but from what I can
 tell, the only place that it can start is by
 talking across the bubbles. My only hope is
 that maybe enough of us can hate The Machine
 more than we hate each other. So I don't think
 there's any way that the people that are sure
 that the 2020 election was stolen by Joe Biden
 but that the 2024 election was free and fair,
 are going to join hands and sing "Kumbaya" in
 a big circle with the people that are sure that
 the 2020 election was fair but that the
 2024 election was stolen by Donald Trump. But I
 think-I hope-that there can be some common
 ground. I hope that a lot of us from across a
 large number of different information bubbles
 can join together, not in admitting our own
 incorrect beliefs, and not in apologizing to
 those on the other side of the aisle-that's way
 too much to ask right now-but rather to join
 together in hating the common enemy of the
 ShrimpJesus Slop-posting conspiracy-creating
 scumbags of the world, and the people that turn
 every new story into an "us versus them"
 loyalty test, and the tool writers who make the
 software that automates more content bots
 and polarizes us so they can extract more ad
 money. So here's your action item: engage
 with those people in your life that you can't
 agree with, and respond to their garbage memes
 and hateful rhetoric, but do not contradict them,
 and do not argue with their core beliefs. Ask
 them questions about their priorities, and try
 to be sincere, Ask questions like: "With all
 that's going on, is what you're talking about
 here really the most important thing to you
 right now" "Is this really what's directly
 affecting your life the most?" "If not, where
 did you get the idea that this is the thing you
 should be talking about right now?" "Why
 do you think they wanted you to think about
 this?" "Do you think they really have your best
 interests at heart?". Just try to get them
 thinking to start with. Try to plant the seed of
 doubt
 about the motives behind the information that
 they're being fed. It's just a start, but at
 least it's something. Hopefully redirecting them
 to thinking about who is feeding them this
 information will help. I can tell you from
 personal experience with some of my extended
 family,
 that if you can change the subject from their
 conspiracy theories and group-think talking
 points to "Who was that told you this was
 priority one and what do you think they're
 trying to keep you from thinking about instead?"
 Then you can at least have much less confrontational
 conversations. It's so much more pleasant than
 trying to argue with them or just biting your
 tongue and trying to say nothing. I know a lot
 of you will find it unpleasant, but here's
 the realityi: as long as we're fighting amongst
 ourselves we can't fight The Machine
 effectively.
 Now, is that going to work? Can we agree that
 there's a greater evil and join forces across
 bubbles to fight it? I don't have any idea, but
 from where I'm sitting, if we can't agree
 that the people manipulating all of us are bad
 then I can't imagine anything we <i>could</i>
 agree on. So maybe that's a start. Maybe this
 might work. And maybe we can find shared cause
 and start digging ourselves out of this
 misinformation nightmare. And maybe we can do
 that before
 AI gets fully weaponized against us and becomes
 that much harder. Or maybe, just maybe, we're
 We're all just F------------