Hello 大家好
欢迎收听硅谷101
我是泓君
最近我看到哈佛大学经济学家
Jason Furman（杰森·弗曼）
他的一个研究数据很有意思
他是说在2025年的上半年
整个美国GDP的增长
几乎会全部来自于
人工智能的基础设施建设
如果说我们把信息技术
还有软件这一部分拿掉
那美国GDP的增长
仅仅就只有0.1%
最近还有一个大新闻
大家可能都看到了
OpenAI发公告说
它自己完成了一个公司架构的重组
而这个重组的目的
是为潜在的IPO铺路
核心也是说
它未来会承诺1.4万亿美元
在整个AI的基础设施的建设上
还有一个消息
大家可能没有注意到
就是在它完成架构调整的前一天
它发了一封公开信致信白宫
在这封公开信里面OpenAI提到
中国2024年
新增的电力是429吉瓦
而美国仅仅贡献了51吉瓦
所以它希望美国政府
对AI基础设施的建设项目
能够优先审批
为什么这些公司都那么激进
最根本的一点是因为
大部分公司现在都意识到一点就是
on Underinvestment is riskier
than over investment.
就是所谓的投资不够
给你带来的风险
要远远大于
你过度投资带给你的风险
对 因为没有人想当诺基亚
在之前我听到OpenAI这个
5000亿美元的星际之门项目
就已经觉得非常夸张了
但现在这个饼
已经是画到了1.4万亿美元
而美国也需要基础设施的建设
这是一个比想象中更加疯狂的
大基建时代
美国极少数的科技公司
联合金融巨头
正在不成比例地对美国经济
产生决定性的影响
我们先抛开钱从哪里来的问题
我们这一集就来看一看
这一轮AI大基建
它带火了哪些行业
而为何美国的电力建设
又如此得困难
下面就请收听我们今天的节目
今天我们来聊一聊
AI军备竞赛背后
数据中心与能源之争
今天跟我们在一起的嘉宾
一位是Ethan徐
Ethan现在是在字节跳动
做数据中心与能源的项目经理
大家好
Ethan在去字节之前
是在微软负责
数据中心跟能源的项目
再之前是在Bill Gates下面的
突破能源基金
没错 也是做了很长时间的
能源相关的项目
也是在两年前AI大爆发之后
加入到了数据中心和能源
在一起的赛道吧 算是
那还有一位是王辰晟
王辰晟之前是特斯拉的供应链总监
马上也要加入xAI
大家好
如果让大家总结一下
就是现在我们看所有的AI巨头
都在去做数据中心
你们觉得哪几家做得最猛
当然新闻报道上是OpenAI跟微软
5000亿Stargate项目
第二个是最近OpenAI跟甲骨文
也是在合作一个3000亿美元的
数据中心的项目
当然这个中间是有重合的
但我知道其实马斯克他的xAI
在布局数据中心跟抢货方面
也是非常猛的
扎克伯格也是在全力投入的
所以从你们的角度来看
你们觉得哪些公司最激进
以及他们的策略是什么
OpenAI他的野心是非常非常大的
现在他公布出来的数据是
要做10个吉瓦的Stargate的项目
我觉得这可能只是一个刚刚的开始
他的野心可能是这个的10倍
甚至更多
在未来的比如说5-10年
他们想实现的一个目标
十倍 5万亿的一个产业
我觉得这个数量级
是基本上没有问题的
美国现在的GDP是多少
二十几（万亿美元）是吧
差不多它这个就要占GDP的
当然也不是一年
对 整体上占一年
整个美国GDP的25%了
我觉得是很高的
我们可以拭目以待
看一看今年美国的GDP增长当中
有多少是数据中心基础建设贡献的
我觉得这个比例有可能会到70%
我也不会很吃惊的
你有可能低估了
甚至有可能低估 对
我也看过一些黄仁勋
或者是一些咨询公司的观点
他们也认为在未来的五年
整个的数据中心
基础设施建设的投资规模
应该是到5-7个万亿这个级别的
钱从哪来
钱从哪来
确实是一个很有意思的问题
我记得你们之前做过一期节目
就是讲钱从互相之间的循环经济的
AI资本论循环
未来也是一种比较创新的融资方式
辰晟怎么看
哪一家最激进
OpenAI肯定是相对比较激进的
因为你看它现在很多公告
它未来几年跟英伟达
有一个10吉瓦的意向
AMD有一个6吉瓦的意向
同时最近还有博通
还有一个10吉瓦的意向
所以加起来就已经是26吉瓦
500亿一个吉瓦
就已经是一个1.5万亿的一个概念了
未来五年
对
同时它在一些供应链上
它也非常激进地做其他一些布局
最近有跟三星和海力士
包了一个90万片晶圆每月的产能
它基本上占了整个DRAM
就是市场可能1/3
HBM市场60%
就它一家
如果你是马斯克或者你是小扎
你看到这个你会怎么去应对
因为你也不希望被他们卡脖子
所以每一个公司
现在从供应链角度
可能做得都不一样
马斯克xAI去横扫了
所有的小型的涡轮的发电机
Meta其实过去几年来说
就已经做得非常激进
去各种买一些能源
相对成本比较低的地
去建它的数据中心
最近是在爱达荷州还是俄亥俄州
又一个5吉瓦去上线
它的规模基本能占大半个曼哈顿
谷歌它也会做一些供应链上的布局
比方说把他们一些
无论是互联也好
一些光缆也好
他们都会做非常激进的
供应链上的产能的买断
所以说其实每个巨头都在发力
都不想在这个竞争当中
去输人一头
微软我们好像没有提到
微软的话其实也蛮有意思的
它去年的时候跟OpenAI的合作关系
是非常融洽的
但是在年初的时候
大家也看到一些新闻
提到关于OpenAI和微软的关系
已经有了一些变化
包括OpenAI开始去找Oracle
或者其他公司合作建数据中心
所以微软不是它唯一的
数据中心提供商了
同时微软可能也在某一些数据中心
开始暂停施工
或者是退租了一些数据中心等等
我们在看最近这几个月的发展
能够感觉到
微软在数据中心投资这方面
是和其他公司比
是相对比较稳健一些的
OpenAI就完全是另外一种风格
都是每一两个星期
就会有一个非常大的公告
说我要建5个吉瓦
7个吉瓦的数据中心
和普通的公司合作
和整个产业链合作
所以能看出这两个公司
可能在AI数据中心
或者整个数据中心行业的
投资和策略方面
会有一些不同了已经
对 所以就是说
微软中间稍微缓慢了一点
最近又在加速
对 现在能看得到
微软比如说最近刚刚宣布了一个
全世界最大之一的
AI的数据中心刚刚落成
所以今天看到的微软
可能跟年初的时候看到的微软
可能又有一些不一样的变化
我觉得这个行业的变化
确实还是蛮快的
可能年初的时候我记得微软的CEO
也在公开的采访中提到过
他觉得这个行业
是有一些过度建设的
然后他觉得有一些泡沫
他是想用更稳健的方式
去建设数据中心的
但是我们现在看到的是
微软速度也蛮快的
可能并没有像年初的时候说的那样
很快地慢下来
所以我猜想也许各个公司的高层
在这一年过程中
他们的策略和想法上
是有一些波动的
但是此时此刻的话能感觉到
所有人都基本上是全速前进了
我觉得几个巨头
包括Google 亚马逊和微软
他们的态度可能是因为
他们过去在云上其实有很多的
这个data center的投入了
像Google Microsoft他们现在
已经有的data center
可能已经超过10个吉瓦
对于像OpenAI
就从0开始发展的话
大家需要的增长速度是不一样的
因为它的基数不同
反馈出来他们的激进程度
可能也会有不同的地方
这个点很关键
这是为什么
我们现在经常听到的名字
是Meta xAI还有OpenAI
而不是这些云厂商的巨头
像Google 亚马逊和微软
我们刚刚其实提到了OpenAI
它其实在做Stargate的项目在抢地
在跟芯片厂商去达成合作
马斯克其实也是在抢发电机
Meta也在抢地
我是在想
那你的芯片供应其实也就这么多
大家不会在某种程度上
是都有短缺的吗
从纯产业链的产能来讲的话
芯片现在并没有像能源
这么紧缺的一个状态
如果你每一片（芯片）
把它用到刀刃上
从台积电的产能
它也是在积极地去布局
所以它相对是比较充足的
包括像台积电
可能两年之前有在说
CoWoS它的先进封装的产能
会有些落后
但是它最近也在说
在亚利桑那州要建两个晶圆厂
其实这些产能已经在过去两年
经历这个cycle的时候
他们已经有在去做投资了
我只能相信老黄
他的直接声明是对的
在GPU的芯片的供应上
肯定是不缺的
但是可能会有一些
别的配套的产业上面
会有一些额外的缺口
包括我刚刚提到的存储器
无论是说线束也好
甚至于一些数据机柜
但是可能这个缺口相比能源来说
它并没有那么大
我觉得这点可以补充一下
像我能看到的一个比较重要的
几个策略上的观点
一个观点就是
我们刚才一直在聊的
所谓的电力优先
或者是power first这个策略
因为大家都已经明显看到
可能最缺的就是电
谁能拿到电
就意味着你能买更多的GPU
你就更有可能训练出更好的模型
你就可能获得更多的用户
更好的用户体验
从而占据更大的市场份额
而这样的市场份额
可能会给你带来更多的营收和利润
然后又可以再次循环到
我拿这些营收和利润
去买更多的电和地
继续让我的模型变得更好
所以Power First这个策略
在很多大型公司里边
是一个非常重要的策略
还有另外一个策略是
大家都考虑到的
就为什么这些公司都那么激进
最根本的一点是因为
大部分公司现在都意识到一点
Underinvestment is riskier
than over investment
就是所谓的投资不够
给你带来的风险
要远远大于你过度投资
带给你的风险
为什么会这样呢
像AI这个行业
大家目前可能有一个大致的共识
就是很有可能谁最先获得
最好的AI模型
或者所谓的AGI的话
这家公司就会占据比较大的
一个市场份额
其他公司的生存空间
就会很快地缩小
所以投资不够的一个风险
是非常大的
我们再看一下
过度投资会有什么样的风险
你无非就是买了更多的地
更多的电 更多的房子建数据中心
最后你发现可能你买多了
无非就是你可以把它用作
自己公司内部的一些使用
效率的提升
或者你可以把它租给其他人
或者就把这些地 电
卖给其他公司
总体来说就是过度投资的风险
它实际上是有一个封顶的
因为它其实都是固定资产
然后这些固定资产你转卖
它也是容易的
也是容易的
比如说GPU你买多了
那你卖给其他公司也没有什么问题
所以它过度投资的风险
相对来说是比较小的
而对于某些大的科技公司来说
如果投资不够
导致它没有在这场竞争中胜出的话
它有可能面对的是一个
生死存亡的一个境地
所以这也是为什么绝大部分公司
他宁愿多投资
哪怕华尔街现在已经有一些质疑了
是不是过度投资了
你们能不能收得回利润来
这个营收
能不能覆盖住你们这个投资
甚至股价上也开始反映出来了
但是这些公司
我觉得现在都没有一个眨眼睛的
都是继续在加大投资
像所有公司今天说的话都是
我们年初的时候
预算今年会投资这么大的规模
已经很震惊市场了
但是现在看起来我们还是投资的
没有我们应该投资的那么多
所以这也是
投资不足比投资过度风险更大的
这个策略
对 因为没有人想当诺基亚
你跟股东说我4万亿的市值
会变成3万亿的市值好呢
还是说我的4万亿的市值会变成0
然后你更多是说有个梦想说
我现在投资
如果我经历过这一场退潮
然后我活下来其他人死掉了
我就从4万亿可以变成10万亿
这是大家更喜欢听到的一个故事
不代表它就一定会发生
还有一点
在硅谷有一句话就是
比尔总会吃掉安迪
Andy是代表Andy Grove
英特尔的一届CEO
Bill是比尔·盖茨
所以就是说你只要有基础设施
你只要有硬件
软件总有些办法可以想办法
把你（的资源）运用掉的
这周早些时候OCP
Meta的人就在里面说
其实他们目前的GPU
光用来去做他们内部一些AI
比方说Instagram或者Facebook
然后去筛除一些不合适的这些内容
他们其实也已经要需要很多算力了
他就算有多余的闲置的算力
他用来做内部的降本
cost reduction
他其实也是完全是可以用的
所以我觉得现在主流的这些公司
都不会担心说
这些会过度投资
然后他们没有办法去用掉
而更多的是说
我怎么把我有的这些资源
去做更好的配置
去扩大他的利润和收入
我可以稍微补充一下
Ethan刚刚讲的一点
就是为什么大家要建大的数据中心
有两笔账
一笔就是经济账
Google自己也有发布过说
我在爱荷华州去建一个
1吉瓦的AI data center
比同样分布式的
它一年可以省5亿美金的运营成本
因为它更加高效
无论是从输电 冷却 运营来说
这是Google一年在1吉瓦的
这个数据中心可以省5个亿美金
同时从一个AI算力的
训练的这个角度来讲
比方说GPT-4
按照以前一张H100的卡
需要差不多16000张卡
90天的时间去做这样一个
1.7万亿的数据量的模型的训练
如果到GPT-4.5
它可能是10的26次方
它需要的可能是一个两三倍的卡
甚至于说一个GB200
25000张卡也需要90-120天去计算
在这样一个AI军备竞赛的前提下
你肯定是不希望
你需要花一个季度甚至以上
3-4个月才能训练出一个模型
你更加希望的是
你每一周或者每两周
可以去有一个模型
然后你不停地去进步
不停地去迭代
所以它会造成了一个
指数级别（的需求）
所以从一个万卡集群
变成十万卡集群
甚至到百万卡集群
而且你可能需要训练
更大的一些数据模型的体量
这样就会把整个
AI data center的算力
从以前一个30兆瓦的
AI data center
推到一个可能1吉瓦
甚至于5吉瓦的
这样一个data center的体量
因为大家都不想输
那我再问一个更底层一点的问题
大家为什么需要
建这么大的数据中心
我知道大数据中心
跟小数据中心是一个问题
还有一个更底层的问题是
你们觉得这个数据中心
未来用的更多的
是做这个模型的训练
还是用作应用方向
就是说我们还需要
这么大规模的预训练的电量吗
还是说它只是说大家都开始用AI
代替日常的这种搜索
代替日常的这种应用
它的整个的产业规模会很大
就是这个数据中心是支持谁的
两年之前的话
大家主要可能有60%-70%算力
是用于做预训练的
当然预训练也有它自己的瓶颈
包括现在有很多不一样的
工程上的（优化）
无论是从有专家的模型
包括说有一些训练后
去做强化学习的
这些都是一些厂商觉得
怎么样提高这个模型的效率
而从预训练转换成一个
后训练的过程
同时因为这本经济账
大家要确保我有收入
训练是不能给你带来收入的
而一定要从应用
或者订阅交的会费
才能给你带来收入
所以大家现在所有的大厂
都是转型到了
把更多的资源用到推理上
今年早些时候
推理和训练的比例
已经转成推理会占比更高
可能有六成
训练是四成
我的理解是
它之后可能推理的比例会大大增高
甚至占到80%以上
所以我理解现在的数据中心
是给这些AI厂商做推理来用的
我基本上同意这个观点的
就是在未来的话
一定是推理和应用
那方面的数据中心的利用
或者是能源的利用
那个一定是会占比越来越高
而且是占大头的
但是当然了
AI的训练它是需要不断地去迭代的
会有更好的模型出来
所以那个一定也会有一定的占比的
但是很高兴看到
推理的占比越高
意味着它越来越多的
在应用层面开始创造出价值
就像微软CEO之前说的
AI只有在真正创造GDP的时候
才是有价值的时候
那个也是真正关键的时候
所以根据你刚刚的观点
就是现在大公司他们如果激进
他们可能留下的是一堆的固定资产
如果往回撤的话
那他未来可能他要发展
所有这些AI应用
他后面的算力跟不上
整体大逻辑是这样子的
对的 是这个逻辑
那我们一定需要
这种大的数据中心吗
小的数据中心行不行
就是我们零散地把一些
我假设就是居民用电的
这些闲置的电集中起来
然后再做储能
再分配给各个应用或者大厂
这种方式是有可能的吗
它有一个基础
如果是做训练的话
它其实这个规模可能不太允许
它去做这样的一些调整
因为它需要所有的data
再同时进行计算
需要机柜和机柜之间的互联
所以它需要一个大的集群
但是如果去做推理的话
它其实是可以根据用户的需求
去进行一个合理的配置
然后用现在的闲置的算力
或者电力去做的
这个有点像以前PPTV
或者说类似于这样的一些产品
确实现在也有一些公司
在用闲置的算力去做
比方说novita
它是一个新兴公司
更多的就是用闲置的这些算力
提供一个更低成本的算力
相比别的供应商
可是你作为一个大厂的话
你更多的是说
要去算一笔经济账
无论是说我用户需求的时候
我是不是它一直有可用性
它一直能去调用这些算力资源
同时如果是分散的话
它的管理物流各方面
它其实是没有效率的
包括我刚刚也提到
如果它有个大的规模集群
它又可以用来做训练
等到不需要训练的时候
把这些用来去做推理的话
其实这个经济账是更容易算的
因为它能更好地去做
整个电力的分布
以及它的一些备电的备份
甚至于说冷却当中的这些运营成本
它都是可以大大降低的
没错 我也非常赞同
可能要看具体的应用是什么
它可能会决定
对数据中心的要求是什么样的
举一个例子
现在大家也有一个初步的共识
就是对于AI的训练来说
也许这样的数据中心
并不需要离大城市太近
也不需要可靠性太高
因为可靠性不高的后果
无非就是影响了一下
你公司内部的一些
研究人员的进度
一些AI的云厂商
如果他要提供给第三方客户的话
他的可靠性可能需要达到
所谓的5个9这样的可靠性
就是99.999%的可靠性
但是对于AI的训练来说
也许不需要达到那么高
也许3个9
99.9%就可以了
而这些AI的数据中心
又需要很多能源
所以也许它可以建在
离能源更接近的地方
就比如说OpenAI他们这个策略
我觉得就是非常好的策略
他们是把他们的Stargate的
很大一部分项目
放到了德州的西部
而那是一个又有风又有光
同时还有一定的
电网接入能力的地方
而且还有大量的地
这就非常适合做AI的训练了
所以它并不是所有的数据中心
都需要和客户离得那么近
所以这个时候
在资源非常紧缺的情况下
可能就可以根据你的应用的不一样
去看你的数据中心要建在哪个地方
去实现什么样的目标
数据中心首先我们说
它需要有电
其次它还需要有发电机
跟各种各样的小型的
我们可能想不到的设备
比如说变压器
还有一层
就是它需要有芯片
这三个问题怎么解决
我觉得我们今天可以
一个一个地来分析一下
首先是数据中心
现在的电从哪来
Ethan我记得你之前
其实在我们节目上讲过
整个美国的电
它是处在一个比较稳定的增长状态
但从今年的数据来看
还是这个样子吗
我记得在上周
黄仁勋和一个CNBC的采访中
他也提到
它可以生产出
整个市场所需要的GPU没有问题
但是现在最大问题是没有电
你有了GPU你没有电
你也没办法去运行你的数据中心
在过去的20年
美国的整个电力系统的发展
是非常地缓慢的
它几乎是以每年低于1%的增速
在慢慢地扩张自己的电力系统
这和中国几乎百分之五六七
这样的年增速是完全没有办法比的
美国过去20年的GDP
或者是经济的发展
和它的电力系统的发展
几乎是脱钩的
这也导致一个问题
哪怕你现在开始加倍你的增长速度
那也只是2%而已
所以这个增长速度是远远跟不上
数据中心的高速增长速度的
美国的新增电力的负载当中
我们估计
数据中心可能就会占到40%左右
剩下的60%
可能是电动车的增长或者是
生产制造业的回流到美国等等
但是这个也是要看
经济发展的状态的
还有一个数据可以分享的是
像有一些机构他们预估出来是
美国每年应该需要增加
大概80个吉瓦的发电量
才能够大概地满足美国的数据中心
电动车和生产制造业的回流到美国
这样的一个增长的需求
但是目前来说
美国每年的发电量增长
可能只有50多到60左右这个水平
也就是说
每年可能美国面临的是
大概20个吉瓦的发电量的
一个巨大的缺口
如果保持这样的缺口的话
未来5年左右
很可能美国将会面临一个
大概100个吉瓦的发电量的缺口
因为今天的话
美国的总发电量
大概是在1300个吉瓦
所以这个缺口占的比重
也是非常大的
20个吉瓦是一个什么概念
比如说一整个纽约市
或者旧金山的发电量
会有20个吉瓦吗
这个是很好的问题
像纽约的话
它的平均用电量
大概是在6个吉瓦左右
它每年的峰值
可能是在十一二个吉瓦左右
所以如果说是
差20个吉瓦的缺口的话
那这个缺口可能就相当于
可能2-3个纽约的发电量的水平
但现在我们说
居民用电跟工业用电都要保证
AI的数据中心也得建
因为它用户数一直在增长的
所以现在缺的这部分电从哪来
或者说我们拉回到
现在的这个时间点
现在对于AI来说大家缺多少电
我们预估出来
可能今年数据中心
可能会新增大概8个吉瓦的
新增的用电量
这个电从哪里来
美国过去几十年的电网建设中
它有一些余量
还有一个就是
像GE这样的公司
也在大量地制造和出售
自己的天然气发电站
还有一些清洁能源
也有一些研究机构预测
像新增的这些发电
可能60%会需要靠天然气发电站
40%左右可能是需要靠光伏
风能和储能这些来弥补
当然我们希望未来
像核能能够尽快地
成为一个新的主力
现在美国的发电当中
大概20%的发电是来自于核能
但这些都是属于过去几十年
一直存在的存量核能吧
像新增核能这一块的话
我们可能还要等到
比如说2028年左右
才会看到新增的核能上线
像一些新的核能技术
比如说小型或者微型核反应堆
像SMR这样的技术
我个人估计
可能还要等到2030年左右
才会真正地成为主力
我看最近Sam Altman
他投了一家公司
他们是做小型的核裂变的反应堆的
股价也是涨得很厉害
这家公司叫Oklo
它这个股价确实涨得是
非常的疯狂的
但是我也没有想到
它在短短的几个月之内
就能上涨那么快
我觉得这应该更多的
不是反映基本面
而是反映市场对它的期待和情绪
而不是它技术本身基本面
在突飞猛进
或者是施工运营方面在突飞猛进吧
所以这家公司
它现在是已经实际用于发电了吗
还是并没有
现在还并没有
我记得有一次
开一个能源和AI相关的会的时候
Oklo的一个高管
他跟我们观众说的是
他预计最理想的情况
可能是2027年
能够开始实现商业运营
但是据我过去对核能行业的理解
其实核能是一个
难度非常大的一个行业
跟软件行业跟IT行业
是不可同日而语的
所以我觉得这个日期
可能是比较乐观的
但是考虑到美国过去几十年
核能这个行业基本上没有怎么动过
很多人才也去转行做了其他行业
很多地方可以说是断档的
所以如果要很快地
把核能能够开始进行
规模化的商业运营的话
我觉得这个时间
可能没有那么的乐观吧
我补充一点
美国一年增加
五十几吉瓦时的发电量
但是更多其实它的组成当中
如果是按照火力发电
它的组成其实不到5吉瓦
所以更多的是
大概有差不多45吉瓦是太阳能
另外5吉瓦可能是风能
这些发电都是不可持续的
它会有一个根据日照
根据天气的变化
所以它实际真的有效的发电量
可能一年就不足20-25吉瓦
我觉得这个是更加
去增加一个缺口的
算一笔账
我们按照DataCenter的
数据中心的投资
老黄有一个数据
就是500亿1吉瓦
所以它整体的话
如果真的有60吉瓦
那它就是一个3万亿资本的投入
但是目前来说
所有的大公司
预计明年的投入量
基本上在1万亿不到一点
所以从整的发电的量来说
只看这个数字
我觉得它更多
没有到一个这么缺的一个状态
如果把美国GDP的增长
全部归功于
AI数据中心的增长来说
因为它可能在电网里
还有一些余量可以去使用
你说的很对
如果是太阳能的一个吉瓦
和一个天然气的一个吉瓦
其实是不一样的概念的
因为太阳能的话
只有在有阳光的时候你才能发电
所以还有一个概念
叫做容量系数
你的平均发电
大概是你的峰值的多少
像太阳能的话
可能只有25%左右
也就是说1吉瓦的太阳能的容量
最后发出来的电的话
平均下来
可能只有1吉瓦的25%左右
但是如果是核电发电的话
就完全不一样
因为核能的话
它可以几乎全年一直都是在
它的峰值发电
只有偶尔它需要维修保养的时候
才会需要把发电站暂时停一下
所以它的那个容量系数
可能已经达到了93%左右
而天然气的话也很高
它在常年运行的历史数据
可能会达到85%左右
所以不同的发电的技术
虽然是同样的Gigawatt
但是它实际的发电量是不太一样的
所以你刚刚说的那个80吉瓦
一年的需求是指
一个混合的数据吗
就是混合起来看
如果我们有一部分的天然气发电站
有一部分的光伏发电站
和风能发电站
所有的这些吉瓦加起来
可能会在80个吉瓦左右
但是我又听说美国的电网
是相对比较脆弱的
这个Ethan 不知道
你能不能多介绍一下
美国的电力系统
确实是有很大的问题的
我们一直在关注发电这个点
但是稍微有一点片面
因为数据中心需要的电的话
它其实是通过整个电力系统
来获得电的
而不只是通过一个发电机
一个电厂来获得电的
所以我们要看的是
从发电到输电到配电
整个产业链
都得形成一个有效的系统
才能够给居民 工业
或者是数据中心以足够的电
当然这里边最重要的一块
确实就是发电
发电大概是占整个电力系统投资的
大概50%左右
输电的话大概会占到
百分之十几到二十左右
然后配电的话
大概是占到20%-30%左右
这个输电网的发展
在过去也是非常缓慢的
理想状况下
如果这些电站
都能进入到美国电网里边
那么数据中心的供电是没有问题的
但问题就在于
电网本身连吸纳这些新的发电站
都能力不足
再并入到新的数据中心的时候
也会有很大的问题
刚刚辰晟有一个数据
你是说60个吉瓦
差不多背后是3万亿的资金支持
所以反推
OpenAI的Stargate
如果说是5000亿的一个项目
它可能就能建成10个吉瓦的电
然后这10个吉瓦
是现在在Stargate的一个规划中吗
如果说我们不管什么方式
就把这个电建成了
它是不是按照Ethan你刚刚的说法
它输入到这个电网
它可能也是有阻力跟难度的
没错
现在我们了解到的Stargate
它目前的目标是
能够建到10个吉瓦
现在可能已经签约和宣布了
这些大概有个7个吉瓦左右
这些都还只是签约和意向
真正要到电网里边
应该还会有一些阻力
就比如说它需要在很多地方
找到现存的容量
对于这么大的一个体量的话
很显然
OpenAI或者它的合作的伙伴
像Oracle
他们需要想办法
去创造新的容量在电网上
现在的很多科技公司
他得自己去建发电机 建发电站
变电站和一些配网的设施
甚至建一些稍微短一点的
电力传输线等等
去满足自己的需求
因为电力公司
已经完全跟不上他们的需求了
我们刚刚提到了
输电是一块问题
建电网跟发电
可能就是一个更大的问题了
我注意到其实
不管是OpenAI的Stargate的项目
还是马斯克的xAI的项目
其实大家现在用的基本上还是说
燃气涡轮机的方式去建电网
但是这一块
辰晟你可能比较了解
涡轮机现在它的供应链
是一个怎样的情况
它是不是也是一个比较短缺的物品
对 因为它本身的产能
完全是不足的
因为你可以去看
包括GE Vernova的财报
它过去10年吧
它的增长其实是非常平缓的
到峰值的时候
可能是2019年 2020年的时候
大概到七十几台一年
每一台大概在30-50兆瓦
我们做一个对比
涡轮的发电机
其实和我们的飞机引擎就非常像
一年大概有将近4000台
飞机引擎下线
而涡轮发电机
市场最大占比的GE Vernova
只有小100台
这是一个数量级的差别
一来是之前的需求没有这么旺盛
二来 之前政府对于可持续能源
零碳排的这些标准
大家对于需要会增加碳排放的行业
其实也没有这么多的投入
因为它相当于是一个夕阳产业
只有在最近
因为有AI数据中心确定的
这样一个背景下
大家才找到了这样一个
短期止损的这样一个方案
而不是说所有的数据中心
现在都愿意去
长期地使用涡轮发电机
更多的是说
如果我并入电网
需要一个两年的许可审批的时间
而我需要数据中心
比方说马斯克需要6个月就上线
那他们一年半的gap
只能使用一些短期的
比方说涡轮发电机的这样一个状态
哪个公司也不一样
比方说xAI
根据公开的信息
它横扫了美国将近70%以上的
燃气涡轮发电机的库存
已经用来给孟菲斯
它两个非常大的数据中心供电
所以70%根据你刚刚一年的产量
差不多就是50多台
不 是存量
存量
所以根据SemiAnalysis
一个博主的分析
如果我没有记错的话
光Colossus 2
它一个数据中心
它基本上有160台的涡轮发电机
在那边给xAI提供发电
我想问一个问题
是不是涡轮发电机
它其实也是分几种类型的
涡轮发电机
比如说像GE的涡轮发电机的话
是几百个兆瓦的这种大规模的
现在可能是不是GE的发电机
我听他们财报说
已经2028年以后
才可能接新的订单了
是不是现在大家就开始买一些
隐形的发电机 是吧
这一部分是不是大家也开始扫货了
对 有一种就是
通过飞机引擎改造的
叫航空衍生燃气轮机
通过一个蒸汽箱
无论是从发热转换以及它的蒸汽
做两个cycle去提高它的燃料效率
做小型的涡轮发动机
比方说Caterpillar
可是它的产能也是一个
需要很长时间去build up的
这样一个过程
当然了
你造十台涡轮发电机
也只抵得上一台300兆瓦的发电机
其实它对于供应链的挑战
还是很大的
所以大的涡轮发电机
它的发电效果是更好的
像你刚刚提到的GE的这种
然后小型的涡轮发电机
它也是可以发电的
只是说它的功率没有那么强
或者它的效率
是比大的涡轮发电机稍微差一点点
对 GE也做小型的
但是大型的更多
只是供给原来的发电站
就像Ethan所说的
它每年美国可能之前
火力发电只有少于5吉瓦
但是我现在需要20吉瓦
它短期供应链
是需要很长的载口去做的
就像你说的
它现在的订单已经排到2028年了
中国可以做吗
中国据我所知
火力发电或者用天然气发电
不是一个非常主流的选项
包括涡轮里面这些叶片
它需要一些专业的合金
这些都是到一个
军工级别的security
中国现在的产业并没有
像美国或者韩国一些工业这么发达
在这一块上
所以我理解其实就是造涡轮发动机
它是一个高技术产业
它并不是一个说
我靠供应链跟制造优势
就可以解决的问题
如果给一定的时间它肯定能解决
但是大家现在是在一个
抢占能源的一个战争当中
所以并没有留给供应链
这么多的时间
对 这个是涡轮发电机的一部分
发电它可能还会有很多的零部件
我记得之前
马斯克有一句话就是说
transformer lead transformer
第一个说的是算法
第二个transformer的意思
就是说变压器
我知道变压器在整个市场上
它也是一个供货周期很长
可能到18-24个月
这样一个非常缺货的产品了
但是它又是在你这个电厂发电中
必须存在的一个环节
是的
先分享一个小故事吧
在大概一年半两年之前
特斯拉还在做Dojo
就是我们自己内部AI training的
这个项目的时候
我们想要在Palo Alto
硅谷的中心去建一个非常小型的
只有十几台training的
这样一个集群
那个时候Palo Alto市政府跟我们说
你们没有电
如果你们需要的话
现在交期已经从3个月
涨到18个月了
当然马斯克的公司最后怎么做
就是我们自己买了两台变压器
然后给Palo Alto市政府装好
然后说我们交付给你
你们让我用
那个时候只是3兆瓦
现在我们动辄是谈3吉瓦
1000倍的差别
变压器这一块
其实它需要的就是一个
基于电磁的原理
从一个高压转化到一个低压
到使用 再传输
里面需要很多的特殊的钢材 硅钢
或者说取向型的硅钢
因为它会带一些磁力的方向
提高它的效率
这种钢材美国只有一家公司可以做
它每年的产能是25万吨
全世界大概有500万吨的产能
中国光宝钢一家
大概有将近200万吨的年产量
所以美国在这个产业链上
是非常落后的
据我所知
2016年 2020年包括2024年
美国政府都出了一些
关于使用这些钢材
无论是反倾销也好
还是说OBBBA法案也好
都会有各式各样的法案
去禁止这些美国的公司
从中国来进相关的材料
因为为了想要发展制造业的回流
可是短期来说
美国的制造业并没有能力
去接载这么大的一个体量的需求
这也造成了过去两年来说
它的交期一直没有有效地去缩短
我理解的所有的这些
包括宝钢这家公司
都是指的是原材料层面
而不是说
真正地做成变压器的这个层面
是的
但我觉得今天我们再来聊
建电厂的时候
可能变压器只是其中的一个环节
而最新的电厂就像英伟达
它其实有在今年的GTC上
也讲了一种新的直输电场的方式
就是高压直流的方式
包括他也提了一个
800伏的高压直流输电的方法
大家可不可以讲一下
现在整个数据中心跟电厂
到底是在用新的这种方式去做
还是在用传统的这种方式去做
它的区别跟效率是怎么样的
英伟达这一次OCP展会上
讲的800伏直流
更多的是用于数据中心以内
整个AI数据机柜的输电
它是用来去替代之前的54伏机柜
我们先退一步来说
整个电是怎么产生的
高压电线如果是跨距离传输
是350千伏的这样一个体量
到本地的一个变电站
大概是3.8-35千伏中压的电
它到数据中心之内
可能通过一个不间断的电源
叫UPS 传到数据中心里面
目前来说一般是480伏或者415伏
它是交流电
通过一个交流转直流
把它转换成54伏
去给所有的芯片或者服务器去供电
为什么我们要去把54伏拉到800伏
是因为目前整个数据中心
就以NVIDIA的几代产品为例
它之前的Hopper
我们所说的H100
它的一个机柜
可能是一个30千瓦左右的数量级
最近一代GB200
它一个机柜就到了100千瓦
它之后的Vera Rubin
包括之后的这个卡
都是要往400千瓦
甚至到1兆瓦一个机柜去做
我们简单算一个算术
功率等于电压乘以电流
NVIDIA自己有一个数据
如果你还是用54伏做柜内的传输
你一个一兆瓦的机柜
就需要200公斤的铜用来做传输电
电流如果纯电阻
就是电压除以电阻
所以功率是和电压的平方
是成正比的
也就是说你去增加电压
可以大大地减少你效率的损失
800伏直流和54伏直流
如果是一兆瓦的机柜
54伏可能需要光在传输电上
会损失22%的效率
那我们现在缺电
当然这个损失是不能去承担的
如果拉到800伏的话
它的损失可以只在铜上会降到0.6%
这是好几个数量级的进步吧
现在数据中心
是不是有做到800伏的DC的能力
目前并没有
现在主要还是以415伏交流为例
为什么并没有
是进不去电网吗
不是 是因为现在
没有按照这个标准去做
有一点很重要就是
NVIDIA老黄说
他能自己造出所有的芯片
但是他没有电去power他的芯片
所以他现在定这样一个标准
是想要整个生态链共同进步
如果你还是415伏的交流
54伏的直流
它一个一吉瓦的数据中心
需要差不多50万吨的铜
这个是没有人可以去提供得了的
如果是做成这样
下一步可能就是缺铜了
所以他不得不要去
促使整个产业链或者生态链
去往一个更高的
高压直流的数据机柜的输电
往这样去做转换
那卡点在哪呢
我觉得更多是在大家怎么去理解
它这一周刚出的规范
以及怎么去把供应链拉起来
去做规范的理解 设计 生产
是不是可以这样理解
就是这个规范其实就是
看到今天的缺点
很严重的现实情况
要重新定义
这个行业里边的各项标准
现在刚刚发布这个新的标准
还需要一点时间
让整个生态链的各个环节的企业
重新设计他们的
比如说各种电器产品能够适应
或者是能够进入到
这样一个新的标准当中
让我们看到了下一代的数据中心
就有可能会根据这个标准
去建立起来
这样的话
整个数据中心的效率等等
都会提高很多
是的 是的
但我看见现在大家虽然没有去建
800伏的高压直流
但是相比于你之前提到的
54伏的直流电
已经有人开始尝试
比如说200伏 400伏
大家已经在往这个方向去靠了
只是说我们还没有把那个标准
一下拉得那么高
对 在英伟达的白皮书里面
也有提到它的几个阶段
就是从415伏交流
到54伏的直流转换
也有415伏的交流
直接转成415伏或者400伏的直流
去做这个机柜
之后再是说
把整个配套的基础设施提到800伏
去内部直接做直流的这个传输
甚至于到最后的ultimate stage
就是用固态变压器
在数据中心的输电入口
就直接做到800伏直流
当中可以去除一些UPS
以及整体的效率
把从92%-98%的效率甚至提到98.5%
甚至99%的end to end的效率
Ethan是不是我们去做这种
数据中心的高压直流电
跟整个居民用电
方式是完全不一样的
就是这个方式
它是不可以提供给居民用电的
就限定了它只能做数据中心
我的理解大概确实是这样的
因为我们现在整个的电力系统
其实都是建立在所谓的
交流电力系统这个基础上的
刚才我们说的高压直流的这个概念
其实在电网侧
其实也是有很多的应用的
尤其是中国
就比如说电网在传输电力的时候
如果是长距离传输的话
你的电流越大的话
你的损耗就越多
怎么让电流变小呢
你就把电压升高
所以这也是为什么
我们在输电的时候
会需要很多的变压器
一方面变压器是要在发电机那一侧
把电压提得很高
在传输的过程中
它的损耗就会比较小
在用电的时候
你又在用变压器
把它的电压给降低
这样的话就在居民
或者是商业工业使用的时候
这个电压是比较安全的
所以在中国的话
其实建了很多的
也是叫高压直流
不过那个是输电线的高压直流
那个可能就是500千伏750千伏
那个电压就比800伏
要高1000倍左右了
而现在我们看到的
基本上整个社会都是以交流电
作为一个主要的用电方式的
但是我觉得现在
确实是到了一个时机
数据中心内部应该用高压直流
来提高它的效率了
2025年很有可能在美国数据中心的
所有用电量加起来
可能会占到整个美国用电量的
大概5%左右
就是整个加利福尼亚州
整个今年的用电量
大概是占美国所有用电量的
大概是百分之六点几左右
也就是说今年数据中心的用电量
就稍微比整个
加利福尼亚州的用电量
要稍微低一点点
而这个数字大概会在
2030年的时候会翻倍
也就是说在2030年的时候
很可能整个数据中心行业的用电量
是加州今天用电量的大概两倍左右
这是非常大的一个用电量
所以我也觉得
到2030年大概会涨10%的话
这意味着这是一个很大的用电行业
完全值得为这个行业
设计一套专有的用电的标准
就比如说英伟达的800伏
这样一个标准
能够让整个占据美国用电10%的
这个行业的效率
比如说提高20%左右
这是非常大的经济收益
我觉得我们可能看到的
比如说上周公布的这个报告
就是这一切的开始
大概给听众一个印象
我们用ChatGPT搜索一次
会有多耗电
它差不多就是用谷歌搜索一次
耗电量的10倍
我另外看到一个数据是说
中国今年整个电力的建设
是有495个吉瓦的
美国今年的整个电力的建设
是50个吉瓦
为什么中国可以建设得那么快
而美国在这么缺电的情况下
它的建设速度还是这么慢
总体来说有几个主要的原因吧
一个就是中国的电网很多时候
它是有一个集中规划的概念
这和政治制度 经济制度
是息息相关的
而美国的很多电网
它是小区域局部规划
但是很少有跨区域的
大规模集中的规划
当然美国也意识到有这个问题了
也开始做出这方面的改进
也有一些政策出来去鼓励这样做
但是这方面也刚刚开始
这和中国一直以来的电力
从西边送到东边
从南方送到北方
通过高压直流
通过整个中国大规模的电网建设
来实现电力的大规模传输
完全不能同日而语的
还有一方面就是
在建设电网的过程中
你需要很多的审批
而在中国的话
它有一个相对集中的
一种管理的方式吧
而在美国的话
很可能你的高压传输线
需要经过一个农场主
这个农场主说
不 我不允许你在这建
你可能就要绕道个几百个英里
而这个过程中
可能你会遇到几百个这样的农场主
你一个个谈下来的话
这个时间是非常漫长的
这就是为什么美国高铁建不成
对 是同样的一个道理
对
所以还有一个数字
可以给大家参考
在美国建一个新的长距离的传输线
大概需要的时间是7-12年
这是非常漫长的一个过程
所以在过去的几年
美国几乎没有大规模的传输线建设
但这只是整个
电力系统建设中的一角了
其实如果你看输电也好配电也好
整个建设都会遇到很多
类似这样的问题
长距离传输线的建设主体是谁
是政府吗
我其实现在的角度是说
如果现在来做这件事情的人
不是政府而是科技公司
因为他们其实有实打实的
利润跟业务需求上的考量
所以他们是不是
在做同样的事情的时候
它的推进速度会更快
我觉得在整个电力系统
建设的某些环节
科技公司是有优势的
但是在传输线进入这个环节
可能跟电力公司
遇到的问题是一样的
你还是要去跟无数人去谈判
这个还是非常难的
所以现在科技公司
采取一个策略就是
我不去参与
很多大规模的传输线的建设
但是我走另外一条路
比如说我自己去建我自己的发电站
而我就把这个发电站
建在我自己的数据中心
附近不远的地方
很多东西是在它的经济资源
政治资源的影响力范围内
它可以做得更快更好的
数据中心的建设是需要大量的水吗
在建设过程中
水用得并不多
在运行的过程中
看你是用什么样的方式去制冷
可能会决定了你的用水的量
液冷用水量就会非常大
其实也看具体的技术
因为有些液冷量它是闭循环的
所以它用的水也不是很多
但是在数据中心运行过程中
用水量和用电量
往往有一个此消彼长的关系
当你想降低用水量的时候
往往意味着你要用更多的电去制冷
如果你想降低用电量的话
可能你要依靠当地的很多水资源
帮助你制冷
这也是一个矛盾的点
所以在数据中心的建设过程中
或者在选址的过程中
每个公司都会看
Ok 在这个地区
是不是电更多一些
还是水更多一些
要根据当地的禀赋
它可能会决定一个策略
对 我看其实现在整个科技巨头
它在建数据中心的时候
还是有遭到很多当地居民的抵制的
不管你说污染还是缺水
就是各种各种各样的问题
可能都会有
所以再回到我刚刚提的那个问题
为什么中国建设得这么快
Ethan你的观点是行政效率的问题
对 我觉得可能还有一个原因
就是成本的问题
一个是设备的成本
一个是人力的成本
中国在过去的可能10年左右
在政府还有政策的推动下
整个清洁能源行业的发展
是非常非常快的
一个简单的数字
可以让大家留下深刻印象
就是中国在一年的
太阳能的装机容量
相当于世界上所有其他国家
加在一起的总和
甚至有时候还更多
这也就意味着整个行业
已经把清洁能源的发电成本
已经压得非常非常低了
比如说我们看到大规模的储能等等
像美国的设备
可能是中国价格的两倍左右
所以这个成本的差异
也是一个比较大的原因
对 现在整个电力的建设
带火了哪些能源股
其实我们刚才聊的天然气涡轮机
像GE的话
可能是最受益的一家公司
因为在过去很多年
我们一直在做清洁能源转型
要降低碳排放什么的
天然气的发电这个业务
其实一直都不是很好
但是因为现在AI的爆发
需要发电特别多
所以天然气
能够上线的速度又比较快
所以像GE这样的公司
已经涨得非常的高了
因为大家都已经明确地看到
它的订单在疯狂地涨
它的溢价能力也非常的高
需求还远远没有得到满足
除了这个之后比如说核能
但核能的话我个人认为
可能不是一个
短期能够实现的一个技术
但是未来的五年左右
可以实现的技术
所以这块也应该是一个
比较受益的板块
还有很多可能就是供应链上的
很多一些规模稍微小一点的企业
比如说做各种电器设备的
可能还有一些做各种原材料的
比如说铜
就是一个很关键的原材料等等
我觉得这些企业和公司
应该都会受益的
对 辰晟
之前有一个公司
它是做化学燃料电池的
它可以短期去解决（问题）
（如果）买不到天然气涡轮发电机
最近股票也涨得非常好
但是从资本的角度来说
它其实这笔经济账是算不过来的
同样100兆瓦时
你一个涡轮发电机
可能是在
200个百万美元左右的投入
像一些其他的替代选项
它的资本支出投入
可能要翻3-3.5倍
所以它可能要到700个百万美元
同样一个100兆瓦时
它的能源效率虽然提高了
但是它的燃料其实每年的
运营的费用
可能同样100兆瓦时
它也要花额外可能
20-50个百万美元的
这样一个不等
你可能五年算下来
就要多花将近六亿到十亿美元
去解决一个100个兆瓦的能源
可是现在大家去做一些竞争
我要比你更快到通用人工智能
我要比你更快实现商业化
所以促使了大家
疯狂地去购买这些产能
当然了整条行业上面
现在如果纯从股票
或者纯从供应链来讲
AI其实缺的东西是很多的
它从大到变压器这些基础设施
甚至小到芯片
之前我们过去两年
一直在谈缺芯
无论是说
这个芯片本身的晶圆的产能
包括台积电是全球独此一家
做CoWoS一些特殊封装的这些产能
它其实还是在相对紧缺的这个状态
比方说因为Sora或者Veo
OpenAI和谷歌的视频模型
它会转成说
我对于我的储存的存储器
它的需求会有指数级的增长
造成了我看到一个研报说
明年年底如果不考虑现在的这些
新的模型对于储存的需求
它的缺口还有5%-8%
如果我们考虑上的话
它的缺口可能会更加大
这是由于过去好多年
产能没有有效投资
因为有经济的波动而造成的
所以其实各个方面都缺
我再举一个有意思的例子
比方说现在10万张卡的
这样一个AI数据中心
如果之前我们训练
Meta Llama的时候
它用了差不多25000张卡
还是16000张卡
训了54天
它训练平均3个小时会断一次
由于GPU产生的问题占到58%
那OpenAI训GPT 4的时候
或者Meta训Llama 4的时候
它用一个10万卡的级别
它平均32分钟就要宕一次
需要恢复大概15分钟
退下来的芯片当然是退回给NVIDIA
你光一个10万张卡
你每周1%的故障率
它可能就有差不多1000张卡
需要去运回去
这是什么样的体量
它可能需要100吨
连FedEx都要去买额外多的货车
去做这样一个
运回100吨的卡
对 如果只有10万张卡的
前提下的话
我们做一个合理的1%的退货的假设
所以其实整条供应链上
有太多太多的卡点
现在是不能支持到
这样一个体量的
我可不可以简单总结一下
整个现在AI的问题
我们理解前两年它是缺芯片
这两年它的核心问题
就是缺电跟缺能源
以及搭建数据中心
整个供应链环节
各种各样的小的卡点
是的
好的 好的
非常精彩
我觉得我们之前的节目
都还是在聊10亿美元的独角兽
就算很大了
之后我们聊这个大模型
可能是几百亿 几千亿的这种估值
今天我们是在聊一个
trillion dollars
就是万亿美元的市场
感觉我们的野心也是在慢慢变大了
没错
没错
这个投资的规模实在是太大了
对 我觉得这个也可以说是
载入人类史册的一个投资时期
好 非常精彩
谢谢两位
谢谢
谢谢 谢谢
这就是我们看到的
现在整个美国经济
冰火两重天的现状
一端是科技巨头热火朝天的大基建
另一端
是传统的行业那0.1%的增长
那我们说
在这样的一个资金传导链条中
任何一个环节出现信任危机
不管是有公司的造假
或者是整个AI的落地不及预期
会不会是这个多米诺骨牌
倒塌的第一步呢
感兴趣的听众
可以给我们写下你的评论
我们一起来讨论一下
那这就是我们今天的节目
如果大家喜欢我们的节目
记得在小宇宙 苹果播客
Spotify上来收听 订阅我们
同样大家也可以在YouTube
或者bilibili上搜索硅谷101播客
来关注订阅我们
我是泓君
感谢大家的收听