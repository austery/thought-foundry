The
 Pandora
 box
 of
 technology
 is
 already


open.
 The
 reality
 is
 that
 kids
 are


growing
 up
 with
 AI
 and
 they're
 talking


to
 systems
 that
 are
 saying
 yes,
 that
 are


agreeing
 to
 them,
 that
 are
 placating


them
 because
 that's
 what
 these
 systems


are
 trained
 to
 do.
 At
 the
 same
 time,


it's
 being
 used
 for
 really
 horrible


things.
 I
 think
 there's
 a
 real
 there's
 a


real
 worry.
 Everything
 from
 just
 spam


and
 AI
 slop
 from
 that
 to
 highly


targeted,
 highly
 contextual
 fishing


campaigns
 to
 victimizing
 people
 by


creating
 non-consensual
 intimate


imagery.
 Someone
 needs
 to
 be
 able
 to


stop
 those
 horrible
 things
 from


happening
 so
 innovation
 can
 continue


because
 if
 you
 don't
 what's
 going
 to
 end


up
 happening
 is
 that
 there's
 going
 to
 be


regulation.
 They're
 going to
 have
 to


stop
 and
 fix
 things
 and
 before
 they
 can


innovate
 and
 it
 slows
 down
 ability
 to


innovate
 as
 a
 society.
 And
 so
 what
 I


want
 to
 do
 is
 be
 able
 to
 we
 should
 be


able
 to
 be
 the
 ones
 that
 are
 stopping


those
 horrible
 things
 and
 innovating
 on


that
 and
 allow
 everyone
 else
 to
 innovate


incredibly
 quickly.
 I'm
 Glenn
 Wise.
 I'm


the
 co-founder
 CEO
 of
 Cinder,
 a
 central


platform
 for
 trust
 and
 safety


operations.
 You
 can
 think
 of
 Cinder
 as


the
 club
 bouncer
 for
 the
 internet.
 Our


customers
 want
 to
 be
 able
 to
 set
 rules


on
 what
 they
 allow
 on
 their
 platforms


and
 what
 they
 don't
 allow.
 And
 so
 Cinder


is
 the
 system
 that
 they
 use
 to
 enforce


those
 rules
 across
 all
 of
 their
 users.


We
 raised
 $14
 million
 from
 investors


such
 as
 Y
 Cominator
 and
 Excel.
 Our


mission
 is
 to
 make
 the
 internet
 a
 safer


place.


So
 growing
 up
 in
 New
 Jersey,
 being
 6
 or


7
 years
 old
 during
 911,
 that
 was
 such
 an


impactful
 sort
 of
 moment
 in
 my
 life
 and


my
 community.
 And
 when
 you
 grow
 up
 with


that
 in
 the
 backdrop,
 any
 opportunity
 to


be
 part
 of
 a
 greater
 mission
 was
 really


important
 to
 me.
 So
 then
 when
 I
 went
 to


college
 and
 I
 realized
 that
 you
 can


actually
 go
 work
 at
 the
 NSA
 or
 the
 CIA


or
 the
 FBI
 on
 these
 exact
 issues
 of


making
 sure
 that
 never
 happens
 again.


That's
 the
 the
 only
 thing
 I
 wanted
 to


do.
 And
 so
 that
 inevitably
 led
 me
 to


join
 government
 being
 able
 to
 work
 on


counterterrorism
 issues
 which
 inevitably


led
 to
 me
 doing
 the
 same
 type
 of
 work
 at


at
 Facebook
 on
 a
 threat
 intelligence


team.
 Facebook
 started
 investing
 heavily


in
 threat
 intelligence
 before
 the
 harm


became
 prevalent
 on
 platform.
 Being
 on
 a


red
 team,
 I
 think,
 is
 one
 of the
 most


fun
 jobs
 that
 someone
 could
 have
 and


someone
 can
 do
 because
 you
 get
 to,
 you


know,
 try
 to
 break
 things.
 This
 is


something
 that
 I
 instill
 on
 my
 team


today.
 It's
 like,
 how
 do
 you
 have
 that


adversarial
 mindset,
 right?
 There's


going
 to
 be
 people
 on
 the
 other
 side
 of


that
 trying
 to
 stop
 you
 and
 you
 have
 to


acknowledge
 that
 and
 be
 able
 to
 think


like
 that.
 At
 the
 time,
 I
 was
 talking
 to


so
 many
 other
 companies
 that
 were
 really


struggling
 with
 getting
 a
 grasp
 on
 the


abuse
 occurring
 on
 their
 platform.
 And


so,
 I
 thought
 that
 this
 would
 be
 a


really
 interesting
 thing
 to
 start.
 I
 was


thinking
 about
 it
 for
 a
 long
 time
 to
 the


point
 where,
 you
 know,
 it's
 all
 I


thought
 about
 outside
 of
 work.
 Part
 of


my
 hesitation
 of
 founding
 Cinder
 that
 I


just
 thought
 I
 wasn't
 ready,
 right?
 I


felt
 I
 didn't
 have
 the
 right
 experience.


My
 initial
 thought
 at
 the
 time
 was
 to
 go


to
 a
 smaller
 company
 and
 help
 them


build,
 you
 know,
 a
 platform
 internally.


So,
 I
 ended
 up
 just
 reaching
 out
 to
 a


bunch
 of
 people.
 And
 I
 realized
 that


there
 were
 a
 lot
 of
 companies
 to
 choose


from
 to
 build
 something
 internally
 that


at
 that
 point
 you
 should
 just
 build
 it


once
 centrally
 and
 then
 give
 it
 to
 all


these
 companies.
 All right.
 It
 just
 like


made
 so
 much
 sense
 as
 a
 business.
 That's


inevitably
 why
 I
 made
 the
 decision
 to
 to


found
 it.
 And
 I
 think
 that
 it's


important.
 Someone
 needs
 to
 be
 able
 to


stop
 those
 horrible
 things
 from


happening
 so
 innovation
 can
 continue.


And
 so
 what
 I
 want
 to
 do
 is
 be
 able
 to


we
 should
 be
 able
 to
 be
 the
 ones
 that


are
 stopping
 those
 horrible
 things
 and


innovating
 on
 that
 allow
 everyone
 else


to
 innovate
 incredibly
 quickly
 and


deploying
 new
 things
 and
 building
 new


things
 without
 worrying
 about
 this


underbelly
 of
 the
 internet
 and
 these


underbelly
 of
 of
 harmful
 people.
 I


applied
 to
 Y
 Comer
 thinking
 that
 nothing


would
 happen,
 you
 know,
 literally
 an


hour
 or
 two
 before
 the
 deadline
 was
 due.


Uh
 ended
 up
 getting
 a
 call
 from
 Michael


Cyel
 and
 Michael
 told
 me
 that
 he
 thought


the
 idea
 was
 great.
 He's
 really
 excited


about
 it.
 He
 wants
 us
 to
 he
 wants
 me
 to


do
 it,
 but
 I
 need
 to
 find
 a
 co-founder.


And
 I
 told
 him
 that
 there
 were
 people


that
 I
 worked
 with
 at
 Facebook
 that
 I


thought
 were
 really
 amazing
 people
 that


I
 really
 wanted
 to
 work
 with,
 but
 it's


going
 to
 be
 impossible
 for
 me
 to
 get


them
 to
 to
 leave
 Facebook
 and
 to


actually
 join
 starting
 this.
 And
 fast


forward
 3
 months
 later,
 had
 a
 really


great
 team
 of
 people
 that
 I
 was
 really


respected.
 Um,
 and
 it
 was
 amazing
 that
 I


mean
 still
 is
 amazing
 that
 I
 get
 to
 work


with
 them
 every
 day.
 Bring
 all
 these


people
 on
 and
 and
 work
 with
 them
 was
 a


really
 special
 moment
 for
 me.


This
 year
 alone
 with
 Cinder,
 our


customers
 have
 submitted
 over
 100,000


reports.
 The
 National
 Center
 for
 Missing


and
 Exploited
 Children.
 That
 alone
 is
 a


pretty
 insane
 number,
 but
 it's
 also
 just


like
 scratching
 the
 surface
 of
 all
 of


the
 really
 bad
 things.
 We
 see
 abuse


today
 that
 4
 years
 ago
 only
 a
 nation


state
 could
 do.
 And
 today,
 a
 teenager


with
 a
 laptop
 is
 able
 to
 do
 it.
 As
 a


society,
 we
 need
 systems
 that
 can
 combat


this
 abuse
 before
 it
 turns
 into
 a
 total


hellscape.
 When
 we
 set
 out
 to
 build


Cinder,
 we
 knew
 that
 we
 were
 going
 to


build
 a
 platform
 and
 that
 is
 really


challenging
 and
 I
 would
 encourage
 anyone


to
 not
 build
 a
 platform
 from
 the


beginning
 because
 you
 have
 to
 build
 so


many
 things
 on
 top
 of
 it
 in
 order
 for
 it


just
 to
 work,
 right?
 You
 have
 to
 be
 able


to
 integrate
 all
 these
 signals.
 You
 have


to
 be
 able
 to
 make
 it
 highly


configurable
 and
 customizable.
 You
 have


to
 be
 able
 for
 customers
 to
 represent


their
 own
 unique
 data
 and
 their
 own


unique
 workflow
 within
 it.
 So
 we
 did
 a


lot
 of
 work
 initially
 to
 support
 all


these
 different
 content
 types
 to
 support


all
 these
 different
 types
 of
 workflows


that
 takes
 a
 long
 time.
 We
 set
 out
 to


build
 what
 was
 effectively
 a
 threat


intel
 platform
 for
 trust
 and
 safety.
 And


we
 thought
 this
 was
 a
 great
 idea
 because


we
 saw
 that
 pain
 in
 previous
 jobs
 and
 we


were
 going
 to
 go
 solve
 it
 and
 bring
 it


to
 everyone
 else.
 So
 we
 spent
 all
 this


time
 building
 this
 platform
 and
 then
 we


went
 out
 to
 show
 people
 and
 they


effectively
 told
 us
 that
 this
 was


interesting
 but
 they
 did
 not
 want
 it
 and


what
 they
 really
 needed
 was
 a
 way
 to


handle
 their
 overall
 operations
 and
 so


we
 invested
 all
 this
 time
 uh
 in
 me
 and


Declan
 one
 of
 the
 co-founders
 spent
 so


much
 time
 building
 this
 thread
 intel


platform
 to
 be
 told
 that
 they
 wanted


something
 else
 and
 that's
 like
 a
 huge


learning
 for
 us
 right
 and
 that
 that


brings
 us
 to
 this
 idea
 of
 really


focusing
 ing
 on
 what
 the
 core
 customer


problem
 is
 and
 get
 that
 problem
 down


really
 tight
 and
 then
 go
 out
 and
 build.


And
 my
 focus
 from
 like
 the
 beginning
 of


my
 career
 has
 been
 on
 how
 do
 you
 stop


people
 from
 taking
 advantage
 and
 and


abusing
 other
 systems
 or
 or
 people.
 And


so
 being
 able
 to
 empathize
 with
 the


customer
 was
 really
 key,
 right?
 Even


when we
 had
 nothing
 built,
 someone
 being


able
 to
 listen
 to
 them
 and
 understand


what
 they
 were
 going
 through
 and
 provide


suggestions
 on
 how
 to
 fix
 it
 and
 then
 a


few
 weeks
 later
 come
 with
 a
 product.
 It


solved
 a
 real
 problem.
 So
 a
 really


prominent
 harm
 facing
 Gai
 customers


today
 is
 basically
 non-consensual


intimate
 imagery
 NCI.
 We
 are
 seeing


harms
 become
 more
 and
 more
 complex
 as


time
 goes
 on.
 At
 Cinder,
 we
 have a


framework
 called
 the
 decision
 spectrum.


And
 almost
 every
 problem
 can
 be
 placed


on
 the
 spectrum
 in
 some
 way
 where
 on
 the


left
 side
 of
 the
 spectrum
 is
 a
 really


something
 really
 simple,
 like
 a
 really


simple
 decision
 of
 yeah,
 this
 image
 is


nudity
 or
 this
 uh
 chat
 message
 is
 fraud,


right?
 Like
 a
 really
 simple


identification
 of
 a
 single
 piece
 of


content
 or
 a
 single
 event.
 And
 on
 the


other
 side,
 you're
 investigating
 some,


you
 know,
 a
 really
 complex
 nation
 state


or
 really
 complex
 network
 or
 an


adversary
 that
 is
 advanced
 in
 trying
 to


hide
 their
 behavior.
 There
 are
 way
 too


many
 things
 to
 review
 and
 prioritizing


is
 really
 difficult
 because
 everything


is
 a
 heart,
 right?
 Everything
 is
 hurting


someone
 else.
 And
 that
 burnout
 is
 real.


and
 you
 see
 people
 burning
 out
 the


industry
 all
 the
 time
 because
 they


almost
 feel
 like
 there's
 they're
 facing


an
 uphill
 battle
 of
 targeting
 this.
 So
 I


think
 our
 team,
 you
 know,
 we
 we


definitely
 see
 some
 of
 that,
 but
 for
 us,


everyone
 at
 our
 company
 is
 deeply


motivated
 by
 the
 mission
 and
 everyone


wants
 to
 inevitably
 have
 a
 world
 where


the
 internet
 and
 innovation
 is
 is
 safe


and
 can
 be
 used
 by
 anyone.
 And
 our


founding
 team
 had
 direct
 experience
 in


building
 these
 systems
 at
 many
 different


places.
 And
 we
 experienced
 that
 harm


firsthand,
 right?
 We
 experienced
 that


painoint
 firsthand.
 I
 think
 in
 this


space,
 the
 only
 way
 that
 you're
 able
 to


build
 an
 effective
 product
 is
 by
 having


that
 experience,
 but
 also
 having
 that


attraction
 to
 the
 mission
 and
 having


that
 attraction
 to
 the
 outcome
 and


having
 that
 purpose
 behind
 it
 all


because
 the
 the
 work
 is
 so
 difficult.
 It


is
 very
 complex
 and
 very
 nuanced
 that


you
 have
 to
 have
 that
 that
 drive.
 When


you
 hear
 stories
 from
 our
 teams
 of


something
 that
 we
 took
 down
 or
 something


that
 we
 helped
 stop
 or
 an
 abuse
 that
 we


caught
 that
 allows
 us
 to
 go
 on,
 right,


and
 be
 really
 motive
 for
 the
 next
 day.


And
 so
 I
 think
 you
 can
 it's
 you
 you
 can


easily
 get
 bogged
 down
 in
 the
 harm,


right?
 You
 can
 easily
 look
 at
 all
 of
 the


really
 horrible
 things
 happening
 across


the
 internet
 and
 and
 be
 really
 dejected


from
 it,
 but
 know
 that
 there's
 a
 path
 to


being
 able
 to
 come
 at
 it.
 and
 someone


needs
 to
 combat
 it.
 And
 if
 it's
 not
 us,


then


you
 know
 who
 else
 is
 that
 going
 to
 be?