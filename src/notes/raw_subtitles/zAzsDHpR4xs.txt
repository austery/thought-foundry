1
00:00:00,233 --> 00:00:02,100
反正现在我没有access了嘛

2
00:00:02,100 --> 00:00:05,466
就是所以也算自由了吧

3
00:00:05,466 --> 00:00:06,900
就是想干啥干啥了

4
00:00:06,900 --> 00:00:07,800
对 现在这样

5
00:00:08,166 --> 00:00:09,866
恭喜 我是在

6
00:00:09,866 --> 00:00:11,166
就是 准备访谈的时候

7
00:00:11,166 --> 00:00:13,866
才发现你在Meta已经工作10年了

8
00:00:13,866 --> 00:00:15,166
对对对

9
00:00:15,166 --> 00:00:15,866
那个时候

10
00:00:15,866 --> 00:00:16,833
2015年还是个

11
00:00:16,833 --> 00:00:18,066
呃不是 对

12
00:00:18,166 --> 00:00:19,633
15年Meta还是一家很小的公司

13
00:00:19,633 --> 00:00:20,966
20212年上市的

14
00:00:20,966 --> 00:00:21,700
对

15
00:00:21,700 --> 00:00:23,166
你加入的时候Meta多少人

16
00:00:23,166 --> 00:00:23,966
那个时候

17
00:00:24,366 --> 00:00:28,000
那个时候可能大概有1万多一点吧

18
00:00:28,000 --> 00:00:28,600
可能

19
00:00:28,600 --> 00:00:29,100
对

20
00:00:29,100 --> 00:00:30,800
其实（公司）也不小了

21
00:00:31,100 --> 00:00:32,566
嗯不是特别小

22
00:00:32,566 --> 00:00:34,900
但是 现在可能几十万

23
00:00:35,466 --> 00:00:36,500
对 嗯

24
00:00:36,500 --> 00:00:39,566
我们沿着原来的那个访谈大纲

25
00:00:39,566 --> 00:00:40,700
去聊你的论文

26
00:00:40,700 --> 00:00:41,500
也行

27
00:00:41,600 --> 00:00:44,833
然后我们address一下这个new development问题

28
00:00:44,833 --> 00:00:45,633
也行

29
00:00:46,000 --> 00:00:48,266
我们可以聊一些论文

30
00:00:48,266 --> 00:00:49,366
我觉得这个还是比较好

31
00:00:49,366 --> 00:00:52,433
因为我其实并不想说太多裁员的事情

32
00:00:52,800 --> 00:00:54,300
我也觉得这个不太好

33
00:00:54,300 --> 00:00:56,966
对 就是推特上已经去

34
00:00:56,966 --> 00:00:58,833
发了一个帖子就有那么多人

35
00:00:58,966 --> 00:00:59,766
那么多人点赞

36
00:00:59,766 --> 00:01:01,366
那我

37
00:01:01,366 --> 00:01:02,600
小红书上也是

38
00:01:02,600 --> 00:01:05,466
刷到你的名字 一天刷到了好多

39
00:01:05,833 --> 00:01:06,866
对 我觉得

40
00:01:06,866 --> 00:01:09,400
其实我觉得 我这边本意就是

41
00:01:09,400 --> 00:01:10,900
因为我这边team也有几个人

42
00:01:10,900 --> 00:01:13,000
是被影响到了嘛

43
00:01:13,000 --> 00:01:16,166
所以我当然希望他们有更好的机会

44
00:01:16,166 --> 00:01:17,066
因为我是无所谓了

45
00:01:17,066 --> 00:01:18,966
我最惨的话 不行就在家里待着

46
00:01:19,166 --> 00:01:22,266
但是他们很多人身份（签证等）会有些问题

47
00:01:22,266 --> 00:01:25,100
如果不能及时找到下一家（公司）的话

48
00:01:25,100 --> 00:01:29,200
对吧 那肯定要想办法

49
00:01:29,200 --> 00:01:30,633
我也帮帮忙 帮找一找

50
00:01:30,633 --> 00:01:32,766
因为我毕竟这边认识人比较多

51
00:01:32,966 --> 00:01:34,100
这个也是我的本意吧

52
00:01:34,100 --> 00:01:35,466
我在想就是我

53
00:01:35,466 --> 00:01:35,800
反正我也

54
00:01:35,800 --> 00:01:37,466
我也不怕自己暴露自己被裁

55
00:01:37,466 --> 00:01:38,400
i don't care

56
00:01:38,666 --> 00:01:40,766
对 但是就是希望

57
00:01:40,833 --> 00:01:43,966
我的手下那些人（前同事）能很快找到工作

58
00:01:44,100 --> 00:01:45,200
这也是我的本意

59
00:01:45,566 --> 00:01:46,866
你需要什么帮忙吗

60
00:01:46,866 --> 00:01:49,366
如果有些事情你自己说不太合适的话

61
00:01:49,366 --> 00:01:50,900
我也可以帮你联系一些人

62
00:01:50,900 --> 00:01:52,166
应该不用 应该不用

63
00:01:52,166 --> 00:01:53,500
我觉得还是有很多人reach out

64
00:01:53,500 --> 00:01:54,866
所以他们还是

65
00:01:54,866 --> 00:01:56,400
我觉得他们是有机会的

66
00:01:56,400 --> 00:01:57,200
他们是有机会的

67
00:01:57,666 --> 00:01:58,833
对 我pass一个

68
00:01:58,833 --> 00:02:01,033
这个ask同不同意都行

69
00:02:01,033 --> 00:02:02,466
就是腾讯新闻

70
00:02:02,466 --> 00:02:03,433
腾讯新闻的人

71
00:02:03,433 --> 00:02:06,366
他说想采访你

72
00:02:06,366 --> 00:02:09,200
然后我说 问问你有没有时间吧

73
00:02:09,266 --> 00:02:10,600
说聊论文也行

74
00:02:10,600 --> 00:02:12,366
聊Meta公司的内部问题也行

75
00:02:12,366 --> 00:02:14,666
他们都可以做出人力来做深度内容

76
00:02:14,666 --> 00:02:15,700
我觉得是这样的

77
00:02:15,700 --> 00:02:16,700
就是不要

78
00:02:16,700 --> 00:02:17,266
我觉得是这样

79
00:02:17,266 --> 00:02:18,566
不要聊Meta公司内部问题

80
00:02:18,566 --> 00:02:19,500
我觉得我已经说够多了

81
00:02:19,500 --> 00:02:20,800
我不想再说了

82
00:02:20,966 --> 00:02:23,066
对 因为我

83
00:02:23,066 --> 00:02:24,800
那你有兴趣跟他们聊论文吗

84
00:02:25,066 --> 00:02:26,633
聊论文 要看聊什么论文吧

85
00:02:26,633 --> 00:02:28,566
对吧 那也是可以的

86
00:02:28,766 --> 00:02:29,766
嗯 对

87
00:02:29,766 --> 00:02:31,833
我不希望聊太多Meta公司内部的

88
00:02:31,833 --> 00:02:34,100
因为其实我觉得

89
00:02:34,100 --> 00:02:36,033
我一般不太愿意说这些

90
00:02:36,033 --> 00:02:38,433
然后我觉得 我在Twitter上唯一说的是

91
00:02:38,433 --> 00:02:41,300
因为就是有人跳出来说

92
00:02:41,300 --> 00:02:42,366
你们被裁是应该的

93
00:02:42,366 --> 00:02:44,266
因为东西没做出来对吧

94
00:02:44,266 --> 00:02:46,966
但是 那我要至少给我们的

95
00:02:46,966 --> 00:02:48,900
至少给我们的team要做澄清

96
00:02:48,900 --> 00:02:50,500
对吧 因为我们team说了很多

97
00:02:50,833 --> 00:02:52,100
的重要工作

98
00:02:52,100 --> 00:02:53,800
那你不能把锅扣到我们头上

99
00:02:53,833 --> 00:02:56,966
所以 这个肯定是要讲清楚

100
00:02:56,966 --> 00:02:59,000
但是我现在就比较defensive

101
00:02:59,000 --> 00:03:01,400
就是OK 如果有人说这个是我们的锅

102
00:03:01,400 --> 00:03:03,166
那我们会说回去

103
00:03:03,400 --> 00:03:06,066
对但除此之外我不会说太多

104
00:03:06,066 --> 00:03:07,600
就是公司内部的事情

105
00:03:07,633 --> 00:03:08,433
嗯

106
00:03:08,666 --> 00:03:10,100
好 那你还有没有什么

107
00:03:10,100 --> 00:03:11,766
想澄清的 你觉得没有澄清

108
00:03:11,766 --> 00:03:12,466
好的

109
00:03:12,466 --> 00:03:14,600
哈哈我觉得差不多了吧

110
00:03:14,600 --> 00:03:15,166
就这样就是

111
00:03:15,166 --> 00:03:15,433
我觉得差不多了

112
00:03:15,433 --> 00:03:17,566
我们其实还是做了很多的工作

113
00:03:17,566 --> 00:03:19,866
就是把（公司）很多的之前的一些问题解决了

114
00:03:19,866 --> 00:03:20,100
比如说

115
00:03:20,100 --> 00:03:22,600
包括long context的那个reinforcement learning

116
00:03:22,900 --> 00:03:23,866
有没有训练的好

117
00:03:23,866 --> 00:03:26,700
对吧 还有包括前面的pertaining model啊

118
00:03:26,700 --> 00:03:28,833
他们的design 其实可能有些问题

119
00:03:28,833 --> 00:03:30,700
像有long attention的问题

120
00:03:31,033 --> 00:03:33,633
这个其实很多是我们团队解决的

121
00:03:33,633 --> 00:03:35,400
就是 反正是我先发现的

122
00:03:35,600 --> 00:03:36,766
关于这个design（方面）有问题

123
00:03:36,766 --> 00:03:37,900
然后去跟他们（公司侧）讲

124
00:03:38,200 --> 00:03:40,833
但是一开始就很难去

125
00:03:40,833 --> 00:03:43,000
就是他们不一定会

126
00:03:43,000 --> 00:03:43,466
不一定会听

127
00:03:43,466 --> 00:03:45,700
因为我当时来（Meta）

128
00:03:45,700 --> 00:03:47,233
我当时去的时候是

129
00:03:47,566 --> 00:03:50,000
按照一个research team来做的

130
00:03:50,000 --> 00:03:52,800
对吧 而对方（相关部门）是做大模型的

131
00:03:53,066 --> 00:03:54,700
那么我这边research team过来的话

132
00:03:54,700 --> 00:03:55,600
他们不一定会听

133
00:03:55,666 --> 00:03:57,633
那他们可能会觉得这个（观）点

134
00:03:57,633 --> 00:03:58,700
（或者说）这个事情没问题的

135
00:03:58,800 --> 00:03:59,400
肯定是对的

136
00:03:59,400 --> 00:04:02,700
那我们这边要用各种实验就证明

137
00:04:02,700 --> 00:04:04,200
我们之前的那些发现

138
00:04:04,200 --> 00:04:05,700
或者说insights（洞察）是对的

139
00:04:06,066 --> 00:04:07,500
但是 后来是他们是被说服了

140
00:04:07,500 --> 00:04:10,033
对 所以他们才会发现其中有问题

141
00:04:10,366 --> 00:04:10,600
对

142
00:04:10,600 --> 00:04:13,600
所以这其实都是我们团队的贡献

143
00:04:13,600 --> 00:04:14,233
还包括

144
00:04:14,233 --> 00:04:19,166
怎么样去让long context first training 更加稳定

145
00:04:19,166 --> 00:04:21,500
对吧 包括有很多的blow up的问题

146
00:04:21,500 --> 00:04:22,633
怎么样去解决

147
00:04:22,633 --> 00:04:24,566
这些东西都是都是我们这边做的

148
00:04:24,833 --> 00:04:25,633
对 所以

149
00:04:25,633 --> 00:04:26,200
这些东西

150
00:04:26,200 --> 00:04:27,833
就是说 也属于“幕后英雄”嘛

151
00:04:27,833 --> 00:04:32,233
就是 因为毕竟最终我们这个模型

152
00:04:32,233 --> 00:04:33,766
也没有真正official release

153
00:04:33,766 --> 00:04:35,900
至少我们有一些贡献在里面

154
00:04:35,900 --> 00:04:37,566
这个我是得说说

155
00:04:37,566 --> 00:04:38,633
说出来

156
00:04:38,633 --> 00:04:39,700
那么这样的话

157
00:04:39,700 --> 00:04:43,833
至少为后面的人添砖加瓦 加一下

158
00:04:43,833 --> 00:04:46,600
对不对 就是做一个比较好的base

159
00:04:46,600 --> 00:04:47,400
就是这样子

160
00:04:47,566 --> 00:04:49,700
说到这 我有两个问题

161
00:04:49,700 --> 00:04:50,033
然后

162
00:04:50,033 --> 00:04:52,100
我自己今天早上还跟我老婆聊的时候

163
00:04:52,100 --> 00:04:54,966
就说 我其实非常愤慨于

164
00:04:54,966 --> 00:04:56,900
很多公司里边内部管理的混乱

165
00:04:56,900 --> 00:04:58,400
然后导致

166
00:04:59,900 --> 00:05:02,200
我先不说 这里管理混乱管理的事情

167
00:05:02,200 --> 00:05:04,066
但是刚才的两个具体的问题就是

168
00:05:04,233 --> 00:05:06,700
第一 你们作为一个research团队

169
00:05:07,200 --> 00:05:07,700
人家不信任你

170
00:05:07,700 --> 00:05:08,366
可能是觉得

171
00:05:08,366 --> 00:05:10,400
之前你没有这个train（训练）大模型的经验

172
00:05:10,400 --> 00:05:11,200
或者怎样

173
00:05:11,233 --> 00:05:12,666
但是你们能很快发现问题

174
00:05:12,666 --> 00:05:14,366
你觉得为什么可以做到

175
00:05:14,566 --> 00:05:16,233
第二个就是

176
00:05:16,233 --> 00:05:17,466
对面的大模型团队

177
00:05:17,466 --> 00:05:18,266
是个什么样的团队

178
00:05:18,266 --> 00:05:21,066
他们自己本身大模型训练经历丰富吗

179
00:05:21,066 --> 00:05:23,266
他们是Llama-1或者2训练（团队）出来的

180
00:05:23,266 --> 00:05:24,233
是经验丰富的

181
00:05:24,233 --> 00:05:24,866
对

182
00:05:24,866 --> 00:05:27,866
但他们有一些 应该说是

183
00:05:27,866 --> 00:05:28,866
他们有一些地方（比如）

184
00:05:28,866 --> 00:05:30,700
之前的实验有bug

185
00:05:30,700 --> 00:05:31,300
有些bug

186
00:05:31,300 --> 00:05:33,500
然后这个bug 导致他们做出错的判断

187
00:05:33,833 --> 00:05:35,600
这个应该是这样的

188
00:05:35,600 --> 00:05:36,300
对

189
00:05:36,300 --> 00:05:37,866
但是我们这边虽然说没有训练大模型

190
00:05:37,866 --> 00:05:38,966
但是

191
00:05:38,966 --> 00:05:41,500
毕竟也是做过关于大模型的一些

192
00:05:41,500 --> 00:05:42,666
一些文章嘛

193
00:05:42,666 --> 00:05:45,300
对吧 包括我以前做过Sparse Attention

194
00:05:45,433 --> 00:05:47,666
就是那种 稀疏注意力

195
00:05:47,833 --> 00:05:48,366
那我当然对（比如）

196
00:05:48,366 --> 00:05:49,866
注意力结构 我知道什么是意思

197
00:05:49,866 --> 00:05:50,700
是怎么回事

198
00:05:50,700 --> 00:05:52,066
那当然 我一看这其中的设计

199
00:05:52,066 --> 00:05:53,166
就觉得有问题

200
00:05:53,466 --> 00:05:56,000
我相信 也有很多人都能看出来

201
00:05:56,000 --> 00:05:57,300
这个并不说是 只有我能看出来

202
00:05:57,300 --> 00:05:58,200
你肯定能看出来

203
00:05:58,300 --> 00:06:00,300
所以

204
00:06:00,433 --> 00:06:01,300
我并不知道

205
00:06:01,300 --> 00:06:03,100
当时这个决定怎么做

206
00:06:03,100 --> 00:06:04,566
但是我愿意说

207
00:06:04,566 --> 00:06:07,166
最后也是没办法

208
00:06:07,600 --> 00:06:11,833
因为 也很难去说服他们

209
00:06:11,833 --> 00:06:12,166
就是

210
00:06:12,166 --> 00:06:14,500
你要花很多时间和精力去跟他们说

211
00:06:14,500 --> 00:06:15,500
说这个是有问题的

212
00:06:15,633 --> 00:06:18,000
一直到他们自己团队发现了问题

213
00:06:18,000 --> 00:06:18,800
也是有这个问题

214
00:06:18,800 --> 00:06:21,466
那么慢慢的就是会改变

215
00:06:21,466 --> 00:06:22,633
这个想法

216
00:06:22,833 --> 00:06:25,500
所以应该 就是说

217
00:06:25,500 --> 00:06:27,200
虽然作为研究员

218
00:06:27,200 --> 00:06:29,766
就是可能我们当时做研究的时候

219
00:06:29,766 --> 00:06:31,833
并没有直接去接触超大模型的训练

220
00:06:31,833 --> 00:06:35,800
但是关于研究的那些直觉

221
00:06:35,800 --> 00:06:37,866
或者说相关的经验其实很有用

222
00:06:38,200 --> 00:06:40,433
对吧 能够很快的找到问题

223
00:06:40,433 --> 00:06:41,600
能够发现什么地方

224
00:06:41,600 --> 00:06:42,466
是

225
00:06:42,466 --> 00:06:43,700
有问题 或者是有出错的

226
00:06:43,900 --> 00:06:45,166
要怎么样去解决

227
00:06:45,166 --> 00:06:47,000
我觉得这个是很重要的

228
00:06:47,000 --> 00:06:49,466
这个是作为一个研究员的宝贵财富

229
00:06:49,466 --> 00:06:51,966
就是因为说实在的

230
00:06:52,233 --> 00:06:52,300
你

231
00:06:52,300 --> 00:06:54,500
如果是一个完全没有任何insights的人

232
00:06:54,500 --> 00:06:56,300
就是OK 我天天就跑实验

233
00:06:56,300 --> 00:06:57,666
然后调参数

234
00:06:57,900 --> 00:06:58,966
那这个

235
00:06:58,966 --> 00:07:00,400
工作其实你说你能做

236
00:07:00,400 --> 00:07:01,366
别人也能做

237
00:07:01,666 --> 00:07:04,800
对吧 那研究员的优势是说 我能不能

238
00:07:05,066 --> 00:07:05,633
嗯 把

239
00:07:05,633 --> 00:07:07,866
这个

240
00:07:07,866 --> 00:07:10,466
根据一些非常稀疏的数据点

241
00:07:10,466 --> 00:07:13,400
能够得到非常重要的结论

242
00:07:13,400 --> 00:07:15,800
然后这结论能够推广到更难的问题上

243
00:07:15,800 --> 00:07:17,666
这个是研究员的能力

244
00:07:17,666 --> 00:07:20,300
你说的稀疏的数据数据点

245
00:07:20,300 --> 00:07:24,666
是不同论文和不同实验的结果

246
00:07:24,666 --> 00:07:25,766
对 比如说

247
00:07:25,766 --> 00:07:27,766
如果我是一位新来的“菜鸟”

248
00:07:27,900 --> 00:07:28,966
那么对我来说OK

249
00:07:28,966 --> 00:07:30,600
我的任务是调参数

250
00:07:30,600 --> 00:07:31,500
跑程序

251
00:07:31,600 --> 00:07:33,366
那我跑比如说我跑1万个点

252
00:07:33,366 --> 00:07:35,066
那我就得到1万个点的参数值

253
00:07:35,066 --> 00:07:35,800
然后我就说

254
00:07:35,800 --> 00:07:36,633
我告诉大家

255
00:07:36,633 --> 00:07:37,766
这1万个点数是我跑的

256
00:07:38,000 --> 00:07:39,166
跑完之后跟大家说OK

257
00:07:39,166 --> 00:07:41,233
跑完了 那这个是我的结论对吧

258
00:07:41,500 --> 00:07:42,600
但是跑完之后

259
00:07:42,600 --> 00:07:44,166
这1万点数值在那边是“死”的

260
00:07:44,166 --> 00:07:45,900
那么你也没有什么Insights

261
00:07:45,900 --> 00:07:46,566
没有什么概念

262
00:07:46,566 --> 00:07:46,800
说

263
00:07:46,800 --> 00:07:48,900
这1万点其实背后代表了什么意思

264
00:07:49,033 --> 00:07:50,700
有什么样的结构

265
00:07:50,966 --> 00:07:51,266
那这个

266
00:07:51,266 --> 00:07:53,866
其实只有那些有经验的人才能看到

267
00:07:53,866 --> 00:07:55,100
（如果）有经验的人可能看到

268
00:07:55,233 --> 00:07:55,766
看了

269
00:07:55,766 --> 00:07:56,400
比如20个点

270
00:07:56,400 --> 00:07:57,633
就知道（其中）有什么问题

271
00:07:57,766 --> 00:07:58,366
甚至就说看了

272
00:07:58,366 --> 00:07:59,000
10个点 就看到

273
00:07:59,000 --> 00:08:00,633
就说这个training curve刚train到一半

274
00:08:00,633 --> 00:08:01,366
（发现）哦 我知道行不通了

275
00:08:01,366 --> 00:08:01,966
（就）不要

276
00:08:01,966 --> 00:08:02,500
继续跑下去

277
00:08:02,500 --> 00:08:03,500
可能（是因为）这其中有些问题

278
00:08:03,900 --> 00:08:06,433
所以这里其实（要表达的是）

279
00:08:06,433 --> 00:08:08,766
为什么AI研究员

280
00:08:08,766 --> 00:08:10,766
（整体）还是薪资比较高

281
00:08:10,766 --> 00:08:12,066
我觉得很多时候是这样

282
00:08:12,200 --> 00:08:13,700
就是你的一个insights（能力）可以

283
00:08:13,700 --> 00:08:15,400
比如说可以抵100块卡

284
00:08:15,433 --> 00:08:16,300
或者说抵1000块卡

285
00:08:16,300 --> 00:08:18,066
一万张卡等 就是比如我不需要那么多卡

286
00:08:18,066 --> 00:08:19,266
但是我还是有insights

287
00:08:19,266 --> 00:08:20,833
可以得到一些比较好的结论

288
00:08:21,266 --> 00:08:23,166
这个是

289
00:08:23,166 --> 00:08:24,633
很重要的

290
00:08:24,866 --> 00:08:26,033
你刚才用了两个词

291
00:08:26,033 --> 00:08:26,866
一个是经验

292
00:08:26,866 --> 00:08:27,900
一个是insights

293
00:08:27,900 --> 00:08:29,200
然后我想double click一下

294
00:08:29,200 --> 00:08:31,566
就是这个到底是个什么东西

295
00:08:31,566 --> 00:08:33,033
有的人会觉得这是一个taste

296
00:08:33,033 --> 00:08:34,566
有的人会觉得是个intuition

297
00:08:34,566 --> 00:08:37,166
对吧 我们有好多词去形容这个东西

298
00:08:37,400 --> 00:08:39,366
那你觉得这个东西到底是个什么

299
00:08:39,466 --> 00:08:40,966
就是

300
00:08:40,966 --> 00:08:42,566
刚刚已经有四个词了

301
00:08:42,566 --> 00:08:42,800
对吧

302
00:08:42,800 --> 00:08:44,866
然后四个词说的好像都是一件事

303
00:08:44,866 --> 00:08:48,833
嗯嗯 那你能不能就是给大家讲一讲

304
00:08:48,833 --> 00:08:50,366
从你的经验来说

305
00:08:50,600 --> 00:08:51,800
你用多长时间

306
00:08:51,800 --> 00:08:54,400
能判断一个人 有这个还是没有这个

307
00:08:54,400 --> 00:08:56,666
然后你觉得他有的话

308
00:08:56,666 --> 00:08:57,833
他除了像你刚刚说的

309
00:08:57,833 --> 00:08:59,200
就是从很小的数据点

310
00:08:59,200 --> 00:09:01,300
就能得出来一个更正确的结论

311
00:09:01,300 --> 00:09:03,666
他可能背后的mental model更好以外

312
00:09:03,666 --> 00:09:04,600
还有什么展现

313
00:09:04,600 --> 00:09:06,600
以及怎么得到这个东西

314
00:09:06,766 --> 00:09:07,766
对

315
00:09:07,766 --> 00:09:08,766
这个我觉得是这样

316
00:09:08,766 --> 00:09:09,800
就是Insights呢

317
00:09:09,800 --> 00:09:11,700
是一个比较

318
00:09:12,166 --> 00:09:14,800
很难描述的一个概念 就是说

319
00:09:15,366 --> 00:09:16,600
其实是这样

320
00:09:16,600 --> 00:09:17,400
就是

321
00:09:17,466 --> 00:09:19,500
特别是一个有经验的人

322
00:09:19,500 --> 00:09:21,366
对吧 比如说在某方面他是位“老师傅”

323
00:09:21,566 --> 00:09:22,500
那么他怎么做

324
00:09:22,500 --> 00:09:24,233
就是他要根据很少的数据

325
00:09:24,233 --> 00:09:26,766
然后判断他就是这个现象

326
00:09:26,766 --> 00:09:29,366
背后的真正原因是什么

327
00:09:29,366 --> 00:09:30,166
这个是重要的

328
00:09:30,166 --> 00:09:31,633
就是比如说一个修车师傅

329
00:09:31,833 --> 00:09:33,666
他可能根据蛛丝马迹

330
00:09:33,666 --> 00:09:34,833
会知道你车哪里坏了

331
00:09:35,233 --> 00:09:36,366
明白别人（在）还没有

332
00:09:36,366 --> 00:09:37,966
反应过来就（知道）说这个车哪里坏了

333
00:09:38,000 --> 00:09:39,433
或者说股票交易员

334
00:09:39,433 --> 00:09:39,966
比如说操盘

335
00:09:39,966 --> 00:09:40,466
操盘的时候

336
00:09:40,466 --> 00:09:42,066
比如说有一个

337
00:09:42,066 --> 00:09:43,100
做股票交易的

338
00:09:43,100 --> 00:09:45,300
那我说我根据这两个迹象

339
00:09:45,300 --> 00:09:46,166
或者看看财报

340
00:09:46,166 --> 00:09:46,833
嗯

341
00:09:46,833 --> 00:09:49,466
比如这个这个股票（等）不能买

342
00:09:49,466 --> 00:09:51,500
所以这种东西（能力）是很重要

343
00:09:51,500 --> 00:09:52,100
然后他也不知道

344
00:09:52,100 --> 00:09:53,033
也讲不清楚到底怎么回事

345
00:09:53,033 --> 00:09:54,166
他就有种感觉说

346
00:09:54,166 --> 00:09:55,200
这个不行 那个行

347
00:09:55,200 --> 00:09:56,233
有一个mental model

348
00:09:56,233 --> 00:09:58,600
然后这个mental model大概率是对的

349
00:09:59,000 --> 00:10:00,833
所以这个（能力项）很重要了

350
00:10:00,833 --> 00:10:03,000
就是有这些东西之后

351
00:10:03,000 --> 00:10:06,033
其实就是很快能够发现问题在哪

352
00:10:06,300 --> 00:10:08,500
然后有这问题我们怎么样

353
00:10:08,500 --> 00:10:09,433
怎么样去解决

354
00:10:09,433 --> 00:10:10,300
去解决这个问题

355
00:10:10,300 --> 00:10:12,200
然后然后往正确方向去走嘛

356
00:10:12,433 --> 00:10:13,366
这个是

357
00:10:13,366 --> 00:10:15,666
可能比GPU还要重要

358
00:10:15,666 --> 00:10:17,000
对 当然了GPU也很重要了

359
00:10:17,000 --> 00:10:18,466
就是有GPU之后你会做更多实验

360
00:10:18,466 --> 00:10:20,033
获得更多的Insights

361
00:10:20,033 --> 00:10:22,400
所以这两个是相辅相成的

362
00:10:22,400 --> 00:10:23,266
应该这么说

363
00:10:24,033 --> 00:10:26,466
你能很快的判断另外一个人

364
00:10:26,466 --> 00:10:28,400
有没有一个好的mental model吗

365
00:10:29,766 --> 00:10:31,033
（补充问题）在你的领域里？

366
00:10:31,166 --> 00:10:32,433
这其实是有一些办法

367
00:10:32,433 --> 00:10:34,500
就是说 你要跟别人聊嘛

368
00:10:34,500 --> 00:10:36,766
然后大概聊一下

369
00:10:36,766 --> 00:10:39,033
感觉一下他平时对这问题是怎么想的

370
00:10:39,033 --> 00:10:40,866
我觉得这个其实挺重要的

371
00:10:41,100 --> 00:10:42,633
对 其实我可以举个例子吧

372
00:10:42,633 --> 00:10:44,066
比如说

373
00:10:45,033 --> 00:10:48,366
比如说那个学校里面有这种PhD exam啊

374
00:10:48,366 --> 00:10:50,666
就是说PhD quantifier啊

375
00:10:50,666 --> 00:10:52,966
就是说一个学生

376
00:10:52,966 --> 00:10:54,166
坐在那个

377
00:10:54,166 --> 00:10:55,600
教室中的一堆老师们面前

378
00:10:55,833 --> 00:10:57,000
然后老师问他

379
00:10:57,000 --> 00:10:57,466
就是

380
00:10:57,466 --> 00:10:59,833
我请问你 对这个问题有什么了解

381
00:10:59,833 --> 00:11:01,966
比如说我们讨论一些学术问题

382
00:11:01,966 --> 00:11:03,833
那么对这老师来说

383
00:11:03,833 --> 00:11:06,166
他想办法就问到底

384
00:11:06,166 --> 00:11:07,433
就是比如说

385
00:11:07,433 --> 00:11:09,466
你对这个偏微分方程

386
00:11:09,466 --> 00:11:10,033
有什么想法

387
00:11:10,033 --> 00:11:10,833
然后你有什么

388
00:11:10,833 --> 00:11:12,566
比如12345等经验

389
00:11:12,800 --> 00:11:14,400
然后就会抓住一个点

390
00:11:14,400 --> 00:11:15,366
然后使劲问

391
00:11:15,366 --> 00:11:16,866
问到

392
00:11:16,866 --> 00:11:19,500
问到就是你能（了解到）他到底懂不懂

393
00:11:19,500 --> 00:11:21,700
他到底知道这里面之间什么关系

394
00:11:21,700 --> 00:11:24,066
这个是能用最简单的语言讲清楚

395
00:11:24,400 --> 00:11:25,600
对 然后就能够知道

396
00:11:25,600 --> 00:11:28,233
最重要的两个东西的关联是什么

397
00:11:28,233 --> 00:11:29,233
那么这样的话

398
00:11:29,233 --> 00:11:30,633
就知道这他真是懂的

399
00:11:30,700 --> 00:11:32,466
或者说他真的是知道这是最关键的

400
00:11:32,466 --> 00:11:33,033
关联在哪里

401
00:11:33,033 --> 00:11:35,600
然后可以用这关联去做更多的

402
00:11:35,600 --> 00:11:36,766
（比如）推广等

403
00:11:36,766 --> 00:11:37,633
这个是重要的

404
00:11:37,633 --> 00:11:39,700
就是因为比如说像

405
00:11:39,700 --> 00:11:41,166
做研究的话

406
00:11:41,166 --> 00:11:42,300
比较忌讳的是说

407
00:11:42,933 --> 00:11:44,033
我就只懂书面知识

408
00:11:44,033 --> 00:11:44,633
（比如有）12345

409
00:11:44,633 --> 00:11:45,433
背出来了

410
00:11:45,466 --> 00:11:46,633
概念套概念

411
00:11:46,633 --> 00:11:48,066
但是他们（之间）有什么关系

412
00:11:48,066 --> 00:11:48,566
然后什么时候

413
00:11:48,566 --> 00:11:49,100
他们两个（在什么条件下）

414
00:11:49,100 --> 00:11:50,033
能不能成立

415
00:11:50,100 --> 00:11:51,200
什么时候要 a into b

416
00:11:51,200 --> 00:11:52,666
什么时候a into c

417
00:11:52,666 --> 00:11:54,600
这个并不知道的话

418
00:11:54,600 --> 00:11:56,800
其实是比较

419
00:11:56,800 --> 00:11:58,166
比较难搞的

420
00:11:58,166 --> 00:12:00,200
我觉得这个是一个问题

421
00:12:00,500 --> 00:12:02,433
对 其实这个很重要

422
00:12:02,433 --> 00:12:03,233
就这说实在的

423
00:12:03,233 --> 00:12:05,900
是我觉得现在的模型才做不到的地方

424
00:12:06,266 --> 00:12:07,300
对 现在模型可能

425
00:12:07,300 --> 00:12:08,833
没有办法用很少的数据

426
00:12:08,833 --> 00:12:10,466
真的去预测将来的

427
00:12:10,466 --> 00:12:11,400
那个结果

428
00:12:11,466 --> 00:12:14,600
对 所以

429
00:12:14,600 --> 00:12:14,800
所以

430
00:12:14,800 --> 00:12:16,466
这个可能是现在人的一些能力

431
00:12:16,466 --> 00:12:18,066
那我们就直接到这个话题吧

432
00:12:18,066 --> 00:12:19,033
我觉得这个话题本身

433
00:12:19,033 --> 00:12:20,833
也是你研究的一个

434
00:12:20,833 --> 00:12:21,433
重点 就是

435
00:12:21,433 --> 00:12:23,800
或者说我一开始想访谈你的原因

436
00:12:23,800 --> 00:12:25,000
嗯嗯

437
00:12:26,266 --> 00:12:27,800
你的论文是Groking

438
00:12:27,966 --> 00:12:28,266
嗯嗯

439
00:12:28,266 --> 00:12:30,366
但它是一个底层的这么一个

440
00:12:30,366 --> 00:12:32,600
就是在一个时间点

441
00:12:32,600 --> 00:12:34,866
它有了一个学习的这样的东西

442
00:12:34,866 --> 00:12:35,766
顿悟的感觉

443
00:12:35,766 --> 00:12:37,200
是吧 嗯嗯

444
00:12:37,633 --> 00:12:40,233
对我在看你跟志渊的专访

445
00:12:40,233 --> 00:12:42,600
里边 你也提到一个点

446
00:12:42,600 --> 00:12:44,566
就是

447
00:12:45,500 --> 00:12:47,466
那个鸽子问题嘛

448
00:12:47,466 --> 00:12:48,700
对

449
00:12:48,700 --> 00:12:49,600
鸽子问题

450
00:12:49,666 --> 00:12:50,200
然后你是

451
00:12:50,200 --> 00:12:50,866
你

452
00:12:50,866 --> 00:12:52,066
当时和丹利.周

453
00:12:52,066 --> 00:12:53,500
在这个Twitter上的

454
00:12:53,500 --> 00:12:55,266
关于chain-of-thought的一些讨论

455
00:12:55,266 --> 00:12:57,366
嗯嗯 就是说确实

456
00:12:57,366 --> 00:12:57,833
理论上

457
00:12:57,833 --> 00:13:00,766
你的这个逻辑能表述

458
00:13:00,766 --> 00:13:01,366
chain-of-thought

459
00:13:01,366 --> 00:13:03,400
就似乎可以解

460
00:13:03,700 --> 00:13:06,600
但是模型会用无限的数据

461
00:13:06,600 --> 00:13:08,233
去试图解决这个问题

462
00:13:08,233 --> 00:13:08,466
但是

463
00:13:08,466 --> 00:13:10,266
人似乎一下子就能get到这个问题

464
00:13:10,266 --> 00:13:11,033
嗯嗯

465
00:13:11,033 --> 00:13:14,566
我觉得和你刚说的那个东西

466
00:13:14,566 --> 00:13:16,900
有一些联系

467
00:13:16,900 --> 00:13:18,066
嗯嗯 然后

468
00:13:18,466 --> 00:13:19,766
但是

469
00:13:19,766 --> 00:13:22,266
如果你来定义这个能力的话

470
00:13:22,266 --> 00:13:23,666
你会把它定义成reasoning吗

471
00:13:23,666 --> 00:13:25,300
还是你把它定义成一个什么

472
00:13:25,833 --> 00:13:26,600
这个顿悟呢

473
00:13:26,600 --> 00:13:27,466
应该说呢

474
00:13:27,466 --> 00:13:28,400
并不一定是

475
00:13:28,400 --> 00:13:30,200
就是它是在reasoning

476
00:13:30,200 --> 00:13:32,633
或者说其他的一些task下面

477
00:13:33,000 --> 00:13:34,600
就说这个机制

478
00:13:34,600 --> 00:13:35,500
下面是什么意思

479
00:13:35,500 --> 00:13:36,433
是更底层的意思还是什么

480
00:13:36,433 --> 00:13:37,400
是更底层的意思

481
00:13:37,600 --> 00:13:39,466
就是说它是一个表关学习（表示学习）

482
00:13:39,466 --> 00:13:41,600
就是representation learning的一些行为

483
00:13:41,866 --> 00:13:45,633
就是 我随着这个训练的

484
00:13:45,633 --> 00:13:46,400
拓展

485
00:13:46,400 --> 00:13:47,700
你会发现

486
00:13:47,866 --> 00:13:51,233
它的表征会改变

487
00:13:51,433 --> 00:13:52,566
就是一开始就说

488
00:13:52,566 --> 00:13:54,433
这就相当于比如说

489
00:13:54,433 --> 00:13:56,266
你看金庸小说

490
00:13:56,266 --> 00:13:59,066
然后张无忌 一开始被他义父谢逊逼着

491
00:13:59,066 --> 00:14:00,300
需要你把东西全背出来

492
00:14:00,500 --> 00:14:01,233
说先把东西全背

493
00:14:01,233 --> 00:14:02,033
背出来之后

494
00:14:02,033 --> 00:14:03,100
然后对

495
00:14:03,100 --> 00:14:03,866
先反复

496
00:14:03,866 --> 00:14:04,600
先全背出来

497
00:14:04,600 --> 00:14:05,766
背出来之后 你不懂没关系

498
00:14:05,766 --> 00:14:07,566
但是 不懂你可以脑子里存着

499
00:14:07,566 --> 00:14:09,033
然后过了几年之后

500
00:14:09,033 --> 00:14:11,033
突然之间就 连了乾坤大挪移

501
00:14:11,033 --> 00:14:12,166
突然懂了

502
00:14:12,233 --> 00:14:13,100
啊 是是

503
00:14:13,100 --> 00:14:13,566
这样子

504
00:14:13,566 --> 00:14:15,166
就是这个是很有意思的

505
00:14:15,166 --> 00:14:17,033
一个机制嘛

506
00:14:17,233 --> 00:14:19,033
其实 比如说你当时教小孩子

507
00:14:19,033 --> 00:14:19,566
可能也是这样

508
00:14:19,566 --> 00:14:21,966
特别是教有些小孩说

509
00:14:21,966 --> 00:14:22,966
你先把它背出来

510
00:14:22,966 --> 00:14:25,500
这个叫“读书百遍其义自现”

511
00:14:25,666 --> 00:14:27,100
就是你现在先读

512
00:14:27,100 --> 00:14:28,500
读了之后你并不知道什么意思

513
00:14:28,500 --> 00:14:30,433
但是过一段时间之后

514
00:14:30,433 --> 00:14:32,400
或者说你跟其他的一些事情

515
00:14:32,400 --> 00:14:33,866
能够联系在一起了

516
00:14:33,866 --> 00:14:34,400
之后呢

517
00:14:34,400 --> 00:14:36,100
那

518
00:14:36,100 --> 00:14:36,800
这样的话

519
00:14:36,800 --> 00:14:39,400
你就会有一个 就突然之间你会觉得

520
00:14:39,400 --> 00:14:39,700
哎 这个

521
00:14:39,700 --> 00:14:40,233
这个意思

522
00:14:40,233 --> 00:14:42,300
是跟我这个现实世界是有关系的

523
00:14:42,366 --> 00:14:44,000
或者说 这两个意思之间是有关联的

524
00:14:44,000 --> 00:14:45,766
我们知道更深的联系

525
00:14:45,966 --> 00:14:49,066
这种其实就是应该说是顿悟的一部分

526
00:14:49,300 --> 00:14:53,266
对 那这个是机制 其实是

527
00:14:53,266 --> 00:14:55,266
就是思维链之下的

528
00:14:55,766 --> 00:14:59,266
就说不管你用思维链做

529
00:14:59,266 --> 00:15:00,800
做思维训练也好

530
00:15:00,833 --> 00:15:02,900
不管你用那个直觉

531
00:15:02,900 --> 00:15:05,066
来判断那个答案也好

532
00:15:05,166 --> 00:15:07,433
或者不管你用啥方式来判断答案也好

533
00:15:07,433 --> 00:15:09,233
对吧 那么这些东西

534
00:15:09,366 --> 00:15:11,033
它的下面有一个共同的机制

535
00:15:11,033 --> 00:15:13,866
就是说 我到底用什么样的表示

536
00:15:13,866 --> 00:15:17,466
用什么样的 对这个世界的理解

537
00:15:17,466 --> 00:15:19,266
导致了这个思维链

538
00:15:19,266 --> 00:15:20,300
就比如说我举个例子吧

539
00:15:20,300 --> 00:15:21,100
嗯

540
00:15:21,400 --> 00:15:22,666
比如说吧

541
00:15:22,666 --> 00:15:24,366
那个小学生做一道题

542
00:15:24,366 --> 00:15:25,233
对吧 他可能说

543
00:15:25,233 --> 00:15:25,966
我这道题怎么做

544
00:15:25,966 --> 00:15:27,433
我用穷举法啊

545
00:15:27,433 --> 00:15:29,700
那个11+1等于1+1等于多少

546
00:15:29,700 --> 00:15:30,566
1+2等于1+3等于多少

547
00:15:30,566 --> 00:15:32,466
那么有一些 穷举的一个路径

548
00:15:32,466 --> 00:15:34,166
可以把这个事情做了

549
00:15:34,166 --> 00:15:36,366
比如说 你要证明一个简单的一道习题

550
00:15:36,366 --> 00:15:37,366
那么小学生会说

551
00:15:37,366 --> 00:15:39,266
我穷举一些答案

552
00:15:39,400 --> 00:15:40,300
看答案差不多了

553
00:15:40,300 --> 00:15:41,466
那可能就对了

554
00:15:41,466 --> 00:15:42,466
这是做法

555
00:15:42,666 --> 00:15:43,200
这种做法

556
00:15:43,200 --> 00:15:45,300
但是你这种方式呢

557
00:15:45,300 --> 00:15:47,600
其实可能很多方面解决不了

558
00:15:47,633 --> 00:15:50,266
那么等到 比如说初中生或者高中生

559
00:15:50,266 --> 00:15:53,400
他们的这个思维其实有种飞跃

560
00:15:53,400 --> 00:15:54,233
什么叫飞跃呢

561
00:15:54,233 --> 00:15:55,366
就是说

562
00:15:55,366 --> 00:15:56,300
我们告诉它

563
00:15:56,300 --> 00:15:57,900
我们可以用数学归纳法

564
00:15:57,900 --> 00:15:58,866
来解决这个问题

565
00:15:59,233 --> 00:16:00,900
那么数学归纳法这个思维

566
00:16:00,900 --> 00:16:02,033
这个思维

567
00:16:02,033 --> 00:16:02,433
这个层次

568
00:16:02,433 --> 00:16:04,066
是高于就是穷举法的

569
00:16:04,300 --> 00:16:05,466
就如果你的数学归纳法

570
00:16:05,466 --> 00:16:07,266
能够证明这个事情是对的

571
00:16:07,466 --> 00:16:09,433
那如果能证明是对的

572
00:16:09,433 --> 00:16:09,566
那么

573
00:16:09,566 --> 00:16:12,300
它就对所有的那个自然数都成立

574
00:16:12,300 --> 00:16:13,033
那这样的话

575
00:16:13,033 --> 00:16:14,033
我的穷举法

576
00:16:14,033 --> 00:16:16,000
就穷举无穷长的那个思维链

577
00:16:16,033 --> 00:16:17,766
它其实都比不过数学归纳法的

578
00:16:17,766 --> 00:16:19,400
很短的证明啊

579
00:16:19,400 --> 00:16:20,900
所以这个是一个飞跃

580
00:16:20,900 --> 00:16:21,666
就是说这样的话

581
00:16:21,666 --> 00:16:24,633
你对这个问题的理解跟那个两种方式

582
00:16:24,633 --> 00:16:25,166
的思维链

583
00:16:25,166 --> 00:16:27,233
它的后面的理解是不一样的

584
00:16:27,233 --> 00:16:29,233
所以这个理解或者说这个表示呢

585
00:16:29,233 --> 00:16:31,200
其实就是神经网络学习的一个重要的

586
00:16:31,200 --> 00:16:33,366
一个不同的地方

587
00:16:33,366 --> 00:16:34,833
我不知道我我讲清楚了没有

588
00:16:35,100 --> 00:16:36,066
很清楚

589
00:16:36,066 --> 00:16:37,800
然后我想跟你对齐一个认知

590
00:16:37,800 --> 00:16:39,100
然后给你看一个

591
00:16:39,600 --> 00:16:41,200
一个东西吧 嗯嗯

592
00:16:42,666 --> 00:16:44,166
就是当时我引用的

593
00:16:44,166 --> 00:16:45,266
就是我们不是教课嘛

594
00:16:45,266 --> 00:16:46,566
然后我们教课的时候

595
00:16:46,700 --> 00:16:48,800
我自己发现

596
00:16:48,900 --> 00:16:52,300
就是当时是伊利亚去

597
00:16:52,300 --> 00:16:53,466
MIT 就是

598
00:16:54,966 --> 00:16:55,800
几年前的时候

599
00:16:55,800 --> 00:16:57,833
2016年的时候 他去讲的

600
00:16:57,833 --> 00:16:59,066
嗯嗯 那个时候还

601
00:16:59,166 --> 00:17:00,633
不是

602
00:17:00,633 --> 00:17:01,500
现在这样子

603
00:17:01,600 --> 00:17:02,066
嗯嗯

604
00:17:02,066 --> 00:17:03,833
总之他当时讲了一个东西

605
00:17:03,833 --> 00:17:05,700
我觉得他说的很深刻

606
00:17:05,700 --> 00:17:07,033
他当时 他觉得很深刻

607
00:17:07,033 --> 00:17:09,466
但是似乎听众没有觉得很深刻

608
00:17:09,466 --> 00:17:09,766
嗯嗯

609
00:17:09,766 --> 00:17:14,166
就说为什么back propagation会work at all

610
00:17:14,266 --> 00:17:15,000
对 为什么

611
00:17:15,000 --> 00:17:15,666
new work呃

612
00:17:15,666 --> 00:17:17,633
然后就是这个

613
00:17:17,800 --> 00:17:20,766
就是theoretically optimal hypothesis class

614
00:17:20,766 --> 00:17:22,366
等于short programs

615
00:17:22,366 --> 00:17:22,700
对

616
00:17:22,700 --> 00:17:25,033
对 就听你刚那个意思

617
00:17:25,033 --> 00:17:28,500
也是就是 本来我要去走好多条点

618
00:17:28,500 --> 00:17:29,000
走到这

619
00:17:29,000 --> 00:17:31,100
然后突然找到了一个更好的联系

620
00:17:31,100 --> 00:17:32,500
然后我就有一个更好的压缩

621
00:17:32,500 --> 00:17:34,100
然后它就更generalizable

622
00:17:34,200 --> 00:17:35,000
对

623
00:17:35,466 --> 00:17:36,033
对

624
00:17:36,033 --> 00:17:36,500
这么说嘛

625
00:17:36,500 --> 00:17:37,766
就是说因为压缩

626
00:17:37,766 --> 00:17:39,866
可能也可以说是更通俗的解释

627
00:17:40,066 --> 00:17:42,500
对吧 但是什么时候这事情能压缩

628
00:17:42,500 --> 00:17:44,666
什么事情这些不能压缩

629
00:17:44,666 --> 00:17:46,200
其实现在不是很清楚

630
00:17:46,200 --> 00:17:46,566
就是

631
00:17:46,566 --> 00:17:48,600
为什么你要去研究grokking这个机制

632
00:17:48,700 --> 00:17:51,600
就是说 它给你提供了一个动力学过程

633
00:17:51,600 --> 00:17:53,033
就是让你知道

634
00:17:53,033 --> 00:17:55,500
它怎么从一个不压缩的状态

635
00:17:55,500 --> 00:17:56,500
变成压缩的状态

636
00:17:56,500 --> 00:17:57,200
你可以这么想

637
00:17:57,200 --> 00:17:58,866
然后我再说一下

638
00:17:58,866 --> 00:18:00,500
就是我接下来问题问问你

639
00:18:00,500 --> 00:18:02,033
一个问题的铺垫

640
00:18:02,033 --> 00:18:02,800
就是我会发现

641
00:18:02,800 --> 00:18:04,700
这个和人类理解知识的

642
00:18:04,966 --> 00:18:05,966
似乎也很接近

643
00:18:05,966 --> 00:18:06,966
就是这个

644
00:18:06,966 --> 00:18:09,833
人类也是information connect us形成knowledge

645
00:18:09,833 --> 00:18:09,866
对

646
00:18:09,866 --> 00:18:12,966
但是这个图是在neural network之前出现了

647
00:18:13,000 --> 00:18:13,600
对 而且啊

648
00:18:13,600 --> 00:18:14,566
很多教育专家

649
00:18:14,566 --> 00:18:16,766
他会发现就是人

650
00:18:17,033 --> 00:18:18,066
我记得在群里面

651
00:18:18,066 --> 00:18:19,066
赵志诚我讲说

652
00:18:19,066 --> 00:18:21,800
reasoning是一个人类固执的幻觉

653
00:18:21,800 --> 00:18:23,466
对 然后这个教育专家说

654
00:18:23,466 --> 00:18:26,666
the most important single factor is prior knowledge

655
00:18:26,700 --> 00:18:28,266
对 你只要有prior knowledge就行了

656
00:18:28,266 --> 00:18:29,866
你知道这个prior knowledge

657
00:18:29,900 --> 00:18:32,300
然后然后就就就就

658
00:18:32,300 --> 00:18:34,466
就没有什么聪明不聪明这种说法吧

659
00:18:34,466 --> 00:18:34,900
反正

660
00:18:34,900 --> 00:18:36,800
你只要把这个大学全都collect起来了

661
00:18:36,800 --> 00:18:37,833
似乎就可以

662
00:18:37,833 --> 00:18:38,800
嗯嗯

663
00:18:38,800 --> 00:18:41,400
这就是 我接下来问题的这个铺垫

664
00:18:41,400 --> 00:18:43,566
那接下来的问题就是

665
00:18:44,166 --> 00:18:47,200
我们不知道 我们的这些knowledge

666
00:18:47,200 --> 00:18:49,100
就是connect us是怎么形成的

667
00:18:49,100 --> 00:18:51,433
对 我们没有办法去讲清楚

668
00:18:51,433 --> 00:18:53,600
对 然后我们也不知道

669
00:18:53,600 --> 00:18:55,833
就是 我觉得甚至在我心中

670
00:18:55,833 --> 00:18:59,500
我不知道哪些knowledge是这个对

671
00:18:59,566 --> 00:19:00,100
是那个dots

672
00:19:00,100 --> 00:19:01,466
哪些是那个东西

673
00:19:01,466 --> 00:19:02,266
还有

674
00:19:02,266 --> 00:19:03,366
在大模型里边

675
00:19:03,366 --> 00:19:06,433
你说在大模型里训练的过程中

676
00:19:06,433 --> 00:19:07,966
似乎大家也不是很清楚

677
00:19:08,066 --> 00:19:08,866
嗯嗯

678
00:19:09,566 --> 00:19:10,066
对 就是

679
00:19:10,066 --> 00:19:11,033
所以就是为什么

680
00:19:11,033 --> 00:19:13,066
搞清楚其实可能会孕育着

681
00:19:13,066 --> 00:19:15,100
就是下一个模型的一个契机嘛

682
00:19:15,266 --> 00:19:16,566
对吧 如果你搞清楚了之后

683
00:19:16,566 --> 00:19:18,066
你就知道什么地方你要修改

684
00:19:18,200 --> 00:19:20,033
这样的话你就模型变得更强啊

685
00:19:20,033 --> 00:19:21,366
所以这是也是个动力

686
00:19:21,366 --> 00:19:22,866
就是因为我们现在就是

687
00:19:22,866 --> 00:19:23,266
如果可以

688
00:19:23,266 --> 00:19:24,000
你看可以满足说

689
00:19:24,000 --> 00:19:24,900
我不我不把搞清楚

690
00:19:24,900 --> 00:19:25,866
我把当黑盒子

691
00:19:26,033 --> 00:19:27,600
然后我就上面调各种参数

692
00:19:27,633 --> 00:19:28,900
开一个相当于一个很大的开关

693
00:19:28,900 --> 00:19:30,633
有很多的开关 对吧

694
00:19:30,633 --> 00:19:33,166
像以前那种电脑屏幕以前的那个

695
00:19:33,166 --> 00:19:34,400
那个大型机

696
00:19:34,400 --> 00:19:36,100
然后有非常多的按钮开关

697
00:19:36,100 --> 00:19:37,200
然后就是

698
00:19:37,200 --> 00:19:39,200
我们就培养操作员坐在上面

699
00:19:39,200 --> 00:19:40,700
然后我把按钮开关开开

700
00:19:40,700 --> 00:19:41,500
就是各种组合

701
00:19:41,500 --> 00:19:42,600
然后看效果怎么样

702
00:19:42,800 --> 00:19:43,700
那这是一种方案

703
00:19:43,800 --> 00:19:44,233
那另外一种方案

704
00:19:44,233 --> 00:19:47,100
就是说我们要把这个大的机器打开

705
00:19:47,266 --> 00:19:48,766
然后理解里面的机制是什么

706
00:19:48,766 --> 00:19:50,566
然后有这个机制的理解之后

707
00:19:50,666 --> 00:19:53,066
那我以后再去播这开关的时候呢

708
00:19:53,066 --> 00:19:54,300
就非常有感觉

709
00:19:54,300 --> 00:19:56,100
我就非常知道哪些开关要开

710
00:19:56,100 --> 00:19:56,666
哪些开关要关

711
00:19:56,666 --> 00:19:57,800
能把这个做出来

712
00:19:57,800 --> 00:19:58,833
这个是

713
00:19:58,833 --> 00:19:59,966
我觉得这可能是一个更好的

714
00:19:59,966 --> 00:20:01,366
一个做法啊

715
00:20:01,366 --> 00:20:04,566
当然就是说 现在可能就是主流的

716
00:20:04,566 --> 00:20:05,866
思维 其实并不是这么说

717
00:20:05,866 --> 00:20:06,766
并主流思维 觉得

718
00:20:06,766 --> 00:20:08,400
（比如）我们就叫做scaling law

719
00:20:08,500 --> 00:20:09,033
我说

720
00:20:09,033 --> 00:20:11,800
我不需要搞清楚你们在干什么

721
00:20:11,800 --> 00:20:12,800
我只需要知道

722
00:20:12,800 --> 00:20:15,566
就（比如）机器量有很多很多

723
00:20:15,766 --> 00:20:17,866
然后我放很多有分量厉害的人进去

724
00:20:18,066 --> 00:20:20,100
然后呢 让他们去拨那些开关

725
00:20:20,100 --> 00:20:22,566
然后这些开关的某种组合找到了

726
00:20:22,633 --> 00:20:24,833
那我们就能够把这个模型做的很强

727
00:20:24,966 --> 00:20:26,000
这两种不同的思维

728
00:20:26,000 --> 00:20:26,866
不同的思维

729
00:20:26,866 --> 00:20:28,033
应该这么说

730
00:20:28,033 --> 00:20:29,066
但哪种是对的呢

731
00:20:29,066 --> 00:20:30,666
现在也不好说对吧

732
00:20:30,666 --> 00:20:33,666
因为现在确实scaling law有很大的应用

733
00:20:33,666 --> 00:20:35,800
然后确实那个效果也非常好

734
00:20:36,033 --> 00:20:38,966
所以至少目前为止看起来就是

735
00:20:39,200 --> 00:20:40,400
就是 我把当作黑盒子

736
00:20:40,400 --> 00:20:43,033
然后让很多人去碰开关

737
00:20:43,266 --> 00:20:44,466
得到一个更好的解

738
00:20:44,466 --> 00:20:46,800
是一个比较好的方案

739
00:20:46,900 --> 00:20:47,666
然后另外一方面

740
00:20:47,666 --> 00:20:50,100
就是你从把那个模型打开那个

741
00:20:50,100 --> 00:20:52,400
那个时间花的代价其实更大

742
00:20:52,400 --> 00:20:54,200
因为其实并没有多少人真的知道

743
00:20:54,200 --> 00:20:55,833
这模型里面在干什么

744
00:20:55,833 --> 00:20:58,466
但是我觉得长远来说可能后者呢

745
00:20:58,700 --> 00:21:00,566
会有更高的天花板吧

746
00:21:00,666 --> 00:21:01,900
这个是我的想法

747
00:21:02,066 --> 00:21:04,766
嗯 我同意你的判断

748
00:21:04,766 --> 00:21:08,900
对 但这里边有这么一个点

749
00:21:08,900 --> 00:21:09,366
就是我觉得

750
00:21:09,366 --> 00:21:13,300
为什么黑盒子现在它是占主流

751
00:21:13,833 --> 00:21:18,600
因为打开了以后人类似乎也没有办法

752
00:21:19,033 --> 00:21:24,100
嗯 真的去判断什么东西是什么

753
00:21:24,100 --> 00:21:26,500
就是这里边有几种学习范式或者怎样

754
00:21:26,500 --> 00:21:28,033
对对

755
00:21:28,033 --> 00:21:29,400
现在是这样

756
00:21:29,400 --> 00:21:31,866
所以就是能不能找到一个比较好的

757
00:21:32,200 --> 00:21:35,100
能够理解整个结构的一个大的框架

758
00:21:35,100 --> 00:21:36,300
是重要的

759
00:21:36,300 --> 00:21:38,166
所以是这样

760
00:21:38,166 --> 00:21:39,566
就是为什么我做成paper的原因

761
00:21:39,566 --> 00:21:41,100
就是比如最近有一篇paper

762
00:21:41,100 --> 00:21:41,833
我们做Grokking对吧

763
00:21:41,833 --> 00:21:42,666
那么证明这篇paper

764
00:21:42,666 --> 00:21:44,200
为什么要做这个paper

765
00:21:44,300 --> 00:21:46,433
所以我觉得就是通过这个方式

766
00:21:46,433 --> 00:21:47,233
得到一个

767
00:21:47,300 --> 00:21:48,700
对这个问题的一个大的理解框架

768
00:21:48,700 --> 00:21:51,266
可能对以后的那个模型的改进

769
00:21:51,266 --> 00:21:52,066
有很大帮助

770
00:21:52,066 --> 00:21:53,233
这个是我的想法

771
00:21:53,266 --> 00:21:54,266
嗯嗯

772
00:21:54,266 --> 00:21:56,633
我再多引入

773
00:21:56,633 --> 00:21:57,633
本来已经有点复杂了

774
00:21:57,633 --> 00:21:58,166
但是我觉得

775
00:21:58,166 --> 00:21:59,866
我再多引入一个问题啊

776
00:21:59,866 --> 00:22:01,233
嗯嗯 就是

777
00:22:01,266 --> 00:22:04,366
似乎我们在学习AI怎么学习的过程中

778
00:22:04,366 --> 00:22:05,566
我们会从人类身上

779
00:22:05,566 --> 00:22:06,700
人类的学习过程中

780
00:22:06,700 --> 00:22:07,700
取得灵感

781
00:22:07,700 --> 00:22:08,266
嗯嗯

782
00:22:08,266 --> 00:22:10,866
包括最近很火的就是

783
00:22:10,866 --> 00:22:13,800
Rich Sutton出来说RL是学习的方式

784
00:22:13,800 --> 00:22:15,266
是人类学习的方式

785
00:22:15,766 --> 00:22:18,033
大约模型这种方式不是要学习方式

786
00:22:18,033 --> 00:22:19,033
它也不能学习

787
00:22:19,033 --> 00:22:20,400
因为它没有objective

788
00:22:20,433 --> 00:22:21,666
对对 那另外一派呢

789
00:22:21,666 --> 00:22:24,700
可能我反而认为是Hinton而不是Karpathy

790
00:22:25,033 --> 00:22:26,033
Hinton他说就是

791
00:22:26,033 --> 00:22:27,266
他还举了例子嘛

792
00:22:27,266 --> 00:22:28,033
就是松鼠啊

793
00:22:28,033 --> 00:22:28,500
或者说是

794
00:22:28,500 --> 00:22:29,266
这个机器

795
00:22:29,266 --> 00:22:30,433
它就是

796
00:22:30,633 --> 00:22:32,666
这是我们所说的这种物理世界

797
00:22:32,666 --> 00:22:34,700
其实并不是一就是就是经验

798
00:22:34,700 --> 00:22:36,833
它并不是一个只存在人脑中的

799
00:22:36,833 --> 00:22:38,300
你通过语言也可以得到经验

800
00:22:38,633 --> 00:22:39,433
嗯

801
00:22:40,233 --> 00:22:44,200
那这个debate我觉得很很重要的

802
00:22:44,200 --> 00:22:45,000
最后就落到了

803
00:22:45,000 --> 00:22:47,500
一个人到底是怎么学习的

804
00:22:47,500 --> 00:22:48,900
然后什么是学习

805
00:22:49,000 --> 00:22:53,233
以及怎么样子才能产生学习

806
00:22:53,233 --> 00:22:54,466
或者产生新的知识

807
00:22:54,466 --> 00:22:55,500
或者connect the dots

808
00:22:55,500 --> 00:22:56,566
对吧

809
00:22:56,566 --> 00:22:58,966
那我就想请你再就这个问题

810
00:22:58,966 --> 00:23:02,266
来发表一下你的猜想

811
00:23:02,266 --> 00:23:02,966
甚至都可以

812
00:23:02,966 --> 00:23:06,633
就是不一定需要一个scientific的proof

813
00:23:06,766 --> 00:23:08,800
或者说是research

814
00:23:08,966 --> 00:23:10,833
我觉得就是通过经验学习

815
00:23:10,833 --> 00:23:11,300
这个是对的

816
00:23:11,300 --> 00:23:12,800
就是有很多经验能够

817
00:23:13,000 --> 00:23:15,266
但说这个经验里面就是什么样的经验

818
00:23:15,266 --> 00:23:16,300
是更有价值的

819
00:23:16,300 --> 00:23:16,666
我觉得

820
00:23:16,666 --> 00:23:19,433
这个是一个比较大的一个问题

821
00:23:19,700 --> 00:23:20,200
对吧 比如说

822
00:23:20,200 --> 00:23:22,000
你要说 就是非常直观的经验

823
00:23:22,000 --> 00:23:22,400
就比如说

824
00:23:22,400 --> 00:23:23,766
有一派是这么说

825
00:23:23,766 --> 00:23:25,000
我没有embodiment

826
00:23:25,433 --> 00:23:29,800
我是没有办法去学到真正的感觉

827
00:23:29,800 --> 00:23:30,966
这个是行万里路

828
00:23:30,966 --> 00:23:32,500
对对对 你要行万里路

829
00:23:32,500 --> 00:23:34,266
或者说你要真正感到痛

830
00:23:34,266 --> 00:23:36,400
感到那个伤心

831
00:23:36,400 --> 00:23:36,966
喜怒哀乐

832
00:23:36,966 --> 00:23:38,833
你才能真正成为人

833
00:23:38,833 --> 00:23:40,900
就是这样的一种说法

834
00:23:40,900 --> 00:23:42,033
或者说比如说

835
00:23:42,033 --> 00:23:43,900
我只能通过看世界

836
00:23:43,900 --> 00:23:46,066
然后才能知道空间结构

837
00:23:46,266 --> 00:23:47,500
或者说只能通过摸

838
00:23:47,500 --> 00:23:48,633
才能才能看空间结构

839
00:23:48,633 --> 00:23:50,800
对吧这是一种说法

840
00:23:51,066 --> 00:23:51,866
那么还有一种说法

841
00:23:51,866 --> 00:23:54,700
就是说我有一些

842
00:23:54,700 --> 00:23:55,433
抽象的概念

843
00:23:55,433 --> 00:23:57,766
我还是能够学会

844
00:23:57,766 --> 00:23:58,633
这样一些东西

845
00:23:58,833 --> 00:23:59,900
对我觉得这两个东西

846
00:23:59,900 --> 00:24:01,400
其实应该说

847
00:24:01,766 --> 00:24:03,966
不是说是互斥的

848
00:24:04,433 --> 00:24:05,633
因为是这样的

849
00:24:05,633 --> 00:24:07,300
就是其实最终是

850
00:24:07,300 --> 00:24:09,000
我的目的 是要学到一个representation

851
00:24:09,266 --> 00:24:10,400
学到一个表关学习

852
00:24:10,400 --> 00:24:11,033
对吧

853
00:24:11,033 --> 00:24:13,166
因为如果你学到一个representation的话

854
00:24:13,166 --> 00:24:15,700
那有个好的表征

855
00:24:15,700 --> 00:24:18,666
那你对有的问题 你能够解决

856
00:24:18,800 --> 00:24:20,300
就是表征是怎么学出来的

857
00:24:20,300 --> 00:24:22,833
这个完全取决于

858
00:24:23,300 --> 00:24:25,433
那个输入有多丰富

859
00:24:25,433 --> 00:24:27,600
然后结构是什么样子的

860
00:24:27,833 --> 00:24:28,466
对 所以就说

861
00:24:28,466 --> 00:24:32,166
也许就是 不管你是直观的学习也好

862
00:24:32,166 --> 00:24:33,700
还是抽象的学习也好

863
00:24:33,800 --> 00:24:35,166
只要能学到这个表征

864
00:24:35,400 --> 00:24:38,433
然后就能够最终得到一个比较好的

865
00:24:38,433 --> 00:24:40,966
那个泛化的效果

866
00:24:41,100 --> 00:24:42,566
我觉得这两个拼起来呢

867
00:24:42,566 --> 00:24:45,300
应该说是比较好的

868
00:24:45,400 --> 00:24:45,966
对

869
00:24:45,966 --> 00:24:48,833
那么两边怎么谁能够什么东西能够选

870
00:24:48,833 --> 00:24:50,000
能够选出表征来

871
00:24:50,000 --> 00:24:50,900
这完全是

872
00:24:51,000 --> 00:24:53,433
应该说是有个定量的方式来啊

873
00:24:53,433 --> 00:24:54,300
来预测的

874
00:24:54,300 --> 00:24:56,000
而不是说是啊

875
00:24:56,000 --> 00:24:57,400
非此即彼

876
00:24:57,466 --> 00:24:59,633
有可能是说两边都一半都可以学

877
00:24:59,633 --> 00:25:01,600
或者说一边1/3一边2/3也可以学

878
00:25:01,633 --> 00:25:02,633
都行 对

879
00:25:02,633 --> 00:25:05,966
所以并不是说是一定是黑或者白

880
00:25:05,966 --> 00:25:07,166
或者左或者右

881
00:25:07,166 --> 00:25:08,166
很多时候是混在一起的

882
00:25:08,166 --> 00:25:09,100
然后最终得到个表示

883
00:25:09,100 --> 00:25:09,833
这表示能够

884
00:25:09,833 --> 00:25:11,400
能够得到

885
00:25:11,400 --> 00:25:13,000
就是能够进行预测

886
00:25:13,000 --> 00:25:15,066
或者说能够操纵你的行动

887
00:25:15,066 --> 00:25:16,200
然后能够

888
00:25:16,200 --> 00:25:18,233
泛化到一个新的没有见过的情况

889
00:25:19,400 --> 00:25:23,300
那我觉得 顺着这个问的话

890
00:25:23,300 --> 00:25:27,666
就是你刚刚所说的后者的工作

891
00:25:27,666 --> 00:25:29,066
就是不是black box

892
00:25:29,066 --> 00:25:32,100
然后不是所谓的这种scaling law

893
00:25:32,100 --> 00:25:34,300
而是真的去打开它

894
00:25:34,300 --> 00:25:36,366
然后去梳理它

895
00:25:36,366 --> 00:25:38,166
然后去怎么样呢

896
00:25:38,166 --> 00:25:40,433
用不同的方式去学习

897
00:25:40,433 --> 00:25:43,266
对对 那它的意义是什么

898
00:25:43,266 --> 00:25:44,233
就是

899
00:25:44,233 --> 00:25:45,800
我觉得几种 比如

900
00:25:45,800 --> 00:25:47,166
就是要么它学的更有效率

901
00:25:47,166 --> 00:25:48,900
但是似乎 现在数据已经

902
00:25:48,900 --> 00:25:49,966
到了一个瓶颈

903
00:25:49,966 --> 00:25:51,466
嗯嗯 还有效率这件事情

904
00:25:51,466 --> 00:25:53,300
不知道它的意义是不是那么大

905
00:25:53,500 --> 00:25:55,200
然后可能是在同样的知识里边

906
00:25:55,200 --> 00:25:56,633
能学到新的东西

907
00:25:56,700 --> 00:25:58,766
嗯嗯 我才能增加新的数据

908
00:25:58,766 --> 00:26:01,366
嗯嗯 或者新的信息吧

909
00:26:01,366 --> 00:26:03,100
嗯嗯 information set

910
00:26:03,100 --> 00:26:03,866
嗯嗯

911
00:26:03,866 --> 00:26:05,100
那它的意义是什么呢

912
00:26:05,100 --> 00:26:06,433
就是那样做的意义

913
00:26:06,433 --> 00:26:07,566
我觉得首先第一个就是说

914
00:26:07,566 --> 00:26:08,400
数据遇到瓶颈的话

915
00:26:08,400 --> 00:26:09,766
其实恰恰就需要这个了

916
00:26:09,866 --> 00:26:11,066
因为如果数据到瓶颈的话

917
00:26:11,066 --> 00:26:13,266
那你意味着scaling law不一定有效了

918
00:26:13,266 --> 00:26:14,400
比如说你就这么点数据

919
00:26:14,400 --> 00:26:16,566
比如说你就只有这个

920
00:26:16,566 --> 00:26:17,500
比如像training token

921
00:26:17,500 --> 00:26:20,066
这样子这样一个skill

922
00:26:20,266 --> 00:26:21,500
那么这个skill

923
00:26:21,500 --> 00:26:24,633
这个token数目就是对一些大众的

924
00:26:24,633 --> 00:26:25,100
那个

925
00:26:25,100 --> 00:26:26,666
那个东西已经绝对够了

926
00:26:26,833 --> 00:26:29,066
对吧但是对一些小众的领域

927
00:26:29,066 --> 00:26:30,366
就是它可能每个小众

928
00:26:30,366 --> 00:26:32,800
你看这样的坑就很少

929
00:26:32,800 --> 00:26:34,300
所以这样的话呢

930
00:26:34,300 --> 00:26:36,966
其实如果数据不够

931
00:26:36,966 --> 00:26:39,266
再加上你的训练算法比较

932
00:26:39,266 --> 00:26:40,166
费数据的话

933
00:26:40,166 --> 00:26:41,233
那你可能很难学会

934
00:26:41,233 --> 00:26:42,300
就是说不管怎么样

935
00:26:42,300 --> 00:26:44,266
你学会的永远是一个memorization

936
00:26:44,266 --> 00:26:45,833
或者说是记忆的结构

937
00:26:45,900 --> 00:26:47,666
而不是一个泛化的结构

938
00:26:47,666 --> 00:26:49,833
那这个是一个问题

939
00:26:51,433 --> 00:26:52,400
对吧 那么这种情况下

940
00:26:52,400 --> 00:26:53,700
你怎么样去用scaling law做

941
00:26:53,700 --> 00:26:56,566
你就说你得去找办法去做data augmentation

942
00:26:56,633 --> 00:26:57,966
也许这是一个办法 对吧

943
00:26:57,966 --> 00:26:59,600
但是如果你对这个问题有理解

944
00:26:59,600 --> 00:27:01,033
对这个模型有更好的理解的话呢

945
00:27:01,033 --> 00:27:02,666
也许不需要data augmentation

946
00:27:02,666 --> 00:27:03,700
也许你需要

947
00:27:03,766 --> 00:27:06,366
就是说 改变这个训练本身的算法

948
00:27:06,366 --> 00:27:08,100
或者说训练的架构

949
00:27:08,266 --> 00:27:09,200
那么有这个架构之后

950
00:27:09,200 --> 00:27:11,366
也许这个模型就会做的更好

951
00:27:11,600 --> 00:27:14,500
嗯 你觉得我们现在就是

952
00:27:14,500 --> 00:27:17,000
大约模型产生出来的inference

953
00:27:17,000 --> 00:27:18,900
生成出来的这些新的token

954
00:27:18,900 --> 00:27:21,233
嗯嗯 它是记忆还是泛化

955
00:27:22,066 --> 00:27:22,800
这个要看

956
00:27:22,800 --> 00:27:24,633
我觉得这个是有些时候是

957
00:27:24,633 --> 00:27:25,633
是混在一起的

958
00:27:25,966 --> 00:27:29,000
就说你可能对那些比较 那个东西比较

959
00:27:29,000 --> 00:27:31,300
就是或者说这个task比较丰富的

960
00:27:31,433 --> 00:27:32,966
你见了很多很多这样情况

961
00:27:33,166 --> 00:27:34,900
它可能是泛化啊

962
00:27:34,900 --> 00:27:37,166
比如说那个记忆越好

963
00:27:37,166 --> 00:27:38,500
泛化越有可能

964
00:27:38,500 --> 00:27:39,433
是这样吗

965
00:27:39,666 --> 00:27:41,633
就是说 给它的记忆材料越多

966
00:27:41,633 --> 00:27:43,266
它越有泛化的可能

967
00:27:43,266 --> 00:27:43,800
你可以这么说

968
00:27:43,800 --> 00:27:44,966
就是给他的材料越多

969
00:27:44,966 --> 00:27:46,233
因为他看到各种组合了之后

970
00:27:46,233 --> 00:27:48,700
他在组合里面可以得到一个比较好的

971
00:27:48,866 --> 00:27:49,500
那个表征

972
00:27:49,500 --> 00:27:51,066
这个表征就可以

973
00:27:51,066 --> 00:27:53,866
它能够有预测能力

974
00:27:53,866 --> 00:27:56,600
或者说这个表征对没见过的

975
00:27:56,600 --> 00:27:57,466
那个组合

976
00:27:57,466 --> 00:27:59,433
它有一些比较好的结构

977
00:27:59,433 --> 00:28:01,100
可以算出来

978
00:28:01,233 --> 00:28:02,400
那么这个是一个

979
00:28:02,400 --> 00:28:03,633
其实就是泛化嘛

980
00:28:03,633 --> 00:28:04,233
就是所谓

981
00:28:04,233 --> 00:28:04,866
我觉得说实在

982
00:28:04,866 --> 00:28:06,500
就是所谓我们真的懂这东西

983
00:28:06,666 --> 00:28:07,700
我真的理解这东西呢

984
00:28:07,700 --> 00:28:08,866
往往它意识的一个是

985
00:28:08,866 --> 00:28:10,433
它的方法能力很强

986
00:28:10,433 --> 00:28:12,200
所以对新的情况下

987
00:28:12,200 --> 00:28:13,700
对于这个

988
00:28:13,700 --> 00:28:15,900
这个表征能够得到正确答案

989
00:28:15,900 --> 00:28:17,166
这是一种对吧

990
00:28:17,433 --> 00:28:18,200
然后第二个呢

991
00:28:18,200 --> 00:28:19,900
就是说是呃

992
00:28:19,900 --> 00:28:24,400
它能够细化到非常简单的这个逻辑

993
00:28:24,566 --> 00:28:25,566
那么这个逻辑呢

994
00:28:25,566 --> 00:28:29,200
可以apply to everything或者apply to a lot of cases

995
00:28:29,433 --> 00:28:30,233
那么这样的话呢

996
00:28:30,233 --> 00:28:32,166
就是说这两个东西综综合起来

997
00:28:32,166 --> 00:28:36,200
就是让你这个学出来的知识能够

998
00:28:36,200 --> 00:28:39,066
能够apply到很多其他的地方

999
00:28:39,100 --> 00:28:40,066
那么这叫泛化对吧

1000
00:28:40,066 --> 00:28:40,666
就是说

1001
00:28:40,666 --> 00:28:42,366
应该说我们对它要下个定义的话

1002
00:28:42,366 --> 00:28:43,100
就这样一个

1003
00:28:43,100 --> 00:28:45,766
定义 那么如果大语言模型对于

1004
00:28:45,766 --> 00:28:48,200
某个领域看了很多很多数据

1005
00:28:48,433 --> 00:28:49,666
它有可能学到更好的表征

1006
00:28:49,666 --> 00:28:50,766
然后这边就可以泛化

1007
00:28:50,766 --> 00:28:51,666
那这个是一个

1008
00:28:51,866 --> 00:28:52,566
然后另外一个

1009
00:28:52,566 --> 00:28:55,233
就是说如果它看到的数据很少

1010
00:28:55,800 --> 00:28:56,233
那这样的话

1011
00:28:56,233 --> 00:28:58,200
有可能就说这个模型本身

1012
00:28:58,266 --> 00:29:01,166
它没有办法学到很好的那个表征

1013
00:29:01,433 --> 00:29:03,266
它没办法学到很好表征的话 OK

1014
00:29:03,266 --> 00:29:05,300
那它就只能把它背出来

1015
00:29:05,300 --> 00:29:05,966
它没法背出来

1016
00:29:05,966 --> 00:29:09,700
那么它得到的那个表征呢

1017
00:29:09,700 --> 00:29:11,166
就是更偏于背诵的

1018
00:29:11,166 --> 00:29:12,300
这样的一个结构

1019
00:29:12,300 --> 00:29:14,500
就是它能够至少对付好

1020
00:29:14,500 --> 00:29:16,866
就是训练的要求

1021
00:29:17,066 --> 00:29:19,266
就是说 我希望这个训练级上的

1022
00:29:19,266 --> 00:29:21,266
错误率还是比较小的

1023
00:29:21,266 --> 00:29:21,500
但是

1024
00:29:21,500 --> 00:29:23,966
它一旦超越了训练级的范围

1025
00:29:23,966 --> 00:29:24,966
之后

1026
00:29:24,966 --> 00:29:27,300
你就会发现 这个错误率就提高了

1027
00:29:27,300 --> 00:29:27,633
那么这个

1028
00:29:27,633 --> 00:29:30,033
其实大家就认为这个是过度拟合了

1029
00:29:30,033 --> 00:29:31,700
或者说是背诵了对吧

1030
00:29:31,766 --> 00:29:33,100
所以大概就是这样子

1031
00:29:33,100 --> 00:29:35,033
其实我觉得就很多时候

1032
00:29:35,033 --> 00:29:36,200
你并不能说神经网络

1033
00:29:36,200 --> 00:29:37,800
是记忆还是背诵

1034
00:29:37,800 --> 00:29:39,200
还是记忆还是泛化

1035
00:29:39,266 --> 00:29:41,666
应该说是完全取决于这个数据的分布

1036
00:29:41,900 --> 00:29:42,866
如果数据多

1037
00:29:42,866 --> 00:29:45,033
那么这个虚拟网络是泛化多

1038
00:29:45,033 --> 00:29:46,233
如果数据少

1039
00:29:46,433 --> 00:29:48,000
那么这个神经网络是记忆多

1040
00:29:48,000 --> 00:29:49,266
这个是我的观点

1041
00:29:49,266 --> 00:29:51,800
我觉得这里边最fascinating的一点

1042
00:29:51,800 --> 00:29:53,833
就是它从记忆到泛化的那一步

1043
00:29:53,833 --> 00:29:55,200
到底是怎么发生的

1044
00:29:55,233 --> 00:29:57,500
对对 是的

1045
00:29:58,366 --> 00:30:00,833
那你觉得就是 帮我们总结一下

1046
00:30:00,966 --> 00:30:04,400
就是像我

1047
00:30:04,400 --> 00:30:08,066
我的理解可能就停留在emerge

1048
00:30:08,266 --> 00:30:09,600
一句话就就出来了

1049
00:30:09,600 --> 00:30:10,833
但是似乎人脑也是这样的

1050
00:30:10,833 --> 00:30:13,100
我记得在2022年的时候

1051
00:30:13,100 --> 00:30:13,666
22年的时候

1052
00:30:13,666 --> 00:30:15,466
我跟李沐正好线下聊了个天

1053
00:30:15,466 --> 00:30:17,000
他跟我说了一本书

1054
00:30:17,066 --> 00:30:18,900
嗯嗯 他是那个

1055
00:30:19,000 --> 00:30:20,033
cognitive science

1056
00:30:20,033 --> 00:30:21,766
然后就是讲关于神经

1057
00:30:21,766 --> 00:30:22,433
科学（方向）的

1058
00:30:22,433 --> 00:30:24,300
那个时候还没有那么多东西

1059
00:30:24,300 --> 00:30:24,833
然后他说

1060
00:30:24,833 --> 00:30:26,966
其实那本书里讲到关于生物

1061
00:30:27,000 --> 00:30:29,366
比如说人脑和猩猩差别不大

1062
00:30:29,366 --> 00:30:30,966
大脑好像差了30%

1063
00:30:31,066 --> 00:30:32,766
嗯嗯 但是似乎就多了这30%

1064
00:30:32,766 --> 00:30:33,966
就emerge出来了语言

1065
00:30:33,966 --> 00:30:35,633
然后就厉害了

1066
00:30:35,633 --> 00:30:36,500
对对

1067
00:30:36,500 --> 00:30:37,966
我觉得是一个

1068
00:30:38,033 --> 00:30:38,866
我觉得应该是这样吧

1069
00:30:38,866 --> 00:30:41,700
就是 至少从我最近的一篇paper来

1070
00:30:41,700 --> 00:30:42,500
角度上来看呢

1071
00:30:42,500 --> 00:30:44,233
就是说这个paper就是告就告诉你

1072
00:30:44,233 --> 00:30:47,100
就是他有很很清楚的一个picture

1073
00:30:47,100 --> 00:30:47,766
就是告诉你

1074
00:30:47,766 --> 00:30:49,400
这些是怎么发生的

1075
00:30:49,400 --> 00:30:52,700
就是说 是在什么点发生的

1076
00:30:52,966 --> 00:30:55,233
或者说它的内在机制是怎么发生的

1077
00:30:55,233 --> 00:30:56,800
就是我们现在感觉上是

1078
00:30:56,866 --> 00:30:58,866
我从记忆突然间跳到泛化

1079
00:30:58,866 --> 00:31:01,100
好像这个变化非常神秘

1080
00:31:01,100 --> 00:31:02,166
嗯 但是呢

1081
00:31:02,166 --> 00:31:03,633
这篇文章其实告诉你说

1082
00:31:03,633 --> 00:31:04,366
其实并不神秘

1083
00:31:04,366 --> 00:31:04,966
它非常有

1084
00:31:04,966 --> 00:31:06,866
一个非常清楚的一个数学途径

1085
00:31:07,233 --> 00:31:08,000
就是比如说

1086
00:31:08,000 --> 00:31:09,866
我们要做优化问题

1087
00:31:09,866 --> 00:31:10,833
我们有一个

1088
00:31:10,833 --> 00:31:11,766
我们可以构造一个

1089
00:31:11,766 --> 00:31:12,700
就是比较复杂的

1090
00:31:12,700 --> 00:31:14,566
一个非凸优化的

1091
00:31:14,566 --> 00:31:15,366
这样的一个结构

1092
00:31:15,366 --> 00:31:17,400
比如说很多山峰 对吧

1093
00:31:17,400 --> 00:31:18,166
然后g呢

1094
00:31:18,166 --> 00:31:19,300
对应其中一个山峰

1095
00:31:19,700 --> 00:31:20,233
然后呢

1096
00:31:20,233 --> 00:31:22,833
那个泛化的对应其中另外一个山峰

1097
00:31:22,966 --> 00:31:23,800
那么这两个山峰呢

1098
00:31:23,800 --> 00:31:25,433
其实对应着不同的表征

1099
00:31:25,433 --> 00:31:27,766
那么这个山峰的结构呢

1100
00:31:27,766 --> 00:31:29,466
其实完全是取决于

1101
00:31:29,466 --> 00:31:31,633
数据的分布

1102
00:31:32,000 --> 00:31:33,066
如果你数据不够

1103
00:31:33,066 --> 00:31:35,166
你可能就只有记忆的山峰

1104
00:31:35,633 --> 00:31:37,233
如果你数据很多的话

1105
00:31:37,233 --> 00:31:37,500
就是

1106
00:31:37,500 --> 00:31:41,033
然后某些泛化能力强的山峰

1107
00:31:41,033 --> 00:31:42,700
就会慢慢慢变得越来越高

1108
00:31:43,100 --> 00:31:45,266
然后记忆的山峰就会变得越来越低

1109
00:31:45,966 --> 00:31:46,633
然后

1110
00:31:46,633 --> 00:31:47,033
这样的话

1111
00:31:47,033 --> 00:31:51,866
你再让神经网络去找到那个 就是好的

1112
00:31:51,866 --> 00:31:52,466
表征的时候

1113
00:31:52,466 --> 00:31:53,600
是相当于是个优化问题

1114
00:31:53,600 --> 00:31:55,033
优化这个

1115
00:31:55,033 --> 00:31:57,633
神经网络

1116
00:31:57,633 --> 00:31:58,766
其中的参数

1117
00:31:58,766 --> 00:32:01,800
使得它能够收敛到某个局部的最大点

1118
00:32:01,800 --> 00:32:04,766
那么如果你的记忆的山峰缩下去

1119
00:32:05,000 --> 00:32:06,500
泛化山峰提上来

1120
00:32:06,633 --> 00:32:08,200
然后泛化山峰那个

1121
00:32:08,200 --> 00:32:09,633
就有很多的那个神经网络

1122
00:32:09,633 --> 00:32:10,166
那个

1123
00:32:10,166 --> 00:32:12,966
它的参数会收敛到那个泛化的山峰

1124
00:32:13,166 --> 00:32:15,000
那么这个模型就泛化了

1125
00:32:15,033 --> 00:32:16,400
那么从记忆到泛化

1126
00:32:16,400 --> 00:32:17,833
中间为什么会顿悟呢

1127
00:32:17,833 --> 00:32:18,700
其实很简单

1128
00:32:18,766 --> 00:32:20,566
就说两个山峰之间的变化

1129
00:32:20,566 --> 00:32:22,666
就是此消彼长 对吧

1130
00:32:22,666 --> 00:32:24,400
然后在某个情况下

1131
00:32:24,433 --> 00:32:25,700
我比你高一点点了

1132
00:32:25,700 --> 00:32:27,700
然后突然之间所有人都往那边扭

1133
00:32:27,833 --> 00:32:30,566
明白 是因为它可以泛化 对对

1134
00:32:30,566 --> 00:32:32,466
因为它能泛化 所以它可以

1135
00:32:32,466 --> 00:32:34,400
就是只要多一点点的话

1136
00:32:34,400 --> 00:32:35,433
它piu就全都过去了

1137
00:32:35,433 --> 00:32:35,900
对对对

1138
00:32:35,900 --> 00:32:36,566
比如说

1139
00:32:36,566 --> 00:32:37,700
你认为就神经网络

1140
00:32:37,700 --> 00:32:39,566
是一个一直在优化的过程

1141
00:32:39,566 --> 00:32:41,000
对吧 然后他会看见

1142
00:32:41,000 --> 00:32:42,066
如果这边高 那边低点

1143
00:32:42,066 --> 00:32:42,900
那么所有人都

1144
00:32:42,966 --> 00:32:45,166
涌到那个高的山峰上去

1145
00:32:45,166 --> 00:32:47,366
那就突然之间 你就懂什么意思

1146
00:32:47,566 --> 00:32:48,600
所以我觉得 是这样的

1147
00:32:48,600 --> 00:32:50,266
一个structure

1148
00:32:50,266 --> 00:32:50,900
也就是这样的话

1149
00:32:50,900 --> 00:32:52,466
你就我可以从树叶上

1150
00:32:52,466 --> 00:32:54,300
或者说从整个树叶框架上

1151
00:32:54,300 --> 00:32:55,600
能告诉你这件事情呢

1152
00:32:55,600 --> 00:32:56,900
是这么发生的

1153
00:32:56,900 --> 00:32:59,200
而不是说是还是非常神秘的

1154
00:32:59,200 --> 00:33:00,366
这样的一个东西

1155
00:33:00,766 --> 00:33:02,200
我觉得非常清楚

1156
00:33:02,200 --> 00:33:03,700
那我是不是可以理解为

1157
00:33:03,700 --> 00:33:07,666
这个泛化的点一直都在数据里边

1158
00:33:07,666 --> 00:33:09,700
只不过我们之前没有找到它

1159
00:33:09,700 --> 00:33:10,866
没有搜索到它

1160
00:33:10,866 --> 00:33:12,866
或者说就搜就搜索到了

1161
00:33:12,866 --> 00:33:14,300
但是没有配pay enough attention

1162
00:33:14,300 --> 00:33:15,500
然后现在因为

1163
00:33:15,500 --> 00:33:17,700
就是越来越

1164
00:33:17,966 --> 00:33:19,700
随着越来越多的数据点

1165
00:33:19,700 --> 00:33:20,833
凸显了它的价值

1166
00:33:20,833 --> 00:33:23,466
然后我们才pay enough attention

1167
00:33:23,566 --> 00:33:24,366
然后 对对

1168
00:33:24,366 --> 00:33:26,066
你可以 但前提是它要存在

1169
00:33:26,300 --> 00:33:27,200
对的 它存在 一个是存在

1170
00:33:27,200 --> 00:33:28,633
然后它有你要足够的数据

1171
00:33:28,633 --> 00:33:30,566
让它显得与众不同

1172
00:33:30,566 --> 00:33:31,366
可以这么想

1173
00:33:31,500 --> 00:33:33,300
对就是如果数据不够的话呢

1174
00:33:33,433 --> 00:33:36,033
你可以有很多泛化的思想

1175
00:33:36,100 --> 00:33:37,966
但是呢 这些泛化的思想

1176
00:33:37,966 --> 00:33:39,233
它的

1177
00:33:39,233 --> 00:33:41,800
说服力不足以说服记忆这边

1178
00:33:41,800 --> 00:33:44,000
就是因为还不如把它记住

1179
00:33:44,000 --> 00:33:46,366
这些规律可能没有那么显然

1180
00:33:46,366 --> 00:33:49,166
对吧 但是就说一个显然了

1181
00:33:49,166 --> 00:33:49,966
嗯

1182
00:33:50,000 --> 00:33:51,066
嗯嗯

1183
00:33:51,066 --> 00:33:52,300
我刚刚想说

1184
00:33:52,300 --> 00:33:55,166
你举个例子就是 孔子和一个傻子

1185
00:33:55,166 --> 00:33:56,800
可能说的话都是一样的

1186
00:33:56,900 --> 00:33:59,033
但是你给孔子100个问题的时候

1187
00:33:59,033 --> 00:34:00,200
问他怎么治国理政

1188
00:34:00,200 --> 00:34:01,033
然后问他什么

1189
00:34:01,033 --> 00:34:02,000
然后你就说哦

1190
00:34:02,000 --> 00:34:03,400
原来这个是个厉害的孔子

1191
00:34:03,400 --> 00:34:04,600
然后那个是个傻子

1192
00:34:04,666 --> 00:34:05,966
哈哈哈

1193
00:34:06,066 --> 00:34:08,066
对 就是如果给孔子100本书

1194
00:34:08,066 --> 00:34:09,800
那么他告诉你所有的东西

1195
00:34:09,966 --> 00:34:11,100
那么这些东西拼在一起

1196
00:34:11,100 --> 00:34:12,266
就是让你觉得他

1197
00:34:12,266 --> 00:34:15,466
那他在解释这些书的背后

1198
00:34:15,633 --> 00:34:17,866
其实是有一个统一的理论

1199
00:34:17,866 --> 00:34:19,966
或者统一的一个思路

1200
00:34:20,200 --> 00:34:22,466
那么这个思路在100本书的解释中

1201
00:34:22,466 --> 00:34:24,066
慢慢的浮现出来

1202
00:34:24,166 --> 00:34:26,566
那么你会觉得这个东西就很有用

1203
00:34:26,600 --> 00:34:28,433
也许可以拿来解释101本书

1204
00:34:28,433 --> 00:34:29,566
那就是这样子

1205
00:34:30,266 --> 00:34:31,833
那这又回到了另外一个问题

1206
00:34:31,833 --> 00:34:33,700
就是怎么样做evaluation

1207
00:34:33,700 --> 00:34:35,633
怎么样子做做reward

1208
00:34:35,633 --> 00:34:36,266
嗯嗯

1209
00:34:36,266 --> 00:34:40,300
因为孔子解释书解释的好不好

1210
00:34:40,300 --> 00:34:42,266
这件事儿听起来

1211
00:34:42,500 --> 00:34:44,300
然后 现在大语言模型还是

1212
00:34:44,300 --> 00:34:46,300
你看你next token predict准不准

1213
00:34:46,300 --> 00:34:47,166
作为reward吗

1214
00:34:47,166 --> 00:34:48,466
还是有其他的方式

1215
00:34:48,466 --> 00:34:51,766
可以让这个有泛化能力的人

1216
00:34:51,766 --> 00:34:54,800
显得更厉害一些

1217
00:34:54,800 --> 00:34:55,366
应该是这样

1218
00:34:55,366 --> 00:34:57,266
现在你要看大语言模型

1219
00:34:57,266 --> 00:34:59,400
有呢一种是Pre training预训练

1220
00:35:00,400 --> 00:35:01,466
和post training后训练

1221
00:35:01,466 --> 00:35:02,466
这两个都有

1222
00:35:02,633 --> 00:35:04,400
所以你很难讲

1223
00:35:04,400 --> 00:35:06,100
就是你说预训练

1224
00:35:06,100 --> 00:35:07,400
我们现在还是用大量的

1225
00:35:07,400 --> 00:35:08,666
就是predict next token

1226
00:35:09,266 --> 00:35:10,066
就这样子

1227
00:35:10,900 --> 00:35:11,700
然后后训练呢

1228
00:35:11,700 --> 00:35:12,833
其实我们可以说

1229
00:35:12,833 --> 00:35:14,600
那个有很多办法可以做

1230
00:35:14,600 --> 00:35:15,600
训练

1231
00:35:15,600 --> 00:35:16,966
那么预训练Pre next token

1232
00:35:16,966 --> 00:35:18,100
那么这个结构

1233
00:35:18,100 --> 00:35:20,200
或者说这个

1234
00:35:20,200 --> 00:35:22,800
损失函数一直没有变

1235
00:35:22,800 --> 00:35:23,900
因为现在相对来说

1236
00:35:23,900 --> 00:35:25,766
这个还是比较一个比较好的

1237
00:35:26,033 --> 00:35:26,766
损失函数

1238
00:35:26,766 --> 00:35:28,900
当然现在有一些新的方案

1239
00:35:28,900 --> 00:35:31,000
比如说什么reinforcement training

1240
00:35:31,000 --> 00:35:33,200
就是我在训练的时候加一段思维链

1241
00:35:33,200 --> 00:35:34,900
然后希望这个思维链会引起

1242
00:35:34,900 --> 00:35:38,000
导致最后的预测是比较准的

1243
00:35:38,000 --> 00:35:39,766
这种类型的一些工作

1244
00:35:39,966 --> 00:35:41,800
对 那么你可以说我我

1245
00:35:41,800 --> 00:35:43,433
我们可以说

1246
00:35:43,733 --> 00:35:45,233
那这个就是可能对

1247
00:35:45,233 --> 00:35:46,466
就是原来预训练的方式呢

1248
00:35:46,466 --> 00:35:47,633
做了一些改变啊

1249
00:35:47,633 --> 00:35:48,833
大概是这样

1250
00:35:49,033 --> 00:35:50,866
那后训练它的花样就很多了

1251
00:35:50,866 --> 00:35:51,233
对吧 花样

1252
00:35:51,233 --> 00:35:51,633
比如说

1253
00:35:51,633 --> 00:35:52,466
你可以改

1254
00:35:52,633 --> 00:35:54,966
那个reinforcement learning的一些函数

1255
00:35:54,966 --> 00:35:56,366
比如说改一些函数的值函数

1256
00:35:56,366 --> 00:35:58,500
改它的一些evaluation对吧

1257
00:35:58,500 --> 00:35:59,566
value function对吧

1258
00:35:59,566 --> 00:36:00,400
reward对吧

1259
00:36:00,400 --> 00:36:02,000
改rubric这些东西都可以改

1260
00:36:02,266 --> 00:36:03,233
那么这里改了之后

1261
00:36:03,233 --> 00:36:04,666
你就可能就是

1262
00:36:04,666 --> 00:36:06,766
你其实是希望这个模型往

1263
00:36:06,766 --> 00:36:07,766
不同的方向走

1264
00:36:09,233 --> 00:36:09,466
对吧

1265
00:36:09,466 --> 00:36:11,433
然后你往不同的方向走了之后呢

1266
00:36:11,500 --> 00:36:12,466
那么有些方向

1267
00:36:12,466 --> 00:36:14,500
可能就强化模型的某个能力

1268
00:36:14,966 --> 00:36:16,666
某些方向强化模型另外一种能力

1269
00:36:17,000 --> 00:36:17,566
那么这样的话

1270
00:36:17,566 --> 00:36:19,866
你这个模型最后就是百花齐放了

1271
00:36:19,866 --> 00:36:21,466
嗯大概是这样子

1272
00:36:21,800 --> 00:36:22,700
对对

1273
00:36:22,700 --> 00:36:24,233
当然了就是说很多时候

1274
00:36:24,233 --> 00:36:26,233
你要优化它到某个能力的

1275
00:36:26,233 --> 00:36:26,666
时候呢

1276
00:36:26,666 --> 00:36:28,666
你其实还是希望

1277
00:36:28,666 --> 00:36:30,866
能够优化的比较

1278
00:36:30,866 --> 00:36:31,800
一个是避免

1279
00:36:31,800 --> 00:36:33,166
就是reward hacking啊

1280
00:36:33,166 --> 00:36:33,633
有些时候

1281
00:36:33,633 --> 00:36:33,766
就是

1282
00:36:33,766 --> 00:36:36,466
模型还是会最大化你的某个值函数

1283
00:36:36,466 --> 00:36:39,366
但是这个最大化的路径是偏的

1284
00:36:39,500 --> 00:36:41,466
你不想让他这么做

1285
00:36:41,466 --> 00:36:42,233
但是他就这么做

1286
00:36:42,233 --> 00:36:43,966
这么做有shortcut啊

1287
00:36:43,966 --> 00:36:44,566
就比如说这样

1288
00:36:44,566 --> 00:36:46,700
比如说你答案就只有a b c d四个

1289
00:36:46,700 --> 00:36:47,866
然后那就瞎猜一个

1290
00:36:48,000 --> 00:36:51,500
25%（准确率）对吧 那我我不希望它瞎猜怎么办

1291
00:36:51,666 --> 00:36:53,200
那我就希望我的思维链

1292
00:36:53,200 --> 00:36:55,066
一个是希望它的每一步

1293
00:36:55,066 --> 00:36:56,433
就是经得起考验

1294
00:36:56,633 --> 00:36:58,400
对吧 每一步逻辑是正确的

1295
00:36:58,400 --> 00:37:00,866
你可能需要一个one model去做这个事情

1296
00:37:01,066 --> 00:37:02,500
这些都是

1297
00:37:02,500 --> 00:37:03,266
比较重要的

1298
00:37:03,266 --> 00:37:04,866
这个是比较重要的

1299
00:37:04,866 --> 00:37:06,600
就是怎么样去做这个事情

1300
00:37:06,600 --> 00:37:07,166
那么这样的话

1301
00:37:07,166 --> 00:37:08,766
你中间肯定要引入各种ribick

1302
00:37:08,966 --> 00:37:09,666
引入各种东西

1303
00:37:09,666 --> 00:37:12,300
去把这个模型给算出来

1304
00:37:12,300 --> 00:37:14,600
就是所以其实花样还是挺多的

1305
00:37:14,600 --> 00:37:17,400
而且有很多地方是可以有人为

1306
00:37:17,500 --> 00:37:19,433
有一些人类的那个思维

1307
00:37:19,433 --> 00:37:21,400
和概念能够放进去

1308
00:37:21,400 --> 00:37:23,266
我稍给大家

1309
00:37:23,266 --> 00:37:25,666
给频道前面的观众做个比方吧

1310
00:37:25,666 --> 00:37:29,000
我觉得一个用比方去理解的话呢

1311
00:37:29,000 --> 00:37:30,566
就是

1312
00:37:30,566 --> 00:37:33,066
大约模型是个非常非常勤奋

1313
00:37:33,066 --> 00:37:33,666
算力

1314
00:37:33,666 --> 00:37:36,000
非常高 就是一天到晚学习的人

1315
00:37:36,000 --> 00:37:37,633
对 然后它就可以不断的读书

1316
00:37:37,633 --> 00:37:39,766
然后它读了唐诗300首

1317
00:37:39,766 --> 00:37:41,500
结果发现它又找到了唐诗3万首

1318
00:37:41,500 --> 00:37:42,900
然后读了300万首唐诗

1319
00:37:42,900 --> 00:37:44,033
然后它会作诗了

1320
00:37:44,033 --> 00:37:46,100
是因为它穷尽了这里面所有规律

1321
00:37:46,233 --> 00:37:48,400
然后它找到了行之有效的方法

1322
00:37:48,400 --> 00:37:50,266
而且它有一个好的方式

1323
00:37:50,266 --> 00:37:51,600
去可以帮助它evaluate

1324
00:37:51,600 --> 00:37:53,466
它自己的诗做得好不好

1325
00:37:53,466 --> 00:37:55,100
对然后它发现

1326
00:37:55,100 --> 00:37:56,833
它找到了这里边的规律

1327
00:37:56,833 --> 00:37:59,166
但前提是这个规律要存在在这里边

1328
00:37:59,166 --> 00:38:00,166
对对

1329
00:38:00,166 --> 00:38:01,500
然后你刚刚所说的

1330
00:38:01,500 --> 00:38:05,966
就是希望用另外一种方式去学习

1331
00:38:06,033 --> 00:38:06,766
是说

1332
00:38:06,766 --> 00:38:10,033
我们不光要让它去背3万还是300万首唐诗

1333
00:38:10,033 --> 00:38:11,000
我们能不能

1334
00:38:11,000 --> 00:38:13,266
就是像发现数学公式那种方式

1335
00:38:13,266 --> 00:38:15,433
去发现一个规律

1336
00:38:15,433 --> 00:38:15,833
对对

1337
00:38:15,833 --> 00:38:18,400
从而让它直接“piu”的跳到那个

1338
00:38:18,400 --> 00:38:18,700
我

1339
00:38:18,700 --> 00:38:22,000
我在23年写那个文章的时候

1340
00:38:22,100 --> 00:38:23,266
就是讲到（《关于ChatGPT最重要的五个问题》）

1341
00:38:23,466 --> 00:38:25,966
就是尤里卡阿基米德发现浮力定律

1342
00:38:25,966 --> 00:38:27,500
他其实是干了两件事

1343
00:38:27,633 --> 00:38:28,833
是两件不同的事

1344
00:38:29,033 --> 00:38:29,900
对第一件事呢

1345
00:38:29,900 --> 00:38:31,866
是他穷尽了

1346
00:38:31,866 --> 00:38:34,366
他肯定当时在想很多很多的方案

1347
00:38:34,366 --> 00:38:35,766
很多很多的可能性

1348
00:38:35,833 --> 00:38:38,000
然后他脑子里边找到了这么一个点

1349
00:38:38,000 --> 00:38:39,000
但是第二件事是

1350
00:38:39,000 --> 00:38:40,866
他马上意识到这个是对的

1351
00:38:42,033 --> 00:38:45,866
我觉得这两者在机器都挺难做到的

1352
00:38:45,866 --> 00:38:47,833
他很难马上意识到这个东西是对的

1353
00:38:47,833 --> 00:38:48,866
嗯嗯 就是说

1354
00:38:48,866 --> 00:38:50,400
意识到这东西对的是有可能的

1355
00:38:50,400 --> 00:38:52,166
就比如说你发现一个新的假设

1356
00:38:52,166 --> 00:38:53,800
这假设能够解释更多现象

1357
00:38:54,033 --> 00:38:55,466
而且它假设更简单

1358
00:38:55,700 --> 00:38:57,633
那你会马上意识到这个是对的

1359
00:38:57,633 --> 00:39:00,366
比如说地心说跟日心说对吧

1360
00:39:00,366 --> 00:39:01,000
那其实说

1361
00:39:01,000 --> 00:39:03,166
说实在的那个地心说也是对的

1362
00:39:03,633 --> 00:39:04,900
只是说那个

1363
00:39:04,900 --> 00:39:06,500
地心说你也可以拿来预测

1364
00:39:06,633 --> 00:39:08,300
只是在地角上来看

1365
00:39:08,300 --> 00:39:10,200
就其他行星的那个运行轨迹

1366
00:39:10,200 --> 00:39:11,566
非常复杂

1367
00:39:11,566 --> 00:39:13,033
就是它是那个

1368
00:39:13,033 --> 00:39:15,066
就是本轮均轮这种运行轨迹

1369
00:39:15,066 --> 00:39:16,200
就是轮子套轮子

1370
00:39:16,200 --> 00:39:17,833
就是可能一边这么走

1371
00:39:17,833 --> 00:39:19,566
还要换个花样再转再转

1372
00:39:19,566 --> 00:39:20,466
轮子里面套轮子

1373
00:39:20,466 --> 00:39:21,700
然后你通过这个方式

1374
00:39:21,700 --> 00:39:24,066
你可以预测那个每个行星的行为

1375
00:39:24,066 --> 00:39:26,200
对吧 所以这两个其实都是对的

1376
00:39:26,200 --> 00:39:27,366
只是说日心说

1377
00:39:27,366 --> 00:39:28,633
如果你切到日心说

1378
00:39:28,633 --> 00:39:30,366
你会发现突然之间

1379
00:39:30,366 --> 00:39:32,766
所有的轨道都非常漂亮

1380
00:39:32,766 --> 00:39:33,766
就是一个椭圆

1381
00:39:33,766 --> 00:39:34,800
非常非常简单

1382
00:39:35,033 --> 00:39:37,166
那么这个时候你会马上意识到

1383
00:39:37,166 --> 00:39:38,566
那个理论

1384
00:39:38,566 --> 00:39:40,700
或者说那种解释是更加完美的

1385
00:39:40,700 --> 00:39:42,666
或者说更加接近真实

1386
00:39:42,666 --> 00:39:44,466
或者更加接近那个更美的

1387
00:39:44,466 --> 00:39:45,266
这样的感觉

1388
00:39:45,266 --> 00:39:46,300
我原来是这样子

1389
00:39:46,566 --> 00:39:47,900
一个逻辑

1390
00:39:47,900 --> 00:39:49,966
你觉得Elegance这个东西

1391
00:39:49,966 --> 00:39:53,000
在模型现在训练的reward function里吗

1392
00:39:53,633 --> 00:39:54,666
这个我觉得是这样

1393
00:39:54,666 --> 00:39:57,066
就是因为它不是reward function

1394
00:39:57,066 --> 00:39:58,366
但是它在训练的时候呢

1395
00:39:58,366 --> 00:40:01,200
应该有implicit bias往这方向走

1396
00:40:01,200 --> 00:40:03,266
就比如说那个

1397
00:40:03,266 --> 00:40:04,366
你展示的那个

1398
00:40:04,666 --> 00:40:06,000
PPT里面 对吧

1399
00:40:06,000 --> 00:40:07,200
提到伊利亚说过这个

1400
00:40:07,200 --> 00:40:08,900
就是我希望它压缩

1401
00:40:08,900 --> 00:40:10,066
我希望找这个模型

1402
00:40:10,066 --> 00:40:13,366
会自动的找到一个比较优美的

1403
00:40:13,366 --> 00:40:14,600
或者比较少的

1404
00:40:14,600 --> 00:40:16,833
那个压缩比最高的

1405
00:40:16,833 --> 00:40:18,066
那个解释

1406
00:40:18,066 --> 00:40:19,066
这个我是同意的

1407
00:40:19,200 --> 00:40:22,166
这个确实是会发生的

1408
00:40:22,166 --> 00:40:23,066
但是呢

1409
00:40:23,066 --> 00:40:24,100
这个不是

1410
00:40:24,100 --> 00:40:24,566
是一个loss function

1411
00:40:24,566 --> 00:40:25,066
是说

1412
00:40:25,066 --> 00:40:27,466
它内建在神经网络的训练过程里面

1413
00:40:27,966 --> 00:40:28,633
这训练过程

1414
00:40:28,633 --> 00:40:29,300
会

1415
00:40:29,300 --> 00:40:34,066
让这个模型自然的发现更加好的

1416
00:40:34,066 --> 00:40:36,800
或者说更加优美的解释

1417
00:40:36,800 --> 00:40:37,700
应该说是这样子

1418
00:40:37,700 --> 00:40:38,433
那么这样的话呢

1419
00:40:38,433 --> 00:40:39,500
就是神经网络

1420
00:40:39,500 --> 00:40:42,566
它才有这个能力去学会更好的表征

1421
00:40:42,566 --> 00:40:43,500
然后才有泛化能力

1422
00:40:43,500 --> 00:40:44,666
应该是这样子对

1423
00:40:45,000 --> 00:40:45,600
对

1424
00:40:45,600 --> 00:40:47,300
在loss function之外

1425
00:40:47,300 --> 00:40:50,100
之上还有一层更隐含的reward

1426
00:40:50,100 --> 00:40:50,566
是的

1427
00:40:50,566 --> 00:40:51,200
是可以这么说

1428
00:40:51,200 --> 00:40:51,466
对对

1429
00:40:51,466 --> 00:40:52,266
这个很重要

1430
00:40:52,266 --> 00:40:52,966
因为说实在

1431
00:40:52,966 --> 00:40:55,200
所有的loss function都是surrogate

1432
00:40:55,200 --> 00:40:56,500
就是说都是代理

1433
00:40:56,666 --> 00:40:57,700
就比如说predicting next

1434
00:40:57,700 --> 00:40:59,200
next token或者是whatever

1435
00:40:59,200 --> 00:41:00,366
或者什么contrastive loss

1436
00:41:00,366 --> 00:41:01,566
non contrastive loss

1437
00:41:01,666 --> 00:41:02,366
对吧 这种

1438
00:41:02,366 --> 00:41:03,400
或者说player loss

1439
00:41:03,400 --> 00:41:04,233
这些东西都是都是代表

1440
00:41:04,233 --> 00:41:06,166
就它的目的是产生一个梯度流

1441
00:41:06,166 --> 00:41:07,966
这个梯度流

1442
00:41:07,966 --> 00:41:11,100
能够让这个表针往正确的方向走

1443
00:41:11,100 --> 00:41:13,100
这个是最重要的

1444
00:41:13,100 --> 00:41:14,500
一个逻辑

1445
00:41:14,500 --> 00:41:15,866
就是至于这个

1446
00:41:16,566 --> 00:41:18,066
至于这个

1447
00:41:18,166 --> 00:41:19,233
目标函数是什么

1448
00:41:19,233 --> 00:41:19,833
其实并不重要

1449
00:41:19,833 --> 00:41:20,666
重要的是这个

1450
00:41:21,100 --> 00:41:22,400
哦

1451
00:41:22,600 --> 00:41:24,366
我直到今天之前

1452
00:41:24,366 --> 00:41:28,100
我一直觉得loss function是整个学习的

1453
00:41:28,100 --> 00:41:30,000
就是目标

1454
00:41:30,100 --> 00:41:32,033
现在我才知道了它是surrogate

1455
00:41:32,033 --> 00:41:32,433
这个

1456
00:41:32,433 --> 00:41:34,700
这个是共识吗

1457
00:41:34,700 --> 00:41:35,500
就是大家

1458
00:41:35,500 --> 00:41:37,200
为什么到今天才知道这件事

1459
00:41:37,200 --> 00:41:38,433
因为它听起来很intuitive

1460
00:41:38,433 --> 00:41:40,100
然后很重要啊

1461
00:41:40,100 --> 00:41:41,033
对 因为

1462
00:41:41,033 --> 00:41:41,600
我

1463
00:41:41,600 --> 00:41:41,900
我自己

1464
00:41:41,900 --> 00:41:43,633
毕竟还是做过很多表征学习的工作的

1465
00:41:43,633 --> 00:41:44,466
我知道

1466
00:41:44,466 --> 00:41:47,033
就是很多表征学习的目标函数

1467
00:41:47,166 --> 00:41:48,466
做过些拆解之后

1468
00:41:48,466 --> 00:41:51,100
你会发现它们其实就是反传梯度的

1469
00:41:51,100 --> 00:41:52,066
不同形式嘛

1470
00:41:52,066 --> 00:41:53,866
对吧 你的loss function换了

1471
00:41:53,866 --> 00:41:55,433
你的反射梯度的结构是不一样的

1472
00:41:55,433 --> 00:41:56,233
那么这个结构

1473
00:41:56,233 --> 00:41:58,700
其实最终能够影响你的表征的学习

1474
00:41:58,966 --> 00:41:59,633
是这样子

1475
00:41:59,633 --> 00:42:01,466
但是你这个loss function其实可以换

1476
00:42:01,466 --> 00:42:03,800
甚至换成一些奇怪的东西

1477
00:42:03,800 --> 00:42:04,433
你从来没见过

1478
00:42:04,433 --> 00:42:05,033
但是

1479
00:42:05,033 --> 00:42:07,266
得到的梯度是差不多的

1480
00:42:07,266 --> 00:42:08,600
那比如说表征也差不多

1481
00:42:08,600 --> 00:42:11,066
你对梯度这个词的使用

1482
00:42:11,066 --> 00:42:13,166
也让我觉得非常的intuitive

1483
00:42:13,500 --> 00:42:14,800
我心中就是

1484
00:42:16,033 --> 00:42:17,900
就是一个一个等高线

1485
00:42:18,000 --> 00:42:19,466
但是我觉得这个这个等高线

1486
00:42:19,466 --> 00:42:21,800
最后画出来的是我们的一个知识

1487
00:42:21,800 --> 00:42:22,633
很本质的东西

1488
00:42:22,633 --> 00:42:24,266
可能就是刻画我们世界规律的

1489
00:42:24,266 --> 00:42:25,100
这么一个

1490
00:42:25,100 --> 00:42:26,966
对对

1491
00:42:26,966 --> 00:42:28,233
等高线这个逻辑呢

1492
00:42:28,233 --> 00:42:28,900
是经常用的

1493
00:42:28,900 --> 00:42:30,966
但是等高线这样的一个思路呢

1494
00:42:30,966 --> 00:42:31,833
其实它忽略了

1495
00:42:31,833 --> 00:42:33,300
这个神经网络本身的结构

1496
00:42:33,466 --> 00:42:36,100
因为它把整个landscape

1497
00:42:36,100 --> 00:42:38,233
做成一个高维空间中的一个

1498
00:42:38,233 --> 00:42:39,700
非常复杂的

1499
00:42:39,700 --> 00:42:40,433
一个山峰

1500
00:42:40,433 --> 00:42:41,266
但是这个山峰

1501
00:42:41,266 --> 00:42:42,033
其实你要知道

1502
00:42:42,033 --> 00:42:44,166
山峰其实对应着神经网络的结构

1503
00:42:44,366 --> 00:42:45,700
所以这两个是有关系的

1504
00:42:46,000 --> 00:42:46,833
所以应该说

1505
00:42:46,833 --> 00:42:49,866
把这个梯度在山峰上的指引

1506
00:42:50,066 --> 00:42:51,033
去

1507
00:42:51,033 --> 00:42:53,266
映射到神经网络的

1508
00:42:53,266 --> 00:42:54,566
具体的

1509
00:42:54,633 --> 00:42:56,800
哪个梯度对于哪个神经元的

1510
00:42:56,800 --> 00:42:58,800
或者每一组神经元的这样的一个过程

1511
00:42:58,966 --> 00:43:00,166
那么这个时候你能看见

1512
00:43:00,166 --> 00:43:02,666
就是它的表征是怎么学出来的

1513
00:43:02,666 --> 00:43:04,466
这个是会比较有趣吧

1514
00:43:04,466 --> 00:43:05,633
但这个可能比较细节

1515
00:43:05,633 --> 00:43:07,066
大概是这样的想法

1516
00:43:07,433 --> 00:43:07,700
我觉得

1517
00:43:07,700 --> 00:43:10,266
它对于我们对这件事儿的intuitive

1518
00:43:10,266 --> 00:43:11,866
understanding挺重要的

1519
00:43:12,033 --> 00:43:12,833
对

1520
00:43:13,033 --> 00:43:13,200
嗯

1521
00:43:13,200 --> 00:43:16,300
就是像你可能刚刚说的就是那个insight

1522
00:43:16,466 --> 00:43:18,800
那个insight就是你有了这个东西

1523
00:43:18,800 --> 00:43:19,600
我觉得就比较好

1524
00:43:19,600 --> 00:43:22,366
容易建立起一个更好的世界模型

1525
00:43:22,366 --> 00:43:23,566
对对 是的

1526
00:43:23,566 --> 00:43:24,166
是

1527
00:43:24,166 --> 00:43:26,000
大概是这样的一个逻辑

1528
00:43:26,000 --> 00:43:27,066
但这个是一家之言

1529
00:43:27,066 --> 00:43:28,666
就是说 我觉得我也是

1530
00:43:28,866 --> 00:43:29,900
我也非常bias

1531
00:43:29,900 --> 00:43:30,566
以我自己（的观点）

1532
00:43:30,566 --> 00:43:31,866
我们来听的就是一家之言

1533
00:43:31,866 --> 00:43:33,000
我们 （哈哈哈）

1534
00:43:33,000 --> 00:43:35,033
如果这个事情有有教科书的话

1535
00:43:35,033 --> 00:43:36,033
我们就去学教科书了

1536
00:43:36,033 --> 00:43:36,833
因为没有

1537
00:43:36,833 --> 00:43:38,233
所以我们一家之言是（因为）

1538
00:43:38,233 --> 00:43:39,766
大家每个人都会有自己的想法嘛

1539
00:43:39,766 --> 00:43:41,233
对吧 我这边也是做一些

1540
00:43:41,233 --> 00:43:42,500
做很多research

1541
00:43:42,500 --> 00:43:42,966
嗯嗯

1542
00:43:42,966 --> 00:43:44,500
我有这样的一个大概的感觉

1543
00:43:44,500 --> 00:43:45,666
就是这样子

1544
00:43:45,666 --> 00:43:47,200
那么我在上面有很多文章

1545
00:43:47,200 --> 00:43:49,766
也是做一些这样的工作

1546
00:43:49,766 --> 00:43:50,600
去分析

1547
00:43:50,600 --> 00:43:52,166
这个梯度的结构

1548
00:43:52,166 --> 00:43:53,666
它训练出来这个表示什么

1549
00:43:53,666 --> 00:43:54,900
改的变化

1550
00:43:54,900 --> 00:43:55,833
这个是重要的

1551
00:43:55,833 --> 00:43:57,300
我相信就是再往上走呢

1552
00:43:57,300 --> 00:43:59,233
也许这样的

1553
00:43:59,333 --> 00:44:00,000
一个理解呢

1554
00:44:00,000 --> 00:44:01,200
是能够改变

1555
00:44:01,200 --> 00:44:03,066
最后的那个

1556
00:44:03,066 --> 00:44:04,633
这个神经网络的学习的方案

1557
00:44:04,633 --> 00:44:06,800
这是这是我们的最终目的

1558
00:44:06,800 --> 00:44:08,400
当然这个方向比较远

1559
00:44:08,400 --> 00:44:09,400
这是long term的

1560
00:44:09,600 --> 00:44:10,466
那么

1561
00:44:10,466 --> 00:44:12,400
当然是希望有很多那short term的东西

1562
00:44:12,400 --> 00:44:14,100
可以跟它辅佐在一起做

1563
00:44:15,300 --> 00:44:17,433
嗯 我觉得这个已经聊得非常的深入了

1564
00:44:17,433 --> 00:44:18,166
感谢感谢

1565
00:44:18,166 --> 00:44:19,000
我们

1566
00:44:19,000 --> 00:44:20,633
这个话题就先聊到这里

1567
00:44:20,633 --> 00:44:21,500
剩下一点点

1568
00:44:21,500 --> 00:44:23,866
我再用十五分钟的时间

1569
00:44:23,966 --> 00:44:25,800
稍稍回顾一下你的科研史

1570
00:44:25,800 --> 00:44:27,266
因为你刚刚也聊到了远期的目标

1571
00:44:27,366 --> 00:44:28,600
就是

1572
00:44:28,600 --> 00:44:31,100
也要有一些近期的目标结合

1573
00:44:31,100 --> 00:44:32,366
嗯嗯 我记得你有一个专访

1574
00:44:32,366 --> 00:44:33,100
里面有讲到

1575
00:44:33,100 --> 00:44:35,033
就是你在刚读博士的时候

1576
00:44:35,033 --> 00:44:36,666
大部分的时间是在想

1577
00:44:36,766 --> 00:44:38,466
但是你后来觉得想的是没有用的

1578
00:44:38,466 --> 00:44:40,500
对 而且关键是你想的那些东西

1579
00:44:40,500 --> 00:44:41,466
没有做工作的话

1580
00:44:41,466 --> 00:44:42,800
就相当于没有存盘

1581
00:44:43,033 --> 00:44:44,100
对对

1582
00:44:44,166 --> 00:44:45,400
你现在就应该

1583
00:44:45,500 --> 00:44:46,700
因为我看你的工作

1584
00:44:46,700 --> 00:44:47,800
其实我能感觉到

1585
00:44:47,800 --> 00:44:49,200
是有一个很强的主线

1586
00:44:49,200 --> 00:44:51,500
或者起码在你的自己的网站上

1587
00:44:51,500 --> 00:44:52,566
介绍的时候

1588
00:44:52,566 --> 00:44:54,766
我就会发现你前面的一个工作

1589
00:44:54,766 --> 00:44:55,766
lead到下一个工作

1590
00:44:55,766 --> 00:44:56,966
然后再lead到下一个工作

1591
00:44:56,966 --> 00:44:57,566
就是每一次

1592
00:44:57,566 --> 00:45:00,466
都能在前面非常重要的结果上

1593
00:45:00,466 --> 00:45:01,100
再往前走

1594
00:45:01,100 --> 00:45:04,833
而且似乎都能跟时代挂钩

1595
00:45:04,833 --> 00:45:06,433
对吧,就是从围棋开始

1596
00:45:06,433 --> 00:45:07,466
然后到大语言模型

1597
00:45:07,466 --> 00:45:10,300
然后到模型训练的

1598
00:45:10,300 --> 00:45:12,466
就是效率方面

1599
00:45:12,466 --> 00:45:13,233
这些东西

1600
00:45:13,233 --> 00:45:16,600
都能踩上应用的点

1601
00:45:16,633 --> 00:45:19,566
所以我想听一下你对

1602
00:45:19,566 --> 00:45:22,200
选择科研topic

1603
00:45:22,466 --> 00:45:26,500
以及在FAIR这样的环境中

1604
00:45:26,500 --> 00:45:27,666
这种就是

1605
00:45:27,666 --> 00:45:28,633
比如说

1606
00:45:28,633 --> 00:45:31,666
你觉得你的科研有应用的压力吗

1607
00:45:31,666 --> 00:45:32,100
或者说

1608
00:45:32,100 --> 00:45:34,233
你到底是怎么决定你的科研方向

1609
00:45:34,233 --> 00:45:36,000
你怎么决定

1610
00:45:36,633 --> 00:45:38,366
把兴趣

1611
00:45:38,400 --> 00:45:41,000
商业和自己的长处结合起来的

1612
00:45:41,700 --> 00:45:42,666
对,我觉得是这样的

1613
00:45:42,666 --> 00:45:43,900
就是你肯定是要结合的

1614
00:45:43,900 --> 00:45:47,166
否则很有可能会比较惨

1615
00:45:47,566 --> 00:45:49,433
我们大家都有家庭

1616
00:45:49,433 --> 00:45:52,066
大家都希望能够有一些比较高的收入

1617
00:45:52,066 --> 00:45:52,266
对吧

1618
00:45:52,266 --> 00:45:53,066
然后

1619
00:45:53,133 --> 00:45:54,566
然后能够

1620
00:45:54,566 --> 00:45:55,833
希望有比较好

1621
00:45:55,833 --> 00:45:57,600
有个比较好的环境

1622
00:45:57,600 --> 00:45:59,166
对吧 然后比如社会地位也比较高

1623
00:45:59,166 --> 00:46:00,433
大家都希望全都要

1624
00:46:00,433 --> 00:46:01,800
成年人说全都要

1625
00:46:01,800 --> 00:46:02,566
不是说小孩子

1626
00:46:02,566 --> 00:46:03,566
只选一个

1627
00:46:03,833 --> 00:46:06,066
对 所以最终你肯定是要找到

1628
00:46:06,100 --> 00:46:07,366
那个结合点

1629
00:46:07,366 --> 00:46:09,400
就是因为我从博士开始

1630
00:46:09,400 --> 00:46:11,066
就已经是“双线作战”了

1631
00:46:11,066 --> 00:46:12,700
就是我有很多的想法

1632
00:46:12,700 --> 00:46:14,633
就是你之前说的也是对的

1633
00:46:14,633 --> 00:46:15,566
就是我会

1634
00:46:15,833 --> 00:46:16,866
我可能花9个月时间

1635
00:46:16,866 --> 00:46:18,300
去想一些不着边际的东西

1636
00:46:18,300 --> 00:46:19,300
然后3个月说

1637
00:46:19,300 --> 00:46:19,800
不行了

1638
00:46:19,800 --> 00:46:20,700
我今年要发paper

1639
00:46:20,900 --> 00:46:22,833
否则老板会不高兴

1640
00:46:22,833 --> 00:46:24,966
对吧 那我可能会跟老板说

1641
00:46:24,966 --> 00:46:26,900
你有什么题目我来帮你做

1642
00:46:26,900 --> 00:46:28,400
那我花3个月

1643
00:46:28,400 --> 00:46:29,966
就把这个事情做了

1644
00:46:29,966 --> 00:46:30,766
出一篇paper

1645
00:46:31,066 --> 00:46:33,233
就要对老板有交代

1646
00:46:33,233 --> 00:46:34,766
他当时比如说课题

1647
00:46:34,766 --> 00:46:37,966
这些课题需要有文章去填

1648
00:46:38,066 --> 00:46:39,500
那么通过这方式

1649
00:46:39,500 --> 00:46:41,800
至少让我觉得

1650
00:46:41,800 --> 00:46:43,633
我在博士阶段会有工作

1651
00:46:43,633 --> 00:46:45,966
然后我能毕业 对吧

1652
00:46:45,966 --> 00:46:47,066
然后老板也开心

1653
00:46:47,066 --> 00:46:49,166
这个还是很重要的

1654
00:46:49,166 --> 00:46:51,100
这很重要 那么工作之后也是一样的

1655
00:46:51,100 --> 00:46:53,700
就是我们当然希望做一些方向

1656
00:46:53,700 --> 00:46:56,633
这方向是迎合时代潮流的

1657
00:46:56,700 --> 00:46:58,500
就是我不可能说

1658
00:46:58,500 --> 00:46:59,966
完全脱离时代潮流

1659
00:46:59,966 --> 00:47:01,366
比如大家都在做大语言模型

1660
00:47:01,366 --> 00:47:02,233
你却不做

1661
00:47:02,433 --> 00:47:03,633
那我

1662
00:47:03,633 --> 00:47:04,033
那我说

1663
00:47:04,033 --> 00:47:04,633
我做别的

1664
00:47:04,633 --> 00:47:06,166
然后我说我就是要做

1665
00:47:06,166 --> 00:47:07,166
比如我就要做SVM

1666
00:47:07,166 --> 00:47:08,266
或者就要做视觉

1667
00:47:08,266 --> 00:47:10,000
这个当然可以

1668
00:47:10,000 --> 00:47:11,833
对 但是这种肯定

1669
00:47:11,833 --> 00:47:13,266
在公司里面

1670
00:47:13,266 --> 00:47:15,000
是没有办法活下去的

1671
00:47:15,066 --> 00:47:17,600
对 所以这是一个比较大的

1672
00:47:17,600 --> 00:47:19,633
问题

1673
00:47:19,700 --> 00:47:21,966
所以会想一想

1674
00:47:21,966 --> 00:47:22,700
就是首先

1675
00:47:22,700 --> 00:47:24,000
你比如说

1676
00:47:24,000 --> 00:47:26,500
我这边的一些比较偏理论的研究

1677
00:47:26,500 --> 00:47:28,300
它对这个问题有更深理解

1678
00:47:28,300 --> 00:47:30,100
比如之前我们有一些关于

1679
00:47:30,100 --> 00:47:31,466
attention sparsity

1680
00:47:31,466 --> 00:47:34,200
就是注意力机制如何变得稀疏的

1681
00:47:34,200 --> 00:47:34,966
这样一些研究

1682
00:47:34,966 --> 00:47:36,900
那么这研究本身是比较理论的

1683
00:47:36,900 --> 00:47:37,700
但是

1684
00:47:37,700 --> 00:47:41,100
你可以拿来做一些比较实用的工作

1685
00:47:41,366 --> 00:47:42,800
比如说我们想到最近的

1686
00:47:42,800 --> 00:47:44,100
之前的attention sink

1687
00:47:44,300 --> 00:47:45,033
那么这种文章

1688
00:47:45,033 --> 00:47:46,000
就是说

1689
00:47:46,000 --> 00:47:47,400
我们其实没有太多理论

1690
00:47:47,400 --> 00:47:50,066
但是我们可以通过观察

1691
00:47:50,066 --> 00:47:51,433
神经网络的稀疏性

1692
00:47:51,433 --> 00:47:53,100
我们可能得到新的算法

1693
00:47:53,266 --> 00:47:56,400
用这新的算法可以把上下文扩展到

1694
00:47:56,400 --> 00:47:57,000
扩展到比如

1695
00:47:57,000 --> 00:47:59,033
400万以上

1696
00:47:59,033 --> 00:47:59,966
那这样的话

1697
00:47:59,966 --> 00:48:00,833
这个东西就有用了

1698
00:48:00,833 --> 00:48:03,366
就是突然之间你可以拿来做

1699
00:48:03,366 --> 00:48:05,966
大语言模型的

1700
00:48:05,966 --> 00:48:07,166
decoding 对吧

1701
00:48:07,166 --> 00:48:08,633
解码的这样的一个应用

1702
00:48:08,633 --> 00:48:09,200
那么这应用

1703
00:48:09,200 --> 00:48:11,200
其实本身也可以放在很多手机上

1704
00:48:11,400 --> 00:48:13,233
这是个有用的应用

1705
00:48:13,233 --> 00:48:15,800
其实这样的联系

1706
00:48:15,800 --> 00:48:17,466
应该说还是比较紧密的

1707
00:48:17,866 --> 00:48:19,200
应该容易想到

1708
00:48:19,200 --> 00:48:21,000
对吧,你想你的attention

1709
00:48:21,000 --> 00:48:22,500
如果有稀疏性的话

1710
00:48:22,500 --> 00:48:23,600
那我为什么

1711
00:48:23,833 --> 00:48:26,000
我就把大部分的attention的score砍掉

1712
00:48:26,000 --> 00:48:27,700
那不就加速了吗

1713
00:48:27,833 --> 00:48:29,366
对吧 那就省内存了

1714
00:48:29,366 --> 00:48:30,500
对吧 那你有各种办法

1715
00:48:30,500 --> 00:48:32,433
可以提高这个效率

1716
00:48:32,433 --> 00:48:35,400
所以这两个关系

1717
00:48:35,400 --> 00:48:36,000
是很大的

1718
00:48:36,000 --> 00:48:38,266
所以其实只要稍微想一想

1719
00:48:38,266 --> 00:48:39,566
就有一个新的算法

1720
00:48:39,700 --> 00:48:41,000
那么有新的算法之后

1721
00:48:41,000 --> 00:48:43,000
你就有一个新的思路

1722
00:48:43,000 --> 00:48:43,866
那么这个新的思路

1723
00:48:43,866 --> 00:48:45,466
你就可以拿来做很多有意思的事情

1724
00:48:45,466 --> 00:48:47,900
我要打断一下 你这个体感

1725
00:48:47,900 --> 00:48:49,700
你觉得在别人身上成立吗

1726
00:48:49,700 --> 00:48:52,233
因为有的人觉得赚钱好容易

1727
00:48:52,233 --> 00:48:53,266
到处都可以赚钱

1728
00:48:53,266 --> 00:48:54,200
像你就

1729
00:48:54,200 --> 00:48:55,600
好多research topic

1730
00:48:55,600 --> 00:48:57,566
然后随便拿一个都可以做

1731
00:48:57,700 --> 00:49:00,166
但是很多人绞尽脑汁都觉得想不出来

1732
00:49:00,166 --> 00:49:00,866
所以说

1733
00:49:00,866 --> 00:49:04,166
你觉得这个东西是你独有的特质

1734
00:49:04,166 --> 00:49:05,433
还是

1735
00:49:05,466 --> 00:49:07,800
这个应该说是很长时间的积累

1736
00:49:07,800 --> 00:49:08,966
就是说我觉得是挺难的

1737
00:49:08,966 --> 00:49:11,100
比如说我拿我的理论研究来说吧

1738
00:49:11,100 --> 00:49:11,666
就是

1739
00:49:11,666 --> 00:49:13,066
这个方向其实做很久

1740
00:49:13,300 --> 00:49:15,066
我其实不是数学科班出身

1741
00:49:15,066 --> 00:49:16,233
我很多时候

1742
00:49:16,233 --> 00:49:17,000
有人跑来问我

1743
00:49:17,000 --> 00:49:18,266
说你是不是数学系的

1744
00:49:18,466 --> 00:49:19,166
我说我不是数学系

1745
00:49:19,166 --> 00:49:20,066
我所有数学都是我自己学的

1746
00:49:20,066 --> 00:49:22,800
然后很多时候是这样

1747
00:49:22,800 --> 00:49:23,266
我特别是

1748
00:49:23,266 --> 00:49:25,600
比如一开始想做一些表征理论的研究

1749
00:49:25,700 --> 00:49:27,166
那很痛苦

1750
00:49:27,166 --> 00:49:29,066
因为你很难去想

1751
00:49:29,066 --> 00:49:30,066
你的思考

1752
00:49:30,300 --> 00:49:32,233
你可能会在很多地方转圈子

1753
00:49:32,500 --> 00:49:33,866
然后浪费时间

1754
00:49:33,866 --> 00:49:35,100
你会发现浪费很多时间

1755
00:49:35,100 --> 00:49:37,100
然后真正的事情都没干

1756
00:49:37,100 --> 00:49:39,166
但是你如果持之以恒

1757
00:49:39,166 --> 00:49:39,700
一直在想

1758
00:49:39,700 --> 00:49:41,900
一直在思考反思的话

1759
00:49:42,033 --> 00:49:43,500
慢慢就会发现

1760
00:49:43,500 --> 00:49:44,766
有些地方你可以存盘

1761
00:49:44,766 --> 00:49:45,833
存下来你就知道

1762
00:49:45,900 --> 00:49:46,566
这个地方

1763
00:49:46,566 --> 00:49:49,833
是你发现一个好的insight的节点

1764
00:49:49,833 --> 00:49:51,900
然后这个insight你既然想到了

1765
00:49:51,900 --> 00:49:52,766
那就是你的了

1766
00:49:52,833 --> 00:49:53,633
那你把它写下来

1767
00:49:53,633 --> 00:49:54,266
存下来

1768
00:49:54,266 --> 00:49:56,766
那么有了这个阶段之后

1769
00:49:56,766 --> 00:49:58,366
你存盘这个能力就成立了

1770
00:49:58,366 --> 00:50:00,600
然后你就会花时间做别的事情

1771
00:50:00,600 --> 00:50:01,266
这是第一个

1772
00:50:01,266 --> 00:50:04,100
然后第二个就是说你看很多文章

1773
00:50:04,100 --> 00:50:05,000
做很多research

1774
00:50:05,000 --> 00:50:06,200
那么可能对这个问题

1775
00:50:06,200 --> 00:50:07,633
有大的概念和思路

1776
00:50:07,633 --> 00:50:09,900
就是知道这一块要怎么做

1777
00:50:09,900 --> 00:50:12,400
比如说我们做reasoning

1778
00:50:12,400 --> 00:50:13,900
做self improvement 对吧

1779
00:50:14,033 --> 00:50:16,600
这些方向其实是一个很火的方向

1780
00:50:16,600 --> 00:50:19,000
那么你看了很多文章之后

1781
00:50:19,066 --> 00:50:21,500
就可以知道什么东西能做

1782
00:50:21,500 --> 00:50:23,166
什么东西不能做 对吧

1783
00:50:23,166 --> 00:50:23,433
所以说

1784
00:50:23,433 --> 00:50:25,400
比如说你要改进思维链的长度

1785
00:50:25,466 --> 00:50:26,400
长和短

1786
00:50:26,400 --> 00:50:29,100
对吧 然后怎么做混合的

1787
00:50:29,100 --> 00:50:30,066
thinking

1788
00:50:30,233 --> 00:50:30,766
这种东西

1789
00:50:30,766 --> 00:50:33,266
其实都是

1790
00:50:33,266 --> 00:50:35,300
通过我们过去的经验

1791
00:50:35,300 --> 00:50:37,666
能够发现一些可能性的

1792
00:50:37,666 --> 00:50:38,700
然后在这上面

1793
00:50:38,700 --> 00:50:40,666
你怎么去做更好的工作

1794
00:50:40,900 --> 00:50:42,300
对,这个也是一个经验积累

1795
00:50:42,300 --> 00:50:43,300
应该说是这样

1796
00:50:43,466 --> 00:50:44,966
就是我建议是多看

1797
00:50:44,966 --> 00:50:45,600
多看文章

1798
00:50:45,600 --> 00:50:47,100
然后多想

1799
00:50:47,100 --> 00:50:48,300
多跟别人讨论

1800
00:50:48,433 --> 00:50:50,366
看看这个思路是怎么出来的

1801
00:50:50,366 --> 00:50:51,366
我觉得这个比较重要

1802
00:50:52,633 --> 00:50:53,266
不好意思

1803
00:50:53,266 --> 00:50:53,700
刚刚打断

1804
00:50:53,700 --> 00:50:54,633
我觉得谢谢

1805
00:50:54,633 --> 00:50:56,100
就是帮大家又讲了很多

1806
00:50:56,100 --> 00:50:59,033
怎么提高自己科研水平的

1807
00:50:59,033 --> 00:50:59,833
干货

1808
00:50:59,900 --> 00:51:01,433
然后继续

1809
00:51:01,433 --> 00:51:03,266
就是你

1810
00:51:03,900 --> 00:51:04,766
到了一个阶段

1811
00:51:04,766 --> 00:51:07,700
是你看到了现在的应用

1812
00:51:07,700 --> 00:51:09,666
然后你能很快地比如说

1813
00:51:11,000 --> 00:51:13,766
找到一些新的应用和论文

1814
00:51:13,800 --> 00:51:14,666
这似乎对你来说

1815
00:51:14,666 --> 00:51:16,566
就变成一个比较简单的事情了

1816
00:51:17,066 --> 00:51:17,666
对 因为

1817
00:51:17,666 --> 00:51:18,466
就是说

1818
00:51:18,466 --> 00:51:19,433
很多时候是这样

1819
00:51:19,433 --> 00:51:20,466
就是特别数学好的人

1820
00:51:20,466 --> 00:51:21,366
物理好的人

1821
00:51:21,600 --> 00:51:24,433
他们转到其他领域是很快的

1822
00:51:24,433 --> 00:51:25,066
就是

1823
00:51:25,066 --> 00:51:26,066
为什么是很快的呢

1824
00:51:26,066 --> 00:51:27,166
我个人感觉是这样

1825
00:51:27,166 --> 00:51:28,900
就是数学和物理

1826
00:51:28,900 --> 00:51:29,666
就是

1827
00:51:29,666 --> 00:51:31,000
它给你一个预训练

1828
00:51:31,000 --> 00:51:33,666
让你脑子里面表征比较好

1829
00:51:33,800 --> 00:51:35,866
然后它可能很容易能够

1830
00:51:35,866 --> 00:51:39,100
映射到不同的领域

1831
00:51:39,100 --> 00:51:40,100
然后它们之间

1832
00:51:40,100 --> 00:51:41,866
这个领域的知识可以迁移

1833
00:51:43,033 --> 00:51:43,500
比如说

1834
00:51:43,500 --> 00:51:45,066
我说我要

1835
00:51:45,066 --> 00:51:45,666
抓住本质

1836
00:51:45,666 --> 00:51:46,266
对 这个很重要

1837
00:51:46,266 --> 00:51:46,766
就是比如说

1838
00:51:46,766 --> 00:51:48,366
我说做efficiency

1839
00:51:48,433 --> 00:51:49,500
那就是优化问题

1840
00:51:49,500 --> 00:51:50,200
优化问题的话

1841
00:51:50,200 --> 00:51:52,300
你可以说我有个目标函数

1842
00:51:52,300 --> 00:51:54,200
我有一堆优化的变量

1843
00:51:54,200 --> 00:51:55,200
对吧 然后有约束

1844
00:51:55,200 --> 00:51:56,200
那就可以优化了

1845
00:51:56,300 --> 00:51:56,400
对吧

1846
00:51:56,400 --> 00:51:58,866
但是具体的优化细节

1847
00:51:58,866 --> 00:52:00,500
那么我们可以讨论具体的细节

1848
00:52:00,500 --> 00:52:01,366
那么这是

1849
00:52:01,500 --> 00:52:03,866
这个问题本身的固有属性

1850
00:52:03,866 --> 00:52:05,433
对吧 那么这么想的话

1851
00:52:05,433 --> 00:52:07,000
你有很多问题可以归结在一起

1852
00:52:07,000 --> 00:52:09,300
那么你的思维就比较连贯

1853
00:52:09,566 --> 00:52:10,500
比较一致

1854
00:52:10,500 --> 00:52:11,666
这个是重要的

1855
00:52:11,666 --> 00:52:12,466
这是重要的

1856
00:52:12,500 --> 00:52:14,966
哦 就是回到你刚才说的

1857
00:52:14,966 --> 00:52:16,800
模型的那个点 就是别人

1858
00:52:16,800 --> 00:52:17,866
可能

1859
00:52:17,866 --> 00:52:21,066
你能在同一个区间发现更多的问题

1860
00:52:21,066 --> 00:52:22,233
你能产生更多的

1861
00:52:22,233 --> 00:52:24,466
就是组合出来更多data points

1862
00:52:24,466 --> 00:52:26,433
你就更容易找到这里面的泛化

1863
00:52:26,666 --> 00:52:27,466
是的

1864
00:52:27,466 --> 00:52:28,300
exactly 就是

1865
00:52:28,300 --> 00:52:29,600
其实就是这样子

1866
00:52:29,666 --> 00:52:31,500
然后如果你已经有一个好的表征的话

1867
00:52:31,500 --> 00:52:34,166
那你就很容易泛化到其他领域

1868
00:52:34,166 --> 00:52:36,866
对吧,因为可能在别人看来

1869
00:52:36,866 --> 00:52:38,000
这些点都是离散的

1870
00:52:38,000 --> 00:52:39,200
然后它们没有关联

1871
00:52:39,400 --> 00:52:42,366
但是作为一个比如说

1872
00:52:42,400 --> 00:52:43,600
表征比较好的研究员

1873
00:52:43,600 --> 00:52:44,833
他能看到它们这些关联

1874
00:52:45,033 --> 00:52:45,400
然后

1875
00:52:45,400 --> 00:52:47,466
并且欣赏这些关联之间的美感

1876
00:52:47,466 --> 00:52:49,966
那么首先他能记住更多东西

1877
00:52:50,166 --> 00:52:51,433
对吧,因为这些东西

1878
00:52:51,433 --> 00:52:53,233
在他们脑子里面是有结构的

1879
00:52:53,433 --> 00:52:55,366
然后另外就是说他不觉得

1880
00:52:55,366 --> 00:52:56,966
把这些东西连起来

1881
00:52:56,966 --> 00:52:58,000
或者说把东西记下来

1882
00:52:58,000 --> 00:52:59,900
找到想法是痛苦的

1883
00:53:00,066 --> 00:53:01,666
他能很自然地找到新的想法

1884
00:53:01,900 --> 00:53:03,566
所以这个其实是连上前面一个点

1885
00:53:03,566 --> 00:53:05,500
就是脑子里就放烟花

1886
00:53:05,500 --> 00:53:05,833
这种感觉

1887
00:53:05,833 --> 00:53:06,200
对,对

1888
00:53:06,200 --> 00:53:07,300
你会有很多其他的想法

1889
00:53:07,300 --> 00:53:08,800
你很多想法是有关联的

1890
00:53:08,800 --> 00:53:11,233
然后你能看到它们之间更本质的关联

1891
00:53:11,233 --> 00:53:12,800
那么这更本质的关联

1892
00:53:12,800 --> 00:53:15,066
本身其实就是一篇很好的文章

1893
00:53:15,066 --> 00:53:16,633
或者说一个很重要的

1894
00:53:16,633 --> 00:53:17,666
思路可以往下走

1895
00:53:17,666 --> 00:53:19,200
对吧,别人只能看到表层的关联

1896
00:53:19,800 --> 00:53:21,466
比如说别人觉得A加B

1897
00:53:21,466 --> 00:53:23,633
两个加起来可能是一个好的工作

1898
00:53:23,766 --> 00:53:26,466
对,那么另外就是说

1899
00:53:26,466 --> 00:53:28,166
这种工作可能很多

1900
00:53:28,166 --> 00:53:30,066
但是有些人就觉得A和B

1901
00:53:30,066 --> 00:53:31,066
之间有个本质的联系

1902
00:53:31,066 --> 00:53:33,600
C,然后我发表一篇关于C的工作

1903
00:53:33,700 --> 00:53:35,866
那么C可能就比A和B更本质

1904
00:53:35,866 --> 00:53:37,600
那么这篇工作可能就

1905
00:53:37,800 --> 00:53:39,800
凌驾于其他工作之上

1906
00:53:39,866 --> 00:53:42,033
在它对学术界的影响力

1907
00:53:42,033 --> 00:53:42,800
可能更大

1908
00:53:42,800 --> 00:53:43,833
这个

1909
00:53:43,833 --> 00:53:44,966
是一个不一样的

1910
00:53:44,966 --> 00:53:45,900
角度

1911
00:53:45,900 --> 00:53:47,400
对 这种connection

1912
00:53:47,400 --> 00:53:49,100
就是

1913
00:53:49,100 --> 00:53:49,666
就是

1914
00:53:49,666 --> 00:53:50,766
一个是表征

1915
00:53:50,766 --> 00:53:52,166
一个是这样的

1916
00:53:52,300 --> 00:53:54,066
就是怎么说

1917
00:53:54,066 --> 00:53:56,300
收集、学习、generalize

1918
00:53:56,300 --> 00:53:57,833
然后最后再联系

1919
00:53:58,000 --> 00:53:59,366
这都是很重要的点

1920
00:53:59,366 --> 00:54:01,700
我觉得最后人和机器还是很像的

1921
00:54:01,700 --> 00:54:03,100
在这些角度来说

1922
00:54:03,100 --> 00:54:03,700
对的

1923
00:54:03,700 --> 00:54:04,466
应该是这么说

1924
00:54:04,466 --> 00:54:06,266
就是其实最近有些文章

1925
00:54:06,266 --> 00:54:08,900
应该说最近我看到有一些

1926
00:54:08,900 --> 00:54:11,233
比如说nature machine learning这种文章

1927
00:54:11,233 --> 00:54:12,800
就是它论证

1928
00:54:12,800 --> 00:54:16,166
人的表征和机器的表征是很接近的

1929
00:54:16,166 --> 00:54:18,066
它们可以通过扫描人的大脑

1930
00:54:18,066 --> 00:54:20,066
然后发现一些神经元的

1931
00:54:20,066 --> 00:54:22,166
activation

1932
00:54:22,300 --> 00:54:22,500
对吧

1933
00:54:22,500 --> 00:54:24,833
它们跟神经网络的activation

1934
00:54:24,833 --> 00:54:26,033
是很有关联度的

1935
00:54:26,033 --> 00:54:27,766
这种我是觉得

1936
00:54:27,766 --> 00:54:29,500
不管你是结构什么样的

1937
00:54:29,500 --> 00:54:30,866
开始不同没关系

1938
00:54:30,866 --> 00:54:31,966
只要你数据是一样的

1939
00:54:31,966 --> 00:54:33,200
数据结构是差不多的

1940
00:54:33,300 --> 00:54:33,833
那它的表征

1941
00:54:33,833 --> 00:54:35,200
可能学到的差不多

1942
00:54:35,200 --> 00:54:36,000
我觉得是这样

1943
00:54:36,066 --> 00:54:37,800
但是可能人的学习能力

1944
00:54:37,900 --> 00:54:39,500
人的学习效率

1945
00:54:39,500 --> 00:54:40,866
是比机器要高的

1946
00:54:40,900 --> 00:54:41,700
大概是这样子

1947
00:54:41,700 --> 00:54:43,100
结构还是不一样

1948
00:54:43,200 --> 00:54:44,266
对,对

1949
00:54:44,466 --> 00:54:47,266
那最后一个问题

1950
00:54:47,266 --> 00:54:49,066
就是

1951
00:54:49,466 --> 00:54:51,000
until recently

1952
00:54:51,033 --> 00:54:52,033
你的科研

1953
00:54:52,033 --> 00:54:54,066
你感觉是按照自己的想法走

1954
00:54:54,066 --> 00:54:55,433
还是

1955
00:54:55,433 --> 00:54:59,100
要做很多application的工作

1956
00:54:59,266 --> 00:54:59,900
以及

1957
00:54:59,900 --> 00:55:02,800
接下来可能会吸引你做的事情是什么

1958
00:55:02,800 --> 00:55:03,833
是继续你对

1959
00:55:03,833 --> 00:55:05,433
就是后一种

1960
00:55:05,433 --> 00:55:08,866
研究范式的继续探索,还是

1961
00:55:09,300 --> 00:55:11,433
我觉得研究范式探索是很重要的

1962
00:55:11,700 --> 00:55:12,566
对 那当然了

1963
00:55:12,566 --> 00:55:14,366
就说我们现在也要与时俱进

1964
00:55:14,366 --> 00:55:15,000
对吧

1965
00:55:15,000 --> 00:55:16,900
我不可能说我关起门来说

1966
00:55:16,900 --> 00:55:18,800
我就用以前的方式来做研究

1967
00:55:18,800 --> 00:55:19,866
比如说我们可以想

1968
00:55:20,066 --> 00:55:22,400
也许我们以后要找到一个

1969
00:55:22,500 --> 00:55:24,700
AI scientist

1970
00:55:24,700 --> 00:55:25,500
或者说

1971
00:55:25,500 --> 00:55:27,600
我自己写一套比如说agent的框架

1972
00:55:27,600 --> 00:55:28,600
然后帮我一起做研究

1973
00:55:28,600 --> 00:55:29,400
这也是可以的

1974
00:55:29,600 --> 00:55:30,600
其实我说

1975
00:55:30,600 --> 00:55:33,066
我们这篇Grokking the paper

1976
00:55:33,100 --> 00:55:33,600
这篇文章

1977
00:55:33,600 --> 00:55:34,566
其实说实话

1978
00:55:34,566 --> 00:55:38,066
是我和GPT-5进行对话

1979
00:55:38,066 --> 00:55:39,066
做出来的

1980
00:55:39,066 --> 00:55:41,266
其实这样子

1981
00:55:41,266 --> 00:55:42,666
我觉得这个很有点

1982
00:55:42,666 --> 00:55:43,800
像self-play

1983
00:55:44,000 --> 00:55:45,966
就是我给它一些问题

1984
00:55:45,966 --> 00:55:47,033
然后我这边有些想法

1985
00:55:47,033 --> 00:55:49,433
然后发给GPT-5

1986
00:55:49,433 --> 00:55:50,800
然后让它去思考

1987
00:55:50,900 --> 00:55:51,600
然后让它

1988
00:55:51,600 --> 00:55:53,033
给一些比如formulation

1989
00:55:53,033 --> 00:55:55,033
对吧,一开始你这么做

1990
00:55:55,033 --> 00:55:56,433
它给你的答案

1991
00:55:56,433 --> 00:55:58,100
都是非常大路的

1992
00:55:58,100 --> 00:55:59,566
没什么意思

1993
00:55:59,866 --> 00:56:01,800
但是你通过思考之后

1994
00:56:01,800 --> 00:56:04,366
我觉得有些关键的insight给它

1995
00:56:04,366 --> 00:56:06,433
它可能会有不一样的输出

1996
00:56:06,700 --> 00:56:08,233
然后这样的输出

1997
00:56:08,233 --> 00:56:10,166
可以往下面挖

1998
00:56:10,166 --> 00:56:11,433
往下面深挖一层

1999
00:56:11,633 --> 00:56:13,566
但是你还是要找到它的错误

2000
00:56:13,566 --> 00:56:15,100
找它的一些矛盾的地方

2001
00:56:15,100 --> 00:56:17,266
找到它做不出来的地方

2002
00:56:17,266 --> 00:56:18,600
然后继续深入

2003
00:56:18,766 --> 00:56:20,566
然后一直深入到

2004
00:56:20,566 --> 00:56:22,000
就是

2005
00:56:22,000 --> 00:56:23,433
这个问题的理解

2006
00:56:23,433 --> 00:56:23,700
或者说

2007
00:56:23,700 --> 00:56:26,033
这个问题的数学描述

2008
00:56:26,033 --> 00:56:28,266
已经达到了我想要的目的

2009
00:56:28,266 --> 00:56:30,300
那么这部分就成功了

2010
00:56:30,300 --> 00:56:30,700
就是这样

2011
00:56:30,700 --> 00:56:32,000
应该是这样的感觉

2012
00:56:32,000 --> 00:56:33,266
我在这个使用的过程中

2013
00:56:33,266 --> 00:56:35,500
我觉得当然是现在模型非常强

2014
00:56:35,766 --> 00:56:36,466
有很多工作

2015
00:56:36,466 --> 00:56:38,033
其实是可以

2016
00:56:38,033 --> 00:56:39,566
你用的是GPT-5 Pro吧

2017
00:56:39,566 --> 00:56:40,166
我猜

2018
00:56:40,166 --> 00:56:41,033
不是Pro

2019
00:56:41,033 --> 00:56:42,300
其实就是thingking

2020
00:56:42,300 --> 00:56:43,900
其实说实话Pro没什么用

2021
00:56:44,200 --> 00:56:45,633
对

2022
00:56:45,633 --> 00:56:48,566
我相信o1 Pro和非Pro区别还挺大的

2023
00:56:48,566 --> 00:56:51,600
是 但是我用下来我觉得

2024
00:56:51,700 --> 00:56:53,433
因为其实我有OpenAI的朋友

2025
00:56:53,433 --> 00:56:55,066
他们送我一个月的Pro

2026
00:56:55,300 --> 00:56:56,566
我后来用了一下

2027
00:56:56,566 --> 00:56:57,233
我觉得

2028
00:56:57,233 --> 00:57:00,766
好像也没有特别出众的地方

2029
00:57:00,766 --> 00:57:01,400
回头

2030
00:57:01,400 --> 00:57:04,666
回头把鸭哥做的那个second mind

2031
00:57:05,566 --> 00:57:06,966
我一直觉得这个事非常神奇

2032
00:57:06,966 --> 00:57:08,600
就是鸭哥做了一个

2033
00:57:08,600 --> 00:57:10,200
就是可以几个模型放到一起用

2034
00:57:10,200 --> 00:57:11,966
而且可以handle knowledge的东西

2035
00:57:11,966 --> 00:57:12,433
对对

2036
00:57:12,433 --> 00:57:13,500
我consistently

2037
00:57:13,500 --> 00:57:15,766
我现在几乎都只跟它交流了

2038
00:57:15,766 --> 00:57:17,766
因为我发现它就是比那些

2039
00:57:17,933 --> 00:57:20,100
这边的Claude和o1

2040
00:57:20,766 --> 00:57:22,200
给的答案更好

2041
00:57:22,200 --> 00:57:22,666
我就觉得

2042
00:57:22,666 --> 00:57:23,800
这个东西很

2043
00:57:23,800 --> 00:57:25,500
非常奇怪

2044
00:57:25,500 --> 00:57:28,466
对,但是我回头跟鸭哥说一下

2045
00:57:28,466 --> 00:57:29,966
然后你可以来试用一下这个东西

2046
00:57:29,966 --> 00:57:31,900
对,对,对,那我很感兴趣

2047
00:57:31,900 --> 00:57:32,300
就是因为

2048
00:57:32,300 --> 00:57:34,166
我觉得鸭哥做的事情都非常厉害

2049
00:57:34,400 --> 00:57:35,033
我非常佩服他

2050
00:57:35,033 --> 00:57:35,866
是挺有意思

2051
00:57:35,866 --> 00:57:37,200
对,可以玩一下

2052
00:57:37,200 --> 00:57:38,566
我倒是可以玩玩

2053
00:57:38,566 --> 00:57:39,766
他这个方法是什么样子

2054
00:57:39,900 --> 00:57:41,000
但是我还有一个点

2055
00:57:41,000 --> 00:57:44,466
就是你那是个solo author paper

2056
00:57:44,466 --> 00:57:47,233
你没有把GPT-5放到co-author里面

2057
00:57:47,366 --> 00:57:48,900
听起来它做了不少工作

2058
00:57:48,900 --> 00:57:50,633
按照逻辑 你可以看

2059
00:57:50,633 --> 00:57:52,466
就是这篇文章是conference投稿

2060
00:57:52,466 --> 00:57:53,800
conference投稿说

2061
00:57:54,000 --> 00:57:56,166
大语言模型不能作为

2062
00:57:56,566 --> 00:57:58,033
不能作为

2063
00:57:58,033 --> 00:57:58,833
作者

2064
00:57:58,833 --> 00:57:59,666
所以没有放 对吧

2065
00:57:59,666 --> 00:58:00,833
那我后面写了一段

2066
00:58:00,833 --> 00:58:02,833
这段话是说

2067
00:58:02,833 --> 00:58:03,366
作者

2068
00:58:03,366 --> 00:58:04,233
我是说我们

2069
00:58:04,233 --> 00:58:05,566
我们广泛使用大语言模型

2070
00:58:05,566 --> 00:58:07,033
我给大语言模型各种想法

2071
00:58:07,033 --> 00:58:07,866
让它去formulate

2072
00:58:07,866 --> 00:58:09,000
让它证明一个东西

2073
00:58:09,100 --> 00:58:10,566
然后发现问题怎么解决

2074
00:58:10,566 --> 00:58:12,000
对吧 它基本上所有东西都是错的

2075
00:58:12,100 --> 00:58:14,666
但是它有一些比较有意思的insight

2076
00:58:14,666 --> 00:58:16,566
有些东西可以细化

2077
00:58:16,600 --> 00:58:18,566
然后把你的idea从一个想法

2078
00:58:18,566 --> 00:58:20,900
变成一个具体的过程

2079
00:58:20,900 --> 00:58:22,433
这个它很擅长

2080
00:58:22,433 --> 00:58:25,000
就相当于它是一个非常勤劳的

2081
00:58:25,233 --> 00:58:27,000
职业的

2082
00:58:27,000 --> 00:58:28,366
PhD

2083
00:58:28,366 --> 00:58:29,766
你可以这么想

2084
00:58:29,900 --> 00:58:31,100
就是它非常勤劳

2085
00:58:31,100 --> 00:58:32,500
然后我给它一个想法

2086
00:58:32,500 --> 00:58:34,000
它马上写出来

2087
00:58:34,000 --> 00:58:35,766
写出一个很长的论述

2088
00:58:35,866 --> 00:58:38,100
让我能够很快进入状态

2089
00:58:38,166 --> 00:58:39,300
这很重要

2090
00:58:39,433 --> 00:58:41,166
对,你比如说你以前要进入状态

2091
00:58:41,166 --> 00:58:41,866
比如说

2092
00:58:41,866 --> 00:58:43,100
我要做research

2093
00:58:43,100 --> 00:58:44,300
好 我有

2094
00:58:44,300 --> 00:58:46,000
我现在有一个小时的时间

2095
00:58:46,033 --> 00:58:48,066
我可能一开始半小时

2096
00:58:48,066 --> 00:58:48,800
我要进入状态

2097
00:58:48,800 --> 00:58:49,233
进入状态

2098
00:58:49,233 --> 00:58:51,033
就我通过写公式

2099
00:58:51,033 --> 00:58:51,800
看文章

2100
00:58:51,800 --> 00:58:52,466
思考一下

2101
00:58:52,466 --> 00:58:53,033
我进入状态了

2102
00:58:53,033 --> 00:58:54,166
进入

2103
00:58:54,166 --> 00:58:55,633
这个叫心流

2104
00:58:55,633 --> 00:58:56,800
对吧 然后去想

2105
00:58:56,966 --> 00:58:59,633
然后才能得到一些结果

2106
00:58:59,633 --> 00:59:01,600
那这个时间其实比较漫长

2107
00:59:01,600 --> 00:59:04,000
但是有了GPT-5之后

2108
00:59:04,000 --> 00:59:05,033
我觉得很重要的一点是

2109
00:59:05,033 --> 00:59:06,466
你进入心流时间很短了

2110
00:59:06,466 --> 00:59:08,200
就是你跟它有一个小想法

2111
00:59:08,200 --> 00:59:09,366
然后它给你写一大段

2112
00:59:09,366 --> 00:59:10,500
比如

2113
00:59:10,500 --> 00:59:12,033
3分钟之内给你写一大段东西

2114
00:59:12,066 --> 00:59:13,033
你看完这段东西之后

2115
00:59:13,033 --> 00:59:14,100
你马上会进入这个状态

2116
00:59:14,100 --> 00:59:15,800
就说我知道我要怎么去想问题

2117
00:59:16,066 --> 00:59:17,233
就现在这个问题在那放着

2118
00:59:17,233 --> 00:59:19,000
然后哪个地方它做得不好

2119
00:59:19,000 --> 00:59:20,866
或者说有什么insight可以进来

2120
00:59:21,200 --> 00:59:23,900
所以这是很大的一个

2121
00:59:23,900 --> 00:59:25,833
应该说效率的改进

2122
00:59:25,866 --> 00:59:26,633
对 我可能觉得

2123
00:59:26,633 --> 00:59:29,033
以前你需要几个月的时间做一篇文章

2124
00:59:29,033 --> 00:59:30,566
你现在可能几个礼拜

2125
00:59:30,566 --> 00:59:32,466
甚至是更短的时间

2126
00:59:32,466 --> 00:59:32,966
我觉得

2127
00:59:32,966 --> 00:59:35,433
这是非常大的效率提升

2128
00:59:35,566 --> 00:59:36,466
如果用得好的话

2129
00:59:36,466 --> 00:59:38,466
是很厉害的

2130
00:59:38,466 --> 00:59:39,833
对 那么这个

2131
00:59:39,833 --> 00:59:40,000
当然

2132
00:59:40,000 --> 00:59:41,633
现在还是一个非常初级的self-play

2133
00:59:41,633 --> 00:59:43,600
对吧 也许说不定以后

2134
00:59:43,600 --> 00:59:44,833
我们可以做一个

2135
00:59:44,833 --> 00:59:46,400
更加自动化版的

2136
00:59:46,400 --> 00:59:47,666
那就很有意思

2137
00:59:48,833 --> 00:59:50,900
这个

2138
00:59:50,966 --> 00:59:52,766
肯定这方面有很多东西可以做

2139
00:59:52,766 --> 00:59:54,600
但是我们在这就不多想了

2140
00:59:54,600 --> 00:59:55,900
对 我自己也有一些经验了

2141
00:59:55,900 --> 01:00:00,800
就是我跟当时是GPT-o1 Pro去探讨

2142
01:00:00,800 --> 01:00:05,066
这是我一直对量子力学的那个many-world

2143
01:00:05,100 --> 01:00:06,366
theory

2144
01:00:06,366 --> 01:00:07,400
我特别感兴趣

2145
01:00:07,400 --> 01:00:10,066
然后我一直觉得它最make sense

2146
01:00:10,066 --> 01:00:12,400
但是我们没有对应的哲学

2147
01:00:12,500 --> 01:00:14,633
然后我觉得其实你看佛经也好

2148
01:00:14,633 --> 01:00:15,566
或者看什么

2149
01:00:15,566 --> 01:00:16,833
就是很多东西

2150
01:00:16,866 --> 01:00:19,900
它的哲学,反而那种所谓玄学的哲学

2151
01:00:19,900 --> 01:00:23,100
和这个many-world theory的哲学是吻合的

2152
01:00:23,266 --> 01:00:24,900
大概意思就是说

2153
01:00:25,566 --> 01:00:28,833
就是我如果非要强行说的话

2154
01:00:28,833 --> 01:00:31,500
我就说这个世界的本质

2155
01:00:31,500 --> 01:00:34,833
就是一个非确定的many worlds

2156
01:00:34,866 --> 01:00:37,766
然后我们之所以现在share一个reality

2157
01:00:37,766 --> 01:00:38,900
这是我们的

2158
01:00:38,900 --> 01:00:39,700
就是最大概率

2159
01:00:39,700 --> 01:00:41,000
当然这个概率可能极大

2160
01:00:41,000 --> 01:00:42,766
就是99.99999

2161
01:00:42,766 --> 01:00:43,033
所以说

2162
01:00:43,033 --> 01:00:45,033
我们就会觉得这个桌子是确定无疑地

2163
01:00:45,033 --> 01:00:45,200
存在

2164
01:00:45,200 --> 01:00:47,566
但是其实它可能并不是真的存在

2165
01:00:48,166 --> 01:00:49,300
对 大概是这种感觉

2166
01:00:49,300 --> 01:00:50,666
对 这个是对的

2167
01:00:50,666 --> 01:00:52,766
就是从科学上也是对的

2168
01:00:52,766 --> 01:00:54,166
因为你可以认为

2169
01:00:54,166 --> 01:00:55,966
它是一堆波函数的组合

2170
01:00:55,966 --> 01:00:57,900
对吧 然后存在一种可能是

2171
01:00:57,900 --> 01:00:58,300
这个桌子

2172
01:00:58,300 --> 01:01:00,566
突然之间跑到那堵墙另外一边去了

2173
01:01:00,833 --> 01:01:01,666
这概率非常小

2174
01:01:01,666 --> 01:01:03,066
但是不是0

2175
01:01:03,066 --> 01:01:03,966
这个是存在的

2176
01:01:03,966 --> 01:01:05,833
只是

2177
01:01:05,833 --> 01:01:07,600
因为这个桌子是宏观物体 对吧

2178
01:01:07,600 --> 01:01:09,866
它的量子态

2179
01:01:09,866 --> 01:01:11,366
就是不是那种相干量子态

2180
01:01:11,366 --> 01:01:12,600
所以

2181
01:01:12,600 --> 01:01:14,766
不会出现这种概率非常小

2182
01:01:14,766 --> 01:01:16,600
就是这样子的东西

2183
01:01:17,100 --> 01:01:18,100
但是我就发现

2184
01:01:18,100 --> 01:01:18,700
这个idea

2185
01:01:18,700 --> 01:01:20,233
我没有办法和它写成一个文章

2186
01:01:20,233 --> 01:01:21,666
因为我自己的水平不行

2187
01:01:21,800 --> 01:01:25,400
所以说就是现在AI能辅助你写出来

2188
01:01:25,400 --> 01:01:27,433
像你这样的文章

2189
01:01:27,500 --> 01:01:29,633
还是主要是自己

2190
01:01:29,633 --> 01:01:30,433
主要是自己

2191
01:01:30,433 --> 01:01:31,066
是的

2192
01:01:31,066 --> 01:01:32,633
就是人还是比较重要

2193
01:01:32,633 --> 01:01:35,033
有很多重要的insight还是要人给

2194
01:01:35,033 --> 01:01:36,966
然后AI现在有很多莫名其妙的问题

2195
01:01:36,966 --> 01:01:39,200
比如说它就会卡在一个地方动不了

2196
01:01:39,200 --> 01:01:41,366
就是它会跟你说很多重复的话

2197
01:01:41,566 --> 01:01:43,766
然后就是它说不到本质上

2198
01:01:43,766 --> 01:01:45,066
这个很有意思

2199
01:01:45,200 --> 01:01:45,866
就像感觉

2200
01:01:45,866 --> 01:01:49,100
它就是你去面试一个新来的PhD

2201
01:01:49,600 --> 01:01:51,366
然后说一大堆话

2202
01:01:51,366 --> 01:01:53,100
它像背诵概念

2203
01:01:53,100 --> 01:01:54,566
就是但它又绕不到

2204
01:01:54,566 --> 01:01:56,166
它就找不到那句最重要的

2205
01:01:56,166 --> 01:01:57,400
本质的话能够说出来

2206
01:01:57,400 --> 01:01:58,366
那这个

2207
01:01:58,366 --> 01:02:00,500
其实是一个表达的问题

2208
01:02:00,500 --> 01:02:02,500
但是这个就需要人去总结

2209
01:02:02,500 --> 01:02:03,766
然后告诉它

2210
01:02:04,500 --> 01:02:06,500
是我们认为的最本质的东西

2211
01:02:06,500 --> 01:02:07,300
然后让它继续往

2212
01:02:07,300 --> 01:02:08,200
下走

2213
01:02:08,200 --> 01:02:09,700
这个是比较重要的 那现在

2214
01:02:09,700 --> 01:02:11,400
刚才

2215
01:02:11,400 --> 01:02:13,766
你就是说这是一个fresh PhD

2216
01:02:13,766 --> 01:02:16,633
fresh PhD意味着它可能是可以被训练的

2217
01:02:16,800 --> 01:02:19,700
我想到是Duolingo的那个founder

2218
01:02:19,700 --> 01:02:21,900
他是一个计算机

2219
01:02:21,900 --> 01:02:22,600
教授

2220
01:02:22,600 --> 01:02:23,366
我忘了叫什么

2221
01:02:23,366 --> 01:02:24,666
冯,是一个

2222
01:02:24,666 --> 01:02:25,600
万开头的 是

2223
01:02:25,600 --> 01:02:26,566
对,

2224
01:02:26,566 --> 01:02:28,066
他讲了一个故事

2225
01:02:28,066 --> 01:02:30,966
就是他去读博士的第一年

2226
01:02:30,966 --> 01:02:31,833
他

2227
01:02:31,833 --> 01:02:32,700
几个月

2228
01:02:32,700 --> 01:02:34,400
他老师是图灵奖

2229
01:02:34,400 --> 01:02:35,033
是图灵奖

2230
01:02:35,033 --> 01:02:36,100
的获得者

2231
01:02:36,100 --> 01:02:37,400
获得者

2232
01:02:37,400 --> 01:02:38,400
对 然后几个月

2233
01:02:38,400 --> 01:02:39,500
他去了以后

2234
01:02:39,566 --> 01:02:41,000
就是他老师

2235
01:02:41,000 --> 01:02:42,100
就只跟他干一件事

2236
01:02:42,100 --> 01:02:43,900
就是你这个东西跟我讲讲

2237
01:02:43,900 --> 01:02:44,766
我没听懂

2238
01:02:44,766 --> 01:02:45,633
下次再来

2239
01:02:45,700 --> 01:02:46,900
就他

2240
01:02:46,900 --> 01:02:48,100
第二个月的时候就崩溃了

2241
01:02:48,100 --> 01:02:49,566
就这个老师肯定不行吧

2242
01:02:49,566 --> 01:02:50,433
怎么回事

2243
01:02:50,433 --> 01:02:51,300
结果后来才发现

2244
01:02:51,300 --> 01:02:52,733
就是他自己没有讲清楚

2245
01:02:52,733 --> 01:02:53,066
对 没有

2246
01:02:53,066 --> 01:02:53,833
你没讲清楚

2247
01:02:53,833 --> 01:02:55,100
说明你理解不深

2248
01:02:55,300 --> 01:02:56,433
对吧 如果理解深的话

2249
01:02:56,433 --> 01:02:56,966
讲清楚了

2250
01:02:56,966 --> 01:02:57,600
别人会觉得

2251
01:02:57,600 --> 01:02:58,433
你确实理解深了

2252
01:02:58,433 --> 01:02:59,166
你确实懂了

2253
01:02:59,166 --> 01:03:00,033
然后你可以做

2254
01:03:00,033 --> 01:03:01,433
你可以做研究

2255
01:03:01,433 --> 01:03:02,400
所以这是一个

2256
01:03:02,600 --> 01:03:03,966
他叫Luis von Ahn

2257
01:03:04,200 --> 01:03:04,633
我想起来

2258
01:03:04,633 --> 01:03:05,966
对对 他是

2259
01:03:05,966 --> 01:03:06,500
应该是

2260
01:03:06,500 --> 01:03:08,233
应该说我当时在CMU读博的时候

2261
01:03:08,233 --> 01:03:09,066
他就在那了

2262
01:03:10,466 --> 01:03:10,866
对

2263
01:03:10,866 --> 01:03:11,966
他有这么一个故事

2264
01:03:11,966 --> 01:03:12,500
所以说

2265
01:03:12,500 --> 01:03:14,400
不知道模型是不是也可以这么训练

2266
01:03:14,400 --> 01:03:15,833
我觉得有希望

2267
01:03:15,833 --> 01:03:17,100
希望可以

2268
01:03:17,100 --> 01:03:18,066
是的是的 对

2269
01:03:18,066 --> 01:03:19,700
当然了 就是大模型可能会

2270
01:03:19,866 --> 01:03:21,566
可能会强行记住

2271
01:03:21,566 --> 01:03:22,900
就是我怎么样讲能讲清楚

2272
01:03:22,900 --> 01:03:24,266
但是它自己不懂也是有可能

2273
01:03:24,566 --> 01:03:26,066
对

2274
01:03:26,266 --> 01:03:26,800
这个

2275
01:03:26,800 --> 01:03:27,666
不知道会怎么

2276
01:03:27,666 --> 01:03:28,033
而且就说

2277
01:03:28,033 --> 01:03:30,233
你怎么才能获得训练数据

2278
01:03:30,400 --> 01:03:33,300
能够让大模型找到最优的讲清楚的

2279
01:03:33,300 --> 01:03:33,600
这样一个

2280
01:03:33,600 --> 01:03:33,966
因为讲

2281
01:03:33,966 --> 01:03:35,566
清楚这个事情是个非常主观的东西

2282
01:03:35,800 --> 01:03:36,633
就是很难

2283
01:03:36,966 --> 01:03:38,433
很难用这个模型

2284
01:03:38,433 --> 01:03:40,766
去model它

2285
01:03:42,466 --> 01:03:44,166
在要求大语言模型之前

2286
01:03:44,166 --> 01:03:45,300
我们先要求自己

2287
01:03:45,300 --> 01:03:47,700
我们先要求自己把一个东西想清楚

2288
01:03:47,700 --> 01:03:49,866
已经是一个很高的要求了

2289
01:03:49,866 --> 01:03:51,500
对对 这个很难

2290
01:03:51,500 --> 01:03:52,200
就是说

2291
01:03:52,200 --> 01:03:54,833
这部分其实可能就需要人有美感

2292
01:03:54,833 --> 01:03:56,200
就是人觉得

2293
01:03:56,366 --> 01:03:58,200
它的讲解是非常有美感的

2294
01:03:58,200 --> 01:04:00,700
或者说非常简单扼要

2295
01:04:00,700 --> 01:04:02,400
那这个才可以

2296
01:04:02,400 --> 01:04:05,700
那这个怎么去设计一个loss function

2297
01:04:05,700 --> 01:04:06,833
是一个question

2298
01:04:07,966 --> 01:04:09,466
好的

2299
01:04:09,566 --> 01:04:11,766
那我们今天已经聊了不少了

2300
01:04:11,766 --> 01:04:14,166
你觉得还有没有什么想聊的东西

2301
01:04:14,166 --> 01:04:15,766
或者说我应该问的问题

2302
01:04:15,800 --> 01:04:17,233
那应该没有了

2303
01:04:17,233 --> 01:04:18,633
对 我觉得已经挺好了

2304
01:04:18,633 --> 01:04:20,833
而且其实我们已经把这篇文章讲

2305
01:04:20,833 --> 01:04:21,366
讲出来了

2306
01:04:21,366 --> 01:04:21,566
对吧

2307
01:04:21,566 --> 01:04:24,200
我也不想要通过非常枯燥的方式来讲

2308
01:04:24,266 --> 01:04:25,200
通过这个对话来讲

2309
01:04:25,200 --> 01:04:26,066
我觉得非常好

2310
01:04:26,566 --> 01:04:28,600
而且能看出来的是

2311
01:04:28,900 --> 01:04:30,366
我觉得通过这个对话

2312
01:04:30,366 --> 01:04:32,233
我也更深层次地理解了

2313
01:04:32,233 --> 01:04:33,566
就是这件事有多重要

2314
01:04:33,566 --> 01:04:35,066
它的context是什么

2315
01:04:35,066 --> 01:04:36,966
和它其实对人也好

2316
01:04:36,966 --> 01:04:38,666
或者对模型来说

2317
01:04:38,666 --> 01:04:39,900
其实都有很多共通的地方

2318
01:04:39,900 --> 01:04:41,600
我觉得通过这个讲

2319
01:04:41,600 --> 01:04:43,466
这个论文我们也讲了很多其他的

2320
01:04:43,466 --> 01:04:44,900
我觉得挺重要的知识

2321
01:04:47,266 --> 01:04:50,400
好的,那祝你接下来一切顺利

2322
01:04:50,400 --> 01:04:51,366
谢谢

2323
01:04:51,833 --> 01:04:52,600
先这样

2324
01:04:52,600 --> 01:04:54,466
拜拜
