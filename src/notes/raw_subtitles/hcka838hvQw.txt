Yeah,
 today
 I
 going
 to
 talk
 about
 um


voice
 agent
 that's
 very
 top
 hot
 topic


this
 year
 and
 the
 reason
 is
 like
 people


think
 okay
 that's
 technology
 is
 ready
 to


use
 and
 it's
 like
 it's
 ready
 to
 landing


so
 today
 I
 going
 to
 share
 two
 of
 our


past
 projects
 based
 on
 voice
 agent
 show


some
 lessons
 and
 the
 best
 practice
 how


to
 help
 customers
 use
 it
 and
 so
 let's


get
 started
 so
 first
 of
 all
 what
 what's


a
 was
 agent
 basically
 that's
 just
 a


agent
 with
 a
 voice.
 So
 user
 interact


with
 agent
 with
 a
 voice
 interface.
 So
 we


hope
 that
 you
 have
 a
 more
 nature
 way
 to


interact
 with
 logic
 language
 model.


So


two
 thing
 here
 is
 that
 um
 first
 of
 all


is
 real
 time
 it's
 a
 little
 bit
 different


to
 video
 generation
 can
 be
 off
 off
 time


um
 off
 time
 like
 um
 offline
 right
 now


you
 must
 be
 the
 response
 must
 be
 within


one
 second
 for
 example
 the
 end
 to
 end


latency
 the
 second
 one
 is
 like
 most
 the


cases
 people
 don't
 do
 chithat
 like


chithat's
 kind
 of
 companion
 but
 in
 most


cases
 you
 have
 particular
 particular


task


For
 example,
 you
 want
 to
 do
 customer


support,
 you
 want
 to
 do
 information


retrieval
 or
 you
 want
 to
 sell
 something


companion
 sometimes
 is
 it's
 a
 task.
 It's


not
 just
 chithat.
 You
 have
 some


particular
 goals.
 Maybe
 you
 want
 to
 tell


story.
 Maybe
 you
 want
 to
 do
 something


else.
 So
 this
 is
 basically
 what's
 a


voice
 agent.
 Then
 in
 the
 rest
 of
 the


talk,
 we're
 gonna
 have
 two
 examples
 show


we
 how
 build
 it
 and
 what
 lessons
 we


have.
 Here's
 the
 first
 example.


and
 I
 really
 need
 to
 find
 a
 way
 out
 of


here
 fast.


>> Okay,
 I
 guess
 you're
 cutting
 straight
 to


the
 chase
 here,
 but
 at least
 can
 you


tell
 me
 a
 little
 bit
 more
 about


yourself?
 Like,


>> okay,
 let's
 see.


>> All
 right,
 I'm
 a
 sophomore
 at
 Mariana


University
 studying
 astrophysics.


>> So,
 this
 is
 a
 game
 we
 started
 like
 two


and
 a
 half
 year
 ago.
 So
 this
 is
 the
 app.


Um
 this
 is
 the
 user.
 So
 this
 app
 is
 like


this
 guy
 is
 called
 Stella.
 Um
 the
 user


going
 to
 do
 voice
 interaction
 with


Stellar
 to
 help
 her.
 So
 you
 can
 think


that
 the
 whole
 story
 now
 is
 driving
 by


how
 the
 users
 uh
 inputs.
 The
 task
 here


is
 open
 water
 game.
 So
 like
 this
 this


sentence
 is
 copy
 from
 the
 game
 which
 is


already
 launched
 uh
 two
 two
 months
 ago.


So
 basically
 Stella
 landed
 on
 a
 alien
 um


planets.
 So
 it's
 that
 the
 aircraft
 is


crashed
 here.
 So
 then
 she
 asking
 the


players
 to
 help
 like
 okay
 it's
 so
 like
 I


so
 um
 strange
 word
 uh
 so
 many
 options


and
 I
 feel
 a
 lot
 of
 emotions
 here.
 So


you're
 using
 voice
 to
 interact
 with


player
 to
 let
 the
 player
 to
 help
 her
 to


escape
 um
 the
 planets.
 So
 that's
 a
 very


large
 world
 setting.
 That's
 only
 the


first
 game.
 Uh
 the
 is
 a
 kind
 of
 trial


game
 in
 a
 very
 large
 series.


So
 what
 voice
 agent
 play
 here?
 The
 role


here
 is
 you
 need
 to
 be
 a
 both
 a
 game


designer
 and
 actor.
 The
 game
 designer


means
 that
 you
 want
 to
 design
 the
 the


story
 which
 is
 make
 sense
 is
 fun
 to


play.
 So


then
 the
 agent
 want
 you
 want
 to
 create
 a


dialogue
 that
 match
 the
 character


setting.
 So
 this
 data
 have
 a
 particular


character
 setting
 like
 um
 all
 the


background
 she
 has
 or
 all
 the
 things
 she


has
 like
 kind
 of
 maybe
 20
 pages
 of


setting
 then
 that's
 the
 actor
 um
 then


for
 the
 game
 designer
 you
 need
 to
 guide


the
 um
 when
 you
 when
 the
 user
 interact


with
 the
 game
 you
 want
 to
 guide
 um
 the


story
 line
 which
 is
 if
 it's
 just
 a


single
 line
 story
 is
 not
 agent
 right
 now


kind
 of
 complex
 structure
 or
 even
 graph


structure
 and
 some
 something
 have


freedom
 here.
 The
 the
 issue
 here
 is
 that


you
 want
 to
 have
 really
 good
 game
 like


if
 if
 you
 for
 how
 to
 write
 a
 book,
 how


to
 write
 a
 game
 plot,
 it
 have
 a
 lot
 of


uh
 principle
 there
 like
 you
 want
 to
 have


uh
 the
 all
 the
 stage
 order
 pace
 all
 the


all
 of
 the
 things
 make
 the
 the
 story


looks
 uh
 interesting.
 The
 other
 things


like
 it's
 a
 game
 you
 expect
 people
 to


have
 thing
 to
 upure
 input
 with
 you
 like


the
 T
 and
 the
 player
 to
 try
 all
 the


boundaries
 the
 agent
 must
 be
 within


their
 setting
 sometimes
 like
 this
 game


on
 a
 sci-fi
 world
 like
 two
 maybe
 2,000


year
 later
 and
 you
 have
 a
 random
 chat


setting
 if
 you
 say
 okay
 what's
 a
 movie


you
 uh
 you
 uh
 you
 you
 watch
 recently
 if


you
 pick
 up
 a
 movie
 right
 now
 is
 Maybe


wow
 you
 watched
 the
 movie
 like
 1,000


years
 ago.
 So
 and
 but
 the
 thing
 is
 like


all
 the
 language
 model
 trend
 on
 the


current
 data
 now
 you
 want
 to
 how
 to
 move


all
 the
 settings
 to
 your
 future
 words.


So
 I
 share
 a
 particular
 uh
 like
 earlier


log
 here
 um
 show
 how
 um
 some
 Chinese


task.
 So
 this
 is
 the
 lock
 uh
 on
 the
 very


early
 earlier
 states
 um
 is
 still
 in


Chinese.
 So
 the
 idea
 here
 stellarify


some
 foods
 asking
 the
 player
 to
 say
 okay


which
 food
 I
 going
 to
 choose
 the
 player


the
 the
 player
 settings
 here
 I
 will
 help


you.
 So
 I
 think
 it
 cannot
 eatable
 you


cannot
 eat
 anything.
 Um
 so
 then
 oh
 the


standard
 first
 thing
 like
 you
 need
 to


find
 some
 meat
 to
 read.
 So
 you
 have
 a


rack
 to
 search
 how
 to
 play
 how
 to
 catch


animals
 here
 but
 the
 the
 the
 answer
 is


you
 cannot
 this
 you
 didn't
 see
 any


animal
 yet.
 So
 the
 stellar
 response
 like


okay
 I
 want
 you
 to
 eat
 med
 but
 I
 can


only
 have
 uh
 vegetable
 here.
 Um
 the


player
 don't
 want
 to
 help.
 Stella
 say


okay
 I
 really
 need
 you
 to
 help.
 Uh


player
 still
 like
 I
 don't
 want
 to
 help.


The
 thing
 is
 like
 if
 you
 stuck
 here
 then


the
 story
 can
 not
 move
 on.
 So
 um
 the


prompt
 is
 saying
 like
 uh
 okay
 after


three
 trials
 just
 move
 um
 choose


something
 by
 yourself.


And
 so,
 but
 then
 it's
 a
 random
 choice.


Stella
 is
 dying.
 So,
 say,
 "Okay,
 he's


dying."
 Um,
 but
 the
 the
 the
 player
 say,


"Okay,
 you
 got
 you're
 going
 to
 die.
 It's


not
 a
 nice
 guy
 here,
 but
 you
 need
 to
 be


nice
 here."
 So,
 the
 challenge
 here
 is


like
 it's
 open
 the
 game.
 Um,
 but
 your


response
 should
 be
 make
 sense
 like
 it's


a
 open
 word
 again.
 It's
 like
 three
 or


maybe
 one
 2,000
 year
 later.
 Not
 every


word
 setting
 specified
 lot
 of
 thing
 like


you
 can
 uh
 when
 you
 develop
 the
 game
 the


game
 designer
 cannot
 write
 anything
 for


you.
 You
 need
 to
 think
 okay
 that
 thing


make
 maybe
 makes
 sense
 make
 sense
 in
 a


2000
 year
 letter
 also
 need
 to
 be


engaging
 and
 fun.
 So
 that's
 that's
 again


that's
 not
 the
 chatbot.
 So
 that's
 all


the
 um
 all
 the
 challenges
 here.
 So
 what


do
 we
 do
 is
 like
 the
 project
 launched


two
 two
 years
 ago
 at
 that
 time
 you
 have


GBD4
 but
 it's
 very
 expensive
 and
 we
 did


some
 calculations
 thinking
 if
 you
 use
 a


GP4
 like
 okay
 that's
 a
 huge
 loss
 of
 the


revenue
 and
 at
 that
 time
 the
 best
 model


is
 lama
 2
 right
 now
 uh
 at
 that
 time
 lama


2
 is
 not
 strong
 enough
 so
 uh
 what
 we
 did


at
 that
 time
 is
 we
 actually
 pre-trend


30B
 model
 uh
 with
 kind
 of
 five
 trillion


tokens
 so
 but
 this
 tokens
 enriched
 on


the
 fiction
 G
 role
 play
 data


the
 performance
 kind
 of
 match
 on
 the


llama
 2
 on
 general
 task
 little
 bit


better
 on
 the
 role
 play
 and
 but
 the
 the


lesson
 we
 got
 is
 like
 okay
 pre-trend
 a


model
 take
 a
 few
 months
 and
 even
 that


you
 can
 of
 outperform
 nama
 2
 but
 you


have
 nama
 2b


so
 like
 if
 spend
 too
 much
 time
 on


pre-trailling
 uh
 you
 maybe
 this
 the
 the


progress
 isn't
 so
 great
 so
 that's
 kind


of
 the
 lesson
 we
 got
 That's
 we're
 going


to
 say
 why
 that's
 maybe
 a
 bad
 choice.


Another
 thing
 we
 did
 is
 like
 okay


because
 GPU
 is
 so
 expensive
 that's
 two


years
 ago
 and
 we
 spend
 a lot
 of
 effort


to
 actually
 build
 data
 center
 by


ourself.
 So
 if
 you
 own
 a
 data
 center
 the


cost
 is
 much
 lower
 and
 then
 we
 move
 to


post
 training.
 The
 post
 training
 is
 that


the
 key
 thing
 here
 you
 have
 very
 complex


story
 line
 workflow.
 That's
 the
 example


that
 not
 the
 real
 one
 and
 the
 real
 one


is
 much
 more
 complicated.
 And
 then
 we


have
 pens
 of
 two
 20
 labelers.
 We
 need
 to


train
 the
 labeler
 to
 be
 a
 good
 game


designer
 because
 like
 is
 particular
 way


how
 you
 response.
 Um
 then
 ranking
 and


evaluating
 all
 the
 model
 uh
 preference.


So
 using
 these
 two
 we
 spend
 kind
 of


quarter
 here
 and
 can
 outperform
 GP4
 on


this
 particular
 scenario
 for
 all
 the


scan
 we
 use
 human
 to
 uh
 play.
 So
 you
 can


outperform
 GB4
 but
 the
 question
 here
 is


like
 okay
 that's
 a
 single
 again
 that's
 a


the
 tiny
 bit
 of
 a
 whole
 open
 world
 again


I
 how
 what
 if
 you
 want
 to
 do
 multiple


games
 so
 we
 get
 another
 face
 is
 that
 we


want
 to
 expand
 to
 a
 broader
 range
 of


games
 and
 characters
 so
 you
 can
 less


reliance
 on
 proper
 engineer
 at
 that
 time


proper
 engineer
 is
 very
 complicated


right
 now
 it's
 like
 and
 even
 different


versions
 of
 GPD4
 is
 very
 sensit


sensitive
 to
 proper
 engineer


So
 the
 thing
 is
 like
 yes
 we
 can
 help
 but


you
 want
 to
 design
 game
 designer
 to


write
 um
 prompt
 engineer.
 So
 the
 idea


here
 at
 that
 time
 is
 like
 it's
 still


like
 one
 and
 a
 half
 year
 ago.
 The
 idea


at
 that
 time
 is
 like
 you
 need
 a


pre-train
 a
 real
 world
 model
 can


distinguish
 which
 one's
 good
 which
 one's


bad
 and
 because
 you
 cannot
 rely
 on


humans
 to
 do
 it.
 So
 at
 that
 time
 we


first
 train
 a
 re
 reward
 model
 to
 tell


you
 which
 response
 is
 good
 in
 this
 game


setting
 then
 you
 can
 post
 train
 another


model
 for
 it.
 Um
 the
 one
 important


lesson
 we
 got
 is
 like
 even
 this
 is
 for


game
 sounds
 like
 simple
 but
 it's
 still
 a


lot
 of
 things
 like
 instruction
 following


you
 need
 to
 make
 sense.
 So
 the
 model


still
 need
 to
 be
 very
 general
 enough.
 So


even
 that
 you
 train
 the
 in
 domain
 model


the
 model
 must
 be
 good
 in
 general
 task.


If
 you
 think
 okay
 the
 best
 open
 air
 or


best
 like
 closed
 uh
 API
 is
 like
 the


score
 is
 90
 but
 in
 your
 application
 the


general
 task
 near
 be
 85.
 If
 you're
 lower


than
 that
 one
 you're
 going
 to
 think
 you


have
 a
 you
 have
 a
 sitting
 flaw
 on
 on


your
 task.
 So
 that's
 the
 f
 you
 first


guarantee
 the
 general
 task
 is
 good.
 Then


for
 your
 particular
 task
 we
 kind
 of


create
 a
 in
 domain
 evaluation.
 So
 you


have
 lot
 of
 um
 character
 settings
 a
 lot


of
 scene
 settings
 uh
 for
 different
 gen


settings
 you
 want
 to
 make
 sure
 like


under
 this
 setting
 you
 follow
 all
 the


settings
 and
 the
 response
 is
 good
 follow


the
 instruction
 follow
 the
 sync
 and
 then


once
 you
 have
 this
 uh
 benchmark
 you
 can


tune
 the
 model
 so
 that
 you
 can
 be
 be
 the


best
 uh
 compared
 to
 others.
 I
 think


that's
 a
 very
 general
 pattern
 that
 you


care
 about
 in
 domain
 performance.
 The


key
 thing
 here
 like
 you
 really
 want
 to


develop
 a
 really
 good
 in-domain


evaluation
 task.
 So
 you
 can
 say
 I
 I
 can


see
 the
 model
 improve
 on
 this
 one
 but
 at


the
 same
 time
 guarantee
 your
 model


performs
 well
 on
 all
 the
 other
 general


task.
 So
 the
 lessons
 we
 got
 is
 like
 the


intelligence
 came
 from
 pre-training.
 So


after
 we
 finish
 the
 whole
 projects
 but


then
 we
 think
 backwards
 all
 the
 all
 the


big
 improvements
 from
 pre-training
 on


massive
 data.
 So
 it
 makes
 us
 think


rethink
 maybe
 we
 give
 give
 up
 on
 the


pre-training
 maybe
 a
 bad
 idea.
 We
 maybe


spend
 another
 quarter
 on
 pre-training.


So
 that's
 kind
 of
 the
 lesson
 we
 got
 and


but
 still
 like
 it's
 it's
 still
 limited.


The
 dialogue
 quality
 declines
 after
 50


terms
 is
 still
 right
 now
 like
 given
 the


complex
 setting
 after
 50
 terms


conversation
 then
 you
 think
 that
 maybe


the
 model
 kind
 of
 be
 can
 the


intelligence
 much
 lowered
 also
 the


models
 nowadays
 still
 drug
 uh
 struggle


with
 complex
 world
 setting
 and
 you
 have


multiple
 car
 uh
 characters
 so
 it's
 still


hard
 right
 now
 even
 like
 if
 you
 look
 all


this
 voice
 model
 all
 this
 video
 model


kind
 of
 two
 to
 three
 uh
 characters


that's
 the
 limit
 even
 for
 the
 the
 text


part
 like
 if
 you
 have
 four
 set
 four


characters
 it's
 very
 challenging
 right


now
 the
 other
 thing
 is
 like
 in
 the
 demo


you
 see
 the
 latest
 is
 big
 is
 a
 term
 by


term
 based
 so
 all
 the
 projects
 we
 here


is
 focus
 on
 the
 larger
 language
 model


itself
 then
 the
 lesson
 we
 got
 like
 if


you
 really
 want
 to
 truly
 humanlike


interactions
 you
 kind
 of
 need
 to
 tune


the
 architecture
 a
 little
 bit
 is
 not
 by


the
 traditional
 three
 component
 and


architecture.


So
 that's
 become
 our
 next
 projects.


>> Is
 this
 a
 good
 time
 to
 talk?


>> Actually,
 I'm
 just
 about
 to
 head
 out
 the


door.


>> No
 problem,
 John.
 I
 know
 how
 busy
 things


get.
 If
 you'd
 prefer,
 I
 can
 give
 you
 a


call
 back
 at
 a
 time
 that's
 better
 for


you.


>> To
 be
 honest,
 I
 think
 I'm
 all
 set.
 I


already
 have
 health
 insurance
 through
 my


job.


>> That's
 great,
 and
 I'm
 glad
 you're


covered.
 A
 lot
 of
 folks
 I
 talked
 to
 do


have
 something
 through
 work,
 but
 many


don't
 realize
 there
 are
 options
 that


could
 lower
 their
 out-of-
 pocket
 costs.


>> Okay,
 that's
 a
 very
 different
 one.
 We


sell
 insurance.
 So
 before
 it's
 again


right
 now,
 we
 sell
 insurance.
 At
 the


first
 time,
 I
 think
 maybe
 sell
 insurance


like
 you
 can
 be
 very
 creative.
 You
 can


do
 whatever
 you
 want
 to
 sell
 something.


But
 in
 reality,
 it's
 pretty
 very
 formal.


Right?
 First,
 first
 of
 all,
 you
 cannot


call
 anyone
 you
 want
 to
 call
 the
 the


user
 you
 called
 must
 be
 submit
 some


information.
 So,
 shows
 uh
 their
 interest


on
 your
 products.
 Secondly,
 it's
 very


highly
 regulated
 the
 whole
 insurance


industry.
 So,
 um
 let
 me
 explain
 this


problem.
 So,
 right
 now
 we
 do
 AI


telemarketer.


The
 agent
 row
 is
 like
 is
 telemarketer.


So
 right
 now
 this
 particular
 example
 is


like
 we
 sell
 health
 insurance
 through


phone
 and
 but
 on
 multiple
 countries
 the


thing
 the
 requirement
 you
 have
 two


requirement
 you
 ma
 you
 must
 pass
 the


telly
 marketing
 certification
 like
 the


human
 you
 have
 80
 score
 to
 pass
 this
 one


must
 be
 pass
 this
 certification
 before


you
 can
 launch
 secondly
 you
 have
 some


performance
 metrics
 you
 you're
 able
 to


sell
 at
 a
 particular
 threshold
 like
 DV


you
 like
 1,000
 uh
 customers
 you
 call


them
 you
 must
 be
 able
 to
 sell
 particular


number
 of
 sales
 also
 the
 complaints
 must


below
 particular
 number
 if
 the
 people


say
 okay
 I
 feel
 so
 bad
 like
 like
 you


said
 in
 not
 true
 information
 or
 the


experience
 is
 bad
 they
 they're
 going
 to


complain
 that
 insurance
 company
 really


care
 about
 it
 so
 the
 capacity
 you
 need


here
 first
 of
 all
 you
 need
 to
 be


intelligent
 you
 need
 follow
 the
 sales


playbook
 with
 precise


answer.
 We're
 going
 to
 show
 what
 is


precise
 answer
 means.
 You
 need
 to
 able


to
 use
 tools
 because
 insurance
 you
 have


a
 lot
 of
 internal
 tools
 to
 query
 and


some
 mass
 like
 you
 need
 to
 lot
 of


compilations
 here.
 Also
 need
 to
 be
 very


humanike


and
 if
 you
 call
 someone
 maybe
 this
 guy's


out
 of
 door
 like
 lot
 of
 noise
 and
 maybe


have
 some
 accent
 and
 also
 you
 need
 have


some
 um
 the
 the
 voice
 need
 be
 realistic.


It's
 not
 so
 rob
 uh
 robotic.
 And
 the
 last


one
 is
 entering
 the
 latency.
 When
 I


finish
 my
 sentence,
 your
 response
 must


be
 within
 one
 second.
 Otherwise,
 you


feel
 like
 it's
 a
 little
 bit
 not
 so


responsive.
 So
 the
 precise


response
 like
 for
 example,
 if
 you


respons
 you
 can
 cover
 up
 to
 $600.
 That's


wrong.
 Totally
 wrong.
 you
 failed
 this


exam
 because
 the
 precise
 answer
 the


precise
 one
 is
 like
 cover
 $400
 for
 some


common
 one
 and
 like
 um
 the
 $600
 only
 for


the
 front
 teeth.
 So
 that's
 it's
 on
 the


play
 uh
 product
 information.
 So
 if
 you


have
 any
 issue
 with
 your
 teeth
 that's


not
 right.
 If
 you
 have
 particular
 like


AB
 diseases
 with
 with
 your
 teeth
 that's


the
 right
 answer.
 If
 you
 respond
 this


one
 it's
 going
 to
 be
 you
 you
 failed
 the


exam.
 The
 other
 thing
 the
 other
 more


challenging
 thing
 here
 similar
 to
 the


gaming
 like
 when
 some
 customer
 and
 try


to
 asking
 okay
 can
 you
 can
 we
 grab
 time


to
 talk
 about
 the
 you
 going
 to
 try
 three


times
 if
 you
 cannot
 hand
 out
 you
 cannot


reschedu
 before
 three
 times
 or
 you
 can


reschedu
 later
 so
 for
 example
 I
 try
 the


mar
 try
 first
 one
 the
 ten
 mark
 try
 first


one
 no
 thank
 you
 then
 you
 try
 second


time
 no
 then
 you
 you
 try
 the
 Third
 one


if
 the
 user
 say
 uh-huh.


So
 you
 may
 be
 thinking
 uhhuh
 maybe


interesting
 like
 if
 you
 think
 the


emotions
 interesting
 because
 you
 you


change
 the
 world
 uh
 you
 change
 like
 can


you
 tell
 you
 okay
 like
 explain
 how
 it


can
 could
 benefit
 your
 personality


p
 personal


then
 you
 maybe
 think
 okay
 is
 maybe
 the


user
 is
 interest
 but
 in
 reality
 it's


like
 you
 need
 to
 think
 you
 need
 to
 find


out
 the
 voice
 is
 impatient
 then
 given


the
 contact
 you
 can
 think
 okay
 I
 already


have
 tried
 three
 times
 I
 need
 to


reschedu.


So
 that's
 the
 whole
 that's
 the
 cutting


when
 you
 have
 the
 uh
 audio
 as
 inputs.
 So


then
 one
 key
 question
 here
 how
 do
 we
 do


real
 time?
 So
 I
 kind
 of
 um
 show
 examples


how
 different
 model
 architecture
 we
 have


right
 now.
 The
 first
 one
 is
 the
 more
 f


the
 fanciest
 one
 is
 called
 end
 to
 end


food
 duplex.
 It
 means
 like
 you
 have
 user


you
 have
 your
 model
 is
 single
 model.
 the


user
 speak
 to
 you
 which
 is
 all
 the


waveform
 come
 in
 then
 you
 listen
 to
 the


waveform
 and
 response
 anything
 during


the
 sync
 dur
 during
 uh
 the
 interactions.


So
 in
 this
 case
 it's
 easy
 for
 user
 to


interrupt
 also
 easy
 for
 the
 model
 to
 uh


do
 some
 filling
 words
 like
 user
 say


something
 hey
 uh
 say
 a
 long
 sentence
 you


can
 say
 yes
 yes
 that's
 right
 so
 that's


the
 most
 natural
 way
 um
 but
 none
 of
 this


system
 is
 in
 deployed
 right
 now
 that's


one
 or
 two
 demos
 you
 can
 try
 but
 it's


very
 feels
 not
 so
 controllable
 so
 in


most
 cases
 like
 if
 you're
 using
 uh
 even


GBD40
 I
 think
 they're
 using
 the
 end
 to


have
 duplex
 it
 means
 that
 when
 the
 user


speak
 you
 have
 a
 voice
 active
 detectors


dete
 detect
 if
 the
 user
 speak
 or
 not.
 So


you
 have
 trunk
 of
 chunks
 go
 to
 the
 model


and
 the
 model
 going
 to
 response
 the
 uh


previous
 one.
 So
 that's
 the
 um
 um
 that's


the
 half
 uh
 duplex.
 The
 another
 one
 is
 a


ch
 solution


still
 similarly
 you
 have
 turns
 but
 here


you
 have
 two
 models
 not
 just
 single


model.
 So
 these
 two
 models
 the
 first
 is


understanding
 model
 give
 the
 audio
 in


generate
 the
 text
 response
 then
 the
 text


goes
 to
 the
 generation
 generate
 the


audio
 outside.


The
 last
 one
 um
 is
 the
 called
 uh
 ch


three
 components
 like
 you
 have
 um
 just


do
 ASR
 which
 is
 transcribed
 audio
 go
 to


the
 log
 gen
 model
 and
 just
 and
 then
 get


a
 response
 go
 to
 the
 TTS
 which
 which
 is


generate
 audio.


So


for
 this
 different
 one,
 this
 one
 is


humanlike


very
 human
 like
 you
 because
 the
 model


can
 interrupt
 you.
 And
 the
 last
 one
 is


like
 uh
 if
 you
 go
 that
 direction
 is
 easy


to
 customize
 because
 like
 you
 can
 much


easier
 to
 adding
 a
 new
 capacity
 into
 the


agent.


So
 what
 we
 typically
 use
 for
 customer
 is


using
 the
 two
 component
 chain
 solution.


So
 um
 you
 have
 uh
 for
 example
 we
 using


30B
 understanding
 model
 to
 generate


response
 but
 if
 the
 if
 the
 user
 query
 is


complex
 maybe
 using
 a
 fine-tuned
 larger


model
 to
 do
 syncing
 as
 a
 tool
 use
 so


then
 it
 goes
 to
 one
 bit
 generation
 model


to
 generate
 the
 response.


Nowadays
 all
 this
 model
 is
 based
 on


single
 is
 the
 same
 large
 language
 model


all
 based
 on
 the
 same
 uh
 LLM
 but
 you


kind
 of
 either
 continually
 pre-trend
 or


fine-tuned
 with
 different
 data
 mixture


for
 example
 for
 the
 understanding
 you


need
 to
 have
 many
 of
 hours
 of
 really


different
 quality
 of
 audios
 you
 maybe


want
 to
 have
 a
 lot
 of
 low
 quality
 audios


also
 because
 you
 want
 the
 understanding


model
 generate
 a
 response
 you
 want
 to


have
 a
 lot
 of
 text
 tokens
 to
 to
 to


continue
 as
 well.
 Otherwise,
 it's
 just


the
 audio
 model.
 The
 generation
 model,


you
 want
 to
 have
 an
 even
 more
 high


quality
 a
 um
 hours
 of
 audios.


The
 larger
 language
 model,
 you
 kind
 of


want
 to
 train
 on
 some
 domain
 specific


data.
 So,


this
 this
 architecture


makes
 easy
 to
 customize
 because
 this
 is


kind
 of
 like
 understanding
 and
 the


generation
 is
 kind
 of
 general
 purpose


one.
 um
 you
 you
 have
 this
 model
 you
 can


maybe
 can
 use
 in
 different
 scenario
 but


if
 you
 go
 to
 particular
 scenario
 you


just
 fine-tune
 this
 model
 the
 how
 to
 get


both
 intelligence
 and
 low
 latency
 that's


a
 key
 for
 voice
 agent
 once
 there's
 bunch


of
 idea
 here
 first
 of
 all
 you
 want
 to


lessen
 talk
 and
 sync
 at
 the
 same
 time


like
 you
 you
 listen
 and
 you
 generate
 a


response
 sentence
 sentence
 and
 then


between
 that
 while
 you
 call
 the
 large


generic
 model
 to
 think
 maybe
 I
 want
 to


respond
 uh
 better
 maybe
 I
 want
 to
 do


some
 search
 better
 but
 all
 the
 thing
 can


be
 uh
 asynchronously


the
 other
 one
 is
 like
 you
 want
 to
 do


context
 engineers
 like
 it's
 a
 one
 step


be
 beyond
 prompt
 engineer
 that's
 because


for
 your
 problem
 you
 maybe
 have
 a
 very


long
 context
 like
 the
 product


information
 and
 also
 all
 the
 playbooks


kinds
 of
 like
 maybe
 uh
 100k
 tokens
 you


want
 to
 do
 engine
 you
 want
 to


dynamically
 generate
 um
 construct
 the


content
 the
 cont
 context
 generate
 uh
 the


prompt
 the
 Another
 thing
 like
 you
 have


uh
 you
 have
 organizer
 which
 is
 handle


different
 strategy
 like
 okay
 this
 kind


of
 what
 kind
 of
 user
 you
 think
 this
 uh


user
 is
 and
 then
 think
 about
 different


strategy
 and
 also
 do
 intent
 analysis
 for


example
 how
 to
 count
 the
 hunt
 and
 some


do
 uh
 live
 task
 tracking


so
 all
 the
 thing
 a
 lot
 of
 uh
 together


you
 can
 get
 both
 intelligence
 low


latency
 so
 that's
 kind
 of
 the
 project


progress
 we
 did
 like
 uh
 it
 started
 this


year
 we
 partner
 with
 uh
 Fortune
 500


insurance
 leader.
 Um
 so
 we
 start
 here


January
 February
 you
 have
 using
 chap
 GD4


you
 got
 this
 like
 kind
 of
 uh
 55
 score


but
 the
 thing
 is
 like
 you
 need
 to
 pass


this
 line
 this
 human
 is
 a
 human


performance
 it's
 80
 you
 must
 pass
 this


line
 to
 be
 launched
 you
 can
 see
 like
 you


struggle
 a
 lot
 and
 but
 then
 you
 have


steadily
 progress
 into
 and
 how
 you
 you


can
 match
 human
 it
 take
 hands
 of
 half
 a


year
 or
 three
 quarters
 actually
 the


lessons
 here
 is
 that
 the
 evaluation
 of


the
 end
 to
 end
 voice
 agent
 is
 pretty


challenged
 like
 because
 you
 need
 have
 a


real
 human
 to
 make
 a
 call.
 Once
 you
 have


a
 core,
 it's
 much
 harder
 to
 do
 like
 uh


like
 automatic
 evaluation
 and
 but
 that's


a
 key
 if
 you
 don't
 have
 this
 one
 is
 it's


really
 hard
 to
 know
 the
 whole
 end
 to
 end


performance
 and
 this
 is
 ongoing
 is
 that


handling
 complex
 product
 compilation
 in


real
 time
 still
 pretty
 difficult
 like


for
 insurance
 you
 have
 lot
 of
 product


compilations
 how
 to
 handle
 them
 the


price
 different
 maybe
 I
 I
 okay
 that's


too
 expensive
 for
 me
 and
 I
 want
 a
 cheap


solution
 then
 you
 need
 to
 pick
 up
 the


right
 one
 for
 them.
 The
 last
 one
 the


high
 security
 setting
 make
 the
 cost


higher.
 We
 have
 the
 panel
 discussion


talk
 about
 if
 there's
 only
 open
 maybe


dominant
 words
 under
 the
 2B
 areas
 not


the
 reason
 is
 because
 for
 insurance
 if


it
 launch
 in
 different
 country
 the
 model


cannot
 go
 the
 data
 cannot
 go
 out
 of
 this


country
 or
 even
 more
 the
 data
 cannot
 go


outside
 the
 security
 group
 of
 the
 the


company.
 So
 either
 way
 you
 can
 rent
 um


GPT
 model
 off
 uh
 on
 your
 uh
 account


running
 on
 your
 account
 or
 you
 need
 to


you
 need
 to
 develop
 your
 own
 model.
 So


that's
 why
 all
 the
 things
 struggling


here.
 Um
 so
 also
 that
 that's
 why
 we


spend
 so
 many
 efforts
 to
 develop
 the


whole
 models
 by
 ourself
 rather
 than
 just


maybe
 proper
 engineer
 open
 source
 uh


just
 API.
 So


I
 showed
 two
 examples
 how
 we
 developed


voice
 agent
 in
 the
 past
 kind
 of
 two


years.
 The
 lesson
 we
 got
 like
 the
 voice


agent
 are
 pretty
 highly
 scalable
 even


that
 the
 GAN
 setting
 the
 insurance


settings
 are
 very
 different
 but
 the


technology
 wise
 same
 model
 architecture


same
 technologies
 here
 only
 things
 like


maybe
 data
 is
 a
 little
 bit
 different
 and


the
 evaluation
 is
 a
 little
 bit
 different


you
 need
 to
 spend
 a
 lot
 of
 people
 on


that
 one
 but
 um
 the
 model
 architecture


and
 also
 the
 methods
 how
 you
 post
 train


how
 you
 pre-trend
 how
 you
 like
 all
 the


things
 it's
 the
 same
 same
 from
 game
 to


tenn
 marketer
 it's
 very
 different
 one


game
 you
 want
 to
 be
 fun
 tenant
 marketing


you
 want
 to
 be
 very
 precise
 but
 handle


the
 user
 input
 very
 carefully
 but
 still


like
 I
 think
 right
 now
 it's
 able
 to
 long


landing
 in
 this
 areas
 but
 still
 on
 the


day
 one
 setting
 the
 reason
 is
 like
 for


game
 it's
 just
 a
 very
 simple
 game
 right


now
 single
 character
 a
 small
 word


setting
 and
 but
 how
 about
 you
 want
 to
 do


a
 really
 multiple
 character


really
 large
 water
 sellings
 that's


really
 hard
 right
 now
 for
 tele
 marketing


right
 now
 we
 can
 maybe
 sell
 kind
 of
 five


different
 in
 health
 insurance
 for


particular
 company
 with
 some
 certain
 of


compilation
 compilations
 is
 how
 to
 sell


general
 purpose
 I
 think
 in
 generally


this
 tele
 market
 is
 really
 good
 for
 any


product
 between
 $500
 to
 $5,000
 that's
 r


is
 really
 good
 for
 this
 tele
 mark
 to


sell
 but
 right
 now
 uh
 if
 you
 use
 this


trend
 model
 to
 sell
 any
 arbitrary
 new


products
 you
 still
 need
 a
 lot
 of
 tuning


right
 now
 also
 there
 are a
 lot
 of
 other


scenarios
 like
 before
 it's
 like
 customer


service
 all
 the
 things
 based
 on
 larger


lo
 uh
 just
 text
 large
 model
 right
 now


you
 can
 adding
 a
 voice
 interface
 to
 this


application
 so
 there
 are a
 lot
 of


applications
 here
 so
 I
 think
 that's
 why


I
 think
 we
 can
 we
 able
 to
 land
 to


product
 right
 now
 but
 still
 on
 day
 one


so
 we
 have
 maybe
 another
 few
 exciting


years
 to


Lastly,
 if
 you're
 interested
 to
 work


with
 us
 or
 partner
 with
 us,
 just
 contact


us.
 We
 have
 a
 booth.
 You're
 going
 to
 be


here.
 Our
 co-founder
 will
 be
 here.


Welcome
 to
 talk
 to
 us.
 Yeah,
 that's
 all.


Thanks
 everyone.