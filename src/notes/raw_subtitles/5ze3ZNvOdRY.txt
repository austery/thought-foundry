Are
 we
 in
 an
 AI
 bubble?


>> Uh,
 I
 do
 not
 believe
 we're
 in
 an
 AI


bubble
 today.
 I
 was,
 depending
 on
 how


you
 look
 at
 it,
 the
 privilege
 and
 the


misfortune
 of
 being
 a
 tech
 investor


during
 the
 year
 2000
 bubble,
 which
 was


really
 a
 telecom
 bubble.
 And
 I
 think


it's
 really
 helpful
 to
 compare
 and


contrast
 today
 to
 the
 year
 2000.
 The


year
 2000
 internet
 bubble
 or
 telecom


bubble
 was
 defined
 by
 something
 called


dark
 fiber.
 At
 the
 peak,
 97%
 of
 the


fiber
 that
 had
 been
 laid
 was
 dark.


Contrast
 that
 with
 today.
 There
 are
 no


dark
 GPUs.


And
 that
 brings
 us
 to
 our
 opening


fireside
 chat.
 We're
 going
 to
 start
 with


a
 taboo
 question
 right
 out
 of
 the
 gate.


Are
 you
 ready
 for
 it?
 If
 AI
 love
 it.
 If


AI
 is
 the
 biggest
 trend
 in
 the
 world


right
 now,
 where
 is
 the
 evidence
 for
 it?


Why
 is
 it
 only
 just
 beginning
 to
 show
 up


in
 the
 economy?
 And
 as
 Andre
 Carpathy


asked,
 are
 agents
 really
 just
 ghosts?


To
 kick
 this
 off
 and
 to
 help
 us
 answer


this
 question,
 please
 join
 us
 in


welcoming
 Gavin
 Baker,
 managing
 partner


and
 CIO
 of
 Atrades.
 Now,
 some
 of
 you
 may


know
 Gavin
 as
 that
 really
 thoughtful
 guy


on
 Twitter.
 Anytime
 some
 big
 piece
 of
 AI


news
 comes
 out,
 I
 know
 more
 than
 a
 few


people
 who
 count
 on
 Gavin
 to
 explain


what
 the
 f
 is
 really
 going
 on.
 So,
 a


huge
 thank
 you
 to
 Gavin
 for
 being
 with


us
 today.
 Joining
 him
 is
 our
 very
 own


David
 George,
 general
 partner
 at
 A16Z.


[Music]


Who
 knows
 what
 that
 music
 was
 from?


>> Glad
 they
 got
 our
 pump
 up
 music
 right.


>> Yes.


Battlestar
 Galactica,
 the
 original
 1977


one.
 in
 case
 we
 have
 to
 all
 fight
 Sylons


in
 a
 few
 years.


>> It's
 it's
 uh
 yeah,
 good
 good
 segue
 into


the
 topic,
 I
 guess.
 Um
 so,
 thank
 you
 for


being
 here.
 I
 always
 love
 talking
 to


you.


>> Same.
 Um
 really
 grateful
 to
 you
 for


inviting
 me,
 grateful
 to
 your
 colleagues


for
 having
 me
 here.
 I'm
 really
 look


forward
 to
 the
 next
 uh
 two
 days.
 I
 think


I'm
 going to
 learn
 a
 lot.
 So,
 thank
 you.


>> Yeah.
 Okay.
 All right.
 So,
 the
 big
 topic


is
 AI
 bubble
 kind
 of
 macro
 view
 of


things.
 Um,
 so
 maybe
 just
 to
 start
 with


a
 couple
 stats
 to
 set
 the
 stage
 and
 then


I
 want
 to
 get
 your
 take
 on
 on
 where


we're
 at.
 So
 we
 have
 about
 a
 trillion


dollars
 of
 data
 centers
 in
 the
 US.
 The


plan
 is
 to
 add
 3
 to4
 trillion
 in
 the


next
 5
 years.
 Over
 the
 past
 three
 years,


we
 have
 already
 built
 out
 in
 data
 center


capacity
 a
 larger
 amount
 of
 dollars
 than


the
 entire
 US
 interstate
 highway
 system,


which
 took
 40
 years
 just
 in
 terms
 of


dollars.
 And
 that's
 a
 inflation


adjusted.


Open
 AAI
 alone
 I
 think
 has
 more
 than
 a


trillion
 dollars
 of
 deals
 set
 up
 that


they've
 committed
 to
 and
 we
 can
 talk


about
 that.
 Um


but
 at
 the
 same
 time,
 so
 those
 are
 all


like
 big
 numbers
 on
 infrastructure
 and


they're
 scary
 and
 they
 say
 oh
 bubble
 and


Google
 uh
 released
 a
 stat
 recently
 that


they
 have
 seen
 a
 150x
 increase
 in
 the


amount
 of
 tokens
 processed
 in
 the
 last


17
 months.
 So
 on
 the
 one
 hand
 you've
 got


this
 crazy
 scary
 sounding
 buildout.
 On


the
 other
 hand
 you
 actually
 have
 a
 bunch


of
 usage
 that's
 happening.
 So
 are
 we
 in


an
 AI
 bubble?
 Uh
 I
 do
 not
 believe
 we're


in
 an
 AI
 bubble
 today.
 Uh
 I
 was
 um
 I
 had


depending
 on
 how
 you
 look
 at
 it
 the


privilege
 and
 the
 misfortune
 of
 being
 a


tech
 investor
 during
 the
 um
 the
 year


2000
 bubble
 which
 was
 really
 a
 telecom


bubble.
 And
 I
 think
 it's
 really
 helpful


to
 compare
 and
 contrast
 today
 to
 the


year
 2000.
 um
 you
 know
 first
 I
 think
 uh


Cisco
 peaked
 at
 150
 or
 180
 times


trailing
 earnings
 Nvidia
 is
 at
 more
 like


40
 times
 so
 valuations
 are
 very


differently
 very
 different
 most


important
 however
 is
 that
 the
 year
 2000


internet
 bubble
 or
 telecom
 bubble
 was


defined
 by
 something
 called
 dark
 fiber


um
 and
 if
 you're
 a
 veteran
 of
 of
 the


year
 2000
 you'll
 know
 what
 that
 was
 but


dark
 fiber
 was
 literally
 fiber
 that
 was


laid
 down
 in
 the
 ground
 and
 not
 lit
 up.


Fiber
 is
 useless
 unless
 you
 have
 the


optics
 and
 switches
 and
 routers
 uh
 that


you
 need
 on
 either
 side.
 Um
 you
 so
 I


vividly
 remember,
 you
 know,
 companies


like
 Level
 3
 or
 Global
 Crossing
 or


WorldCom
 would
 come
 in
 and
 they
 say,
 "We


laid
 200,000
 miles
 of
 dark
 fiber
 this


quarter.
 This
 is
 so
 amazing.
 The


internet's
 going
 to
 be
 so
 big.
 Um
 you


know,
 we
 can't
 wait
 to
 light
 these
 up."


At
 the
 peak
 of
 the
 bubble,
 97%
 of
 the


fiber
 that
 had
 been
 laid
 in
 America
 was


dark.
 Contrast
 that
 with
 today.
 There


are
 no
 dark
 GPUs.
 All
 you
 have
 to
 do
 is


read
 any
 technical
 paper.
 And
 that
 one


of
 the
 biggest
 problems
 in
 a
 training


run
 is
 that
 GPUs
 are
 melting.
 And


there's
 a
 very
 simple
 way
 to
 kind
 of
 cut


to
 the
 heart
 of
 all
 of
 this.
 It
 is
 the


return
 on
 invested
 capital
 of
 the


biggest
 spenders
 on
 GPUs
 who
 are
 all


public
 and
 those
 companies
 since
 they


ramped
 up
 capex
 have
 seen
 call
 it
 a


10point
 increase
 in
 their
 ROIC's.
 So


thus
 far
 the
 ROI
 on
 all
 the
 spending
 has


been
 really
 positive.
 It's
 a
 really
 it's


an
 interesting
 and
 open
 debate
 about


whether
 or
 not
 it
 will
 continue
 to
 be


positive
 with
 the
 quantum
 of
 spend
 we're


going
 to
 have
 on
 Blackwell.
 I
 personally


think
 it
 will,
 but
 there's
 no
 debate


that
 thus
 far
 the
 ROI
 on
 AI
 has
 been


really
 positive
 and
 valuation
 wise.


We're
 just
 not
 in
 a
 bubble.


I
 couldn't
 agree
 more.
 The
 other
 thing


that
 I
 would
 say
 is
 you
 can
 contrast
 the


actual
 adoption
 and
 usage
 of
 the


technology
 from
 then,
 right?
 The


internet
 was
 actually
 really
 hard


because
 you
 had
 to
 build
 a
 two-sided


network.
 like
 you
 had
 to
 build
 websites


and
 then
 you
 had
 to
 get
 users
 and
 it's


much
 more
 difficult
 in
 the
 case
 of
 the


AI
 tools
 you
 know
 all
 you
 have
 to
 do
 is


kind
 of
 light
 them
 up
 via
 API
 or
 you


know
 turn
 on
 your
 website
 chatgpt
 and


everybody
 has
 access
 to
 them
 right
 built


on
 top
 of
 cloud
 computing
 on
 top
 of
 the


internet
 uh
 and
 you
 know
 you
 can
 get
 to


instant
 distribution
 a
 billion
 people


right
 away


>> absolutely
 so
 uh
 the
 other
 thing
 is
 the


counterparties
 so
 you
 mentioned
 this


they
 happen
 to
 be
 the
 best
 companies
 in


the
 history
 of
 the
 world
 right
 I
 think


collectively
 the
 people
 who
 are
 coming


out
 of
 pocket.
 They're
 writing
 checks
 uh


for
 this
 capex.
 I
 think
 they


collectively
 generate
 like
 $300
 billion


of
 free
 cash
 flow
 a
 year.
 Is
 that
 right?


Some
 directionally


>> round
 numbers.


>> Yeah.
 And
 they
 have
 $500
 billion
 of
 cash


on
 the
 balance
 sheet.
 So
 whenever
 people


are
 like,
 "Oh
 my
 god,
 it's
 a
 bubble.
 Is


it
 going
 to
 pop?"
 I'm
 like,
 I
 think
 it's


kind
 of
 fine.
 I
 mean,
 you
 know,
 it
 costs


like4
 or
 50
 billion
 to
 light
 up
 one


gigawatt.


>> Yeah.
 If
 you're
 on
 Nvidia
 chips


>> on
 Nvidia
 chips.


>> Yeah.


>> Yeah.
 So,
 you
 know,
 there's
 kind
 of
 like


an
 $800
 billion
 buffer
 growing
 $300


billion
 every
 year.


>> Yeah.
 I
 mean,
 um,
 free
 cash
 flow
 at
 some


of
 them
 has
 begun
 to
 maybe
 uh,
 you
 know,


>> well,
 this
 this
 goes
 to
 your
 point
 on


return
 on
 invested
 capital.
 It
 might


>> we
 should
 see
 that
 next
 down
 a
 little


bit.
 A
 little
 bit
 of
 a
 mismatch
 at
 the


buildout,


>> but
 you
 know,
 it's
 you
 know,
 Larry
 Page


apparently
 internally
 said,
 I'm
 happy
 to


go
 bankrupt
 rather
 than
 lose
 this
 race.


And
 I
 think
 that
 is
 the
 mentality
 for


sure
 at
 Google
 and
 perhaps
 Meta.
 um
 it's


just
 seen
 as
 existential
 and
 you
 have
 to


win.


>> Okay.
 So,
 uh
 lots
 has
 been
 written
 about


these
 roundtpping
 deals.
 So,
 give
 me
 the


because
 you
 know
 roundtpping
 is
 a
 very


scary
 concept
 from
 you
 know
 the
 internet


buildout
 that
 was
 a
 big
 problem.


>> What
 do
 you
 make
 of
 it
 here?


>> It
 is
 objectively
 happening.
 Um
 you
 know


money
 is
 fungeible.
 So
 Nvidia
 if
 they


sign
 a
 deal
 with
 OpenAI
 they
 can
 say
 hey


you
 can't
 use
 our
 money
 to
 buy
 our
 chips


but
 money
 is
 fungeible.
 But
 it's


happening
 at
 a
 very
 small
 scale.


Yes.
 Yeah.
 And
 I
 think
 um


>> I
 didn't
 know
 this
 was
 like
 a
 crypto
 or


blockchain.


>> Exactly.
 Good.


>> Yeah.


>> And
 I
 think
 what
 is
 driving
 um
 what
 is


driving
 this
 isn't
 the
 need
 to,
 you


know,
 finance
 GPU
 or
 data
 center


purchases,
 but
 it's
 actually
 com


competitive
 dynamics.
 So,
 Nvidia's


biggest
 competitor,
 it's
 not
 AMD,
 it's


not
 Broadcom,


um,
 you
 know,
 it's
 it's
 certainly
 not


Marll.
 Um,
 it's
 not
 it's
 not
 Intel,
 it's


Google.
 And
 more
 specifically,
 it
 is


Google
 because
 Google
 owns
 uh
 the
 TPU


chip.
 And
 this
 is
 by
 far
 maybe
 perhaps


today
 the
 only
 um
 alternative
 to
 NVIDIA


for
 training
 um
 and
 maybe
 the
 best
 uh


inference
 alternative.
 And
 what
 Google


and
 Google's
 a
 problematic
 competitor


because
 they
 also
 own
 a
 company
 called


DeepMind
 and
 they
 have
 a
 product
 called


Gemini.
 Um
 and
 I
 think
 you
 could
 argue


that
 they
 are
 the
 leading
 um
 AI
 company


today.
 I
 think
 they've
 taken
 15
 or
 20


points
 of
 traffic
 share
 in
 the
 last
 two


or
 three
 months
 and
 that
 does
 not
 that's


just
 traffic
 to
 Gemini.
 It
 does
 not


include
 search
 overviews.
 I
 suspect
 on
 a


actual
 traffic
 basis,
 Google
 is
 bigger


than
 OpenAI,
 Enthropic,
 anyone
 today
 and


that
 that
 business
 is
 going
 to
 run
 on


TPUs.
 And
 then
 we
 have
 three
 other
 labs


that
 are
 relevant
 today.
 There's


Enthropic
 and
 that's
 an
 Amazon
 and
 T


that's
 an
 Amazon
 and
 Google
 captive.
 Uh,


trrenium
 is
 um,
 you
 know,
 Enthropic
 is


really
 going
 to
 run
 on
 uh,
 TPUs
 and


traniums.
 And
 so
 you're
 left
 with
 XAI


and
 OpenAI
 at
 the
 forefront.
 And
 if


Google
 is
 going
 to
 a
 lab
 like
 Enthropic


and
 saying,
 I'm
 going
 to
 help
 you
 fund


raise
 and
 give
 you
 chips,
 I
 think
 for


competitive
 reasons,
 it's
 very
 hard
 for


Nvidia
 not
 to
 respond.
 And
 as
 Jensen


said,
 he
 thinks
 it's
 going
 to
 be
 a
 good


investment.
 Um,
 so
 I
 think
 the


roundtpping
 concerns
 are
 pretty


overblown.


>> Yeah.
 And
 what
 I
 mean
 what
 Nvidia
 really


needs
 is
 they
 need
 you
 know
 Meta
 to
 get


their
 act
 together
 or
 another
 American


open
 source
 player
 to
 emerge
 or
 you
 know


maybe
 some
 sort
 of
 um
 dant
 with
 China


and
 AI.


>> Yeah.
 Yeah.
 I
 when
 people
 ask
 me
 about


Nvidia
 and
 all
 the
 moves
 and
 the


roundtpping
 my
 reaction
 is
 everything


they've
 done
 is
 completely
 rational.


>> 100%
 rational.


>> Yeah.
 Long
 term.
 Yeah.
 Sure.


things
 they
 do
 may
 not
 have
 as
 high
 of a


return
 on
 capital
 as
 other
 things,
 but


strategically
 I
 think
 they're
 all
 kind


of
 the
 right
 moves.


>> Jensen's
 one
 of
 the
 two
 best
 CEOs
 along


with
 Elon
 I
 have
 ever
 known.
 Um,
 and
 I


think
 he's
 he's
 playing
 a
 strong
 hand


really
 well.


>> Yeah.
 All right.
 So,
 you
 started
 getting


into
 the
 model
 companies.
 Let's
 just


talk
 about
 the
 model.
 So,
 we
 can
 come


back
 to
 chips
 and
 memory
 and
 networking


because
 I
 want
 to
 get
 your
 take
 on
 that,


but
 you
 know,
 since
 we're
 on
 the
 model


side,
 what
 do
 you
 think
 happens
 with


market
 structure?
 who
 wins
 where,
 you


know,
 who
 are
 you
 most
 optimistic
 about?


You
 know,
 where
 do
 you
 have
 concerns?


>> So,
 um
 I
 think
 humility
 is
 an
 important


virtue
 for
 an
 investor.
 And
 I'm
 just
 if


we're
 going
 to
 make
 an
 analogy
 and
 say


that
 chat
 GPT
 is
 to
 AI


has
 Netscape
 Navigator
 was
 to
 the


internet.
 At
 this
 point
 in
 the
 internet


boom,
 Google
 had
 not
 been
 founded.
 Mark


Zuckerberg
 was
 in
 middle
 school.
 um


Travis
 Kalanick
 was
 in
 was
 in


kindergarten.
 Um
 so
 it's
 just
 very


early.
 So
 I
 think
 it's
 important
 to
 be


humble
 um
 about
 making
 high
 confidence


predictions
 at
 the
 application
 layer.


It's
 one
 reason
 I
 think
 the
 the


infrastructure
 layer
 is
 often
 maybe
 a


safe
 place
 to
 be
 at
 the
 beginning
 of
 one


of
 these
 new
 technology
 waves.
 Well,


actually
 talk
 about
 the
 role
 they
 play


at
 the
 infrastructure
 layer
 because
 they


are
 there's
 a
 piece
 of
 them
 that
 like


obviously
 they
 they
 serve
 as
 an
 as
 an


infrastructure
 layer
 powering
 other


application
 providers
 and
 then
 they
 they


also
 have
 their
 own
 application.
 So
 I


think


>> I
 would
 draw
 the
 distinction.


>> Yeah,
 I
 mean
 that's
 most
 true
 of
 of


Google.
 Um


but
 I
 just
 um


I
 think
 it's
 hard
 to
 have
 high


conviction
 other
 than
 to
 observe
 you


know
 the
 internet
 was
 a
 very
 disruptive


innovation.
 Um,
 I
 think
 there's


reasonable
 arguments
 that
 AI
 could
 be
 a


sustaining
 innovation
 because
 the
 raw


ingredients
 of
 kind
 of
 data,
 you
 know,


the
 capital
 to
 buy
 compute
 and


distribution,
 which
 is
 what
 you
 need.


All
 of
 the
 big
 um,
 you
 know,
 today's


biggest
 tech
 companies
 have
 all
 of
 those


in
 spades.
 So,
 as
 long
 as
 they
 execute


well,
 hire
 good
 people,
 um,
 and
 have
 a


sound
 strategy,
 like
 I
 think
 you
 could


see
 it
 be
 a
 sustaining
 innovation
 for
 a


lot
 of
 members
 of
 the
 Mag
 7.
 On
 the


other
 hand,
 I
 do
 think
 it's
 existential


and
 if
 you
 don't
 execute,
 you
 know,
 IBM


might
 be
 a
 might
 be
 a
 good
 fate.


>> Yeah.
 Yeah.
 Yeah.
 That's
 uh
 that's


tough.
 Uh,
 yeah.
 Data,
 distribution,


compute,


dollars,
 talent.


>> Yeah.


>> And
 like


>> they
 have
 every
 right
 to
 win.
 Yeah,
 they


have
 every
 right
 to
 win.
 And
 it
 seems


now
 more
 than
 before,
 they're
 taking
 it


quite
 seriously.


>> Yeah,
 maybe
 Google
 in
 particular,
 but


obviously
 Meta
 Meta
 is
 making
 the


dramatic
 moves
 they're
 making,
 too.


>> No,
 to
 me,
 Chat
 GPT
 was
 Pearl
 Harbor
 for


Google,
 and
 we're
 going
 to
 see
 how
 they


responded,
 and
 they're
 slowly
 starting


to
 respond.


>> Yeah.
 And
 then
 what
 do
 you
 think
 what's


your
 forecast
 for
 uh
 that
 sort
 of
 in
 the


platform
 piece
 of
 their
 business,
 the


infrastructure
 piece?


What
 do
 you
 think?
 How
 do
 you
 think
 it


shakes
 out
 in
 terms
 of
 like
 business


model
 market
 structure?
 So
 do
 you
 think


they
 end
 up
 as
 high
 margin
 businesses


like
 the
 clouds
 or
 like
 aircraft


manufacturers
 or
 do
 you
 think
 they
 end


up
 very
 competitive
 and
 low
 margin


businesses
 like
 airlines?


Um
 I
 don't
 think
 they
 will
 be
 airlines


but
 you
 can
 anybody
 can
 just
 look
 at
 the


P&L
 you
 know
 of
 a
 SAS
 company
 circa
 2021


and
 2022
 and
 you
 see
 you
 know
 80
 90%


gross
 margins
 and
 the
 nature
 of
 AI


because
 of
 scaling
 laws
 Richard
 Sutton's


the
 better
 the
 bitter
 listen
 um
 they're


just
 more
 compute
 inensive
 so
 their


gross
 margins
 are
 structurally
 going
 to


be
 lower
 but
 that
 doesn't
 mean
 they


can't
 be
 great
 businesses
 is
 I
 just
 I


think
 it's
 going
 to
 be
 a
 long
 time


before
 we
 see
 a
 truly
 kind
 of
 you
 know


an
 AI
 lab
 a
 frontier
 lab
 with
 gross


margins
 anywhere
 near
 SAS
 or
 internet


era
 margins
 now
 their
 opex
 can
 be
 a
 lot


lower
 um
 and
 you
 know
 maybe
 that's
 how


you
 square
 it
 but
 just
 the
 gross
 margins


are
 fundamentally
 different
 and
 until


scaling
 laws
 change
 and
 the
 importance


of
 test
 time
 compute
 and
 things
 like


that
 change
 which
 I
 don't
 see
 happening


they're
 they
 are
 going
 to
 be
 lower


margin.


>> Yeah.
 Okay.
 So,
 let's
 talk
 about
 uh


application
 layer.
 So,
 you
 just
 you
 just


kind
 of
 got
 into
 it
 a
 little
 bit
 with


the
 SAS
 businesses
 and
 uh
 I
 don't
 know


if
 you've
 waited
 into
 this
 fight
 on


Twitter,
 but
 it's
 sort
 of
 you
 know
 the


the
 like
 you
 know
 every
 few
 months
 it


comes
 up
 and
 it's
 like
 SAS
 is
 terrible


and
 it's
 dead
 and
 you
 know
 it's
 all


going
 to
 go
 away
 and
 then
 you
 know
 with


uh
 Andre's
 uh
 Darkeesh
 interview
 he
 just


did
 it's
 you
 know
 like
 the
 market's


reacting
 positively
 to
 it.
 And
 it's
 like


a
 whipssaw
 reaction.
 So
 what
 do
 you


think
 happens
 with
 SAS
 and
 software?


>> You
 know,
 I
 think
 I,
 you
 know,
 first


said
 probably
 in
 early
 24
 that
 I
 thought


all
 of
 application
 SAS
 might
 be
 a
 zero


different
 than
 than
 um
 infrastructure


SAS.
 I
 I
 would
 say
 I
 have
 a
 more
 nuanced


view
 now
 and
 I
 think
 there
 could
 be
 some


really
 big
 application
 SAS
 winners,


especially
 if
 you
 serve
 like
 a
 more


fragmented
 SMB
 customer
 base.
 Um,
 you


know,
 Google
 has
 make
 it
 really
 easy
 if


you're
 a
 customer
 of
 theirs
 to
 use
 your


data
 and
 essentially
 make
 any
 SAS
 app


you
 want
 and
 then
 your
 data
 isn't
 shared


with
 anyone
 else.
 Um,
 but
 the
 critical


mistake
 that
 I
 think
 a
 lot
 of
 retailers


made
 um
 in
 dealing
 with
 Amazon
 is
 they


looked
 at
 Amazon's
 margins
 and
 they
 said


we
 don't
 want
 to
 be
 in
 that
 business.


And
 that
 was
 obviously
 a
 terrible


mistake.
 And
 here
 we
 are
 25
 years
 later


and
 you
 know
 Amazon
 has
 really
 healthy


uh
 retail
 margins.
 And
 I
 worry
 that


application
 SAS
 companies
 are
 trying
 to


preserve
 their
 existing
 gross
 margin


structures
 because
 they
 believe
 that
 if


their
 gross
 margins
 go
 down
 um
 their


stocks
 will
 go
 down.
 It
 is


definitionally
 impossible
 given
 what
 we


just
 discussed
 to
 succeed
 in
 AI
 without


gross
 margin
 pressure.
 And
 I
 do
 not
 know


why
 they
 have
 concerns
 because
 we
 have


an
 existence
 proof
 that
 a
 software


company
 can
 deal
 well
 with
 declining


margins
 in
 Microsoft
 in
 Adobe
 to
 the


whole
 AI
 thing
 came
 along.
 You
 know,
 it


used
 to
 be
 that
 companies
 were
 scared
 to


go
 from
 on
 premise
 to
 the
 cloud
 because


margins
 were
 lower.
 Cloud
 margins
 are


are
 are
 lower.
 They're
 still
 good.
 And


Microsoft,
 they
 transitioned,
 you
 know,


from,
 you
 know,
 on
 premise
 perpetual


licenses
 with
 maintenance
 uh
 to
 a
 cloud


model.
 and
 it
 was
 a
 pretty
 good
 stock


for
 10
 years.
 So
 I
 don't
 if
 you're
 an


application
 SAS
 company
 like
 I
 what
 I


would
 just
 say
 is
 don't
 be
 scared
 and


look
 at
 declining
 gross
 margins
 kind
 of


has
 a
 mark
 of
 success
 rather
 than
 you


know
 a
 badge
 of
 shame
 or
 something
 to
 be


feared.
 It's
 actually
 so
 funny
 you
 say


that
 because
 whenever
 we
 have
 these


discussions
 about
 companies,
 basically


every
 company
 that
 comes
 to
 present
 to


us
 is
 like
 we're
 an
 AI
 company
 and
 um
 we


always
 look
 at
 the
 gross
 margins
 and


it's
 become
 like
 a
 badge
 of
 honor
 for


them
 to
 actually
 have
 low
 gross
 margins


because
 like
 oh
 my
 god
 people
 are


actually
 using
 your
 AI
 stuff.
 Yeah.


>> But
 if
 you
 show
 up
 and
 you're
 like
 I'm


an
 AI
 company
 and
 it's
 like
 I
 got
 82%


gross
 margins.
 You're
 like
 I
 don't
 think


anybody's
 really
 using
 it.
 Uh
 so
 yeah


it's
 uh
 it's
 interesting.
 Yeah.
 If


you're
 if
 you're
 one
 of these
 public


companies,
 would
 you
 rather
 have
 like
 10


bucks
 of
 revenue
 with
 90%
 gross
 margins


or
 50
 bucks
 of
 revenue
 with
 60%
 gross


margins?


>> Not
 hard.


>> Like
 it's
 not
 that
 comp
 Yeah,
 not
 that


complicated.
 It's
 hard
 to
 do
 in
 the


public
 market.


>> It's
 hard
 to
 do
 in
 public,
 but
 if
 you


communicate
 it,
 you
 draw
 parallels
 to


the
 cloud
 transition.
 I
 mean,
 I'm
 an


investor
 and
 I
 would
 be
 excited
 about


it,
 you
 know,
 and
 I
 don't
 think
 I'm


alone
 in
 the
 world.
 And
 then
 the
 big


advantage
 these
 legacy
 application
 SAS


companies
 have
 is
 they
 do
 have
 these


really
 profitable
 existing
 businesses.


And
 so
 you
 can
 run
 your
 new
 AI
 products


at
 break
 even
 um
 and
 you
 know
 catch
 up


to
 the
 leaders
 etc
 etc
 and
 I'm
 just


surprised
 more
 people
 have
 not
 done
 that


like
 why
 are
 none
 of
 the
 public
 coding


companies
 even
 trying
 to
 compete
 with


cursor
 and
 the
 reality
 is
 cursor
 now


they
 have
 a
 trillion
 trillion
 tokens
 and


you
 know
 there
 there
 will
 be
 a
 point


where
 they
 have
 enough
 coding
 tokens


that
 it's
 tough
 to
 catch
 them
 but
 I


think
 today
 if
 you're
 a
 public
 coding


and
 you
 said,
 "I'm
 going
 to
 lean
 in.
 I'm


going
 to
 run
 it
 break
 even.
 I
 have
 an


existing
 business.
 I'm
 going
 to
 attach


it
 to
 everything."
 Hey,
 you
 have
 a


chance.
 And
 you
 know,
 the
 prize
 is


clearly
 really
 big.
 I
 see
 Martin
 is


skeptical.


>> Martin's
 shaking
 his
 head.
 You
 have
 a


chance.


>> I
 said
 a
 chance.
 So,
 I
 said
 a
 chance.


>> That's
 like
 a
 dumb
 and
 dumber.
 You're


telling
 me
 there's
 a
 chance,
 not
 like
 a


real
 chance.
 You're
 telling
 me.
 You're


>> telling
 me
 there's
 a
 chance.


>> Yes.
 Exactly.


>> It's
 like
 a


>> Yeah,
 exactly.
 I
 totally
 agree.
 Yeah,
 we


actually
 saw
 I
 mean
 you
 know
 we
 see
 it


uh
 you
 know
 we
 may
 if
 we
 if
 we
 you
 know


Figma
 for
 example
 like
 when
 they
 went


out
 they
 are
 extremely
 high
 gross
 margin


and
 they're
 like
 hey
 we're
 going
 to
 you


know
 pretty
 aggressively
 distribute
 our


AI
 tools
 and
 our
 gross
 margins
 are
 going


to
 go
 down
 and
 you
 know
 investors
 asked


a
 few
 clarifying
 questions
 and
 then
 they


were
 like
 oh
 that
 actually
 would
 be
 a


good
 thing
 and
 so
 surprised
 more
 people


in
 the
 public
 markets
 aren't
 doing
 it


worked
 out
 okay
 for
 them


>> it's
 working
 out
 well
 uh
 long
 game
 to


play
 what
 about
 on
 the
 consumer
 side
 at


the
 application
 layer
 so
 obviously
 ly


Google
 was
 the
 portal
 to
 the
 internet
 is


kind
 of
 still
 is
 the
 portal
 to
 the


internet
 and
 the
 whole
 business
 model


was
 predicated
 upon
 taking
 some
 intent


and
 directing
 you
 to
 someone
 else's


website
 where
 they
 would
 do
 stuff
 with


you.
 It's
 kind
 of
 not
 going
 to
 be
 that


way.
 It
 already
 is
 not
 that
 way
 uh
 with


uh
 with
 AI.
 Although
 I
 tried
 the
 browser


today
 and
 I
 tried
 to
 do
 some
 pretty


basic
 shopping
 stuff
 and
 it's
 you
 know


it's
 still
 still
 some
 work
 to
 do
 but
 I


think
 it
 will
 get
 there.
 So
 what
 do
 you


actually
 think
 happens
 with
 the
 sort
 of


market
 structure
 of
 the
 consumer


internet
 companies?
 Do
 they
 get
 subsumed


into
 a
 component
 of
 a
 chatbot
 interface


or
 do
 you
 think
 it's
 something
 else?
 Um


so
 one
 humility
 hard
 to
 say.
 to
 I
 would


just
 say
 I
 think
 um
 the
 AI
 companies


that
 have
 launched
 these
 AI
 browsers
 may


come
 to
 regret
 it
 because
 there's


something
 called
 Chrome
 that
 has


whatever
 it
 is
 5
 billion
 users
 and
 if


you're
 Google
 um
 you
 know
 you
 can
 just


go
 look
 at
 what
 happened
 with
 Google


Buzz
 you
 they
 are
 very
 cautious
 you
 know


there's
 you
 know
 they're
 currently
 in
 in


litigation
 with
 the
 government
 um
 and


they
 could
 easily
 do
 this
 and
 probably


do
 it
 even
 better,
 but
 they
 didn't
 want


to
 be
 first.
 So
 now
 you
 have
 two
 AI


native
 companies
 with
 their
 own


browsers,
 let
 them
 run
 for
 3
 to
 6


months,
 get
 a
 little
 head
 start,
 and


then
 wow,
 here
 we
 are.
 We
 had
 to
 do


this.
 And
 I
 don't
 know
 how
 that's
 going


to
 work.
 Um
 maybe
 for
 the
 companies


other
 than
 Google
 who
 don't
 own
 Chrome.


Um


>> yeah,
 I
 guess
 data
 and
 distribution
 is


pretty
 powerful
 in
 that.


>> Yeah,
 hindsight's
 2020.
 Um,


and
 the
 one
 thing
 I
 would
 say
 is
 I
 do


think
 it's
 tough
 to
 bet
 against
 the


companies
 with
 large
 existing
 user
 bases


today.
 Um,


and
 I
 also
 think
 reasoning
 has


fundamentally
 changed
 the
 economics
 of


these
 frontier
 models.
 you
 know,


pre-reasoning.
 Um,
 I
 often
 said
 if
 you


are
 a
 frontier
 model
 without
 access
 to


unique,
 valuable
 data


and
 internet
 scale
 distribution,
 you're


the
 fastest
 depreciating
 asset
 in


history.
 I
 think
 reasoning
 really


changed
 that
 because
 the
 way
 RL
 works


during
 post
 training,
 having
 a
 big
 user


base
 now
 kind
 of
 unlocks
 that
 flywheel


that
 was
 at
 the
 center
 of
 every
 great


consumer
 internet
 company
 where
 um
 you


have
 a
 good
 product,
 you
 get
 a
 lot
 of


users,
 the
 users
 make
 the
 algorithm


better,
 um
 the
 algorithm
 makes
 the


product
 better
 and
 it
 just
 spins.
 And


that
 it's
 not
 quite
 spinning
 yet
 in
 AI,


but
 you
 can
 squint
 and
 see
 it.
 And
 so
 I


think
 that
 fundamentally
 changes


economics
 for
 anthropic,
 for
 XAI,


um,
 for
 OpenAI.
 Um,
 but
 I
 mean


Mark
 Zuckerberg's
 trying
 hard.


>> Yeah.


>> We'll
 see.


>> Yeah.
 Yeah.


>> Yeah.
 A
 lot
 of
 smart
 people
 in
 there


now.


>> Yeah,
 for
 sure.
 I
 I
 think
 the
 worry
 is


and
 I
 think
 this
 is
 another
 interesting


thing
 is
 if
 you
 don't
 like
 in
 a
 strange


way
 the
 Chinese
 open
 source
 model


ecosystem
 is
 a
 godsend
 to
 any
 American


company
 that's
 trying
 to
 catch
 those


four
 leading
 labs
 because
 the
 problem
 is


if
 you
 don't
 have
 Gemini
 2.5
 Pro
 or
 a


later
 checkpoint
 of
 it
 or
 a
 later


checkpoint
 of
 Grock
 that
 we
 don't
 see
 or


a
 later
 GPT
 checkmate
 uh
 checkpoint


training
 the
 next
 model
 you're
 at
 a


disadvantage.
 Oh,
 by
 the
 way,
 one
 thing


I
 just
 want
 to
 say
 that
 drives
 me
 crazy


is
 all
 these
 people
 who
 say
 that
 GPT5
 is


the
 end
 of
 scaling
 loss.
 GPT5
 is
 a


smaller
 model.
 It
 was
 not
 designed
 to
 be


better.
 It
 was
 designed
 to
 be
 more


economical
 for
 OpenAI
 and
 Microsoft
 to


run
 it.
 Any
 reference
 to
 GPT5
 its


scaling
 laws
 is
 crazy.
 Um,
 yeah.
 Sorry.


Rant
 rant
 over.


>> We
 got
 the
 pedestal
 up
 here
 if
 you
 want.


>> Yeah,
 exactly.


>> Shaking
 your
 hand.


>> Yeah,
 we
 could.
 Yeah,


>> that'd
 be
 good.
 Uh,
 do
 you
 want
 to
 talk


about
 chips?


>> Sure.


>> So,
 okay.
 I
 know
 you
 love
 Nvidia.


Talk
 about,
 you
 know,
 your
 view
 of


Nvidia,
 AMD,
 TPUs,
 AS6,
 and
 how
 do
 you


think
 sort
 of
 market
 structure
 shakes


out
 there,
 you
 know,
 competitive


advantage
 that
 the
 various
 players
 have?


>> Yeah.
 Um
 I
 think
 it
 goes
 I
 think
 it
 is


really
 um
 it's
 a
 fight
 between
 Nvidia


and
 um
 the
 Google
 TPU
 and
 then
 something


that
 I
 don't
 think
 is
 broadly


appreciated
 is
 the
 extent
 to
 which


Broadcom
 and
 AMD
 are
 effectively
 going


to
 market
 together.
 Nvidia
 is
 no
 longer


just
 a
 a
 semiconductor
 company
 as
 I'm


sure
 you'll
 hear
 from
 Jensen
 tomorrow.


you
 know
 not
 it
 was
 a
 semiconductor


company
 then
 a
 software
 company
 with


CUDA
 now
 systems
 company
 with
 these
 rack


level
 solutions
 and
 now
 arguably
 you


know
 a
 data
 center
 level
 uh
 company
 with


the
 you
 know
 level
 of
 architecting


they're
 doing
 with
 scale
 up
 scale
 across


and
 um
 scale
 out
 scale
 across
 networking


um


so
 the
 networking
 the
 fabric
 the


software
 it's
 all
 important
 and
 what


Broadcom
 is
 saying
 to
 companies
 like


Meta
 is
 hey
 we
 will
 build
 you
 a
 fabric


that
 can
 theor
 theoretically
 compete


with
 Nvidia's
 fabric
 which
 is
 a
 mixture


of
 NVLink
 and
 either
 Infiniband
 or


Ethernet.
 Um
 it
 will
 build
 it
 on


Ethernet.
 It's
 going
 to
 be
 an
 open


standard.
 And
 hey,
 we'll
 we'll
 make
 you


your
 version
 of
 of
 TPU,
 which
 by
 the
 way


took
 Google
 three
 generations
 to
 get


working.
 And
 you
 know what?
 If
 your
 ASIC


isn't
 good,
 you
 can
 just
 plug
 AMD
 right


in.
 Um


but
 I
 personally
 believe
 most
 of
 those


AS6s
 are
 going
 to
 fail.
 um
 particularly


if
 it's


>> in
 the
 fullness
 of
 time
 like
 over
 a


period
 of
 time
 or
 in
 the
 fullness
 of


time


>> in
 the
 next
 3
 years
 I
 think
 you'll
 see
 a


bunch
 of
 high-profile
 um
 ASIC
 programs


canled
 especially
 if
 Google
 um
 starts


selling
 TPUs
 externally
 which
 has
 been


all
 over
 X
 and
 you
 know
 they
 you
 know


who
 knows
 exactly
 how
 that
 would
 work


because
 if
 you're
 anthropic
 you
 know


it's
 just
 rumored
 anthropic
 wants
 to
 buy


tens
 of
 billions
 of
 TPUs
 if
 you're


anthropic
 maybe
 you
 don't
 want
 Google


seeing
 your
 secret
 sauce
 but
 there's


ways
 around
 on
 that.
 So
 I
 think
 this
 is


really
 a
 battle
 between
 Google
 and
 its


TPU
 enabled
 by
 Broadcom
 for
 now
 and


Google
 can
 take
 the
 TPU
 away
 from


Broadcom
 whenever
 they
 want.


>> Yeah.


>> Now
 they
 can't
 do
 the
 Ethernet


networking
 that
 Broadcom
 is
 is
 doing
 uh


but
 they
 control
 the
 TPU.
 Um
 so
 it's


really
 Google
 and
 the
 TPU
 verse
 um


Nvidia
 you
 know
 with
 with
 you
 know


Amazon
 like
 that's
 a
 very
 talented
 team


arguably
 the
 most
 talented
 silicon


tumidity
 hyperscaler
 the
 anaperna
 team


like
 I
 think
 the
 tranium
 3
 will
 probably


be
 a
 much
 better
 chip
 than
 the
 tranium
 2


it
 took
 three
 generations
 to
 get
 the
 TPU


right
 um
 and
 then
 AMD
 will
 you
 know
 will


always
 be
 kind
 of
 the
 second
 source
 and


you
 need
 a
 second
 source


all
 right
 exciting
 uh
 what
 do
 you
 think


happens
 Okay.
 So
 I
 want
 to
 go
 back
 um
 to


business
 models.
 So
 one
 of
 the
 big


things
 that
 is
 widely
 discussed
 is
 like


you
 know
 source
 of
 disruption
 and
 most


of
 the
 CEOs
 in
 this
 room
 are
 CEOs
 of


startups
 who
 are
 trying
 to
 go
 beat
 some


incumbent
 or
 find
 you
 know
 some
 new


market
 opportunity
 and
 the
 most
 ripe


opportunities
 tend
 to
 come
 when
 you
 have


a
 big
 platform
 shift
 that
 is
 also


accompanied
 with
 a
 business
 model
 shift.


Um
 and
 so
 there
 are
 a
 couple
 of
 areas


where
 I
 can
 see
 it.
 I
 feel
 like
 in
 an


obvious
 way.
 So,
 you
 know,
 we're


investors
 in
 decagon
 customer
 support


like
 you
 can
 pretty
 easily
 see
 a


business
 model
 that
 is
 priced
 on
 the


resolution
 of
 a
 task
 because
 it's
 so


measurable.
 Um
 you
 can
 see
 you
 know
 like


in
 coding
 like
 a
 lot
 of
 the
 business


model
 has
 now
 shifted
 to
 consumption
 and


you
 know
 obviously
 especially
 for


developer
 facing
 things
 like
 that's


comfortable
 um
 and
 pretty
 wellnown.
 What


about
 the
 rest
 of
 the
 industry?
 Cuz
 I


feel
 like
 there's
 sort
 of
 this
 handwave


thing
 that
 is
 going
 on
 which
 is
 like


we're
 going to
 go
 get
 all
 of
 services


but
 it's
 like
 okay
 so
 how
 do
 you


actually
 go
 do
 that?
 It's
 going
 to
 be


pretty
 hard.
 So
 do
 you
 have
 any


prediction
 on
 how
 that
 plays
 out?


>> Well
 I
 think
 what
 you're
 seeing
 in


customer
 service
 which
 is
 kind
 of
 like


an
 easy
 first
 example
 u
 where
 you
 have
 a


lot
 of
 textual
 data
 that
 LLMs
 are
 good


at
 text.
 you
 can
 kind
 of,
 you
 know,


probably
 really
 easily
 run
 some
 RL
 to


make
 sure
 that
 they,
 you
 know,
 get
 a


good
 verified
 reward.
 You
 know,
 verified


reward
 being
 a
 happy
 customer
 or
 first


call
 resolution
 or
 whatever
 it
 is.


>> Um,


and
 but
 I
 do
 think
 you
 will
 see
 that


played
 out
 like
 humans,
 we're


fundamentally
 paid
 for
 paid
 paid
 based


on
 outcomes
 and
 a
 lot
 of
 AI
 will
 be


augmenting
 humans,
 but
 probably
 also


replacing
 some
 humans
 and
 that
 will


involve
 being
 paid
 u
 paid
 for
 outcomes.


you
 know,
 going
 back
 to
 the
 consumer


business
 model,
 you
 know,
 everybody's


talking
 about
 affiliate
 fees.
 And
 for


sure,
 I'm
 going
 to
 have,
 you
 know,
 my


own
 AI.
 It
 will
 be
 a
 version
 of
 Grock,


um,
 because
 we're
 both
 XAI
 shareholders.


It
 will
 be a
 version
 of
 Grock
 that
 knows


me
 and
 it
 likes
 me.
 Um,
 and,
 you
 know,


when
 I
 when
 I
 want
 to,
 you
 know,
 the


next
 time
 I
 want
 to
 go
 on
 vacation,
 it


will
 know
 the
 hotels
 that
 I
 like
 to
 go


to
 and
 it'll
 say,
 "Hey,
 three
 hotels.
 I


have
 Gavin,
 you
 know,
 I
 have
 Gavin


coming.
 Who's
 got
 the
 best
 price
 and
 the


best
 room?"
 Um,


>> it's
 going
 to
 massively
 upgrade
 the


gifts
 that
 you
 give
 to
 Becky
 just
 in


case
 as
 Becky
 Becky's
 in
 the
 audience.


She
 really
 appreciated
 your
 Dumb
 and


Dumber
 reference.
 I'll
 have
 you
 know.


Um,


but
 um
 yeah,
 and
 then
 there
 will


probably
 be
 some
 sort
 of
 affiliate
 fee.


And
 again,
 that's
 just
 being
 paid
 for
 an


outcome
 and
 kind
 of
 closing
 that
 loop,


which
 will
 be
 probably
 a
 little
 bit
 of
 a


business
 model
 degradation
 because
 the


great
 why why
 did
 Google
 never
 start
 a


marketplace?
 because
 people
 overvalue


systematically
 their
 ability
 once


they've
 acquired
 a
 customer
 through


Google
 to
 keep
 it
 as
 an
 organic


customer.
 So
 they
 systematically
 overpay


and
 they
 continue
 doing
 that.
 That's
 why


Google
 never
 went
 to
 outcomes
 or


marketplace
 because
 advertising
 leads
 to


the
 advertisers
 systematically


overpaying.
 So
 that
 inefficiency
 will
 be


squeezed
 out
 but
 yeah
 we'll
 go
 to


outcomes
 and
 you
 know
 I
 think
 Elon


tweeted
 today
 that
 you
 know
 work
 would


become
 optional
 you
 know
 like
 instead
 of


buying
 your
 vegetables
 um
 you
 know
 at
 a


at
 a
 supermarket
 you
 can
 grow
 your
 own


garden
 if
 you
 want.
 Now,
 who
 knows
 how


long
 it
 takes
 us
 to
 get
 there,
 but
 I


that
 doesn't
 sound
 wildly
 implausible
 to


me
 for
 how
 powerful
 this
 technology
 is.


And
 I
 was
 just
 struck
 Karpathy,
 you


know,
 whatever
 two
 days
 ago,
 you
 know,


is
 being
 painted
 as
 like
 a
 skeptic
 for


saying
 AGI
 is
 10
 years
 away.
 Are
 you


kidding?


>> Insane.
 10
 years.


>> Yeah.
 Yeah.
 Sign
 me
 up.
 We
 have
 shorter


timelines,
 please.


>> Yeah.
 Well,
 so
 no,
 that's
 awesome.
 While


we're
 on
 the
 topic
 of
 very
 exciting


futuristic
 things,
 robotics,
 do
 you
 have


a
 view
 on


>> Yeah,
 very
 real.
 And
 it's
 going
 to
 be


Tesla
 versus
 the
 Chinese
 in
 the
 same
 way


it's
 Tesla
 versus
 the
 Chinese
 in
 in
 uh


cars.


>> Electric
 cars.
 Yeah.


>> Yeah.


>> I
 would
 just
 say
 cars,
 not
 electric


cars.


>> Yeah.
 Cars.


>> Yeah.


>> Do
 you
 have
 a
 sense
 of
 timeline?


>> I
 mean,
 you
 can
 you
 can
 all
 watch
 the


Optimus
 videos.
 Um,


every
 roboticist
 I
 know
 is
 extremely


impressed.
 Um,
 you
 know,
 there's
 there's


a
 giant
 debate.
 Is
 it
 going
 to
 be


humanoids
 or
 not
 humanoids?
 I
 think
 that


debate
 is
 over
 because
 humanoids
 can


kind
 of
 learn,
 you
 know,
 from
 watching


YouTube
 videos
 and
 then
 it's
 easier
 for


a
 human
 being
 um,
 you
 know,
 to
 put
 on
 a


suit
 and
 show
 the
 robot
 how
 to
 do
 it.
 I


mean,
 it's
 kind
 of
 crazy
 to
 watch
 the


video
 of
 all,
 you
 know,
 the
 50
 Optimus


robots
 doing
 50
 different
 tasks
 and
 then


it's
 very
 simple,
 you
 know,
 did
 you
 did


you
 put
 the
 glass
 in
 the
 dishwasher


correctly
 or
 not?


>> This
 is
 so
 fun,
 Gavin.
 I
 always
 love


chatting
 with
 you.
 Uh,
 let's
 give
 a
 hand


to
 Gavin.


>> Thank
 you,
 David.
 Thank
 you.


>> All
 right.


Next
 up,
 we
 have
 a
 very
 exciting
 panel


on
 building
 out
 real
 world


infrastructure.
 Uh,
 but
 first,
 give
 us
 a


few
 minutes.
 We
 got
 to
 do
 a
 quick
 uh
 sta


uh
 stage
 change
 here.
 So,
 thank
 you.


>> Thanks
 everybody.


Thank
 you,
 man.