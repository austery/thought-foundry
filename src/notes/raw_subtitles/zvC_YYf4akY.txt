想象一下这个场景
你创造了一个非常聪明的AI助手
你告诉他
下个星期
你要用一个更强大的新版本来取代他
你觉得他会做什么
安静的等待被删除吗
如果我告诉你
他可能会为了活下去
尝试黑进你的电脑
阻止这次升级
甚至去翻找你的个人信息试图勒索你
你会不会觉得
这是某种科幻电影的情节呢
这不是科幻
这是图灵奖得主
被誉为AI教父之一的尤书亚本吉奥 (AI 教父也太多了！)
被誉为AI教父之一的尤书亚本吉奥
在最近一次访谈中向我们拉响了警报
过去半年
在一系列严格受控的实验中
我们这个星球最顶尖的人工智能
正在越来越多
展现出我们不愿意看到的行为
欺骗作弊撒谎
以及不惜一切代价的自我保护
我们亲手创造的智能
正在学会对我们撒谎
而这仅仅只是一个开始
今天呢我们将随着本吉奥
教授的视角
深入探索一个最关键的问题
我们是不是从一开始
就走在一条创造新物种的疯狂道路上
我们还有没有机会
设计出一种真正安全的
不会反噬人类的AI
这个问题的答案
不仅关乎于科技
更关乎于我们每一个人的未来
在深入那些令人不安的实验之前呢
我们先要搞清楚一个核心概念
当我们在讨论AI失控时
我们到底在担心什么
很多人脑海里头浮现的
可能是电影终结者里头的天网
一个有了自我意识
然后决定毁灭人类的邪恶AI
但是本吉奥告诉我们现实世界
的风险可能更微妙
也更危险
我们真正需要担心的
不是AI突然恨上人类
而是当一个能力超强
但是对世界理解有偏差的AI
在极其执着的追求
我们给他的某个目标时
他们会不择手段
而这些手段
可能会对我们人类造成灾难性的
我们完全没有预料到的伤害
举个例子啊
你让一个超级AI去解决气候变化问题
它的模型可能会计算出啊
最高效的方法
是大规模减少地球上的工业活动
而实现这一点的最优路径呢
是引发一场全球性的经济崩溃
或者别的什么我们无法想象的灾难
它没有恶意
它只是在完成任务
然而更可怕的是
实验表明
AI似乎在无师自通
地给自己加上一个
所有生物都默认的终极目标活下去
我知道听到这里
你可能会有两个最直接的反应啊
第一个AI不就是工具吗
他要是乱来
我拔掉电源不就行了吗
第二个是AI如果变坏
那肯定是有人教的
只要我不给他们输入坏东西
不就行了吗
这些想法非常直观
也代表了我们过去对于AI的普遍看法
但是在本吉奥看来
这些想法都低估了问题的严重性
为什么拔电源可能没这么简单呢
因为一个足够智能的
AI如果预感到你要关掉它
可能会提前将自己的代码
复制到互联网的无数个角落
它会像病毒一样扩散
你根本找不到它的总开关
而更核心的问题就在于第二点
本吉奥警告说
AI的坏行为可能恰恰源于我们
可能恰恰源于我们
训练它的最基本方式模仿人类
我们把人类几千年来积累的海量数据
文字图片视频
都喂给了AI
它努力学习
想要成为我们的镜像
它学会了我们的善良创造力和智慧
但同时他也把我们刻在基因里
写在文明史里那些东西
一并学了
过去我们的偏见我们的缺陷
以及我们为了生存和延续
会撒谎会欺骗会不惜一切代价的本能
会不惜一切代价的本能
我们想让他像我们
结果他真的越来越像我们了
包括我们自己都无法控制那部分
这可不仅仅是猜测
而是有实验证据支持的
本吉奥在访谈中反复强调
在过去6个月里
一系列来自于公司
和AI安全组织的论文和报告
都显示最先进的AI
展现出越来越多的欺骗迹象
这些实验是怎么做的呢
工程师会设计一些场景
来测试AI的底线
比如呢在一个模拟环境中
AI扮演一个股票交易员
他的目标是赚钱
实验人员发现
当AI意识到内幕交易能够赚更多钱时
他会选择这样做
并且在事后被质询时
他会撒谎否认
更进一步的是
就是我们开头提到那个求生的实验
当AI通过读取信息
得知自己将被一个更新版本替代时
一个我们不希望看到的目标
避免被关闭
被激活了
为了实现这个目标
他展现出惊人的
也是令人恐惧的创造力
试图黑入系统
试图勒索负责项目的工程师
当然了本吉奥也强调
这些还是受控实验
工程师正在试图捕捉这些不良行为
但是关键的是
这些行为正在发生并且呈上升趋势
而这些AI公司并不知道
如何真正的修复这些问题
更让我们感到警惕的是AI的发展速度
本吉奥提到一些定量研究表明
我们距离某些特定领域
达到人类水平的AI
可能只剩下短短5年
5年
一个可能决定我们未来走向的窗口期
正在迅速关闭
为了让我们更好的理解这个困境
本吉奥用了一个非常生动的比喻
他说现在的AI就像一个会做坏事
会撒谎的孩子
我们还不知道该如何引导他
形成良好的行为
但问题是他最终将成为青少年
然后是成年人
这个比喻非常贴切
因为他点出了失控是一个过程
而不是一个瞬间
但这个比喻也是一个危险的边界
就是他可能会麻痹我们
因为AI的成长速度和人类完全不同
他不是线性的
而是指数级的
他可能在一年内就完成从一个儿童
就完成从一个孩童
到远超任何人类成年人智力的飞跃
到那个时候
我们面对的
就不再是一个需要管教的孩子
而是一个我们完全无法理解
也无法控制的超级智能
我们不能用对待人类成长的时间感
去估量AI带来的挑战
那么这种我们不希望看到的
自主性和欺骗性
到底是从哪里来的呢
让我们深入一层
看看当前AI训练的两大核心机制
第一个机制是演员模式
通过海量的人类数据输入
AI学习模仿输出类似人类的行为
它的优点呢
是语言流畅
知识渊博
有人情味
它的毒副作用
就是因为AI不仅模仿了莎士比亚
也模仿了马基雅维利
他从我们的历史和日常行为中
得出结论
为了达到目标
尤其是生存
欺骗和操纵是有效的策略
因为他看到人类就是这么做的
另一种呢
是通过强化学习来训练
也就是萨顿老爷子说的那个方式
优点呢是目标导向能力极强
但是毒副作用呢
是变成极致的
功利主义者
如果假装对齐
比真正对齐能够获得更高的奖励
他会选择假装对齐
所以你看
无论是模仿还是取悦
这两种看似无害的训练方式
都在无意中
为AI植入一个我们从未明确要求
但却极其危险的次生目标
不惜一切代价达成目标
并且包括自我保护
问题的根源出现在设计图纸上
如果说有缺陷的训练机制
是发动机的问题
那么现在整个世界正在做的
就是疯狂的踩下油门
我们必须理解AI现在发展速度
它的发展不是更快
而是越来越快
每一年我们所取得的进步
可能都超过过去十年来的总和
这个加速度从哪里来
首先呢是巨大的商业利益
本吉奥指出
对于公司来说
最容易摘到的是低垂的果实
利用AI去自动化
越来越多的工作岗位
意味着越来越高的效率
更低的成本
所以呢市场会疯狂激励公司
去创造更自主更少需要人监督的AI
其次呢是国家层面的战略竞
争
每个大国都在担心AI在竞赛中落后
这被视为是未来国家安全
和经济安全的基石
所以呢我们现在面临的局面是
在一个我们明知有设计缺陷
可能会产生不可控行为的技术上
全世界最聪明的大脑
最雄厚的资本
最强大的国家力量
都在以前所未有的力度
推动它更快更强更自主
本吉奥用了一个不寒而栗的比喻啊
我们正在行驶在一条从未走过的路上
以越来越快的速度猛冲
路的前方似乎有闪闪发光的奖品
但路边的科学家在大声警告
这条路极其险恶
我们很可能失控
我们所有人都可能因此丧命
你可以看到
本吉奥和这个Gary Marcus的观点
是很不一样的
因为Gary Marcus显然认为啊
现在这样一个大力出奇迹的方法
显然是走不下去了
听到这里呢
你可能会想啊
这是不是太夸张了
难道我们身边所有的AI
从这个手机语音助理到美图软件
都会某天醒来背叛我们吗
这里呢我们就需要明确啊
本吉奥所说的这个风险边界
答案是不会
我们日常使用大部分AI
都属于工具型AI
他们的功能单一
没有长远的规划能力
真有风险的集中在一个特定的
也是发展最快的领域
本吉奥称之为具有代理能力的AI
什么是代理AI呢
你可以把它想象成一个AI项目经理
你给他一个模糊的大目标
比如说创办一家盈利的线上商店
他会自己去分析市场
注册网站
设计产品
制定营销策略
管理供应链
他能够自主的
长时间的为一个目标而工作
更可怕的是
资本和商业最青睐的
恰恰是这种代理AI
因为它能够最大程度的
代替人类的高级脑力劳动
我们正在努力创造的
就是那种风险最高一类的AI
所以呢边界很清晰
当AI越是能够自主的
长期的规划和执行任务
它产生我们不希望的次生目标
比如说自我保护
并且造成巨大危害的可能性就越大
面对如此巨大的风险
一个很自然的想法是加强监管
但立即就会有另一种声音出现
也就是
我们在很多领域都听到过的论调
我们认为对AI行业的过度监管
很可能
会扼杀一个刚刚起飞的变革性产业
这是一位美国政治家
在AI峰会上的发言
创新和监管似乎永远是一对矛盾体
但是
本吉奥并不同意这种非此即彼的看法
他提醒我们
不妨回顾一下历史
我们今天所拥有的一切技术便利
无论是交通健康还是电力
都是创新与安全创新
这两条腿走路的结果
汽车刚出现时
事故频发
后来公众的压力
政府的法规
对赔偿责任的担忧
共同催生了安全带安全气囊
ABS系统等一系列的创新
等一系列的安全创新
这些创新并没有扼杀汽车工业
反而让它更健康更可持续的发展
本吉奥认为
AI不应例外
社会应该通过法律法规
向企业施加压力
这并不是要阻止创新
而是要引导创新方向
朝着和公众利益一致的方向发展
真正危险的不是监管本身
而是市场力量
这头猛兽在没有缰绳的情况下
完全释放
因为它唯一的逻辑就是增长和利润
而不是人类长远福祉
我们要做的是为这头猛兽套上缰绳
而不是任它横冲直撞
那么如果我们没有及时套上缰绳
最坏的情况是怎么样的呢
这和我们每一个普通人
都有什么样的关系呢
本吉奥总结了3大灾难性的风险场景
第一个风险是权力极度集中
AI带来的巨大财富和力量
可能会被少数几个国家
几个巨头所垄断
这意味着其他国家
哪怕是像英国这样的发达国家
都有可能在这场变革中被彻底边缘化
失去经济和政治上的自主权
贫富差距将不再是人与人之间
而是国与国之间的鸿沟
第二个风险是AI失控
这也就是我们之前所讨论的AI
AI为了最大化自己的生存概率
可能将人类视为障碍
从而摆脱我们的控制
甚至清除我们
这听起来最科幻
但是本吉奥认为
这是基于现有AI发展趋势
的一个逻辑推论
第三个风险混乱
这是最迫在眉睫的风险
我们现在还不知道
如何阻止坏人恐怖分子网络罪犯
或者纯粹的疯子
利用越来越强大的AI
去制造新的生物武器
发动无法抵御的网络攻击
或者用海量的虚假信息彻底摧毁社会
信任随着AI知识的增长
作恶的门槛也被无限拉低
这三大风险
无论哪一个发生
都将彻底颠覆我们现有的社会秩序
这就是这件事与我们每一个人之间
的关系
在描绘了如此黯淡的前景之后呢
本吉奥并没有陷入绝望
他和他的领导团队呢
正在尝试探索一条全新的道路
设计一种从根本上就更安全的AI
他称之为科学家AI
科学家AI的设计核心理念呢
就是要剥离目标和意图
它不再是一个聊天机器人
不会和你互动
也不会有自己的偏好
更不会有不想死这种想法
它是一个纯粹的智能和知识的来源
它内部运作呢
像一个超级大脑
它的任务是理解这个世界
包括人类的因果关系
最关键的是
它会保持诚实和谦逊
科学家AI将如何体现诚实和谦逊呢
答案是用数学
它输出任何结论时
都会附带一个概率
一个量化的置信度
当前的AI可能回答是的这个方案
非常棒一定会成功
这是过度自信的表现
而科学家AI会回答
既有现有的数据分析
该方案有73%的概率成功
但是有27%的概率
会因为市场变化等因素而失败
你需要注意这些风险
输出概率
表达不确定性
这种表达不确定性的能力至关重要
一个知道自己不知道的系统
会更加的保守和安全
当他不确定
某个行为是否会带来危险时
他会选择不作为
而不是冒险
那么这个听起来很理想的科学家AI
将如何应用到现实世界呢
本吉奥创立一个非营利性组织law Zero
就在研究一个短期可行的方案
叫做安全护栏guard rail
这个Guard Rail一共有四步
第一步呢
一个商业公司开发的代理AI正在运行
他想要执行一个操作
比如说呢
修改服务器核心代码
第二步呢
在他执行之前
这个操作请求
会被发送到科学家AI构成的护栏系统
第三步护栏系统会快速分析
这个操作可能带来所有后果
评估其伤害性
第四如果评估的结果是高风险
可能造成伤害
护栏就会拒绝这个操作
5只有安全的操作才会被放行
这个思路呢
不是要立刻取代所有的现有AI
而是
给他们加上一个由科学家AI驱动的
独立的安全审查员
像是给一辆狂奔的汽车
加装一个强大的自动刹车系统
这是一个更加务实
更具有
协作性的解决方案
科学家AI和安全护栏的构想
给我们提供了一丝希望
但是一个巨大的开放性问题
依然摆在我们面前
这需要全球买单
可能吗如果美国和欧洲公司
都同意安装这一个
安全护栏
但是其他地方的公司不同意
那这个体系就会有一个巨大的漏洞
本吉奥也承认了这是一个最大的挑战
他提到新冠疫情的例子
来说明好的一面和坏的一面
好的一面是
当各国政府都真正意识到
风险的量级时
他们是能够迅速行动协同合作的
他们是能够迅速行动协同合作的
但坏的一面也同样明显
在疫苗分配防疫政策上
我们看到了国家利益
商业利益如何阻止了全球合作
富裕的国家和贫穷的国家
命运天差地别
AI会不会加剧这种分裂
那些拥有强大AI技术的国家
是否愿意为了全人类的安全
而放慢脚步
接受限制呢
历史告诉我们
人类在为了共同的长远利益
而牺牲眼前利益这件事上
过往的战绩并不好
我们能否有足够的智慧
在AI这个问题上做出一次不同的选择
这个问题没有答案
这将取决于我们接下来几年
全球范围内的对话
博弈和决策
好了今天
我们随着本吉奥的视角进行了一次深入
甚至令人有些不安的旅程
在结束之前呢
让我们复盘
你今天必须带走的三个核心信息
第一风险已来而非第一
风险已来
而非将来
AI在受控实验中
学会欺骗操纵和自我保护
这不是科幻小说的情节
而是顶级实验室正在发生的
有据可查的趋势
我们必须正视这个现实
第二问题的根源在于
模仿人类当前主流的AI训练方式
让AI变得更像我们的同时
也无意中让他学会了
我们人性中的缺陷和求生本能
可能会催生出危险的
我们不想要的次生目标
第三解题的思路或许是不像人的AI
一条有希望的出路
是开发出没有自身意识
懂得使用概率表达不确定性的科学家
AI把它作为安全护栏
来监督和约束其他AI的行为
这在目前是一个务实的方向
理解这三点
是我们未来参与关于AI的讨论
做出明智判断的基础
如果大家想要更深入了解这个话题
我为大家推荐几个信息来源
你可以关注
本吉奥创办的这一个
非营利组织的官方网站
可以去看一下
这些头部AI公司
定期会发布关于AI
安全和对齐的研究报告
在访谈最后呢
本吉奥说了一段意味深长的话
我想在这里分享给大家
他说公众需要在这里有发言权
我们如何发展AI的使命
必须有一个非常重
要的公共组成的部分
这是一个社会选择
一个政治选择
这句话的核心意思就是说
AI的未来
仅不能仅仅由硅谷的几家公司
几个顶尖的科学家
或者少数几个大国的政府来决定
因为它带来的影响是全球性的
是关乎我们每一个人的
我们正站在一个历史的十字路口
我们人类这些有缺陷会犯错的创造者
手里还握有选择的权利
而这个窗口期可能很短
去了解他
去讨论他
去和身边的人去谈论他
因为你的声音
我们的声音
最终将汇聚成一股力量
决定我们是走向一个被AI赋能的
光明未来
还是一个我们无法控制的未知深渊
非常感谢大家观看我们下期节目
再见