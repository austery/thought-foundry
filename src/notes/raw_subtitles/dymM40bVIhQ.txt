反正现在我没有access了
所以也算自由了
想干什么干什么了
我是在准备访谈的时候
才发现你在Meta已经工作10年了
对对
那个时候2015年
很小的公司
2012年上市的
对
你加入的时候Meta多少人
加入的时候
大概有1万多一点
也不小了
不是特别小
但对比现在可能几十万
我们是沿着原来的访谈大纲
去聊你的论文
然后我们address一下这个new development的问题
也行
我们就可以聊一些论文
我觉得这个还是比较好
因为我其实并不想说太多裁员的事情
我也觉得这个不太好
推特上就发了一个帖子
那么多人点赞
小红书上也是
刷到你的名字
这一天刷了好多
其实我这边本意
因为我这边team也有几个人
被影响到了
所以我当然希望他们有更好的机会
因为我无所谓
我最惨
我在家里待着
但是他们很多人身份会有一些问题
如果不能及时找到下一家的话
想办法帮忙找一找
因为我毕竟认识的人比较多
这个也是我的本意
我反正不怕暴露自己被裁
I don't care
但是希望我的下属那些人
能很快找到工作
这也是我的本意
我觉得是这样
不要聊你们在公司的问题
我觉得我已经说够多了
我不想再说了
我一般不太愿意说这些
我觉得我在Twitter上唯一说的是
因为有人跳出来说
你们被裁是应该的
因为东西没做出来
那我要至少给我们的team澄清
对吧 因为我们team做了很多重要工作
你不能把锅扣到我们头上
所以这个肯定是要讲清楚
但是我现在就比较defensive
如果有人说这个是我们的锅
那我会说回去
除此之外
我不会说太多公司内部的事情
那你还有没有什么想澄清的
你觉得没有澄清好的
哈哈
我觉得差不多了
就这样
我觉得
我们其实还是做了很多的工作
把很多之前的一些问题解决了
比如说
包括long context的reinforcement learning
有没有训练得好
还有包括前面的pretraining model
他们的design其实可能有些问题
像有sparse attention的问题
这个其实很多是我们团队解决的
我先发现的 问你这个design有问题
然后去跟他们讲
但是一开始很难
他们不一定听你们
我当时去的时候
相当于一个research team过来的
对方是做大模型的
我这边research team过来的话
他们不一定会听
他们可能会觉得这个事情没问题
肯定是对的
我们这边要用各种实验去证明
我们之前的那些发现
或者说那些insights是对的
后来他们是被说服了
所以他们才会发现这里有问题
这个其实都是我们团队的贡献
还包括
怎么样去让long context的reinforcement
learning更加稳定
包括有很多blew up的问题
怎么样去解决
这些东西都是我们这边做的
但这些东西也就属于幕后英雄
毕竟最终我们这个模型
也没有真正official release
至少我们有一些贡献在里面
这个我得说
说出来
至少为后面的人添砖加瓦
做一个比较好的base
就是这样子
我倒有两个问题了
第一 你们作为一个research团队
人家不信你
可能是觉得
你之前没有这个训练大模型的经验
或者怎样
但是你们能很快发现问题
你觉得为什么可以做到
第二个就是
对面那个大模型团队
是个什么样的团队
他们自己本身大模型训练经历丰富吗
他们训练是经验丰富的
那他们有一些
之前的实验有bug
嗯
这个bug导致他们做出错的判断
但是我们这边虽然说没有训练模型
但你毕竟是做过大模型的
有些文章
对吧 包括我以前
做过sparse attention
稀疏的注意力
那我当然对注意力结构
我知道什么意思
怎么回事
那我当然一看这个设计
我知道有问题
这个我相信很多人都能看出来
这个并不是说我能看出来
你肯定能看出来
但我并不知道
当时这个决定怎么做
但是我愿意说
但是没办法
因为其实也很难说服他们
就是
你要花很多时间和精力去跟他们说服
这个是有问题
后来他们自己团队发现了
也是有这个问题
慢慢就会改变这个想法
虽然说研究员
可能我们当时做研究的时候
并没有直接去接触超大模型训练
但是研究的这些直觉
或者说这些经验其实很有用
对吧 它能够很快能够找到问题
能够发现什么地方是有问题
是有出错的
怎么样去解决
我觉得这个是很重要的
这个是作为一个研究员的宝贵财富
说实在的
你如果是一个
完全没有任何insights的人
OK 我天天就跑实验
然后调参数
这个工作其实你说你能做
别人也能做
对吧 那研究员的优势是说
我能不能
根据一些非常稀疏的数据点
能够得到非常重要的结论
这结论能够推广到难的问题上
这个是研究员能力
你说的稀疏的数据点
是不同论文和不同实验的结果
对 就比如说
我如果是个新来的菜鸟
那么对我来说OK
我的任务是调参数
跑程序 比如我跑1万个点
我就得到1万个点的参数的值
然后我就说
我告诉大家这1万个点是我跑的
跑完之后跟大家说OK
跑完了 这个是我的结论
但是跑完之后这1万点就在那边
是死的 你也没有什么insights
没有什么概念
说
这1万点其实代表了后面什么意思
有什么样的结构
那这个
其实只有那些有经验的人才能看到
有经验的人可能看到20个点
我就知道有什么问题
甚至说看10个点
看到
这个training curve刚刚训练了一半
哦 我知道不行了
不要跑下去
可能你这里有问题
这个其实是为什么
AI的研究还是薪资比较高
我觉得很多时候是这样
你的一个insight可以抵
比如说100块卡
或者说抵1000块卡
（还是）多少张卡 我不需要那么多卡
但是我还是有insights
可以得到一些比较好的结论
这个是重要的
你刚才用了两个词
一个是经验
一个是insights
然后我想double click一下
这个到底是个什么东西
有的人会觉得这是一个taste
有的人会觉得是个intuition
我们有好多词去形容这个东西
那你觉得这个东西到底是什么
刚刚已经有四个词了
对吧
四个词说的好像都是一件事
那你能不能给大家讲一讲
从你的经验来说
你用多长时间能判断一个人有这个
还是没有这个
你觉得它有的话
它除了像你刚刚说的
从很小的数据点
就能得出来一个更正确的结论
还有什么展现
以及怎么得到这个东西
我觉得是这样
insights
是一个很难描述的概念
特别是一个有经验的人
比如说在某方面他是个老师傅
那么他怎么做
他要根据很少的数据
然后判断
这个现象背后的真正原因是什么
这个是重要的
比如说一个修车师傅
他可能根据蛛丝马迹
会知道你车哪里坏了
明白
你还没有反应过来
说这个事情就坏了
或者说一个交易员
我做股票交易的
我说我根据这两个迹象
或者看看财报
嗯
所以这种东西是很重要
他讲不清楚到底怎么回事
但他就有种感觉说
这个不行 那个行
有一个mental model
这个mental model大概率是对的
这个其实很重要
有这些东西之后
其实很快能够发现问题在哪
然后有这问题
我们怎么样去解决这个问题
然后往这个方向去走
这个可能比GPU还要重要
当然GPU也很重要
有GPU之后
你会做更多实验
获得更多的insights
这两个是相辅相成的
应该这么说
你能很快判断另外一个人
有没有一个好的mental model吗
这个其实是有一些办法
就是说你是要跟别人聊
大概聊一下
感觉一下他平时对这问题怎么想的
我觉得这个其实挺重要的
其实我可以举个例子
比如说学校里面有这种
PhD exam PhD qualifier
一个学生坐在自己老师面前
然后老师问他
请问你对这个问题有什么了解
比如说我们讨论一些学术问题
对这个老师来说
他想办法问到底
比如说
你对这个偏微分方程有什么想法
你有什么一二三四五这些经验
然后就是抓住一个点
然后使劲问
你就知道他到底懂不懂了
他到底知道这里面之间什么关系
能用最简单的语言讲清楚
对 然后就能够知道
最重要的两个东西的关联是什么
这样的话
就知道他真是懂的
或者说他真的是知道最关键的
关联在哪里
可以用这关联去做更多的推广
这个是重要的
像比如做研究的话
比较忌讳的是说
我就只懂书面知识
一二三四五
背出来了
但是他们有什么关系
什么时候他们两个成立
他们俩不能成立
什么时候imply B
什么时候imply C
这个并不知道的话
其实是比较难搞的
我觉得这个是一个问题
其实这个很重要
说实在的
是我觉得现在的模型做不到的地方
现在模型可能没有办法
用很少的数据
真的去预测将来的结果
那我们就直接到这个话题吧
你的论文是Grokking
但是它是一个底层的
这么一个
在一个时间点
它有了一个学习的这样的东西
顿悟的感觉 是吧
嗯
我在看你跟智源的专访
里边你也提到一个点
就是鸽子问题
你当时和Denny Zhou在
Twitter上
关于chain of thought的一些讨论
就是说确实
理论上也许你的这个逻辑能表述的话
chain of thought似乎可以解
但是模型会用无限的数据
去试图解决这个问题
但是
人似乎一下子就能get到这个问题
我觉得和你刚说的那个东西
有一些联系
但你如果来定义这个能力的话
你会把它定义成reasoning吗
还是你把它定义成一个什么 顿悟呢
它是在reasoning
或者说其他一些task下面
下面是什么意思
是更底层的意思还是
更底层的意思
就是说它是一个表征学习
比如representation learning的一些行为
随着这个训练的拓展
你会发现表征会改变
就相当于看金庸小说 对吧
张无忌一开始被他义父谢逊逼说
你把东西全背出来
现在全背出来
背出来之后你不懂没关系
不懂你可以脑子里存着
过了几年之后
突然之间有点 会了乾坤大挪移
突然懂了
这个是很有意思的一个机制
比如说你当时教小孩子
可能也是这样
特别是有些小孩说你先把它背出来
读书百遍
其义自现
就是你现在先读
并不知道什么意思
但是过一段时间之后
或者说你跟其他的一些事情
能够联系在一起了之后
你就会有一个突然之间你会觉得
这个意思
是跟我这个现实世界是有关系的
或者说这两个意思之间是有关联的
我们知道更深的联系
这种其实是应该说是顿悟的一部分
这个机制其实是在思维链之下的
不管你用思维链做推理训练也好
不管你用那个直觉
来判断那个答案也好
或者不管你用什么方式来判断答案也好
对吧 这些东西
它的下面有一个共同的机制
就是说我到底用什么样的表示
用什么样的对这个世界的理解
导致了这个思维链
比如说那个小学生做一道题
他可能说
我这道题怎么做
我用穷举法
1+1等于多少
1+2等于多少
1+3等于多少
那么有一些穷举的一个路径
可以把这个事情做了
比如说你要证明一个简单的一道习题
那么小学生会说
我穷举一些答案
看答案差不多了
那可能就对了
但是你这种方式
其实可能很多问题解决不了
等到比如说初中生或者高中生
他们的这个思维其实有一种飞跃
什么叫飞跃呢
就是说我们告诉他
我们可以用数学归纳法
来解决这个问题
数学归纳法这个思维
这个层次是高于穷举法的
如果你的数学归纳法
能够证明这个事情是对的
那么它就对所有的自然数都成立
那这样的话
我的穷举法
穷举无穷长的那个思维链
它其实都比不过数学归纳法的
很短的证明
所以这个是一个飞跃
这样的话
你对这个问题的理解
两种方式的思维链
它的后面的理解是不一样的
所以这个理解或者说这个表征
其实就是神经网络
学习的一个重要的地方
我不知道我讲清楚了没有
很清楚
然后我想跟你对齐一个认知
然后给你看一个
就是当时我引用的
我们不是教课吗
然后我们教课的时候
我自己发现当时是Ilya去MIT
几年前了
2016年的时候他去讲的
总之他当时讲了一个东西
我觉得他说的很深刻
就说为什么这个back propagation works at all
然后就是这个
theoretically optimal hypothesis class
等于short programs
对对
就听你刚刚那个意思
也是 就是本来我要去走好多条点
走到这
然后突然找到了一个更好的联系
然后我就有一个更好的压缩
然后它就更generalizable
对
这么说
就是说因为压缩
可能也可以说是更通俗的解释
对吧 但是什么时候这事情能压缩
什么事情不能压缩
其实现在不是很清楚
这是为什么你要去研究Grokking
这个机制
它给你提供了一个动力学过程
让你知道
它怎么从一个不压缩的状态
变成压缩的状态
你可以这么想
我再说一下
就是我接下来问你一个问题的铺垫
就是我会发现
这个和人类理解知识似乎也很接近
人类也是information connect dot
但是这个图是在neural network之前出现了
对 而且
很多教育专家他会发现
就我记得在群里面
赵智沉有讲说
reasoning是一个人类固执的幻觉
对 然后这个是个教育专家说
the most important single factor is prior knowledge
对 你只有prior knowledge就行了
你只教prior knowledge
没有什么聪明不
聪明这种说法
反正
你只要把这些知识全都connect起来了
似乎就可以
这就是我接下来问题的这个铺垫
那接下来的问题就是
我们不知道我们的这些knowledge
connections是怎么形成的
对 我们没有办法去讲清楚
你说在大规模预训练的过程中
似乎大家也不是很清楚
对 所以这是为什么搞清楚
其实可能孕育着
就是下一个模型的一个契机
对吧 如果你搞清楚了之后
你就知道什么地方你要修改
这样的话你模型变得更强
所以这是也是一个动力
因为我们现在 你看 可以说
我把它搞清楚
我把它当黑盒子
就相当于一个很大的开关
有很多的开关
对吧 像以前那种电脑
那个大型机 非常多的按钮开关
我们就培养操作员坐在上面
然后把按钮开关打开
各种组合
然后看效果怎么样
那这是一种方案
那另外一种方案就是说
我们要把这个大的机器打开
然后理解里面的机制是什么
有这个机制的理解之后
那我以后再去拨这开关的时候
就非常有感觉
我就非常知道哪些开关要开
哪些要关能把这个做出来
我觉得
这肯定是一个更好的做法
当然 现在可能主流的思维
其实并不是这么说
主流思维是觉得
我们就叫scaling law
我不需要搞清楚你们在干什么
我就机器
很多很多很多
放很多聪明厉害的人进去
然后让他们去拨那些开关
这些开关的某种组合找到了
那我们就能够把这个模型做得很强
两种不同的思维
但哪种是对的呢
现在也不好说 对吧
因为现在确实scaling law有很大的应用
确实那个效果也非常好
至少目前为止看起来
我把它当黑盒子
然后让很多人去拨开关
得到一个更好的解
是一个比较好的方案
另外一方面就是你把那个模型打开
那个时间花的代价其实更大
因为其实并没有多少人真的知道
这模型里面在干什么
但是我觉得长远来说
可能后者
会有更高的天花板
我同意你的判断
但这里边有这么一个点
我觉得
为什么黑盒子现在它是占主流
因为打开了以后
人类似乎也没有办法真的去判断
什么东西
是什么
就是这里边有几种学习范式或者怎样
对对 现在是这样
所以能不能找到一个比较好的
能够理解整个结构的一个大的框架
是重要的
所以是这样
这是为什么我做paper的原因
比如最近有一篇paper
我们做Grokking 对吧
那么这篇paper
为什么要做这个paper
所以我觉得通过这个方式
得到一个对这个问题的
一个大的理解
框架可能对以后的模型的改进
有很大帮助
这个是我的想法
本来已经有点复杂了
但是我觉得我再多引入一个问题
似乎我们在学习AI
怎么学习的过程中
我们会从人类身上
人类的学习过程取得灵感
包括最近很火的Sutton出来说
RL是人类学习的方式
大语言模型这种方式不是学习方式
它也不能学习
因为它没有objective
那另外一派呢
Hinton他说经验
并不是一个只存在人脑中的
你通过语言可以得到经验
这个debate
最后就落到人到底是怎么学习的
然后什么是学习
怎么样子才能产生学习
或者产生新的知识
或者connect the dots
就想请你再就这个问题
来发表一下你的猜想
甚至都可以
我觉得通过经验学习
这个是对的
但说这个经验里面
什么样的经验是更有价值的
我觉得这个是一个比较大的问题
对吧
比如说你要说非常直观的经验
就比如说我有一派是这么说
我没有embodiment
我是没有办法去学到真正的感觉
这个是行万里路
对对
你要行万里路
或者说你要真正感到痛
感到伤心
喜怒哀乐
你才能真正成为人
就是这样的一种说法
或者说比如说
我只能通过看世界
然后才能知道空间结构
或者说只能通过摸才能看空间结构
对吧 那么还有一种说法
就是说我有一些抽象的概念
我还是能够学会这样一些东西
我觉得这两个东西
其实应该说不是说是互斥的
因为是这样的
其实最终我的目的
是要学到一个representation
学到一个表征学习
对吧
因为如果你学到一个representation的话
有个好的表征
那么对的问题你能够解决
表征怎么学出来
的这个完全取决于
你的那个输入有多丰富
结构是什么样子的
不管你是直观的学习也好
还是抽象的学习也好
只要能学到这个表征
就能够
最终得到一个比较好的泛化的效果
我觉得这两个拼起来
应该说是比较好的
那么两边谁能写出表征来
这完全是应该说
是有个定量的方式来预测的
而不是说是非此即彼
有可能是说两边都一半都可以学
或者说一边1/3边2/3也可以学
都行
所以并不是说一定是黑或者白
或者左或者右
很多时候是混在一起的
然后最终得到个表征
这表征就是能够进行预测
或者说能够操纵你的行动
能够泛化到一个新的
没有见过的情况
那我觉得顺着这个问的话
就是你刚刚所说的后者的工作
就是不是black box
然后不是所谓的这种scaling law
而是真的去打开它
然后去梳理它
然后怎么样呢
用不同的方式去学习
对对 那它的意义是什么
就是几种
就是要么它学得更有效率
然而
似乎现在我们数据已经到了一个瓶颈
效率这件事情
不知道它是不是意义那么大
然后可能是在同样的知识里边
能学到新的东西
或它能增加新的数据
就是新的信息
information set
嗯嗯
它的意义是什么呢
就是那样做的意义
我觉得首先第一个就是说
数据到瓶颈的话
其实恰恰就需要这个了
因为如果数据到瓶颈的话
那你意味着
scaling law不一定有效了
比如说你就这么点数据
比如说你就只有这个
hundred trillion tokens （几百万亿tokens）这样一个scale
这个token数目
对一些大众的东西
已经绝对够了
对吧 但是对一些小众的领域
就是
它可能每个小众里它占的比例就很少
所以这样的话
其实你如果数据不够
再加上你的训练算法比较费数据的话
不管怎么样
你学会的永远是一个memorization
或者说是记忆的结构
而不是一个泛化的结构
那这个是一个问题 对吧
那么这种情况下
你怎么样去用scaling law做
你比如说你得去找办法
去做data augmentation
也许这是一个办法 对吧
但是如果你对这个问题有理解
对这个模型有更好的理解的话
也许不需要data augmentation
也许你需要改变
这个训练本身的那个算法
或者说训练的那个架构
那么有这个架构之后
也许这个模型就会做得更好
你觉得我们现在大语言模型
产生出来的inference
生成出来的这些新的token
它是记忆还是泛化
我觉得这个是
我觉得是混在一起的
task比较丰富的
你见了很多很多这样情况
可能是泛化
给它的记忆材料越多
它越有泛化的可能
是这样吗
你可以这么说
就是给它的材料越多
因为它看到各种组合了之后
它在组合里面
可以得到一个比较好的表征
这个表征它能够有预测能力
或者说
这个表征对没见过的那个组合
它有一些比较好的结构可以算出来
这个其实就是泛化
我觉得说实在
所谓我们真的懂这东西
我真的理解这东西
往往意识的一个
是它的泛化能力很强
对新的情况下
这个表征能够得到正确答案
然后第二个
就是说
它能够细化到非常简单的这个逻辑
那么这个逻辑
可以apply to everything或者apply to lots of cases
这两个东西综合起来
就是让你这个学出来的知识
能够apply到很多其他的地方
那么这个叫泛化
应该说我们对泛化下个定义的话
这样一个定义
那么如果大语言模型
对某个领域看了很多很多数据
它有可能学到更好的表征
然后这边就可以泛化
那这个是一个
然后另外一个
就是说如果它看到的数据很少
那这样的话
有可能就说这个模型本身
它没有办法学到很好的那个表征
OK 那它就只能把它背出来
它得到的表征就是更偏于背诵的
这样的结构
就是
它能够至少对付好训练的那个要求
就说
我希望这个训练集上的那个错误率
还是比较小的
但是
它一旦超越了那个训练集的范围
之后
你就会发现这个错误率就会提高了
那么这个其实大家就认为
这个是过度拟合了
对吧 或者说是背诵了
所以大概就是这样子
其实我觉得很多时候
你并不能说神经网络是记忆还是泛化
应该说是完全取决于这个数据的分布
如果数据多
那么这个神经网络是泛化多
如果数据少
那么这个神经网络是记忆多
这个是我的观点
我觉得这里边最fascinating的一点
就是它从记忆到泛化的那一步
到底是怎么发生的
帮我们总结一下
至少从我最近的一篇paper角度上来看
告诉你
就是它有很清楚的一个picture
告诉你就是这是怎么发生的
内在机制是怎么发生
就是我们现在感觉上是
我从记忆突然间跳到了泛化
好像这个变化非常神秘
但是这篇文章其实告诉你说
其实并不神秘
它有非常清楚的一个数学图景
就是比如说
我们要做优化问题
我们可以构造一个
比较复杂的一个非凸的
一个优化的结构
比如说很多山的山峰
然后记忆
对应其中一个山峰
那个泛化
对应其中另外一个山峰
这两个山峰
其实对应着不同的表征
那么这个山峰的这个结构
其实完全是取决于数据的分布的
如果你数据不够
你可能就只有记忆的山峰
如果你数据很多的话
某些泛化能力强的山峰
就会慢慢变得越来越高
然后记忆的山峰就会变得越来越低
这样的话
你再让神经网络
去找到那个好的表征的时候
是相当于是个优化问题
优化这个神经网络这个参数
使得它能够收敛到某个局部的最大点
那么如果你的记忆的山峰缩下去
泛化的山峰提上来
然后泛化的山峰
那么就有很多的那个神经网络
它的参数会收敛到那个泛化的山峰
那么这个
模型就泛化了
那么从记忆到泛化
中间为什么会顿悟呢
其实很简单
就说你两个山峰之间的变化
此消彼长 对吧
然后在某个情况下
我比你高一点点了
然后突然之间所有人都往那边走
那就是因为它可以泛化
把它给泛化
因为它能泛化
所以它可以
只要多一点点的话
它就全都过去了
对对 因为你认为
神经网络
是一个一直在优化的过程
它会看见
如果这边高
那边低点
那么所有人都涌到那个高的山峰上去
那就突然之间你就懂什么意思
所以我觉得是这样的一个结构
也就是这样
从整个数学框架上
能告诉你这件事情
是这么发生的
而不是说是
还是非常神秘的这样的一个东西
那我是不是可以理解为
这个泛化的点一直都在数据里边
只不过我们之前没有找到它
没有搜索到它
或者说搜索到了
但是没有pay enough attention（足够注意）
然后现在
因为它随着越来越多的数据点
凸显了它的价值
然后我们才pay enough attention
对对 你可以
问题是它要存在
对 它存在
然后它有
你要足够的数据让它显得与众不同
可以这么想
就是如果数据不够的话
你可以有很多泛化的那个思想
但是就说这些泛化的思想
它的说服力不足以说服记忆这边
就是因为还不如把它记住
规律可能没有那么显然 对吧
那这又回到了另外一个问题
就是怎么样子做evaluation
怎么样子做reward
现在大语言模型还是你看你next token
predict（预测）准不准
作为reward（奖励）吗
还是有其他的方式
可以让这个有泛化能力的
显得更牛一些
应该是这样
就是现在你要看大语言模型
一种是pre-training预训练
和post-training后训练
对吗 这两个都有
所以你很难讲
你说预训练
我们现在还是用大量predict next token
然后后训练
其实我们可以说
有很多办法可以做训练
那么预训练这个结构
或者说这个损失函数其实没有变
因为现在相对来说
这个还是比较好的损失函数
当然现在有一些新的一些方案
比如说reinforcement training（强化训练）
就是我在训练时候加一段思维链
然后希望这个思维链
会导致最后的那个预测是比较准的
这种类型的一些工作
这个就是可能对原来预训练的方式
做了一些改变
大概是这样
那后训练它的花样就很多了
对吧 花样
就比如说
你可以改reinforcement learning的一些函数
比如说改比如说它的值函数
改它的evaluation 对吧
value function（值函数） 对吧
reward 对吧
改rubric（评价细则） 这些东西都可以改
你这些改了之后
可能就是
你其实是希望这个模型
往不同的方向走
对吧
然后你往不同的方向走了之后
那么有些方向
可能就强化模型的某个能力
某些方向强化模型另外一种能力
那这样的话
你这个模型最后就是百花齐放了
当然就是说很多时候
你要优化它到某个能力的时候
你其实还是希望能够优化得比较
一个是避免
reward hacking
有些时候就是
模型还是会最大化你的某个值函数
但是这个最大化的路径是偏的
不想让它这么做
但是它就这么做
这么做有shortcut
比如说你答案就只有ABCD四个
然后拿去瞎猜一个25%
我不希望它瞎猜怎么办
那我就希望我的思维链
一个是希望它的每一步
经得起考验
每一步逻辑是正确的
你可能需要一个另外的模型去做这个事情
这是比较重要的
一个就是怎么样去做这个事情
那么这样的话
你中间肯定要引入各种rubric
引入各种东西去把这个模型给调出来
所以其实花样还是挺多的
而且有很多地方
是可以有一些人类的那个思维和概念
能够放进去
听到现在用比方去理解它的话
就是大语言模型是个非常非常勤奋
算力非常非常高
就是一天到晚学习的人
读了唐诗三百首
结果发现它又找到了唐诗3万首
读了300万首唐诗
然后它会作诗了
是因为它穷尽了这里面所有规律
找到了行之有效的方法
且它有一个好的方式
去可以帮助它evaluate
它自己的诗作得好不好
它找到了这里边的规律
但前提是这个规律要存在在这里边
对对
然后你刚刚所说的
就是希望用另外一种方式去学习
是说我们不光要让它去背300万首唐诗
我们能不能
就是像发现数学公式那种方式
去发现一个规律
阿基米德发现
浮力定律它其实是干了两件事
肯定当时在想很多很多的方案
很多很多的可能性
然后它脑子里边找到了这么一个点
但是第二件事是
它马上意识到这个是对的
这两者在机器都挺难做到的
它很难马上意识到这个东西是对的
我觉得意识到这东西对的是有可能
比如说你发现一个新的假设
这假设能够解释更多现象
而且它假设更简单
那你会马上意识到这个是对的
就比如说地心说跟日心说
其实说实在的
那个地心说也是对的
地心听说你也可以拿来预测
只是在地球上来看
其他行星的运行轨迹非常复杂
本轮均轮这种运行轨迹
就是轮子套轮子
一边这么走
还要换个花样再转再转
就轮子里面套轮子
然后你通过这个方式
你可以预测一个行星的行为
这两个其实都是对的
日心说的时候
你会发现突然之间
所有的轨道都非常漂亮
就是一个椭圆
非常非常简单
这个时候你会马上意识到那个理论
或者说那种解释是更加完美的
或者说更加接近真实
或者更加接近那个更美的
这样的感觉
原来是这样子一个逻辑
你觉得elegance这个东西
在模型现在训练的reward function里吗
我觉得是这样
它不是reward function（奖励函数）
但是它在训练的时候
应该有implicit bias（隐性偏见）往这方向走
就比如说那刚才你说
Ilya说过这个
我希望它压缩
我希望这个模型会自动的
找到一个比较优美
的或者比较少的
压缩比最高的那个
解释 这个我是同意的
这个确实是会发生的
但是这个不是
是一个loss function
是说它内建在神经网络的训练过程里面
这训练过程
会让这个模型自然地发现更加好的
或者说更加优美的解释
那么这样的话
神经网络
它才有这个
能力去学会更好的表征
然后才有泛化能力
在loss function之上
还有一层更隐含的reward
是的
是可以这么说
对对
这个很重要
因为说实在所有的loss function都是surrogate
都是代理
就比如说predicting next token
或者是whatever
或者什么contrastive loss
non-contrastive loss
或者说player loss
这些东西都是代理
就是它的目的是产生一个梯度流
这个梯度流
能够让这个表征往正确的方向走
这个是最重要的一个逻辑
至于这个目标函数是什么
其实并不重要
重要的是这个
哦
我直到今天之前
我一直觉得
loss function是整个学习的目标
现在我才知道了它是surrogate（代理）
这个是共识吗
我为什么到今天才知道这件事
因为它听起来很intuitive
然后很重要
我自己
毕竟还是做过很多表征学习的工作的
我知道
很多表征学习的那个目标函数
你做过些拆解之后
你会发现它们其实就是反向传播梯度的
不同形式
你loss function换了
你的反向传播梯度的结构是不一样的
那么这个结构
其实最终能够影响你的表征的学习
但是你这个loss function其实可以
换 你甚至换成一些那个奇怪的东西
你从来没见过
但是你最后得到那个梯度是差不多的
那你求出的表征也差不多
你对梯度这个词的使用
也让我觉得非常的intuitive
我心中就是一个一个等高线
这个等高线最后画出来的
是我们的一个知识
很本质的东西
可能就是刻画我们世界规律的
这么一个
等高线这个逻辑
是经常用的
但是等高线这样的一个思路
其实它忽略了
这个神经网络本身的结构
因为它把整个landscape
把它做成一个高维空间中的
一个非常复杂的一个山峰
但是这个山峰
其实你要知道
山峰其实对应着神经网络的结构
所以这两个是有关系的
应该说
把这个梯度在山峰上的这个指引
去映射到这个神经网络的
具体的哪个梯度
对于哪个神经元的
或者每一组神经元的这样一个过程
那么这个时候你能看见
就是它的表征是怎么学出来的
这个是会比较有趣
但这个可能比较细节
大概是这样的一个逻辑
但这个是一家之言
我们来听的就是一家之言
有教科书的话我们就去学教科书了
当然每个人都会有自己的想法
这边也是做很多research
有这样的一个大概的感觉
在上面有很多文章做一些这样的工作
分析这个梯度的结构
我相信就是再往上走
也许那个理解
是
能够改变这个神经网络的学习的方案
这是我们的最终目的
当然这个方向比较
远 这是long-term的
当然是希望有很多那short-term的东西
可以跟它辅佐在一起一起做
要回顾一下你的这个科研史
看你的工作
其实我能感觉到
它是有一个很强的主线
自己的网站上介绍的时候
我就会发现
你前面一个工作lead到下一个工作
然后再lead到下一个工作
就是每一次
都能在前面非常重要的结果上
再往前走
你到底是怎么决定你的科研方向
你怎么样子把兴趣
商业和自己的追求结合起来的
肯定是要结合的
不然的话就是很有可能就很惨
大家都有家庭
大家都希望能够有一些比较高的收入
小孩也有个比较好的环境
社会地位也比较高
大家都希望这都要
成年人说大家都要
不是说小孩子
要选一个
所以最终你肯定是要找到一个结合点
因为我从博士开始
已经是很多是双线作战了
我可能花9个月时间
去想一些不着边际的东西
然后3个月说不行了
我今天要发paper
不然的话老板不爽 对吧
那我可能会跟老板说
你有什么题目
我来帮你做
我花3个月我就把这个事情做了
几篇paper就要对老板有交代
通过这方式至少让我
我是觉得让我会有工作
我能毕业 对吧
然后老板也开心
这个是重要的
工作之后也是一样的
我们当然希望做一些方向
这方向是迎合时代潮流的
不可能说完全脱离时代潮流
比如大家都在做大语言模型
你偏偏不做
比如我就要做SVM
肯定在公司里面是没有办法活下去的
会想一想
就是说
我这边的一些比较偏理论的研究
对于这个问题有更深理解
比如之前我们有一些关于
attention sparsity
注意力机制如何变得稀疏的
这样一些研究
那么这研究本身是比较理论的
但是你就可以拿来做一些
比较实用的工作
比如说之前的attention sink
我们其实没有太多理论
但是我们可以通过观察
这个神经网络的稀疏性
我们可能得到新的算法
用这新的算法
把上下文扩展到400万以上
这样的话
这个东西有用了
突然之间
你可以拿来做大语言模型的
coding解码的这样的一个应用
这应用
其实本身也可以放在很多手机上
这样的联系应该说还是比较紧密的
应该容易想到
你的attention有稀疏性的话
那我就把大部分的attention的score砍掉
那不就是加速了吗
其实省内存了
对吧
那你有各种办法可以提高这个效率
这两个关系是很大的
你只要稍微想一想
就有一个新的算法
你有新的算法之后
你就有一个新的思路
那么这个新的思路
你就可以拿来做很多
最后一个问题
就是until recently
你的科研
你感觉是按照自己的想法走呢
还是要做很多application的工作
及接下来
可能会吸引你做的事情是什么
是继续你对后一种研究范式
继续探索呢还是
我觉得研究范式探索是很
重要的 当然了
我们现在也要与时俱进
对吧 就是了
我不可能我关起门来说
我就用以前的方式来做这研究
也许我们以后要找到一个AI scientist
或者说我自己写一套比如说agent框架
然后帮我一起做研究
这也是可以的
就是说我们这篇那个Grokking的paper
就是我和GPT-5进行对话做出来的
其实我觉得很有点像这种self-play
我给它一些问题
然后我这边有些想法发给那个GPT-5
让它去思考
给一些比如formulation
就一开始你这么做
它给你的答案都是非常大路的
非常没什么意思
但是你通过思考之后
关键的一个insight给它
它可能会有不一样的输出
这不一样输出
可以往下面深挖一层了
但是你还是要找到它的错误
找到它的一些矛盾的地方
它做不出来的地方
然后继续深入
然后一直深入到
这个问题的那个理解
或者说这个问题的一个数学的
这样描述
已经达到了我想要的这个目的
这部分就成功了
但是我还有一个点
就是那是个solo author paper
你没有把GPT-5放到co-author里边
这篇文章是个conference投稿
conference投稿说
大语言模型不能作为作者
所以你没有放 对吧
那我后面写了一段
这段话是说我们广泛地使用大语言模型
我给大语言模型各种想法
让它去formulate
让它证明一个东西
然后发现问题怎么解决
对吧 它基本上所有
东西都是错的
但是它有一些比较有意思的insights
很多东西可以细化
然后把你的idea从一个想法
变成一个具体的过程
这个它很擅长
就相当于它是一个非常勤劳的
junior的一个PhD
它非常勤劳
我给它一个想法
它马上把它写成一段落
让我能够很快地进入状态
以前你要进入状态
我现在有一个小时的时间
一开始半小时我要进入状态
通过写写公式
看看文章
思考一下
我进入状态了
叫心流
然后才能得到一些结果
这个时间其实比较漫长
有了这个GPT-5之后
进入心流时间很短了
你跟它有一个小想法
然后它给你写一大段
三分钟之内给你写一大段东西
你看完这段东西之后
你马上会进入这个状态
就说我知道我要怎么去想问题
什么地方它做得不好
或者说有什么insight可以进来
这个是很大的一个效率的改进
以前你需要几个月的时间做一篇文章
你现在可能几个礼拜
甚至是更短的时间
这个是非常大的效率的提升
如果用得好的话
是很厉害的
当然
现在还是个非常初级的一个self-play
对吧 也许
说不定
以后我们可以做一个更加自动化版的
就很有意思
嗯
那肯定这方面有很多东西可以做
自己也有一些经验了
就是我跟当时是o1-pro
探讨量子力学的那个many-world
theory 我特别感兴趣
然后我一直觉
得它最make sense
但是我们没有对应的哲学
反而那种所谓玄学的哲学
和这个many-worlds theory的哲学是吻合的
就是我如果非要强行地说的话
我就说这个世界的本质
就是一个非确定的many worlds
然后我们之所以现在share一个reality
这个是我们的最大概率
当然这个概率可能极大
就是99.99999
所以说我们就会觉得
这个桌子是确定无疑的存在
但是其实它可能并不是真的存在
嗯
对 大概是这种感觉
对 这个是对的
从科学上也是对的
你可以认为它是一堆波函数的组合
对吧
然后存在一种可能
是这个桌子突然之间跑到另一堵墙
另外一边去了
这概率非常小
但是不是0
这个是存在的
只是因为这个桌子是宏观物体
它的那个量子态不是那种相干量子态
所以就出现这种概率非常非常小
就是这样子一个东西
但是我就发现
这个idea
我没有办法和它写成一个文章
因为我自己的水平不行
就是说现在AI能辅助你写出来
像你这个顿悟的这样的文章
主要是自己
最后还是人还是比较重要了
有很多重要的insight还是要人给
然后AI现在有很多奇怪问题
比如说它就会卡在一个地方动不了
它会跟你说很多车轱辘话
然后它就说不到
本质上 这个很有意思
感觉上就是
你去面试一个新来的PhD
然后说一大堆话
它像背诵概念
但它又绕不到
它就找不到那句最重要的
本质的话能够说出来
这个其实是一个比较大的问题
但是这个就需要人去总结
然后告诉它
这个是我们认为的最本质的东西
然后让它继续往下走
这个是比较重要的
就是说这是一个fresh PhD
fresh PhD意味着它可能是可以被训练的
我想到是duolingo的那个founder
他是一个计算机教授
我忘了叫什么
他讲了一个故事
就是他去读博士的第一年
他老师是图灵奖的获得者
对 然后几个月
他去了以后
他老师就只跟他干一件事
就是你这个东西给我讲讲
我没听懂
下次再来
他第二个月的时候就崩溃了
就这个老师肯定不行
怎么回事
结果后来才发现
就是他自己没有讲清楚
没讲清楚说明你这个理解不深
对吧 如果理解深的话
讲清楚了
别人会觉得
你确实理解深了
你确实懂了
然后你可以做
你可以做研究
所以这个是一个
对
他叫那个Luis von Ahn
对
我想起来
对对对
应该是说我当时在CMU读博的时候
他就在那了
对 他有这么一个故事
所以说
不知道模型是不是也可以这么搞定
我觉得有希望
希望可以
是的是的
对 当然了
大模型可能会强行地记住
怎么样讲能讲清楚
但它自己不懂也是有可能
而且就是说
你怎么样才能获得训练数据
能够让大模型
找到最优的讲清楚的这样一个
因为讲清楚这个事情
是一个非常主观的东西
很难用这个模型去model它
在要求大语言模型之前
我们先要求自己
我们先要求自己把一个东西给讲清楚
已经是一个很高的要求了
这个很难
就是说
这部分其实可能就需要人有美感
就是人觉得它的那个讲解
是非常有美感的
或者说非常简单扼要
这个才可以
那么这个怎么样去设计一个loss function
是一个question
通过这个对话
我也更深层次地理解了
这件事多重要
它的context是什么
和它其实对人也好
或者对模型来说
其实都有很多共通的地方
我觉得通过讲这个论文
我们也讲了很多其他的
我觉得挺重要的知识
对对对
好的 那祝你接下来一切顺利
谢谢 好
先这样
拜拜