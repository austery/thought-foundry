好 那這一堂課呢 
是要講有關評量大型語言模型的事情
那我們今天
講了好多有關推論模型的事情
那我們怎麼知道這些模型有好的推論能力呢
事實上啊
今天評量模型推論能力的方法
就是簡單粗暴
直接考他些數學問題
答得對了
就當作你有好的推論能力
答錯了
就當作你沒有好的推論能力
比如說在DeepSeek技術報告的第一頁
他就展示了DeepSeek的模型
還有OpenAI o1系列的模型
在一些數學問題
還有程式問題上面的正確率
AIME呢 是一個數學競賽
那縱軸呢 是這個
答題的正確率
那DeepSeek呢 在這個AIME上
它的正確率 看起來比o1的模型
高了一點點
好 現在呢
評量這些模型推論能力
都是用這麼簡單粗暴的方式
解得出數學問題
就當作你有推論能力
解不出來 就當作你沒有
其實不只DeepSeek的paper是這樣衡量啦
你看這個o系列的模型
它在釋出的時候
也通常會量這些數學的問題
用數學問題來展示模型的推論能力
但是 能解數學問題
就代表他有推論能力嗎
有沒有可能 他只是
我恰好就看過這題數學問題
我知道答案 我裝模作樣的推論一下
然後直接把我知道的答案輸出來
然後你以為他很會推論
其實他只是正好看到一樣的問題而已
有沒有可能是這樣呢
還真的不是不可能的
這篇paper是去年10月的paper
他想知道 有多少答案
可能是記憶出來的
那在衡量模型數學能力上啊
有一個很知名的資料集叫做GSM8K
裡面都是一些比較簡單的應用問題
那今天多數模型 GSM8K的問題
都是可以答對的
那這篇論文就說
那我們把GSM8K這些應用題裡面
的一些symbol 一些符號換掉
看看會不會怎樣
比如說 GSM8K裡面常常出現人名
那這個人名呢 跟解題是
完全沒有半毛錢關係的
比如說這邊有一個人叫Sophia
換成別的名字 會發生什麼事呢
然後這邊還出現了一個親戚關係
Sophia 看到他的侄子在做什麼
那把侄子換成別的親戚 會怎麼樣呢
或者是 把數字換掉
把數字換掉並不會影響問題的難度
但是對模型的正確率 會不會有影響呢
所以這篇paper 就把原來的
GSM8K裡面的題目
裡面的一些詞彙 一些數字改掉
在不影響問題難度的前提下
再去問市面上多數模型這個問題
好 那在這一頁投影片裡面啊
縱軸的數字 代表說
在這個新的 有一些文字被置換的
GSM8K上
相較於原來的GSM8K
模型的正確率掉了多少
那你會發現 多數模型
它的正確率 都是有減低的
尤其是 像這個Mistral啊
Gemma啊
看起來他們的正確率 都受到了
蠻大的影響
所以看來這些模型
它是有稍微背到一些這些問題的答案
不然 為什麼換了一下數字
換了一下人名 你就答錯了呢
好 不過其實啊 從這個結果看起來啊
這些會推論的模型還是蠻厲害的
比如說 o1-mini
這個是去年10月的文章
那個時候就已經有o1-mini了
o1-mini 受到的影響
看起來是蠻小的
其實這篇論文呢 後面還有很多內容
比如說 他們用一個奇妙的方法
打爆了o1的模型
他們在他的題目裡面啊
加上一些完全不相干的句子
然後就可以讓o1模型的錯誤率（此處應為正確率）暴跌
不過我覺得這並不能夠說o1模型
沒有推論能力或者是記憶了那個題目
因為我覺得他們加的那個句子
如果是給人類看的話
人類應該也會有影響
比如說他告訴你說有三個蘋果
然後後面括號說 嗯
其中有幾個爛掉了
然後那你 你作為一個人類你會想說
那出這個題目到底是什麼意思
這個爛掉蘋果到底跟解題有沒有關係
那結果是跟解題沒有關係啊
我覺得就會讓那種reasoning model想太多
最後答錯 那我覺得人類遇到這種題目
也蠻有可能會答錯的
所以我覺得 後面
說這個他們說改了題目以後
o1 performance就很差 
這邊感覺可以做一些更嚴謹的測試
比如說讓人也來做一些題目
如果人不會被影響 模型被影響了
我們才比較好說 模型可能是
背到了這些題目的答案
好 但是這樣子的發現其實很多
這邊再另外引用一篇論文
他們嘗試了幾個模型
叫他們解GSM8K的問題
那他們做了兩種題目
那灰色的代表是原來GSM8K的題目
藍色的代表是
把一些句子的順序對調
但是不影響題目的意思
他們發現說啊
把一些句子的順序換掉
這些模型解題的正確率
居然都下降了
所以看起來呢 模型
它學到了一些不該學的東西
那有人可能會想說
那我們要怎麼避免模型學到不該學的東西呢
你想想看 今天這些模型啊
它都是在網路上看過非常大量的資料
所以 他們有偷看到
GSM8K裡面的題目
是非常有可能的
那怎麼解決這個問題呢
有人可能會想說
也許我們就是在訓練的時候啊
把訓練資料裡面
看起來跟GSM8K測試資料一樣的題目
把它拿掉
那避免模型呢
偷看到這些會拿來做測試的題目
但這樣的方法其實
不能夠完全解決問題
因為你想
搞不好有人把GSM8K呢
隨便做個翻譯
翻成蒙古文
然後放在網路上
然後你的這個爬蟲也爬到了
也拿來訓練語言模型
但它蒙古文 所以你也不知道它是GSM8K
所以模型可能還是看到了一樣的題目
只是用不同語言看的
那今天模型蠻有跨語言學習的能力的
所以它等於還是看到GSM8K的題目
只是 但是你又不好
你又不容易檢測出來
你總不能夠把GSM8K英文
翻成所有的語言都去檢查一遍
所以你不太容易檢查出
模型有沒有偷看到這一些你要問他的問題
好 所以今天啊
這些測試的結果
往往不一定那麼可靠
因為你永遠不知道說
這些模型是不是早就看到了
類似的問題了
今天在做這個模型推理能力測試的時候
有一個現在很常被討論到benchmark corpus
叫做ARC-AGI
在o3那個模型釋出的時候
也特別幫ARC-AGI宣傳了一下
那ARC-AGI是什麼樣的題目呢
裡面都是這種有圖形的
智力測驗題目
裡面的題目都是像這樣子的
給你這張圖
然後告訴你說正確答案是這樣
給你這張圖
告訴你正確答案是這樣
給你這張圖 告訴你正確答案是這樣
給你這張圖 然後問你說
正確答案是什麼
這算是一個比較簡單的問題啦
這邊的規則就是
看看在原來圖裡面
哪一種形狀最常出現
就輸出那個形狀
所以這一題 是這個
加號最常出現
正確的答案
就是這個樣子
但像這種ARC-AGI的好處是
模型在回答的時候
它不能夠憑藉著
它已經看過的的東西
它在網路上已經學過的知識
來回答問題
希望模型可以憑藉著它真正的推理能力
來回答這些問題
那我剛才有講說在o3釋出的時候
有特別宣傳了一下
他們在ARC-AGI上面的能力
在o3釋出的demo影片裡面
他們在ARC-AGI放的示範題目是這樣子的
就這是輸入 這是輸出
這是輸入 這是輸出
這是輸入 這是輸出
這是輸入
然後問你說 正確的答案
應該長什麼樣子
那這一題呢 可能就沒有那麼直觀
那這一題其實正確的答案是
外面這個有顏色的框框
它的厚度
就是裡面有顏色點的數目
所以今天這一題呢
要再這一個黃色框框外面框一圈
這個裡外面要框兩圈
這邊要框五圈
這個其實也是ARC-AGI裡面
比較簡單的題目
你在ARC-AGI的官網上面
可以找到很多它的範例題目
有一些蠻難的
裡面有蠻多
人類花一些時間還是想不出來的題目
好 那可能會問說
那這種語言模型是怎麼解這種圖形的問題的呢
難道也要考驗語言模型看圖的能力嗎
其實不是
ARC-AGI呢
丟給語言模型的時候
它的題目 長得像是
這個樣子的
所以它是用文字
來表示那些圖案
然後用數字來表示不同的顏色
比如說0就代表沒有顏色
12345分別代表不同的顏色
就告訴模型說 這是輸入 這是輸出
這是輸入 這是輸出 這是輸入
接下來 你要輸出什麼
那ARC-AGI呢
過去一直被認為是一個蠻困難的問題
事實上ARC-AGI 我記得是
2019年的時候
就已經問世了
但從2019年問世以來
這個ARC-AGI呢
一直沒有人有取得非常重大的突破
順帶一提 ARC-AGI的作者呢
其實就是Keras的作者
欸 現在還有人在用Keras嗎
大家知道Keras是什麼嗎
知道Keras的同學舉手一下
好 很少啊
這個時代 Keras的時代
過去了
這個時代真的變化很快
這個ARC-AGI作者呢
其實就是Keras的作者啊
這一張圖是ARC-AGI
他們有個官網 官網上
截下一張圖
這張圖是要表示呢 ARC-AGI
真的是一個非常困難的問題
這邊縱軸呢 代表的是
正確率
這邊每一條線 都代表一個
benchmark corpus
橫軸 代表的是那個benchmark corpus
被釋出多長的時間
那你會發現說 多數的benchmark corpus啊
都在釋出兩三年之內
就被打爆了
被玩壞了
被模型overfit 可以得到
將近100%的正確率
但是 ARC-AGI
在釋出的五年之內
沒有非常大的進展
正確率的進步 是非常小的
然後這邊有一個peak
就是因為他們辦了一個比賽啦
辦了一個叫ARC Prize的比賽
就如果你做得好 有錢可以拿
比較多人參加
所以正確率就提升了
但現在啊 o3
看起來在ARC-AGI上
居然是可以得到挺不錯的結果的
這個縱軸呢 是ARC-AGI上面的正確率
橫軸代表什麼
橫軸代表
這個模型 回答一個問題的時候
要花多少錢
然後呢 這邊就比了o系列的模型
這個是o1-mini、o1-preview
還有o1 (Low)、o1 (Medium)跟o1 (High)
這指他們的推論的過程有多長
那這邊呢 也有一些人類的結果
比如說這個點
是平均人類的表現
這個點
是數理科的畢業生的表現
那你發現說 o3
最強的模型
是介於 這個
比一般人類還要強
弱於STEM領域學生的能力
所以 哇 他居然可以比
一般人類還要強
不過他付出了非常大的代價
你看這個縱軸
這縱軸是1000啊 1000美金
所以每答一題
需要耗費相當於1000美金的算力
才有辦法回答一個問題
但是我覺得ARC-AGI啊
雖然它當初創立的目標
就是避免模型去網路上
記一些它已經看過的東西
他們相信這些問題
你在網路上可能找不到一模一樣的
而且他們有一個隱藏的testing set
那個testing set是沒有公開的
你 他們最後呢 評比的結果
會看那個沒有公開的testing set上的結果
但是呢 其實也不完全表示
你沒有辦法去fit ARC-AGI這個比賽
因為你想想看 它比賽的題型
它有釋出 它有釋放出一些範例問題
所以你完全可以根據它的範例問題
自己再創造出更多更多的題目
[聽不清楚] 創造了幾千萬題
然後我的模型什麼都不做
就光刷ARC-AGI
搞不好也可以刷出一個好表現出來
也說不定
所以我會覺得 就算是像ARC-AGI這種題目
他說這是比較接近
智力測驗的題目
那你沒有辦法在網路上找到一模一樣的題目
也許可以防止模型
背了這些問題的答案
但是要hack這種比賽
我覺得也不是完全不可能的
好 那要怎麼樣才能夠公平的衡量模型呢
有人說 哎呀
你只要有一個固定的出題方向
就有可能被猜題猜中
就想說 假設是有一個單位在出題的話
那個單位可能就會有固定的出題傾向
有固定的出題傾向
它的呼吸被抓到以後
這個benchmark就很容易被玩壞
那能不能夠讓全世界的人都來測
這樣就沒有固定的出題傾向了呢
所以 有一個benchmark
也它不能夠稱作為benchmark
有一個平台叫做Chatbot Arena
Chatbot Arena呢
就是你在那個平台上
你每次登進去的時候
他就隨機給你兩個模型
模型A跟模型B
接下來呢 你就問這兩個模型
一樣的問題
比如說我這邊問他
如何評估模型的推理能力
兩個模型都給我答案
然後你要決定哪一個模型是比較好的
根據這些比賽的結果
每一個模型會有一個分數
然後會有一個排行榜
那有人就會想說 像Chatbot Arena這一種
評量方式 應該就很難被hack了吧
因為它是全世界的人
都可以來問問題
全世界的人都是主考官
你根本不知道全世界的人
會問什麼樣的問題
你根本沒有辦法針對特定的題型
去訓練你的模型
但 真的是這樣嗎
傳說 Chatbot Arena
也是有辦法被hack的
因為人類 還是有他
喜歡的傾向
比如說一個傳說是
假設你的模型輸出比較多的emoji的話
你就可以在Chatbot Arena上打爆其他人
或是如果你的模型
比較會產生這一種
有粗體字啊
或者是有bullet point啊
就會比較容易獲得青睞
或是你的模型呢 比較喜歡長篇大論的話
你就比較容易獲得青睞
所以有人會說 Chatbot Arena
其實也沒那麼準
因為多數人在評比這些模型的時候
你根本就不會仔細去看它的內容
你通常是看他輸出的風格
所以輸出的風格 反而對結果
影響比較大
輸出的內容 現在這些模型都很強了
一般人的知識也沒那麼多
模型是不是在唬爛的
你也看不出來
所以就好像說你要評比一個比你聰明的人一樣
他講的話到底是對不對
你根本就無法評斷
你只能聽他聲音好不好聽而已
所以Chatbot Arena 也不是完美的
那其實Chatbot Arena這個官方呢
他們也有想辦法想要解決這個問題
他們怎麼解決這個問題呢
我們就來先簡短介紹一下
Chatbot Arena的評比機制
他們這邊呢 用的是Elo score
那這也是很多競賽呢 會使用的
評比方式
它算法是這樣子的
每一個模型啊
這個 假設有大K個模型
M1到MK
每一個模型 都會有一個分數
這個分數 代表它的戰力
這邊用β 來代表這個模型的戰力
所以第一個模型它的戰力是β1
第二個模型它的戰力是β2
以此類推
那今天 假設隨機匹配到兩個模型
第j個模型 跟第i個模型的話
這個時候啊 這兩個模型評比的時候
這兩個模型對戰的時候
它的勝率
會取決於這兩個模型
它的戰力的差距
所以 第I個模型
贏過第J個模型的機率有多大呢
它可以根據這兩個模型的戰力
計算出來
這個戰力怎麼計算呢
它這邊的方法就是
把第I個模型的戰力
減掉第J個模型的戰力
除掉一個normalization的分數
這是為了讓分佈比較好看一點
通常都會設成400
前面乘一個負號 再取exponential
這其實就是sigmoid function
如果 I的戰力比J的戰力
大很多的話
算出來的數值就會趨近於1
代表說 I呢 幾乎確定能贏J
如果I呢 比J小很多的話
如果I比J小很多的話
那 β i減β j就會是一個負值
exponential負的β i減β j
就會是一個很大的正值
那算出來的勝率 就會趨近於零
好 但實際上
在這個比賽裡面
你真正能知道的
並不是這些戰力
而是根據比賽的結果
你可以統計 某個模型對戰到某個模型的時候
它的勝率是多少
所以這個Elo score的求法是
我們先得到 先把這些模型
進行大量的比賽以後
你知道模型跟模型間
如果他們對戰的時候的勝率
再根據勝率 你就可以
反推出這些β的值
那這個不是我們今天上課的重點
所以我們這邊呢 就不詳談
總之 你有辦法根據這個勝率
實際觀察到的勝率
去反推出每一個模型的戰力
應該有多少
但在Chatbot Arena上
他們就覺得 會有太多跟模型本身
實力無關的因素
會干擾到評比的結果
所以 當今天計算正確率的時候
只知道β i跟β j是不夠的
要加一項 叫做β0
這個β0 是模型
實力以外的因素
那其實在棋類比賽裡面
有時候也會加上這個β0
比如說 如果在下某些棋類遊戲的時候
先手有優勢
如果先手有優勢的話
那你其實就應該把先手優勢考慮進去
那β0呢 就是考慮先手優勢
好 那如果呢 是在Chatbot Arena裡面
我們剛才講說 有很多事情
可能都會影響
跟模型的本身的實力無關
但是會影響人類對模型的評價
舉例來說 模型
可能回答越長 人類就會越喜歡
所以今天β0裡面
應該把長度的差距
乘上一個常數γ1
當作β0
或者是 emoji的數量
可能會影響模型被喜好的程度
可能會影響模型的勝率
emoji講越多的
可能人類就越喜歡
所以呢 應該計算一下 兩個模型
在這一次評比 在這一次對戰中的
emoji的數量差
然後乘以γ2
總之你可以把所有你覺得
跟模型實力無關
但會影響評比結果的各種factor
通通都找出來
然後前面乘一個γ
代表這個factor的影響的程度
然後全部加起來 變成β0
然後呢 你就可以根據勝率
你就可以根據實際統計出來的勝率
去反推出β 也反推出γ
如果今天 統計出來γ是
正的
就計算出來γ是正的
就是代表說呢 今天長度的差距
是會有影響的
就如果i比j還要更長的話
如果i的答案比j的答案更長的話
那i的勝率就會比較高
那如果γ趨近於零
就代表說這個變量沒有什麼影響
那如果小於零 就代表說這個變量
是負相關的 長度越短越好 等等
好 如果上述講的你沒有聽得很懂的話
反正就是告訴你
有沒有考慮這些實力以外的因素
比如說跟書寫風格有關的因素
其實是有蠻決定性的影響的
好 所以 這個是來自於
那個Chatbot Arena官方blog的一篇文章
他就告訴你說 有沒有考慮
這些風格相關的因素
其實會影響模型的排名
左邊 是
直接根據對戰成績
去計算出模型的戰力
不考慮任何其他跟實力無關
因素的評比結果
右邊 是
把風格的影響
那他們這邊就列舉了一些
他們覺得可能會有影響的
這個變量
比如說 模型回答的長度啦
emoji使用的數目啊
比如說模型的回答有多正面啊 等等
或是模型呢 有沒有使用headline啊
等等 各式各樣的風格都考慮進去
他們發現考慮進去以後
根據模型的戰力 再來做排名以後
這個排名 是有大幅影響的
所以有些模型 你會發現
本來排名在比較前面
經過考慮過風格之後
它的排名就掉了
或有一些模型 它本來排名很後面
但考慮風格之後
它的排名就上升了
其中上升的最多的就是Claude啦
就是Claude Claude系列的模型
所以Claude系列的模型
一直是大家認知 覺得蠻厲害
但是在Chatbot Arena上
不知道為什麼評分起不來的模型
那一個可能就是 Claude的模型講話
太無聊了 你發現Claude的模型
很少輸出emoji
但它並不妨礙說
它是一個很聰明的模型
比如說 它很會寫程式
它很會做網頁等等
所以Claude 雖然是一個蠻聰明的模型
但是它就吃虧在它憨慢講話這樣啊
它不太會講話
所以 它不太會講讓人開心的話
只看人類覺得哪一個模型講話比較好聽的話
那Claude其實佔不到優勢
但是如果去掉書寫風格
所造成的影響的話
Claude其實它的名次
就會大幅向前
所以 這個故事告訴我們
就算是Chatbot Arena
也是有可能被hack的
也有可能會有人訓練了一個模型
就是針對Chatbot Arena的
就是要在這個比賽裡面打贏
比如說我的模型 特別喜歡輸出emoji
特別喜歡講好笑的話
特別喜歡講好聽的話
讓人類高興
然後可能就可以 你的模型
可能不用特別聰明 但可能就可以在
Chatbot Arena裡面佔到優勢
到底什麼樣的指標
才是好的評量指標呢
也許結論就是 沒有好的
評量指標
這個叫做Goodhart's Law
Goodhart's Law的意思就是
一旦一項指標啊 被當作目標
它就不再是一個好的指標
有一個講到這個Goodhart's Law的時候
常講的故事 就是眼鏡蛇現象
這個故事是這樣子的
過去在英國殖民印度時期
曾經一度蛇患猖獗
所以英國政府就想說
好 那請大家來捕蛇
每捕到一隻蛇 給你一塊錢
然後印度人呢 為了要賺錢
就在家裡養一大堆蛇這樣
反而蛇就變得更多了
對 這就是Goodhart's Law
那如果要為這堂課下一個結語的話
就是你這麼在意這個評分系統幹什麼呢？
它會把模型的努力給異化掉的
好 那這個課的結語
就是這句話