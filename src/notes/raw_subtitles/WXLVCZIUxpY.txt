The
 code
 is
 no
 longer
 being
 written
 by


human
 but
 by
 AI
 system.
 So
 much
 more


code
 is
 being
 written
 now
 by
 cursor
 or


Windsor
 for
 copilot.
 AI
 is
 going
 to


write
 so
 much
 more
 code.
 No
 one
 really


understands
 all
 of
 it.
 No
 one
 has
 full


context.
 No
 team
 has
 full
 context
 about


what's
 happening
 because
 it's
 such
 a


complex
 system.
 When
 software
 breaks,


it's
 going
 to
 be
 really
 difficult
 to


troubleshoot
 it.
 Right?
 One
 of
 the


biggest
 problems
 is
 downtime
 is


troubleshooting.
 Global
 IT
 cyber
 outage.


>> Global
 outage,
 major
 IT
 outage.


>> It's
 also
 affecting
 hospitals,
 law


enforcement
 departments,
 banks,
 and


major
 airlines.


>> The
 cost
 of
 downtime
 to
 annually
 for
 all


enterprises
 is
 around
 $400
 billion.
 So,


it's
 a
 huge
 problem.


>> It
 could
 be
 several
 hours
 or
 days
 before


the
 situation
 is
 fully
 resolved.


>> Fundamentally,
 what
 we're
 doing
 is
 when


we
 have
 large
 complex
 software
 systems,


we
 help
 figure
 out
 and
 they
 break,
 we


help
 figure
 out
 what
 happened.
 having
 a


team
 of
 on
 call
 engineers
 24/7
 looking


at
 all
 of
 your
 data.
 So
 by
 the
 time
 an


engineer
 comes
 onto
 a
 Slack
 channel,
 the


root
 cause
 or
 current
 root
 cause
 is


already
 given.
 So
 rather
 than
 them


spending
 so
 much
 time
 trying
 to
 figure


out
 what
 happened
 or
 you
 know
 calling


more
 and
 more
 teams
 because
 typically


what
 happens
 is
 you'll
 have
 one
 team


look
 at
 the
 the
 the
 data.
 They're
 like


oh
 it's
 not
 my
 fault.
 Then
 they'll
 call


another
 team
 and
 another
 team
 and


another
 team.
 That's
 how
 you
 go
 from


five
 people
 to
 like
 80
 people
 on
 a


channel,
 right?
 And
 so
 then
 rather
 than


50
 people
 over
 an
 hour,
 it's
 like
 5
 to


10
 people
 for
 a
 few
 minutes
 just


verifying
 the
 answer.


My
 name
 is
 Anish.
 I'm
 the
 CEO
 and


co-founder
 of
 Traversal.
 We
 came


ourselves
 with
 $48
 million
 in
 the
 series


A
 funding
 which
 were
 led
 by
 Sequoia
 and


Kleiner
 Perkins.
 We
 just
 announced
 our


series
 A
 raise
 and
 we
 came
 out
 of


stealth.
 We're
 building
 an
 AI
 site


reliability
 engineer.
 So
 what
 that
 means


is
 when
 you
 have
 large
 complex
 software


systems
 and
 they
 break,
 we
 troubleshoot


to
 help
 you
 figure
 out
 why
 it
 broke
 and


then
 help
 fix
 it
 automatically.
 But
 it's


sort
 of
 like
 perplexity
 when
 when
 you


ask
 perplexity
 a
 question,
 it
 kind
 of


gives
 you
 evidence,
 right?
 It
 gives
 you


citations
 of
 how
 it
 got
 to
 that
 answer.


But
 our
 world
 that
 the
 citations
 aren't


web
 links,
 the
 citations
 are
 links
 to


your
 observability
 system
 that
 we
 can


now
 publicly
 talk
 about.
 We've
 been


working
 with
 them
 for
 the
 last
 6
 months


now
 very
 closely
 is
 Digital
 Ocean.
 So


they're
 a
 large
 public
 cloud
 service


provider.
 I
 think
 they're
 the
 third


largest
 actually
 by
 number
 of
 people


using
 them
 as
 their
 cloud
 provider.
 I


think
 they
 have
 over
 600,000
 people
 um


using
 them
 as
 their
 core
 infrastructure.


And
 you
 can
 imagine
 when
 they
 break,
 you


know,
 every
 person
 that
 is
 using
 them


feels
 the
 pain
 because
 that's
 the
 main


thing
 powering
 their
 their
 system.
 We've


been
 working
 with
 them
 for
 6
 months
 now


and
 we
 found
 that
 in
 that
 6
 month
 period


we've
 dropped
 the
 the
 time
 to
 resolution


by
 over
 40%
 like
 37%
 to
 be
 exact,
 which


is
 incredible,
 right?
 Because
 as
 I
 said,


every
 minute
 of
 downtime
 is
 like
 is


worth
 thousands
 of
 millions
 of
 dollars.


I
 like
 sports.
 I
 like
 competing
 a
 lot


and
 I
 always
 naturally
 gravitated
 to


math
 and
 science.
 I
 just
 liked
 how


abstract
 and
 clean
 it
 was
 and
 it
 felt


quite
 universal
 in
 and
 what
 you
 could


do.
 I
 came
 to
 MIT
 just
 because
 I
 thought


machine
 learning
 and
 AI
 was
 really


important
 and
 I
 wanted
 to
 understand
 it


really
 deeply.
 This
 is
 like
 2016.
 about


like
 8
 n
 years
 ago
 and
 once
 I
 got
 there


I
 think
 the
 one
 of
 the
 biggest
 moments


in
 my
 like
 academic
 research
 career
 was


Europe's
 2017
 and
 the
 keynote
 was
 given


by
 the
 Google
 AlphaGo
 team
 and
 I
 just


found
 that
 incredible
 that
 a
 system
 can


learn
 this
 creative
 thing
 by
 itself


because
 the
 complaint
 you
 always
 had


before
 was
 that
 it's
 just
 copying
 people


but
 this
 was
 purely
 it
 was
 learning


creativity
 by
 by
 selfplay
 so
 I
 was
 like


we
 should
 apply
 that
 everywhere
 this


kind
 of
 architecture
 I
 was
 fortunate


enough
 to
 get
 into
 Colombia's
 faculty


and
 I
 like
 thinking
 about
 theoretical


problems
 mathematical
 abstractions
 And
 I


think
 university
 is
 an
 amazing
 place
 to


do
 that.
 The
 thing
 that
 changed
 and
 that


was
 the
 time
 when
 everything
 with
 Chad


GPT
 was
 was
 happening.
 And
 so
 it
 just


felt
 like
 something
 incredible
 has


happened
 in
 the
 world.
 And
 it's
 like
 a


once
 in
 a-lifetime
 thing
 where
 the
 world


is
 fundamentally
 changed.
 People
 don't


even
 realize
 it.
 It
 just
 felt
 like
 this


almost
 religious
 experience
 as
 to
 what


was
 happening
 in
 the
 world.
 I
 really


like
 uncertainty.
 I
 like
 creating


something
 from
 0
 to
 one.
 similar
 between


research
 and
 entrepreneurship
 is
 that


the
 uncertainty
 you
 have
 no
 idea
 what's


happening
 most
 of
 the
 time
 and
 you
 have


to
 find
 ways
 of
 of
 creating
 structure


from
 nothing
 I
 think
 obviously
 the


difference
 is
 in
 here
 the
 time
 spans
 are


compressed
 right
 in
 research
 you
 get
 5


years
 10
 years
 to
 to
 make
 an
 impact
 here


you
 get
 1
 month
 right
 so
 the
 feedback


cycle
 is
 very
 quick
 but
 I
 think
 in
 this


age
 of
 AI
 when
 AI
 is
 shooting
 so
 quickly


being
 in
 that
 quick
 feedback
 cycle
 is


actually
 very
 important
 we've
 kind
 of


entered
 into
 the
 industrial
 age
 of


artificial
 intelligence
 you
 And
 I
 also


saw
 some
 of
 the
 smartest
 people
 around


me.
 They
 were
 either
 at
 OpenAI
 or


Enthropic
 or
 you
 know
 Meta
 or
 they
 were


creating
 companies
 and
 that's
 what
 makes


me
 really
 excited.
 And
 so
 I
 think


starting
 a
 company
 was
 felt
 to
 me
 like
 a


great
 expression
 of
 that.
 I
 guess


I
 think
 the
 best
 AI
 companies
 are
 always


going
 to
 be
 at
 the
 edge
 of
 where
 the


models
 are
 going
 to
 be,
 right?
 That's


how
 you
 differentiate
 yourself
 is
 you're


always
 at
 the
 edge.
 If
 you're
 the
 edge


and
 sometimes
 it
 works,
 sometimes
 it


doesn't
 work.
 And
 you
 need
 to
 know


quickly
 when
 it's
 working
 and
 when
 it's


not
 working
 and
 correct
 for
 that.
 When


we
 started
 the
 company
 in
 like
 January


of
 2024,
 we
 started
 without
 an
 idea.
 But


we
 had
 a
 clear
 taste
 of
 the
 type
 of


problem
 we
 wanted
 to
 take
 on.
 So
 we


wanted
 to
 do
 something
 that
 was
 at
 the


intersection
 of
 our
 research
 which
 was


in
 causal
 machine
 learning
 and


reinforcement
 learning
 and
 how
 it


intersected
 with
 AI
 agents.
 Causal


machine
 learning
 is
 a
 study
 of
 cause
 and


effect.
 And
 what
 you
 want
 to
 understand


is
 how
 do
 you
 get
 these
 AI
 systems
 to


pick
 up
 cause
 and
 effect
 relationships


from
 data.
 AB
 test
 is
 an
 example
 of
 of


learning
 cause
 and
 effect
 relationships.


like
 clinical
 trial
 is
 another
 example.


So
 these
 are
 like
 basic
 ways
 of
 of


running
 experiment.
 And
 so
 that's
 what


the
 study
 of
 of
 causal
 machine
 learning


is
 and
 we're
 trying
 to
 see
 how
 did
 that


intersect
 with
 AI
 agents
 uh
 which
 we


thought
 was
 like
 super
 cool
 and


something
 we
 followed
 for
 like
 now


almost
 2
 and
 a
 half
 years.
 We
 went


through
 a
 few
 different
 ideas.
 The


fourth
 person
 who
 joined
 us
 our
 fourth


co-founder
 Ahmed
 and
 so
 he
 pitched
 us


the
 problem
 of
 dealing
 with
 incidents.


And
 as
 we
 looked
 into
 it,
 it
 kind
 of


felt
 like
 a
 perfect
 problem
 finding
 this


needle
 in
 a
 hay
 stack
 with
 many
 fake


needles
 everywhere.
 So
 it
 fit
 with
 our


research
 in
 causal
 machine
 learning
 and


reinforcement
 learning
 really
 well.
 It


fit
 with
 LLMs
 really
 well
 because
 the


haststack
 is
 composed
 of
 like
 logs
 and


metrics
 and
 traces
 and
 code
 and


configuration
 files
 and
 so
 on
 and
 so


forth.
 It
 fits
 with
 AI
 agents
 really


well
 because
 you
 have
 to
 automate
 this


complex
 workflow
 where
 you're,
 you
 know,


querying
 all
 these
 different
 pieces
 of


software.
 You're
 reasoning
 over
 them
 and


then
 you're
 writing
 more
 queries
 and


it's
 like
 this
 like
 sequential
 adaptive


flow.
 And
 so
 it's
 a
 big
 market
 because


everyone
 cares
 about
 software
 not
 going


down.
 And
 I
 think
 it's
 only
 going
 to
 get


bigger,
 right?
 because
 so
 much
 more
 code


is
 being
 written
 now
 by
 companies
 like


cursor
 or
 windsurf
 or
 copilot
 or
 what


have
 you
 just
 like
 cambrian
 explosion
 of


code
 being
 written
 no
 one
 understands
 it


in
 some
 ways
 and
 so
 when
 software
 breaks


it's
 it's
 going
 to
 be
 really
 difficult


to
 troubleshoot
 it
 right
 and
 so
 I
 think


that's
 what
 gave
 us
 confidence
 that
 this


is
 the
 problem
 we
 should
 be
 taking
 on


and
 then
 honestly
 the
 first
 VC
 I
 met
 in


my
 life
 was
 Sequoa
 and
 I
 think
 they've


been
 looking
 for
 a
 team
 to
 solve
 this


problem
 they
 reached
 the
 same
 thesis


they
 felt
 this
 is
 the
 problem
 where
 like


the
 AI
 risk
 and
 technical
 risk
 is
 high


and
 the
 market
 risk
 is
 low
 because
 if


you
 can
 solve
 it,
 there's
 a
 big
 market


and
 so
 people
 like
 us
 who
 don't
 come


from
 this
 world
 but
 are
 good
 on
 the
 AI


side
 are
 the
 right
 people
 to
 solve
 it.


And
 so
 obviously
 that
 validation
 also


give
 us
 confidence
 that
 this
 is
 the


right
 problem.


A
 lot
 of
 what
 these
 AI
 agent
 companies


are
 doing
 is
 trying
 to
 replicate
 what


humans
 have
 done,
 but
 there's
 so
 much


more
 that
 can
 be
 done.
 And
 so
 thinking


from
 first
 principles
 what
 AI
 systems


are
 good
 at
 and
 exploiting
 that
 versus


just
 trying
 to
 replicate
 what
 a
 human


has
 done
 I
 think
 is
 also
 going
 to
 be


very
 important
 to
 reinvent
 and
 actually


get
 to
 the
 next
 level
 of
 innovation.


Creating
 a
 MVP
 is
 so
 easy
 with
 all
 the


tools
 out
 there.
 You
 can
 really
 iterate


quickly
 with
 putting
 a
 product
 in


people's
 hands.
 We
 built
 our
 first
 MVP


probably
 last
 year
 in
 June
 or
 July
 like


about
 3
 months
 in.
 And
 with
 small


companies
 it
 worked
 great
 because
 the


scale
 of
 the
 data
 was
 small.
 we
 could


kind
 of
 look
 at
 their
 historical


incidents,
 see
 what
 the
 playbook
 was
 and


then
 put
 that
 into
 an
 AI
 agent.
 And
 so


like
 our
 accuracy
 was
 like
 90%.


Something
 amazing,
 right?
 So
 we
 felt


really
 confident
 that
 this
 is
 going
 to


work.
 Just
 because
 it
 works
 in
 the
 one


time
 doesn't
 mean
 it's
 always
 going
 to


work
 because
 the
 world
 is
 constantly


changing.
 And
 then
 we
 hit
 some
 of
 the


larger
 enterprises
 including
 Digital


Ocean,
 our
 accuracy
 went
 to
 0%.
 Which
 is


very
 difficult
 to
 see.
 It
 was
 a
 tough


week.
 Creating
 an
 MVP
 is
 easy,
 but


creating
 a
 production
 system
 that
 works


in
 complex
 environments
 is
 really
 hard.


And
 so
 I
 think
 one
 should
 not
 confuse
 an


MDP
 with
 a
 production
 AI
 system.
 Those


are
 like
 two
 very
 very very
 different


things.
 But
 then
 we
 rearchitected
 a
 lot


of
 things.
 We
 said
 how
 do
 we
 make
 sure


that
 we're
 no
 longer
 trying
 to
 use
 our


creativity
 and
 seeing
 you
 know
 get
 that


into
 an
 agent
 but
 really
 use
 what
 these


AI
 systems
 are
 good
 at
 which
 is
 using


computation
 right
 using
 inference.


That's
 really
 what
 unlocked
 us
 and


suddenly
 our
 accuracy
 went
 back
 to
 up
 to


90%.
 How
 do
 you
 make
 sure
 that
 your


system
 gets
 better
 with
 the
 reasoning


models?
 because
 there
 are
 a
 lot
 of


people
 we
 saw
 in
 competing
 companies
 and


so
 on
 and
 so
 forth
 where
 as
 the
 reason


models
 came
 out
 they
 didn't
 get
 any


better.
 So
 how
 do
 you
 make
 sure
 that


you're
 exploiting
 what
 the
 reasoning


models
 are
 good
 at?
 And
 the
 way
 I
 put
 it


is
 that
 the
 reasoning
 models
 are
 very


good
 at
 like
 detective
 stories.
 You
 have


a
 mystery
 novel
 and
 you're
 trying
 to


figure
 out
 who
 who
 did
 the
 crime.


There's
 all
 these
 different
 pieces
 of


evidence
 that
 you're
 seeing
 and
 you're


trying
 to
 figure
 out
 who
 is
 the
 person


who
 did
 it.
 Connecting
 all
 those
 dots


and
 figuring
 out
 the
 thing,
 you
 know,


the
 person
 who
 did
 it.
 that
 kind
 of


detective
 story
 type
 workflow
 which
 I


think
 these
 reasoning
 models
 are
 very


good
 at
 where
 you
 have a
 clear
 answer
 at


the
 end
 and
 you
 have
 lots
 of
 moving


pieces
 that
 you
 have
 to
 like
 connect
 the


dots
 between
 to
 get
 to
 the
 clear
 answer


that
 felt
 kind
 of
 perfect
 for
 us
 right


because
 for
 us
 you
 have
 all
 these


different
 symptoms
 that
 happen
 at
 the


same
 time
 you
 find
 ways
 to
 connect
 the


dots
 to
 find
 that
 specific
 right
 answer


like
 who
 did
 it
 making
 sure
 we
 were


exploiting
 them
 to
 the
 maximum
 was
 was


crucial
 I
 think
 and
 so
 I
 think
 that's


the
 way
 I
 would
 put
 it


is
 going
 to
 write
 so
 much
 more
 code
 and


no
 one
 really
 understands
 all
 of
 it,


right?
 If
 you
 wrote
 all
 of
 it,
 you
 have


in
 your
 head
 just
 how
 it
 all
 fits.
 And


as
 you
 get
 to
 bigger
 and
 bigger
 systems


already,
 right,
 you
 work
 with
 some
 of


the
 largest
 fortune
 100
 companies,
 no


one
 is
 full
 context.
 No
 team
 is
 full


context
 about
 what's
 happening
 because


it's
 such
 a
 complex
 system.
 And
 that's


just
 happening
 not
 just
 at
 the
 large


companies,
 but
 also
 at
 the
 small


companies
 because
 this
 the
 code
 is
 no


longer
 being
 written
 by
 human
 but
 by
 or


engineer
 but
 by
 AI
 system,
 right?
 So
 the


lack
 of
 context
 means
 that
 when
 it's


when
 an
 incident
 happens,
 it's
 just
 so


much
 harder
 to
 debug
 it
 because
 you
 just


don't
 have
 all
 of
 the
 context
 you
 need.


And
 actually
 it's
 already
 happening
 like


most
 people
 now
 are
 not
 developing
 code.


They're
 starting
 to
 like
 validate
 QA


code
 or
 troubleshoot
 code
 and
 that


doesn't
 scale.
 So
 that's
 the
 big


problem.
 And
 I
 think
 the
 second
 big


problem
 I
 think
 is
 that
 you
 know
 with


all
 all
 the
 developments
 happening
 with


AI
 software
 engineering,
 our
 belief
 is


that
 as
 engineers
 we
 get
 to
 do
 the


really
 creative
 fun
 work
 architecting


system
 design.
 Over
 time,
 all
 engineers


will
 be
 doing
 will
 be
 troubleshooting,


which
 would
 be
 sad
 in
 my
 opinion.
 Like


they
 should
 be
 doing
 the
 most
 we
 as
 a
 as


engineers
 should
 be
 doing
 the
 most


creative
 work,
 right?
 And
 to
 to
 make


that
 a
 reality,
 you
 you
 need
 to
 have


systems,
 not
 just
 developing
 your


software
 and
 building
 it,
 but
 also


maintaining
 it.
 And
 so
 I
 think
 all
 of


software
 maintenance
 needs
 to
 be


reinvented.
 You
 have
 to
 just
 kind
 of


persevere.
 If
 something
 goes
 wrong,


that's
 okay.
 I
 think
 it
 in
 some
 ways


it's
 a
 good
 thing
 because
 if
 it
 was


easy,
 then
 everyone
 could
 do
 it,
 right?


I
 think
 this
 is
 one
 of
 those
 problems


where
 the
 problem
 statement
 is
 very
 easy


to
 state,
 but
 to
 actually
 solve
 it
 is


really
 hard.
 And
 I
 think
 that's
 where


there's
 like
 a
 lot
 of
 companies
 trying


it,
 but
 very
 few
 actually
 succeeding.


And
 I
 think
 having
 the
 ability
 to
 like


stay
 resilient
 and
 have
 grit
 when


something
 doesn't
 work
 and
 just
 stick


with
 the
 problem
 is,
 I
 think,
 a
 big
 part


of
 what
 differentiates
 us
 uh
 as
 a


company.
 Think
 about
 what's
 going
 to
 be


important
 10
 years
 from
 now
 regardless


of
 whatever
 happened
 in
 the
 world.
 You


have
 no
 idea
 what's
 happening
 most
 of


the
 time.
 And
 you
 have
 to
 find
 ways
 of


of
 creating
 structure
 from
 nothing.
 And


so
 like
 one
 way
 I
 say
 it
 is
 that
 you


know
 in
 typically
 hard
 jobs
 whether
 it's


in
 finance
 or
 it's
 in
 technology
 as
 an


engineer
 like
 you
 have
 a
 point
 A
 if
 you


get
 a
 point
 B
 and
 it's
 very
 hard
 to
 get


from
 point
 A
 to
 point
 B
 in
 the
 world
 of


research
 and
 also
 in
 the
 world
 of


entrepreneurship
 you
 don't
 really
 know


where
 point
 A
 is
 you
 don't
 know
 where


you
 are
 you
 don't
 know
 where
 point
 B
 is


you
 don't
 know where
 you
 want
 to
 go
 and


if
 you
 did
 know
 it's
 still
 very
 hard
 and


so
 you're
 constantly
 like
 in
 this
 game


of
 trying
 to
 just
 decide
 where
 you
 are


and
 where
 you're
 trying
 to
 go
 and
 that's


exactly
 the
 same
 thing
 in
 research
 as


well.
 What's
 interesting
 in
 this
 job
 is


that
 the
 the
 stresses
 are
 are
 can
 be


very
 high,
 lows
 can
 be
 very
 low.
 So,
 I


think
 getting
 used
 to
 like
 just
 very


high
 highs
 and
 low
 lows
 is
 important.


But
 I
 think
 that
 one
 thing
 I've
 learned


is
 that
 time
 it
 takes
 me
 to
 to
 recover


is
 very
 fast.
 Even
 if
 I'm
 super


stressed,
 I'm
 super
 tired,
 within
 one
 or


two
 days,
 if
 I
 just
 take
 it
 off,
 I'm


back
 to
 full
 force.
 And
 so
 I
 think


that's
 been
 like
 a
 good
 learning
 is
 that


if
 you're
 really
 enjoying
 what
 you're


doing
 and
 even
 though
 there's
 these


moments
 of
 massive
 stress,
 levels
 of


stress
 that
 you'll
 never
 face
 otherwise,


if
 you
 really
 love
 a
 problem
 and
 you're


you're
 attracted
 by
 it,
 that's
 where


attracts
 other
 people,
 right?
 We
 all


love
 the
 problem.
 We're
 all
 faced
 in
 our


lives.
 And
 so
 we
 really
 feel
 like
 a


great
 deep
 desire
 to
 solve
 it.
 And


probably
 the
 most
 important
 thing
 out
 of


anything
 is
 surround
 yourself
 with


people
 that
 you
 care
 that
 you
 like
 that


you
 want
 to
 be
 like.
 And
 if
 you
 do
 that,


life
 will
 be
 okay.
 I
 think
 about
 my


research
 life.
 I
 found
 the
 right
 PhD


adviser
 advisers
 that
 really
 molded
 me


and
 guided
 me
 the
 right
 way.
 If
 I
 think


about
 this
 world,
 I
 found
 the
 right


investors
 that
 guided
 me
 at
 the
 start,


the
 right
 customers
 that
 you
 know
 that


helped
 define
 the
 product.
 You
 live
 and


die
 by
 the
 people
 you
 you
 surround


yourselves
 with
 and
 the
 people
 will
 kind


of
 guide
 you
 through
 these
 different


parts.
 And
 so
 I
 think
 building
 a
 taste


for
 the
 right
 people
 to
 mentor
 you
 and


and
 be
 a
 partner
 with
 you
 is
 the
 most


important
 thing.
 The
 rest
 of
 it,
 I


think,
 will
 figure
 itself
 out
 if
 you
 can


find
 the
 right
 people
 around
 you.
 But
 I


wouldn't
 just
 start
 a
 company
 for
 the


sake
 of
 it.
 I
 think
 you
 should
 you


should
 feel
 like
 some
 thing
 deep
 in
 you


cuz
 it's
 not
 easy.
 And
 so
 you
 need
 that


kind
 of
 deep
 belief
 or
 you
 know
 or


motivation
 to
 sustain
 you
 over
 time.