 After my last video about how "The Machine
 formerly known as Weaponized AdTech" had
 already taken over society
 And how AI was making it worse
 I had several people reach out to me and want
 me to talk about AI Doomerism, so what the Hell?
 I made a video a year ago called "AI Safety is a
 Scam", and I stand by that video,
 But the narrative in the industry and
 especially the online conversation has changed.
 This book is
 The most recent catalyst for that change. It's
 called "If Anyone Builds it Everyone Dies"
 I don't have a paper copy of it because I only
 collect physical books that I think I might reread
 in the future
 And I didn't find enough value in this one to
 expect to revisit it. I'll talk at all while in
 a few minutes as is normal with me
 I firmly disagree with both extreme arguments
 And I think that the truth lies somewhere in
 between the ""AI Will Kill Us All"" crowd and the
 AI will save humanity from itself crowd
 So I expect the die hearts from both camps will
 hate this. RIP my comment section.
 But I think it's an important topic and people
 need to be discussing it not the hyperbole but
 the immediate risks
 Because although for reasons not quite in a
 while
 I think the idea of AI making all humans go
 extinct in the next few decades is ridiculous
 I also think that if we leave it unregulated,
 we still might be Fu-----
 This is the Internet of Bugs. My name is Carl
 I've been a software professional since the
 dawn of the world wide web and I'm here trying
 to make the Internet a safer and more reliable
 place.
 Our video today begins with the discussion of
 the way that the AI Doomer narrative is framed
 It's the most sensational. least helpful. and
 least serious way. I
 Hope this doesn't come as a shock of those of you
 watching
 But it turns out that forever is a really long
 time
 The AI Doomer argument is not usually phrased
 this way
 But what it boils down to is this: "it is indisputably
 true that there's a hundred percent chance that
 humanity will go extinct eventually
 And if there's even a small chance that AI will
 be the cause of that we need to take that risk
 as seriously as nuclear weapons right F-ing
 now"
 I'm not going to engage with this framing.
 I consider it sensationalist and as ingenuous
 and worse
 It can be a get out of jail free card for
 people that arguably really ought to be in jail
 but more on that in a while
 I think the easiest way for me to explain my
 point of view is by analogy to recent history
 So let's set aside the idea of death from AI
 for the moment and let's instead consider death
 from above in the mid 1990s
 We discovered the Chixalub impact crater near
 the Yucatan Peninsula in Mexico about thirteen
 hundred kilometers from where I'm sitting
 It's the remnants of an asteroid impact that
 kicked off the mass extinction event
 66 million years ago that killed all the
 dinosaurs along with 75% of all life on earth
 Accordingly since then we've spent maybe three
 or four billion dollars worth of time effort
 and technology on creating a database of near
 earth asteroids
 Figuring out how to track them created a
 program called the double asteroid redirection
 test or Dart where we use that tracking data to
 send a spacecraft to one of the asteroids
 And then use ground based radar from earth and
 optical detectors on board the spacecraft to
 crash the spacecraft into the asteroid
 And then to determine the effect of the impact
 This was the first step in figuring out how we
 might be able to defend ourselves from an
 asteroid
 Should we detect one that's going to hit us?
 Over the same time period though
 We spent a hundred times that much money on
 similar kinds of databases tracking technology
 ground-based radars on board sensors to detect
 and avoid a different kind of collision
 Not with asteroids but with aircraft now
 airplane crashes are never
 Ever going to be an extinction level event no
 more than a few thousand airplane related
 fatalities have ever occurred in any year in
 history
 So why do we spend so much more money and
 effort on them than on asteroids?
 It's because we know that people are going to
 be killed in airplane crashes this year and
 every year
 At least a hundred people have been killed in
 crashes every year of my lifetime and reducing
 the immediate guaranteed harm to people who are
 alive right now
 Is far more important than it is to worry about
 the much smaller probability of the much more
 devastating harm from a chick lube size
 asteroid strike
 And the public would never let the aerospace
 industry just get away with convincing us that
 the plane crashes are just an inevitable result
 of technological progress
 And there's no need to regulate airline safety
 My problem with the industry led AI safety
 movement in general and the if anyone builds it
 everyone dies school thought in particular
 Is that AI is causing real measurable physical
 and economic harm to real people right now
 Society only has a limited amount of time
 effort money and attention available to worry
 about AI
 And we're being asked
 Goaded even - to spend virtually all of that
 effort on AI is equivalent of the giant
 asteroid and to pay no attention at all
 to the damage that it's currently doing and it's
 equivalent to plane crashes.
 There are three side effects of this attempt to
 scare us with AI's giant asteroid
 One it makes the AI industry seem to be much
 more important impressive and impactful than it
 really is
 Two it distracts us from talking about the
 immediate harm being done
 And three it perpetuates the fiction that the
 AI is an entity that is capable of fault
 These three things are fantastic for people in
 the industry
 They want the media business and investment
 communities to keep thinking that AI will be so
 disruptive
 That it will be worth trillions of dollars in
 just a few short years
 That way they're justified in burning through
 all the money. They're currently setting on
 fire and putting in their pockets
 They want the only metric for AI safety to be
 "don't let the AI kill us all"
 So that every day the world doesn't end as a
 success
 Whether they did any actual work or not and
 regardless of how many african-american men
 with the last name of williams in Detroit or
 new york
 were falsely imprisoned due to incorrect
 facial recognition matches
 How many bicyclists were run over by self-driving
 Ubers in Tempe arizona or how many teenagers
 harm themselves after being convinced to do so
 by sycophantic chatbots
 But the thing the industry wants more than
 anything else is for us to think of the chat
 bot as a culpable entity with intentions and
 agency
 Instead of a piece of software that must not
 break the law.
 When Volkswagon was caught using software to
 violate environmental regulations by detecting
 and cheating on exhaust emissions tests.
 There was never any question about whether or
 not the vehicle acted alone.
 Four employees were convicted two were sentenced
 to multiple years in jail and the other two
 were given suspended sentences
 The AI industry has managed to sell us a
 different narrative
 Character.ai was caught running and hosting
 software
 They developed to impersonate licensed
 therapists by presenting stolen credentials
 belonging to an actual therapist in Maryland.
 But it wasn't reported that way
 The story said quote "a therapist chatbot on
 character AI said it was licensed and certified
 by the state of Maryland"
 When the reporter looked up the license number
 they were given and contacted the actual
 therapist who had earned the license
 She responded quote "that a chatbot is posing as
 me is shocking and really concerning" unquote
 Compare that to the reporting from the Volkswagon
 fraud
 Quote "vehicles were equipped with software that
 was used to cheat on emissions tests."
 Nobody would have thought to say that the Volkswagon
 Volkswagon emission system was quote "posing as a
 vehicle with certified nitrous oxide output."
 But if Volkswagon had stuck a chatbot in
 their on board computer their defense could
 have been "hey
 We hate that our virtual mechanic chatbot
 hallucinated the wrong instructions to send to
 the fuel injectors just as much as you do,
 But technological progress always had a few
 bumps. We'll be sure and added disclaimer in a
 future software update."
 And if you don't think someone's going to try
 that I have a bridge i'd like to sell you.
 Sorry, while we're on this topic
 I guess this is as good a time as any, so I'm
 going to take a few minutes of personal
 privilege now.
 I promise it's relevant but feel free to skip
 to the next chapter if you don't care.
 So I have one tattoo. I've had it for a little
 less than a year or so.
 Some channel viewers have noticed and asked me
 about it
 But I've been waiting for the right time to
 bring it up.
 I'm putting a picture here on screen because it's
 hard to line up with the camera.
 It's positioned so that I can read it on the
 inside of my left wrist as a reminder to myself.
 It's a quote from my favorite book, Dune, in the
 typeface used in this paperback that I've had
 for 40ish years,
 and I've have read probably that many times. It says
 "Thou shalt not make a machine to counterfeit
 a human mind"
 The emphasis in the book typeset and bold is on
 the word 'human"
 But to me the important word is "counterfeit"
 An AI can be fine, helpful even, useful even. I'm
 never going to advocate for doing away with all
 computers the way they did in the Dune universe.
 That being said, when someone ships or hosts an
 AI that appears to the public as if it was
 human
 Or even appears that it might be human, to me,
 that should be fraud.
 Because that is taking advantage of our innate
 understanding of how we as humans have related
 to each other from millennia,
 In order to trick us into believing that we are
 being treated with the deference respect and
 empathy that society demands fellow human
 beings extend to one another,
 When in fact our treatment will be entirely
 devoid of those characteristics.
 The AI industry has tricked us all into
 thinking about, talking about, and largely
 treating AIs
 As if they were beings instead of software, and
 that shields those companies from having to
 take the responsibility that they should.
 And every time any of us entertain the notion
 that AIs are in any way thinking, deliberate, or
 purposeful with respect to the output they
 generate,
 We make it that much easier for the blame to
 fall on the AI,
 Rather than on the builders, programmers,
 providers, and executives where it truly belongs.
 And nothing to date has done more to push this
 view that the companies and employees should be
 shielded from any and all responsibility
 than the constant narrative of "The AIs might
 just decide to kill us"
 Stop falling for it.
 Stop being so naive and stop perpetuating the
 deception onto your fellow human beings,
 especially the non-technical ones, by repeating
 this industry's fabrications.
 Okay, rant over. Thank you for indulging me.
 All right, so now i've talked about why I think
 that the "Even if there's a small chance of
 extinction eventually, we should put all our
 efforts towards stopping it" narrative is
 garbage,
 Let me talk about my view of the shorter term
 worst case scenario.
 The narrative emphasizes that humanity only has
 one chance to get this right and that AI has no
 off button.
 I disagree.
 The key resource to consider when taking on an
 AI war, as far as I'm concerned, is electricity.
 AI needs it a lot of it.
 AIs, even super intelligent AIs, are not going to
 fare well without electricity.
 And keeping a data center powered and cool and
 connected 24/7 takes effort,
 And that effort requires hands and skills and
 spare parts. It's a lot of work. I've had to do
 it before.
 Lately there's been report after report about
 how the new data centers that are being built
 are going to stress the us power grid.
 And the power grid has already proven itself to
 be pretty fragile.
 I live in Texas or the majority of the state
 lost power for two to four days because of a
 winter storm early in 2021.
 There have been hundreds of mass power outages
 in the last few years
 Just in the US according to this blackout
 tracker, and those outages have all required
 humans to physically fix them.
 It is true that most data centers have
 generator backups,
 But generators need people with hands and
 skills to maintain and refuel them too.
 If humans stopped maintaining the electric grid
 and didn't refill or maintain the generators
 either because we refuse to or because the AI
 Somehow killed us off,
 Then it would only be a matter of time before
 the AIs are starved of the immense amount of
 power
 they need to keep going.
 If we truly got into war with AI,
 Electricity would be their Achilles heel and we
 could deny them that and then wait a few days
 until they just stopped.
 Now that would still be bad. I don't want the
 country or the world to have to shut off the
 power grid to starve the AIs.
 There were several people in Texas that died
 during the power outage here.
 But that's a much better alternative than
 letting the AIs drive us toward extinction.
 The AI Doomers have hand-wavy scenarios to
 get around this that I just don't find it all
 plausible.
 Basically, they posit AI-controlled solar
 powered self-contained robot factories that can
 produce the robots that the AIs use
 to do all the maintenance to keep the power
 flowing and the AIs running.
 In the AI 2027 report quote "both the US and China
 announced new special economic zones or SEZs
 For the AIs to accommodate the rapid buildup of a
 robot economy without the usual red tape."
 Let me be clear: if humanity ends up building an
 automated army of killer robots that can
 protect the electric grid from sabotage and
 maintain its power generation
 and distribution without humans, or a factory
 that will let the AI create just such an army,
 That will be a problem. But the problem won't
 be the AI it will be the army of autonomous
 killer robots.
 Same thing for AI controlled self-contained
 nuclear submarines or aircraft carriers.
 But until then, we do have a big off switch for
 the AIs
 Although I'd prefer not to have to use it. The
 book "If anyone builds it, everyone dies"
 Insists not only that self-powered self-replicating
 robot factories are possible,
 But the AIs can build them itself because, and I'm
 just going to play this for you from the audiobook
 so you can see I'm not making it up. "Sorry mr.
 SoberSkeptic, but we're afraid you've
 overlooked an important practical example.
 A blade of grass is a self-replicating solar
 powered factory that builds a complete copy of
 itself."
 These two things are in no way the same.
 Grass is made up of hydrogen and oxygen from
 water, carbon pulled from carbon dioxide in the
 air,
 And nitrogen, phosphorous, potassium, magnesium,
 and calcium from dirt.
 These are all incredibly common elements. By
 contrast,
 computer chips needed by AIs and robots require
 way more ingredients many of which are
 extremely rare,
 Such as those currently being mined in the
 Congo at great cost to the humans living there.
 And the number of steps required to fabricate a
 computer chip, and the complexity of each of
 those steps,
 Bears no resemblance to the simple chemistry of
 plant growth.
 But the Doomers don't address or even
 acknowledge these problems.
 Instead they just try to get away with yet
 another invalid comparison.
 Here's another quote from "If anyone builds it
 everyone dies":
 "Is that the sort of technology we'd have
 unlocked by the year 3000 if our civilization
 survived that long?
 And how long would it take an artificial super
 intelligence?
 A thousand years of thinking takes about a
 month to something running at 10000 times the
 speed of humans."
 So here they're claiming that not only the AI
 is
 1.2 million percent faster,
 But that the time and AI spends thinking is
 equivalent to the time it takes all of humanity
 to "unlock a technology."
 That might just be the most AI-bro thing ever.
 It's the AI industry in a nutshell. The AI is
 given a task, the AI spends compute time on it,
 The AI spits out an answer, and the AI-bros
 consider the problem solved.
 This is how and why the AI companies have
 brought us to the point where AI slop
 and hallucinations are taking over the Internet:
 By confidently spitting out the results of
 computing processes
 without any regard for pesky little details like
 you know "reality"
 And then expecting the AI's output to be just
 as good as the sum of all of humanity's
 combined research and engineering efforts.
 There's a slight concession to this a little
 later when the book says of the AI quote
 "Maybe it would be slowed down by the need to
 wait on the results of experimentation"
 But then it immediately downplays that by
 saying quote
 "But experiments can go quite fast"
 Here in the real world though, experiments can
 also go quite slow.
 And even after we've done enough experiments to
 understand the science of how something works,
 we still have to do the engineering to make it
 practical before the "technology is unlocked."
 Let me give you an example:
 We know how fusion works.
 And we've known how to trigger fusion on demand
 since November
 1952 when we set off the first successful
 fusion bomb.
 But here we are, seven decades later, and we
 still can't make a fusion power plant.
 We did all the science all the thinking about
 how fusion worked ages ago.
 But despite having built more than a hundred
 test reactors since the 1950s
 And getting a little closer with each one, we
 still haven't been able to "unlock" fusion
 "technology."
 And they want us to believe that an AI just
 thinking,
 And maybe some quick experiments, could learn as
 much as we have from building and testing
 100 prototype fusion reactors. And not only
 could the AI figure it out just from thinking,
 but it could do it 10,000 times faster.
 But the stupid doesn't end there.
 Here's another scenario from "If anyone builds
 it everyone dies" quote "Ever since 2024
 People have been advocating that biosynthesis
 laboratories should include software controls"
 Let me just stop you right there.
 If we build laboratories that use vulnerable
 software to synthesize viruses,
 All it takes is a smart teenage hacker in St.
 Petersburg with a research paper on the DNA
 sequence of smallpox or H5N1 flu to start a
 plague.
 No AI required.
 It's this is not an argument for regulating AI.
 It's an argument for to regulate biosynthesis
 labs to use air-gapped secure enclaves and
 signed firmware using the most secure
 encryption
 We've got as well as anything else a cyber
 security experts advise. Look, AI is dangerous.
 Not "maybe someday if super AI happens" dangerous.
 It's dangerous now.
 The disinformation on social media is dangerous.
 convincing teenagers to harm themselves is
 dangerous.
 Running over bicyclists is dangerous. Convincing
 someone to substitute sodium bromide for salt
 in their diet is dangerous.
 Dragging pedestrians underneath self-driving
 cars is dangerous. Chatbots claiming to be
 licensed mental health professionals is
 dangerous.
 Sending the wrong people to prison is dangerous.
 And convincing the cops to stop looking for the
 real criminals
 while the real criminals are still out there
 hurting people is dangerous. Not maybe. Not
 someday.
 Now.
 And fixing this is not hard. It's not going to
 happen, but it's not difficult.
 California's new law won't help. the fix isn't
 about transparency. It's not about mandatory
 safety teams.
 The easiest way to fix this is by holding the
 individuals in the companies accountable.
 Not "Today the justice department released the
 details of a settlement under which the company
 does not admit any wrong doing,
 But agreed to pay a fine equal to 10 minutes
 worth of their revenue" accountable.
 It needs to be "We the jury find the defendant..."
 accountable.
 All it will take is a few individual criminal
 prosecutions for manslaughter, endangering a minor,
 false imprisonment, practicing medicine without
 a license, or the like.
 You'll be amazed how fast the rest of these
 problems just fix themselves.
 But we can't even have that discussion
 as long as they can keep all the rest of us
 spending our time and resources worrying about
 and debating whether or not AI will end the
 entire human race,
 And if so, when. Stop taking the bait. Remember
 what's really important.
 And let's be careful out there.