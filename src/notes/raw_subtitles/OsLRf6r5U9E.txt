The
 good
 news
 is
 infrastructure
 is
 sexy


again.
 So
 that's
 kind
 of
 cool.
 This
 is


like
 the
 combination
 of
 the
 buildout
 of


the
 internet,
 the
 space
 race,
 and
 the


Manhattan
 project
 all
 put
 into
 one
 where


there's
 a
 geopolitical
 implication
 of


it.
 There's
 an
 economic
 implication,


there's
 a
 national
 security
 implication,


and
 then
 there's
 just
 a
 speed


implication
 that's
 pretty
 profound.


>> I
 mean,
 I
 think
 it's
 easy
 to
 say.
 I've


seen
 nothing
 like
 this.
 I'm
 fairly


certain
 no
 one's
 seen
 anything
 like


this.
 The
 internet
 in
 the
 late
 90s,


early
 2000s
 was
 big
 and
 we
 felt
 like,
 oh


my
 gosh,
 can't
 believe
 the
 uh
 buildout,


the
 rate.
 This
 makes
 it
 I
 mean
 10x
 is
 an


understatement.
 It's
 100x
 what
 the


internet
 was.


[Music]


>> Hello.
 Hello.


All right.


What
 better
 time
 and
 place
 to
 talk


infrastructure?
 All right.


So,
 we
 were
 back
 in
 the
 green
 room
 and


just
 as


um
 the
 first
 question
 was
 getting


answered,
 I
 got
 cut
 off.
 So,
 this
 could


be
 an
 entire
 repeat
 for
 all
 I
 know.
 So,


but
 anyway,
 let's
 go.
 Right.
 Um
 the


first
 question
 is
 similar.
 So,
 both
 of


you
 firstly
 welcome
 and
 thank
 you
 for


being
 here.


and
 hope
 you'll
 have
 a
 great
 day
 and
 a


half
 as
 well.
 Um,
 both
 of
 you
 been
 in


the
 industry
 for
 a
 while
 and
 both
 of
 you


have
 lived
 through
 many
 infrastructure


cycles,
 right?
 So,
 have
 you
 seen


anything
 like
 this
 cycle
 from
 your


vantage
 point?
 Not
 from
 an
 investor


vantage
 point
 but
 from
 your
 internal


um
 vantage
 point
 where
 you
 are


responsible
 for
 building
 things
 and
 and


planning
 for
 things
 and
 so
 on.
 Anyone
 of


you?
 Where
 do
 you
 want
 to
 start?
 You


want to
 start
 a
 mean?


>> I
 mean,
 I
 think
 it's
 easy
 to
 say.
 I've


seen
 nothing
 like
 this.
 I'm
 fairly


certain
 no
 one's
 seen
 anything
 like


this.
 The
 internet
 in
 the
 late
 90s,


early
 2000s
 was
 big,
 and
 we
 felt
 like,


oh
 my
 gosh,
 can't
 believe
 the
 uh
 build


out,
 the
 rate.
 This
 makes
 it
 I
 mean
 10x


is
 an
 understatement.
 It's
 100x
 what
 the


internet
 was.
 Um
 I
 think
 the
 upside
 is


as
 big
 as
 the
 internet
 was,
 same
 thing.


10x
 and
 100x.
 Yeah.
 No,
 nothing
 like
 it.


>> Yeah,
 I'd
 agree.
 I
 don't
 think
 there's


any
 priors
 to
 this
 size,
 the
 speed
 and


scale.
 Um
 I'
 I'd
 say
 um
 the
 good
 news
 is


infrastructure
 is
 sexy
 again.
 So
 that's


kind
 of
 cool.
 Um
 it
 was
 a
 long
 time
 or


it
 wasn't
 sexy.
 Um
 the
 um
 the
 thing
 I


would
 say
 that's
 that's
 really


interesting
 is
 this
 is
 like
 the


combination
 of
 the
 buildout
 of
 the


internet,
 the
 space
 race
 and
 the


Manhattan
 project
 all
 put
 into
 one
 where


there's
 a
 geopolitical
 implication
 of


it,
 there's
 an
 economic
 implication,


there's
 a
 national
 security
 implication,


and
 then
 there's
 a
 um
 you
 know
 just
 a


speed
 implication
 that's
 pretty


profound.
 So
 uh
 yeah,
 we've,
 you
 know,


none
 of
 us
 have
 ever
 seen
 it
 um
 at
 this


size
 and
 scale.
 On
 the
 other
 hand,
 um
 I


think
 we're
 grossly
 underestimating
 like


there's
 the
 most
 common
 question
 I
 ask


right
 now
 is
 is
 there
 a
 bubble?
 I
 think


we're
 grossly
 underestimating
 the


buildout.
 I
 think
 there's
 going
 to
 be


much
 more
 needed
 than
 what
 we
 are


putting
 the
 um
 you
 know
 projections


towards.


>> So
 that's
 the
 following
 question
 is


where
 are
 we
 do
 you
 think
 in
 the
 capex


spend
 cycle?
 But
 more
 importantly,
 what


are
 the
 signals
 that
 you
 guys
 use


internally
 right
 in
 your
 thinking?
 I


mean,
 you
 have
 to
 plan
 data
 centers


whatever
 four
 five
 years
 in
 advance.
 You


have
 to
 buy
 nuclear
 reactors
 and


whatnot.
 So,
 how
 do
 you
 think
 about
 the


demand
 signals
 as
 well
 as
 your


technology
 signals
 and
 G2
 same
 thing
 for


you,
 but
 from
 the
 point
 of
 view
 of


enterprise
 and
 neo
 clouds
 etc.


uh
 we're
 early
 in
 the
 cycle
 is
 uh
 what


what
 I
 would
 say
 certainly
 relative
 to


the
 demand
 that
 we're
 seeing
 our


internal
 users
 are
 uh
 we've
 been


building
 TPUs
 for
 10
 years
 uh
 so
 we
 have


now
 seven
 generations
 in
 production
 for


internal
 and
 external
 use
 our
 seven
 and


8y
 old
 TPUs
 have
 100%
 utilization


and
 that
 that
 just
 shows
 what
 the
 the


demand
 is
 everyone
 would
 of
 course


prefer
 to
 be
 on
 the
 latest
 generation
 uh


but
 whatever
 they
 can
 get
 so
 this
 tells


me
 that
 the
 demand
 is
 tremendous,
 but


also
 who
 we're
 turning
 away
 and
 the
 use


cases
 that
 we're
 turning
 away.
 It's
 it's


not
 like,
 oh
 yeah,
 that's
 kind
 of
 cool.


It's,
 oh
 my
 gosh,
 we're
 actually
 not


going
 to
 invest
 in
 this
 and
 there's
 no


option
 because
 that's
 where
 we
 are
 on


the
 list.
 Same
 with
 many
 of
 you
 in
 the


room,
 right?
 We're
 we're
 working
 with


many
 of
 you
 in
 the
 room
 and
 many
 of
 you


are
 telling
 me
 directly
 and
 thank
 you.


Um,
 we
 need
 more
 earlier,
 right?
 Now
 the


challenge
 here
 though
 is
 as
 you
 said


that
 we're
 limited
 by
 power,
 we're


limited
 by
 transforming
 land.
 We're


limited
 by
 um
 permitting
 and
 we're


limited
 by
 uh
 backup
 delivery
 of
 uh
 lots


of
 things
 in
 the
 supply
 chain.
 So
 one


worry
 I
 have
 is
 that
 uh
 the
 supply
 isn't


actually
 going
 to
 catch
 up
 to
 the
 demand


as
 quickly
 as
 uh
 we'd
 all
 like.
 I
 I


heard
 the
 previous
 session
 some
 of
 the


discussions
 of
 the
 um
 trillions
 of


dollars
 that
 we're
 going
 to
 be
 spending


which
 I
 think
 is
 accurate.
 I'm
 not
 sure


that
 we're
 going
 to
 be able
 to
 cash
 all


those
 checks.
 Like
 in
 other
 words,


literally
 you
 all
 have
 so
 many money
 you


can't
 spend
 it
 all
 as
 fast
 as
 you
 want.


I
 think
 that's
 going
 to
 extend
 for
 3,


four,
 5
 years.


>> Wow.
 And
 how
 do
 you
 deal
 with
 the


depreciation
 cycles
 that
 are
 involved


there?


>> Is
 the
 demand
 curve
 and
 the
 depreciation


cycle
 curves
 match
 up?


>> Well,
 fortunately
 we
 buy
 just
 in
 time.


But
 the
 nice
 thing
 is
 just
 in
 time
 for


the
 hardware
 the
 depreciation
 cycle
 for


the
 space
 power
 is
 more
 like
 uh


somewhere
 between
 25
 and
 40
 years.
 So
 we


have
 uh
 benefits
 there.


>> I
 think
 if
 you
 think
 of
 on
 the


networking
 side
 and
 you
 look
 at
 both
 um


um
 enterprise
 and
 the
 hyperscalers
 as


well
 as
 neoclouds
 I
 think
 the
 story
 is


quite
 different.
 So
 the
 the
 the


enterprise
 is
 pretty
 nent
 in
 its


buildout
 of
 true
 infrastructure.
 Um
 I


just
 don't
 think
 that
 the
 data
 centers


like
 if
 you
 assume
 that
 100%
 of
 the
 data


centers
 are
 at
 some
 point
 in
 time
 you


will
 need
 to
 get
 rerracked
 and
 you
 will


need
 a
 very
 different
 level
 of
 power


um
 requirement
 per
 rack
 that's
 going
 to


be
 there
 compared
 to
 what
 used
 to
 be


there
 in
 the
 traditional
 data
 centers.
 I


just
 don't
 think
 that
 um
 the
 enterprises


are
 far
 enough
 along.
 Maybe
 the
 few


enterprises
 that
 are
 at
 super
 high
 scale


might
 be
 there,
 but
 I
 don't
 think
 the


enterprises
 are
 far
 enough
 along.


Hyperscalers
 and
 NeoClouds
 is
 a


completely
 different
 story.
 And
 uh
 to
 A


mean's
 point
 on
 this
 notion
 of
 scarcity


of
 power,
 compute
 and
 network
 being
 the


three
 big
 kind
 of
 constraints
 in
 this


thing.
 Um
 I
 I
 would
 say
 right
 now
 that


because
 there's
 not
 enough
 power


singularly
 in
 one
 location,
 data
 centers


are
 being
 built
 where
 the
 power
 is


available
 rather
 than
 power
 being


brought
 to
 where
 the
 data
 centers
 are.


Um
 and
 that's
 why
 you're
 seeing
 a
 lot
 of


projects
 that
 are
 being
 built
 out
 all


throughout
 the
 world.
 The
 other
 point


though
 is
 the
 um
 the
 the
 lion
 share
 of


the
 constraints
 that
 we're
 going
 to
 have


I
 I
 think
 are
 going
 to
 be
 sustainable


for
 a
 for
 a
 long
 period
 of
 time.
 And
 as


you
 have
 data
 centers
 that
 are
 being


built
 farther
 and
 farther
 apart
 one


there's
 going
 to
 be
 a
 huge
 demand
 for


scale
 up
 networking
 so
 that
 you
 can
 have


a
 rack
 that
 gets
 more
 and
 more


networking
 for
 scale
 up.
 The
 second
 is


you're
 going
 to
 have
 a
 lot
 of
 demand
 for


scale
 out
 where
 you
 have
 multiple
 racks


and
 clusters
 that
 need
 to
 get
 connected


together.
 But
 we
 just
 launched
 a
 a
 new


piece
 of
 silicon
 as
 well
 as
 a
 new
 chip


and
 a
 system
 for
 scale
 across
 networking


where
 you
 might
 have
 two
 data
 centers


that
 act
 as
 a
 logical
 data
 center
 that


could
 be
 up
 to
 8
 900
 kilometers
 apart.


Um
 and
 and
 you
 will
 see
 that
 just


because
 there's
 not
 going
 to
 be
 enough


concentration
 of
 power
 in
 a
 single


location.
 So
 you'll
 just
 have
 to
 have


different
 architectures
 that
 get
 built


out.


>> Actually
 that
 brings
 us
 uh
 to
 the
 next


topic
 that
 I
 want
 to
 discuss
 the
 future


of
 systems
 and
 networking
 and
 so
 on
 and


so
 forth.
 So


Google
 brought
 about
 the
 first
 or
 at


least
 large
 scale
 scale
 out
 commodity


servers
 and
 production
 for
 the
 web


revolution
 and
 now
 Nvidia
 is
 bringing


back
 the
 mainframe
 in
 a
 different
 form.


So
 what
 do
 you
 think
 happens
 next?
 I


mean,
 is
 is
 this
 the
 new
 style
 of


coherent
 clusterwide
 computing
 that
 we


need
 and
 there's
 going
 to
 be
 shared


memory
 and
 all
 sorts
 of
 things
 or
 do
 you


think
 the
 pattern
 changes
 again?


>> I
 I
 don't
 think
 we're
 quite
 to
 um
 back


to
 mainframes
 in
 that
 it
 is
 still
 the


case
 that
 people
 are
 running
 on
 uh
 scale


out
 architectures
 across
 these
 pools.
 In


other
 words,
 whether
 you
 have
 GPUs
 or


TPUs,
 you're
 not
 necessarily
 saying,


"Hey,
 that's
 my
 GPU
 supercomput."
 You're


saying,
 "I've
 got
 16,384
 GPUs."
 Y


>> and
 maybe
 I'm
 going
 to
 go
 grab
 some


subset.
 Now
 I've
 got
 uniform
 all


connectivity
 uh
 in
 many
 cases
 which
 is


fantastic.
 Same
 with
 TPUs.
 It's
 not
 like


I
 say
 I
 have
 a
 9,000
 chip
 pod
 and
 I
 have


to
 make
 my
 job
 fit
 on
 that.
 Maybe
 I


actually
 only
 need
 256.
 Maybe
 I
 need


100,000.
 So
 I
 do
 think
 that
 actually
 the


uh
 software
 scale
 out
 is
 uh
 still
 going


to
 be
 there.
 Uh
 I'll
 note
 two
 things


though.
 one
 you're
 absolutely
 right
 that


say
 about
 25
 years
 ago
 uh
 at
 Google
 and


other
 places
 simultaneously


there
 was
 really
 a
 transformation
 of


computing
 infrastructure
 like
 the
 notion


that
 actually
 you
 would
 scale
 out
 on


commodity
 PCs
 essentially
 the
 same
 ones


that
 you
 could
 buy
 off
 the
 shelf
 running


a
 Linux
 stack
 and
 that's
 what
 you
 would


do
 for
 disk
 that's
 what
 you
 would
 do
 for


compute
 that's
 what
 you
 do
 for


networking
 I
 mean
 you
 all
 take
 it
 for


granted
 that
 this
 is
 sort
 of
 it
 was


radical
 there
 are
 many
 people
 who


thought
 that
 this
 was
 a
 terrible
 idea


that
 wasn't
 going to
 work.
 I
 think
 the


exciting
 thing
 about
 this
 moment
 right


now
 is
 actually
 that
 we're
 going
 to
 be


reinventing
 I'm
 not
 saying
 Google
 we
 are


going
 to
 be
 reinventing
 computing
 and
 5


years
 from
 now
 whatever
 the
 computing


stack
 is
 from
 the
 hardware
 to
 the


software
 right
 is
 going
 to
 be


unrecognizable
 and
 by
 the
 way
 there
 was


this
 code
 design
 because
 if
 you
 think


about
 it
 I'll
 use
 Google
 examples


because
 I
 know
 those
 best
 big
 table


spanner
 GFS
 Borg
 Colossus
 they
 were


handinhand
 codeesigned
 with
 the
 hardware


the
 cluster
 scale
 out
 architecture


picture
 and
 it
 was
 really
 the
 com
 we


wouldn't
 have
 done
 the
 scale
 out


hardware
 if
 you
 didn't
 have
 the
 scale


out
 software


>> y


>> same
 thing
 is
 going
 to
 happen
 in
 this


moment
 so
 I
 I
 think
 actually
 the


mainframe
 um
 it's
 going to
 look
 very


very
 different


>> okay


>> yeah
 I
 do
 think
 there'll
 be
 like
 this
 ex


uh
 extreme
 demand
 for
 an
 integrated


system
 because
 like
 right
 right
 now
 we


are
 very
 fortunate
 at
 Cisco
 where
 we
 do


everything
 from
 the
 um
 from
 the
 physics


to
 the
 semantics
 you
 know
 you
 think


about
 the
 silicon
 to
 the
 application


Um
 and
 the
 other
 than
 power,
 one
 of
 the


constraints
 is
 how
 well
 integrated
 are


these
 systems
 and
 do
 they
 actually
 work


with
 the
 least
 amount
 of
 um
 lossiness


uh
 across
 the
 entire
 stack.
 And
 so
 that


that
 level
 of
 tight
 integration
 is
 going


to
 be
 super
 important.
 And
 what
 that


means
 the
 industry
 will
 have
 to
 evolve


into
 is
 we
 will
 have
 to
 work
 like
 one


company
 even
 though
 we
 might
 actually
 be


multiple
 companies
 that
 actually
 do


these
 pieces.
 And
 so
 when
 we
 work
 with


hyperscalers
 like
 Google
 or
 others
 um


there's
 a
 deep
 design
 partnership
 that


actually
 you
 know
 goes
 on
 for
 months
 and


months
 together
 uh
 ahead
 of
 the
 time


before
 we
 actually
 even
 do
 them
 uh
 deal


and
 then
 once
 a
 deal
 is
 done
 of
 course


there's
 a
 tremendous
 amount
 of
 pressure


to
 make
 sure
 that
 the
 you
 moving
 pretty


fast
 but
 I
 think
 the
 industry's
 muscle


of
 making
 sure
 that
 you
 operate
 in
 an


open
 ecosystem
 and
 not
 be
 a
 walled


garden
 is
 going
 to
 get
 important
 at


every
 layer
 of
 the
 stack.
 Y
 completely


agree.
 And
 so
 let's
 talk
 about
 the


disagregate
 the
 stack
 a
 little
 bit.


One
 of
 the
 most
 interesting
 topic
 is


processors,
 right?
 Clearly
 there's
 an


amazing
 vendor
 producing
 an
 amazing


processor
 that
 has
 massive
 market
 share


today,
 right?
 And
 we
 see
 startups
 all


the
 time
 doing
 all
 sorts
 of
 processor


architectures.
 You
 got
 an
 amazing


processor
 inside


um
 your
 fortress.


What
 do
 you
 think
 happens
 next
 in


processor
 land?


>> Yeah,
 we're
 uh
 huge
 fans
 of
 Nvidia.
 Uh


we
 we
 sell
 a
 lot
 of
 uh
 Nvidia
 uh


products
 and
 chips.
 Uh
 customers
 love


them.
 Uh
 we're
 also
 huge
 fans
 of
 our
 uh


TPUs.
 Uh
 I
 think
 the
 future
 is
 actually


really
 exciting
 and
 actually
 uh
 we're


it's
 not
 that
 I
 don't
 think
 that
 we've


hit
 the
 point
 of
 okay
 there's
 TPUs,


there's
 GPUs,
 there's
 whatever
 tranniums


or
 or
 something
 else.
 We're
 really


seeing
 the
 golden
 age
 of
 specialization.


And
 that
 that's
 my
 observation.
 In
 other


words,
 if
 you
 look
 at
 it,
 a
 TPU,
 I'll


use
 that
 example
 again
 because
 I
 know
 it


best
 for
 certain
 computation
 is


somewhere
 between
 10
 and
 100
 times
 more


efficient
 per
 watt.
 And
 it's
 this
 watt


that
 really
 matters


>> than
 a
 CPU.


>> That's
 hard
 to
 walk
 away
 from,
 right?
 10


to
 100x.
 And
 yet
 we
 know
 that
 there
 are


other
 computations
 that
 if
 you
 built


even
 more
 specialized
 systems
 for,
 but


not
 just
 a
 niche
 computation,


computations
 that
 we
 run
 a
 lot
 of
 at


Google,
 right?
 for
 example,
 uh
 maybe
 for


serving
 maybe
 for
 agentic
 workloads
 that


would
 benefit
 from
 an
 even
 more


specialized
 architecture.
 So
 I
 think


that
 actually
 one
 bottleneck
 is
 how
 hard


is
 it
 and
 how
 long
 does
 it
 take
 to
 turn


around
 a
 specialized
 architecture.
 Right


now
 it's
 forever.


>> Yeah.


>> Right.
 For
 the
 best
 teams
 in
 the
 world


really
 from
 concept
 to
 in
 live
 in


production
 speed
 of
 light
 is
 two
 and
 a


half
 years.


>> Yeah.


>> I
 mean
 that's
 that's
 if
 you
 nail


everything,
 right?
 And
 there
 are
 a
 few


teams
 that
 do,
 but
 how
 do
 you
 predict


the
 future
 two
 and
 a
 half
 years
 out
 for


building
 specialized
 hardware?
 So,
 A,
 I


think
 we
 have
 to
 shrink
 that
 cycle.


>> But
 then
 B,
 at
 some
 point
 when
 things


slow
 down
 a
 little
 bit,
 and
 they
 will,
 I


think
 we're
 going to
 have
 to
 build
 more


specialized
 architectures
 because
 the


power
 savings,
 the
 cost
 savings,
 the


space
 savings
 are
 just
 too
 dramatic
 to


ignore.


>> And
 this
 will
 actually
 have
 a
 really


interesting
 implication
 on
 geopolitical


structures
 as
 well.
 Because
 if
 you
 think


about
 what's
 happening
 in
 China,
 China


actually
 doesn't
 make
 2
 nanometer
 chips.


They
 make
 you
 know
 7
 nanometer
 chips.
 Um


and
 and
 so
 if
 you
 think
 about
 what
 but


they
 have
 unlimited
 amount
 of
 power
 um


and
 they
 have
 unlimited
 amount
 of


engineering
 resource
 and
 so
 what
 they


can
 do
 is
 do
 the
 optimization
 on
 the


engineering
 side
 keep
 the
 seven


nanometer
 chips
 and
 make
 sure
 that
 they


give
 people
 unlimited
 amount
 of
 power.


We
 might
 have
 a
 different
 architectural


design
 where
 you
 have
 to
 get
 extremely


power
 efficient.
 you
 don't
 have
 as
 many


engineers
 as
 you
 might
 enjoy
 in
 China


and
 you
 can
 actually
 go
 to
 two
 nanometer


chips
 but
 and
 those
 might
 be
 power


efficient
 in
 some
 ways
 but
 they
 might


have
 thermal
 lossiness
 in
 other
 ways


like
 there's
 a
 whole
 bunch
 of
 things


that
 have
 to
 get
 factored
 in
 um
 on
 the


architecture
 that'll
 get
 more


specialized
 even
 by
 geo
 and
 by
 region


and
 then
 depending
 on
 how
 the
 regulatory


frameworks
 evolve


uh
 you
 know
 how
 that
 that
 geo
 and


expands
 like
 if
 China
 expands
 to


different
 regions
 in
 the
 world
 you
 will


have
 a
 very
 different
 architecture
 that


plays
 out
 than
 if
 America
 expands
 to


different
 regions
 in
 the
 world.
 So
 this


is
 a
 very
 interesting
 kind
 of
 game


theory
 exercise
 to
 go
 through
 on
 what


happens
 in
 the
 next
 3
 years
 in


>> in
 tech
 in
 general
 and
 no
 one
 knows


right
 now.


>> Yeah,


>> that's
 the
 beauty
 of
 the
 world
 that
 we


live
 in.


>> Yeah.
 Yeah.


>> So
 we'll
 soon
 be
 measuring
 systems
 by


engineers
 per
 token
 in
 addition
 to
 watts


per
 token.
 Um
 all
 right
 so
 let's
 jump
 to


another
 topic
 which
 very
 much


>> engineer
 per
 kilowatt


>> engineer
 per
 kilowatt


>> in
 the
 US


>> um
 networking
 right
 obviously
 you


alluded
 to
 it
 um
 scale
 up
 scale
 out
 in


your
 case
 you
 mentioned
 scale
 across
 so


it
 seems
 to
 me
 that
 networking
 is
 also


going
 to
 get
 reinvented
 in
 a
 fairly


significant
 way
 so
 what
 are
 the
 leading


sides
 that
 you're
 seeing
 that
 and
 the


signals
 that
 you're
 seeing
 and
 on
 the


direction
 networking
 is
 going
 to


Yeah,
 networking
 is
 going
 to
 need
 a


transformation
 uh
 for
 certain.
 In
 other


words,
 uh
 it
 the
 amount
 of
 bandwidth


that's
 needed
 at
 scale
 within
 a
 building


is
 just
 astounding.
 I
 mean
 and
 uh
 and


it's
 it's
 going
 up.
 The
 network
 is


becoming
 a
 primary
 bottleneck.
 Uh
 which


is
 uh
 scary.
 So
 more
 bandwidth


translates
 directly
 to
 more
 performance.


And
 then
 given
 that
 the
 network
 winds
 up


actually
 being
 a
 small
 power
 consumer


that
 delivered
 utility
 you
 get
 per
 watt


like
 it's
 a
 super
 linear
 benefit
 like


spend
 a
 little
 bit
 here
 get
 way
 more


there.
 So
 I
 think
 that
 uh
 that
 side
 is


absolutely
 there.


>> Um
 I'll
 put
 in
 a
 plug
 here
 in
 that
 in


this
 for
 these
 workloads
 we
 actually


know
 what
 the
 network
 communication


patterns
 are
 a
 priority.
 So
 I
 think
 this


is
 a
 massive
 opportunity.
 In
 other


words,
 do
 you
 then
 need
 uh
 the
 full


power
 of
 a
 packet
 switch
 when
 actually


you
 know
 what
 the
 rough
 circuits
 are


going
 to
 be?
 And
 I'm
 not
 saying
 you
 need


to
 build
 a
 circuit
 switch,
 but
 there
 is


an
 optimization
 opportunity.
 The
 other


aspect
 of
 this
 here
 is
 these
 workloads


are
 just
 incredibly
 bursty.


>> Yeah.
 and
 and
 we're
 to
 the
 point
 where


uh
 and
 we've
 written
 about
 this
 uh
 power


utilities
 notice
 when
 we're
 doing


network
 communication
 relative
 to


computation
 at
 the
 scale
 of
 tens
 and


hundreds
 of
 megawatts,
 right?
 Like


massive
 demand
 for
 power,
 stop
 all
 of
 a


sudden
 and
 do
 some
 network
 communication


and
 then
 burst
 back
 to
 computing.
 So,


how
 do
 you
 build
 a
 network
 that
 needs
 to


go
 at
 100%


for
 a
 really
 short
 amount
 of
 time
 and


then
 go
 idle?


>> Yeah.
 And
 then
 same
 actually
 for
 the


scale
 across
 use
 case
 which
 uh
 we're


absolutely
 seeing
 you
 don't
 run
 large


scale
 pre-training
 across
 all
 your
 wide


area
 data
 center
 sites
 12
 months
 of
 the


year.
 So
 and
 then
 you're
 going
 to
 this


is
 a
 problem
 I
 think
 about
 a
 lot
 is


let's
 say
 you
 build
 the
 latest
 greatest


chips
 in
 these
 three
 data
 center
 sites.


How
 long
 are
 you
 going
 to
 be
 there


before
 you
 migrate
 to
 the
 latest
 latest


chips
 in
 three
 other
 sites?


And
 then
 what
 do
 you
 do
 with
 the
 network


that
 you
 left
 behind?
 People
 are
 going


to
 run
 jobs
 on
 them.
 Yeah,


>> but
 you're
 not
 going
 to
 need
 nearly
 the


network
 capacity


>> that
 you
 did
 for
 large
 scale
 training,


pre-training
 anyway.
 So
 the
 shift
 of


needing
 massive
 networks
 for
 like
 5%
 of


the
 time
 it
 I
 I
 don't
 know
 how
 to
 build


a
 network
 like
 that.
 So
 if
 any
 of
 you


do,
 please
 um
 please
 please
 let
 me
 know.


>> I
 mean,
 if
 you
 don't
 know
 how
 to
 build


this,
 there's
 nobody
 that
 knows
 how
 to


build
 this.


>> We're
 trying
 to
 figure
 it
 out.
 It


actually
 is
 a
 fascinating
 problem.


>> Yeah.


>> Yeah.
 Right.
 I
 do
 think
 like
 if
 if
 you


think
 of
 if
 power
 is
 the
 constraint
 and


if
 compute
 is
 the
 asset
 I
 think
 network


is
 going
 to
 be
 the
 force
 multiplier


>> because
 you
 know
 if
 a
 if
 a
 packet
 if
 if


you
 have
 low
 latency
 and
 low
 performance


and
 high
 energy
 and
 efficiency
 then
 the


packet
 the
 every
 kilowatt
 of
 power
 you


save
 moving
 the
 packet
 is
 a
 kilowatt
 of


power
 you
 can
 give
 to
 the
 GPU.


>> Y


>> um
 which
 is
 you
 know
 super
 important.
 Um


the
 the
 other
 thing
 is
 you
 know
 when
 you


think
 about


um
 scale
 up
 versus
 scale
 out
 versus


scale
 up
 across
 you'll
 also
 need


especially
 on
 inference
 versus
 training


there
 are
 different
 things
 that
 get


optimized
 like
 you
 might
 optimize
 for


latency
 much
 more
 on
 training
 runs
 you


might
 optimize
 much
 more
 for
 memory
 on


inferencing
 um
 there there's
 uh
 there's


architectural
 and
 so
 I
 I
 also
 feel
 like


the
 way
 that
 networking
 will
 evolve
 is


rather
 than
 it
 being
 um
 a
 training


infrastructure
 that
 then
 gets
 applied
 to


inferencing.
 You
 might
 have
 inferencing


native
 infrastructure
 that
 gets
 built
 um


over
 time.
 And
 so
 there's
 there's
 good


considerations
 to
 look
 at
 on
 like
 how


all
 of
 the
 architectural
 components
 are


um
 are
 moving.
 But
 um
 in
 my
 mind
 like
 if


if
 I
 were
 to
 say
 strategically
 one
 of


the
 biggest
 things
 that's
 happening
 in


networking
 from
 our
 vantage
 point
 is
 if


you're
 just
 a
 wrapper
 around
 broadcom


then
 you've
 got
 a
 monopoly
 that's
 going


to
 be
 a
 very
 predatory
 one.
 Um
 and
 so


one
 of
 the
 big
 reasons
 where
 Cisco
 is
 um


super
 relevant
 is
 you
 don't
 just
 have
 a


broadcom
 world
 with
 people
 just
 wrapping


mean
 that
 their
 systems
 aroundcom
 but


you
 will
 actually
 have
 a
 choice
 of


silicon
 and
 that
 choice
 and
 diversity
 of


silicon
 is
 going
 to
 be
 super
 important


uh
 especially
 for
 high
 volume
 you
 know


kind
 of
 consumption
 patterns.


So
 last
 question
 on
 the
 system
 since
 you


brought
 that
 up
 and
 we'll
 move
 to
 use


cases.
 Um
 inference
 both
 of
 you
 have


mentioned
 I
 mean
 you
 talked
 about
 in
 the


context
 of
 the
 processors
 you
 just


started
 talking
 about
 the
 architecture


are
 you
 deploying
 today's
 specific


architectures
 for
 inference
 I
 mean
 or
 is


it
 still
 shared
 workloads?
 We
 are


deploying
 uh
 specialized
 architectures


for
 inference
 and
 I
 think
 as
 much


software
 as
 hardware
 but
 the
 hardware
 is


also
 uh
 deployed
 in
 different


configurations
 is
 the
 way
 I
 would
 say


it.
 And
 then
 the
 other
 aspect
 of


inference
 that
 is
 becoming
 really


interesting
 is
 uh
 reinforcement
 learning


uh
 especially
 on
 the
 critical
 path
 of


serving
 because
 latency
 just
 becomes


absolutely
 critical.
 uh
 and
 I
 think
 that


so
 how
 you
 would
 build
 your
 system
 and


how
 you
 would
 connect
 it
 up
 to
 one


another
 and
 of
 course
 networking
 plays
 a


a
 key
 role
 there
 uh
 becomes
 increasingly


interesting


>> and
 are
 there
 singular
 choke
 points
 that


if
 removed
 would
 accelerate
 the


thousandfold
 reduction
 in
 the
 cost
 of


inference
 that
 we
 need
 or
 is
 this
 just
 a


natural
 curve
 that
 we
 are
 writing
 down


>> so
 so
 we're
 massive
 I
 mean
 two
 things


here
 one
 again
 maybe
 many
 of
 you
 are


familiar
 with
 this
 prefill
 and
 decode
 on


inference
 look
 very
 very
 different.
 So


actually
 ideally
 uh
 if
 you've
 uh
 you


would
 have
 different
 hardware
 actually


the
 balance
 points
 are
 different.
 So


that's
 that's
 one
 opportunity.
 It
 comes


with
 downsides.
 Uh
 we
 can
 talk
 about


that.


>> Uh
 what
 I
 would
 say
 though
 is
 that
 maybe


something
 people
 don't
 realize
 is
 that


we're
 actually
 driving
 massive


reductions
 in
 the
 cost
 of
 inference.
 I


mean
 10
 x's
 and
 100
 x's.
 The
 problem
 or


opportunity
 is
 the
 community,
 the
 user


base
 keeps
 demanding
 higher
 quality.


>> Mhm.
 not
 better
 efficiency.
 So
 just
 as


soon
 as
 we
 deliver
 um
 all
 the
 efficiency


improvements
 we're
 looking
 for,
 the
 next


generation
 model
 comes
 out
 and
 it
 is
 the


whatever
 um
 intelligence
 per
 dollar
 is


way
 better,
 but
 you
 still
 pay
 more
 and


it
 costs
 more
 relative
 to
 the
 previous


generation
 and
 then
 we
 repeat
 the
 cycle.


>> And
 it's
 almost
 like
 the
 longer


um
 the
 reasoning


>> Yeah.


>> that
 you
 have
 the
 more
 impatient
 the


market
 gets,
 right?
 So
 for
 example,
 if


you
 have
 a
 20
 minute
 reasoning
 cycle


like
 for
 example
 with
 deep
 research
 you


could
 have
 autonomous
 execution
 for


about
 20
 minutes
 that
 was
 interesting.


Now
 you
 have
 you
 know
 most
 of
 the
 coding


tools
 that
 can
 go
 up
 to
 7
 hours
 to
 30


hours
 of
 you
 know
 duration
 of
 autonomous


execution.
 When
 that
 happens
 there's


actually
 a
 greater
 demand
 for
 saying


compress
 that
 time
 down.
 Um,
 and
 so


you'll
 it's
 it's
 kind
 of
 a


self-fulfilling
 prophecy
 where
 you
 need


to
 have
 more
 performance
 because
 of
 the


fact
 that
 you've
 been
 able
 to
 go
 out
 and


do
 things
 for
 a
 longer
 autonomous
 amount


of
 time.
 And
 so
 it's
 almost
 a
 never-


ending
 loop
 where
 you
 you'll
 need
 to


have
 more
 performance
 for
 inference.


>> Yeah.


>> In
 perpetuity.


>> Yeah.
 Though


intelligence
 per
 dollar
 is
 a
 business


model
 metrics
 metric.
 So
 it
 is
 not
 just


the
 processor
 capability.


>> No,
 it's
 end
 to
 end.
 Absolutely.


>> Yeah.
 So
 okay.
 So
 let's
 uh
 change
 topics


and
 talk
 about
 actual
 usage,
 right?
 So


both
 of
 you
 have
 massive
 organizations.


Where
 are
 the
 key
 wins
 that
 you're


getting
 today
 with
 with
 applying
 all
 the


AI
 that's
 available
 to
 you
 and
 uh
 then


we'll
 talk
 about
 what
 your
 customers
 are


doing.
 But
 I'm
 actually
 curious
 about


what
 you're
 doing
 internally


>> wi
 within
 the
 teams.


>> Yeah.


>> Yeah.
 So,
 so
 I
 mean
 coding
 is
 the


obvious
 one
 and
 that's
 actually
 picking


up
 uh
 increasing
 traction
 and
 incre


increasing
 capability.
 Uh
 we
 just


actually
 in
 the
 last
 couple
 of
 days
 uh


published
 a
 paper
 that
 showed
 how
 we


applied
 AI
 techniques
 to
 uh
 do


instruction
 set
 migration.
 So
 in
 other


words,
 we
 actually
 had
 a
 fairly
 massive


migration
 from
 x86
 to
 ARM
 making
 our
 uh


entire
 codebase
 and
 at
 Google
 it's
 a


very
 very
 large
 codebase
 uh
 uh
 sort
 of


instruction
 set
 agnostic
 and
 including


to
 you
 know
 future
 risk
 5
 or
 whatever


else
 might
 come
 along
 uh
 tens
 and


thousands
 hundreds
 of
 thousands
 of


individual


>> your
 entire
 codebase
 you're
 going
 to


make
 it
 agnostic


>> entire
 codebase
 because
 we
 we
 um
 want


and
 need
 all
 of
 our
 codebase
 to
 be


>> man
 that's
 a
 crazy
 ass
 project.


>> Yeah.
 So,
 so
 we
 we
 it it
 was
 and
 the
 the


motivation
 though
 for
 this
 actually
 was


a
 few
 years
 ago.
 Uh
 we
 had
 this
 uh


amazing
 uh
 legacy
 system
 called
 Bigtable


and
 then
 a
 new
 amazing
 system
 called


Spanner.
 And
 we
 decided
 to
 tell
 the


company,
 hey,
 everyone
 needs
 to
 move


from
 Bigtable
 to
 Spanner.
 And
 by
 the


way,
 Bigtable
 was
 amazing
 for
 its
 time,


but
 Spanner
 was
 better.
 The
 estimate
 for


doing
 that
 migration
 for
 Google
 was


seven
 staff
 millennia.


>> How
 much?


>> How
 much?
 seven
 staff
 millennium


that
 we
 we
 had
 a
 new
 unit
 that
 we
 had
 to


actually


to
 see
 what
 and
 and
 it
 was
 it
 wasn't


like
 made
 up
 people
 being
 lazy.
 It's


like
 this
 is
 this
 is
 what
 it
 was.


>> It's
 endearing
 that
 they
 came
 up
 with


that
 though


>> and
 you
 know
 what
 we
 decided
 long
 live


big
 table


what
 it
 just
 wasn't
 worth
 it.


>> Yeah.


>> Honestly
 like
 the
 opportunity
 cost
 was


uh
 too
 high.
 So
 the
 and
 we
 have
 these


sorts
 of
 migrations.
 So
 tensor
 uh
 flow


to
 jacks
 we
 actually
 I
 mean
 again


somewhat
 private
 but
 not
 not
 too
 secret


we've
 affected
 this
 internally
 with
 AI


assist
 went
 integer
 factors
 faster.
 Now


there
 are
 other
 tasks
 which
 um
 the
 tools


probably
 aren't
 quite
 yet
 up
 to
 the
 um


whatever
 standard
 for
 but
 the
 the
 area


under
 the
 curve
 is
 getting
 bigger
 and


bigger
 and
 bigger.


So
 we're
 seeing
 probably
 like
 three
 or


four
 really
 good
 use
 cases
 and
 then
 we


are
 seeing
 some
 use
 cases
 which
 are
 not


working
 yet.
 And
 so
 what
 is
 working
 code


migrations
 is
 working
 relatively
 well
 so


far
 we
 use
 largely
 a
 combination
 of


codeex
 cloud
 and
 um
 and
 cursor
 some
 win


surf
 and
 so
 um
 code
 migrations
 tends
 to


work
 pretty
 well.
 Um,
 debugging,


oddly
 enough,
 has
 actually
 been
 very


very
 productive
 with
 um
 with
 these


tools,
 especially
 with
 CLIs.
 Um,
 the
 um


um
 where
 we've
 not
 done
 as
 good
 a
 job.


And
 then
 front
 end
 0ero
 to1
 projects


tend
 to
 do
 extremely
 well
 like
 the


engineers
 are
 super
 productive.
 when
 you


go
 to
 code
 that's
 older
 um
 and


especially
 further
 down
 in
 the


infrastructure
 stack
 much
 harder
 to
 go


out
 and
 get
 that
 to
 happen.
 But
 the


challenge
 that
 we
 have
 to
 orient
 our


engineers
 on
 this
 is
 actually
 much
 more


of
 a
 cultural
 reset
 problem
 than
 it
 is
 a


um
 just
 a
 technical
 problem
 which
 is
 if


someone
 uses
 something
 and
 says
 this


isn't
 working
 right


um
 you
 can't
 put
 it
 back
 on
 the
 shelf


saying
 this
 doesn't
 work
 for
 another
 6


or
 9
 months.
 you
 have
 to
 come
 back
 to
 it


within
 four
 weeks
 and
 see
 if
 it
 works


again
 because
 the
 speed
 at
 which
 these


tools
 are
 kind
 of
 advancing
 is
 so
 fast


that
 you
 almost
 have
 to
 kind
 of
 get
 like


so
 I
 was
 with
 a
 150
 of
 our
 distinguished


engineers
 today
 and
 what
 I
 had
 to
 urge


them
 to
 do
 is
 um
 assume
 that
 these
 tools


are
 going
 to
 get
 infinitely
 better


within
 6
 months.


>> Yeah.
 and
 make
 sure
 that
 you
 get
 your


mental
 model
 to
 where
 that
 tool
 is
 going


to
 be
 in
 six
 months
 and
 what
 are
 you


going
 to
 do
 to
 be
 bestin-class
 in
 six


months
 rather
 than
 assessing
 it
 for


where
 it
 is
 today
 and
 then
 putting
 it


aside
 for
 6
 months
 assuming
 that
 that's


not
 going
 to
 work
 for
 the
 next
 6
 months.


I
 think
 that's
 a
 big
 strategic
 error.
 So


we've
 got
 25,000
 engineers.
 I'm
 hoping


that
 we
 can
 get
 at
 least


um
 two
 or
 3x
 productivity
 within
 a
 very


short
 amount
 of
 time
 within
 the
 next


year.
 um
 and
 we
 it'll
 we'll
 be able
 to


see
 what
 if
 um
 if
 that
 happens.
 The


second
 a
 couple
 of
 the
 big
 areas
 that
 we


are
 starting
 to
 see
 some
 good
 responses


is
 in
 sales
 preparation
 going
 into
 an


account
 call
 really
 good
 legal
 contract


reviews


actually
 much
 better
 than
 what
 we
 had


thought.
 Um
 and
 then
 the
 last
 one
 is
 not


super
 high
 inference
 volume
 but
 product


marketing.
 Um,
 I
 think
 the
 first
 chat


GPT


take
 on
 competitive
 is
 always
 better


than
 what
 my
 any
 product
 marketing


person
 comes
 up
 by
 themselves.
 So,
 we


should
 never
 start
 from
 blank
 slate.


Just
 start
 from
 chat
 GPT
 and
 then
 go


from
 there.


>> Okay.
 Now,
 we
 could
 be
 talking
 about
 the


topic
 for
 a
 long
 time,
 but
 they
 showed


me
 the
 two-minute
 warning.
 So,
 I
 want
 to


focus
 on
 one
 last
 question
 here.
 So,
 we


got
 a
 lot
 of
 founders
 here,
 right?


Building
 amazing
 companies.
 So
 what
 is


the
 most
 interesting
 development
 they


should
 look
 forward
 to
 in
 the
 next


calendar
 year
 let's
 call
 it
 or
 the
 next


12
 months
 a
 from
 your
 company
 and
 B
 from


the
 industry
 if
 you
 are
 look
 at
 your


crystal
 ball


>> I
 mean
 I
 think
 to
 build
 on
 the
 point
 uh


these
 these
 models
 are
 getting
 more


spectacular
 uh
 by
 the
 by
 the
 month
 and


then
 they'll
 be
 from
 whatever
 companies


you
 like
 uh
 a
 bunch
 of
 really
 excit


including
 ours
 I
 forgot
 to
 say
 you're


not
 allowed
 to
 say
 models
 will
 get


better.


>> Yeah,


>> everybody
 knows


>> the
 models
 the
 models
 are
 going
 to
 get


but
 I
 mean
 they're
 getting
 scary
 good
 is


the
 part
 that
 I
 would
 say
 um
 but
 I
 think


that
 then
 the
 agents
 that
 get
 built
 on


top
 of
 them
 and
 the
 frameworks
 for


making
 that
 happen
 are
 also
 getting


scary
 good.
 So
 the
 ability
 to
 um
 have


things
 go
 quite
 right
 for
 quite
 long


over
 the
 coming
 12
 months
 is
 going to
 be


transformative.
 on
 anything.
 Do
 you
 want


to
 leak
 any
 aspect
 of
 your
 road
 map


>> next
 12
 months?


>> Not
 so
 not
 right
 now.
 Yeah.


>> Okay.
 Do
 you


>> I
 I
 I'd
 say
 the
 the
 big
 shift
 and
 what
 I


would
 urge
 startups
 to
 do
 is
 don't
 build


thin
 wrappers
 around
 models
 that
 are


other
 people's
 models.
 I
 think
 the
 the


the
 combination
 of
 a
 model
 working
 very


closely
 with
 the
 product
 and
 the
 model


getting
 better
 as
 there's
 feedback
 in


the
 product
 is
 going
 to
 be
 super


important.
 So
 you
 are
 going
 to
 need


foundation
 models
 but
 if
 you
 just
 have
 a


thin
 wrapper
 I
 think
 the
 durability
 of


your
 business
 will
 be
 very
 very
 um
 you


know
 shortlived.
 So
 that
 would
 be


something
 that
 I
 would
 I
 would
 urge
 you


on
 and
 I
 think
 the
 intelligent
 routing


layer
 of
 some
 sort
 that
 says
 I'm
 going


to
 use
 my
 models
 for
 these
 things.
 I'm


going
 to
 probably
 use
 foundation
 models


for
 other
 things
 and
 dynamically
 keep


optimizing
 will
 be
 uh
 I
 think
 cursor


does
 that
 pretty
 well.
 Um
 but
 that


that'll
 be
 a
 a
 a
 good
 way
 that
 the
 the


software
 development
 life
 cycle
 will


evolve.
 Um
 what
 you
 should
 expect
 from


Cisco
 is
 look
 truth
 be
 told
 for
 the


longest
 time
 people
 thought
 Cisco
 was
 a


legacy
 company
 like
 that
 they
 were
 has


been
 and
 I
 think
 in
 the
 past
 year


hopefully
 you've
 you've
 paid
 attention
 I


think
 there's
 a
 level
 of
 momentum
 in
 the


business
 there's
 a
 spring
 in
 the
 step
 in


the
 employee
 base
 so
 uh
 you
 should


expect
 like
 I
 said
 from
 the
 physics
 to


the
 semantics
 in
 every
 layer
 from


silicon
 to
 the
 application
 a
 fair
 amount


of
 innovation
 in
 uh
 silicon
 and


networking
 and
 security
 and


observability
 ility
 and
 the
 data


platform
 uh
 as
 well
 as
 applications
 um


you
 know
 from
 us
 and
 um
 we're
 excited
 to


work
 with
 um
 the
 startup
 ecosystem
 and


um
 so
 if
 you
 if
 you
 ever
 feel
 like
 you


want
 to
 work
 with
 us
 make
 sure
 that
 you


reach
 out
 to
 us.


>> What
 are
 you
 going
 to
 say
 something
 you


mean?


>> I
 mean
 one
 aspect
 that
 I
 I
 want
 to


highlight
 about
 the
 models
 is
 um
 where


we
 were
 with
 let's
 say
 text
 models
 two


and
 a
 half
 three
 years
 ago
 they
 were
 fun


like
 hey
 write
 me
 a
 haiku
 about
 Martin


did
 a
 great
 job.
 Now
 they're
 amazing.
 I


think
 that
 what's
 going
 to
 happen
 in
 the


next
 12
 months
 is
 the
 same
 thing
 is


going
 to
 be
 happening
 with
 input
 and


output
 of
 images
 and
 video
 to
 these


models.
 And
 to
 the
 extent
 that
 even
 for


images,
 imagine
 them
 as
 productivity
 and


educational
 tools,
 not
 just
 okay,
 here's


Martinez
 Superman
 on
 a
 like
 that's
 cool


too,
 right?
 But
 using
 it
 for


productivity
 gains
 and
 learning,
 I
 think


is
 going
 to
 be
 really
 really


transformative.


>> Awesome.
 So
 on
 that
 note,
 we'll
 have
 to


end
 this
 session.
 Thanks
 for
 a
 great


conversation.
 I
 mean,
 thanks
 Tito.


[Music]


[Music]