Cyber
 security
 is
 next.
 That's
 the


subtext
 behind
 every
 article,
 every


chart,
 every
 AI
 hype
 headline
 making
 the


rounds
 right
 now.
 Entry-level
 roles


gone.
 Analysts
 automated.
 Entire
 teams


replaced
 by
 models
 that
 don't
 sleep,


don't
 blink,
 and
 never
 burn
 out.
 But


here's
 the
 problem.
 Almost
 none
 of
 those


claims
 are
 rooted
 in
 actual
 deployment


data,
 team
 structures,
 or
 labor
 market


shifts.
 In
 this
 episode,
 I'll
 dissect


those
 claims,
 every
 single
 one
 of
 them,


every
 layoff,
 every
 stat,
 every
 quote


against
 actual
 data,
 market
 shifts,
 and


seven
 years
 of
 AI
 deployments
 on
 cyber


security
 teams.
 And
 at
 the
 end,
 we're


going
 to
 look
 at
 our
 AI
 signal
 card,


showing
 which
 roles
 are
 really
 being


automated,
 which
 ones
 are
 evolving,
 and


where
 the
 capital
 is
 flowing.
 Let's
 dive


in.
 Case
 in
 point,
 Goldman
 Sachs
 2023


report
 on
 generative
 AI
 predicts
 300


million
 full-time
 jobs
 being
 put
 at
 risk


by
 2030
 with
 cyber
 security
 cited
 as


vulnerable
 due
 to
 automation.


Crowdstrike,
 a
 well-known
 American
 cyber


security
 company
 based
 in
 Austin,
 Texas,


announces
 5%
 job
 cut,
 saying
 that
 AI
 is


reshaping
 every
 industry.
 Cyber
 security


threats
 on
 Reddit
 are
 full
 of
 comments


like
 these.
 Here's
 one
 of
 the
 best


examples.
 A
 user
 in
 Reddit
 took
 the
 time


to
 conduct
 an
 experiment
 using
 clot


code.
 He
 analyzed
 a
 WordPress
 plug-in


for
 vulnerabilities.
 The
 author
 notes


that
 currently
 AI
 struggles
 with
 certain


nuanced
 aspects.
 For
 example,
 generated


perfect
 exploit
 page
 loads,
 but
 the
 gap


is
 closing
 fast.
 A
 series
 of
 online


articles
 written
 by
 sources
 dedicated
 to


cyber
 security
 agree
 that
 Genai
 will


reduce
 the
 skill
 gap
 in
 the
 field,


citing
 sources
 like
 Gardner
 who
 theorize


that
 about
 50%
 of
 entry-level
 cyber


security
 positions
 will
 be
 eliminated.


I'll
 test
 these
 claims
 against


independent
 data
 sources,
 field
 reports,


and
 actual
 data
 to
 give
 you
 a
 detailed


data-backed
 analysis
 on
 which
 of
 them


hold
 true
 and
 which
 ones
 are
 clearly


exaggerating.
 The
 evidence
 when
 it
 comes


to
 cyber
 security
 predictions
 are


generally
 framed
 around
 three
 areas.


End-to-end
 automation,
 where
 AI
 is


promoted
 as
 being
 able
 to
 triage,


investigate,
 and
 remediate
 incidents


with
 little
 or
 no
 human
 oversight.


Superior
 pattern
 recognition.
 The
 claim


rests
 on
 the
 belief
 that
 machine


learning
 can
 outperform
 humans
 at


detecting
 subtle
 or
 emerging
 threats
 and


reduction
 of
 error
 and
 fatigue.
 Given


that
 AI
 does
 not
 experience
 burnout
 or


lapses
 in
 concentration,
 it
 is
 often


said
 to
 be
 able
 to
 replace
 analysts
 who


are
 susceptible
 to
 such
 issues.
 Now,


let's
 talk
 about
 what
 AI
 is
 truly


capable
 of
 doing.
 AI
 systems
 can


continuously
 analyze
 vast
 streams
 of


logs,
 network
 data,
 and
 user
 activities


to
 flag
 anomalies
 and
 potential
 threats.


Machine
 learning
 models
 can
 classify
 and


prioritize
 incidents
 based
 on
 risk


context
 and
 potential
 business
 impact.


As
 AI
 models
 learn
 and
 adapt,
 they
 can


decrease
 the
 volume
 of
 unnecessary


alerts,
 lowering
 analyst
 fatigue
 and


missed
 signals.
 AI
 tools
 can
 connect


disperate
 data
 points
 across
 endpoints,


networks,
 emails,
 and
 cloud
 services,


uncovering
 relationships
 and
 attack


paths
 that
 would
 take
 humans
 much
 longer


to
 recognize.
 Advanced
 systems
 do
 offer


security
 analysts
 richer
 contexts


upfront
 through
 thread
 intelligence.


Once
 incidents
 are
 validated,
 AI
 systems


can
 execute
 predefined
 containment
 or


mitigation
 steps
 such
 as
 isolating


endpoints,
 disabling
 compromised


accounts,
 blocking
 IPs
 with
 little
 to
 no


human
 intervention.
 AI
 can
 generate


detailed
 documentation
 after
 the


incident,
 which
 response
 actions
 were


taken
 and
 lesson
 learned.
 Now
 let's
 look


how
 many
 companies
 have
 actually


integrated
 AI
 into
 cyber
 security
 on


their
 teams
 and
 whether
 it's
 actually


working.
 For
 this
 section,
 I
 will
 be


getting
 my
 data
 from
 a
 very
 recent
 study


conducted
 by
 a
 US-based
 nonprofit


organization
 called
 ISC2,
 International


System
 Security
 Certification


Consortium,
 described
 as
 the
 world's


largest
 IT
 security
 organization.
 This


is
 a
 very
 strong
 and
 credible
 report


that
 has
 been
 widely
 cited
 by
 news


sources
 just
 in
 time
 for
 the
 video.
 The


study
 is
 based
 on
 insights
 from
 436


US-based
 cyber
 security
 professionals


working
 at
 organizations
 of
 all
 sizes.


So
 enterprise
 organizations
 with
 staff


size
 over
 10,000
 employees
 lead
 the


adoption
 of
 AI
 and
 cyber
 security
 with


37%
 actively
 using
 AI
 platforms.
 Mid
 to


large
 companies
 between
 2
 and
 a
 half
 to


10,000
 employees
 and
 smaller
 companies


between
 100
 and
 2
 and
 a
 half
 thousand


each
 with
 33%
 adoption.
 The
 smallest


organizations
 happen
 to
 be
 the
 most


conservative
 with
 23%
 reporting
 no
 plans


to
 evaluate
 AI
 security
 tools.
 Now
 what


is
 AI
 being
 used
 for
 on
 cyersack
 teams?


AI
 is
 being
 used
 the
 most
 in
 network


monitoring
 and
 intrusion
 detection.
 This


covers
 log
 and
 data
 heavy
 functions


where
 AI
 performs
 repetitive
 and


timeintensive
 work,
 produces
 fast


responses
 and
 reaction
 times
 for


detection,
 endpoint
 protection
 and


response,
 vulnerability
 management
 and


threat
 modeling.
 All
 of
 these
 tasks


involve
 analyzing
 large
 data
 sets
 for


monitoring
 real-time
 network


information.
 And
 lastly,
 security


testing,
 which
 is
 a
 very
 time-consuming


task
 for
 cyber
 security
 personnel.
 AI


expedites
 the
 efficiency
 of
 testing
 and


ensures
 that
 it's
 being
 done
 correctly.


If
 you
 map
 what
 the
 companies
 claim
 to


be
 using
 AI
 for
 to
 what
 AI
 can
 actually


do,
 you
 will
 see
 that
 these
 things
 are


matching
 and
 AI
 is
 truly
 being
 used
 for


a
 lot
 of
 things,
 cyber
 security.
 And
 you


may
 go,
 okay,
 so
 what
 you
 said
 before


isn't
 really
 hype
 after
 all.
 and
 cyber


security
 is
 indeed
 being
 replaced.
 Hold


up,
 let's
 talk
 about
 historic
 trends.
 AI


began
 being
 widely
 integrated
 into
 cyber


security
 teams
 at
 tech
 companies


starting
 2018
 with
 rapid
 acceleration


and
 widespread
 integration
 occurring
 in


the
 early
 2020s.
 The
 first
 two
 years
 it


was
 marked
 by
 machine
 learning
 tools
 for


thread
 detection
 and
 automated
 responses


like
 blocking
 suspicious
 activity,


isolation
 affected
 endpoints
 and


behavioral
 analytics.
 Between
 2020
 and


2022,
 AI
 evolved
 to
 realtime
 analytics,


analyzing
 massive
 volumes
 of
 data
 in


real
 time
 and
 allowing
 cyers
 teams
 to


scale
 incident
 triage
 and
 response.


Also,
 AI
 systems
 improve
 their
 ability


to
 predict
 attacks.
 Starting
 2023
 until


present,
 AI
 went
 through
 widespread


adoption
 and
 autonomous
 security.


Platforms
 like
 Dark
 Trace
 and


Crowdstrike,
 for
 example,
 now
 produce


fully
 autonomous
 responses.
 Jedi
 is


being
 used
 by
 both
 defenders
 and


attackers
 for
 smarter
 deep
 fakes,


fishing,
 LLM
 poisoning,
 which
 creates


the
 need
 for
 rapid
 threat
 modeling
 and


simulation
 of
 attack
 scenarios.
 All
 of


this
 is
 to
 say
 that
 AI
 and
 cyber
 sec
 is


not
 new.
 It's
 been
 making
 its
 way
 for


the
 past
 7
 years
 and
 this
 is
 before
 Chad


GBT,
 before
 Perplexity,
 before
 AI
 first


everything.
 So,
 of
 all
 tech


specializations
 we're
 reviewing
 in
 this


series,
 cyber
 sec
 is
 a
 really
 good


example
 because
 it
 didn't
 start
 2
 years


ago.
 AI
 and
 cyber
 security
 has
 been
 used


for
 a
 long
 time.
 Okay,
 so
 AI
 and
 cyber


sec
 has
 been
 around
 for
 a
 while.
 So


teams
 must
 have
 been
 shrinking
 for
 the


past
 70
 years,
 right?
 Let's
 see.
 Looking


at
 the
 recent
 layoff
 data,
 AI


integration
 and
 cyber
 security


operations
 at
 major
 tech
 companies
 in


the
 US
 is
 set
 to
 directly
 contribute
 to


layoffs
 in
 entry-level
 and
 repetitive


operational
 roles.
 But
 what
 does
 this


really
 mean?
 Microsoft
 cut
 3%
 of
 its


global
 tech
 force
 in
 May
 and
 July
 2025.


CyberSack
 numbers
 are
 not
 disclosed,
 but


internal
 reporting
 and
 external
 analysis


confirm
 that
 security
 operations
 and


manual
 monitoring
 roles
 are
 among
 those


affected
 as
 AI
 based
 security
 scales
 up.


Amazon
 at
 least
 hundreds
 of
 jobs


eliminated
 within
 AWS
 including
 security


operations
 units
 in
 July
 2025.
 Again,


specific
 numbers
 for
 cyersack
 were
 not


disclosed.
 Meta
 laid
 off
 about
 5%
 of


workforce
 in
 2024,
 including
 sock
 and


trust
 and
 safety
 teams.
 Laid-off
 roles


were
 the
 ones
 handling
 routine
 incident


and
 policy
 workflows.
 Data
 among
 smaller


companies
 or
 non-fang
 enterprises
 is


similar
 between
 five
 to
 20%
 layoffs
 on


the
 company
 level
 specific
 cyber


security
 numbers
 not
 cited
 but
 the


affected
 rules
 include
 technical
 writers


in
 security
 teams
 manual
 reporting
 and


monitoring
 rules.
 What's
 interesting
 is


that
 offshoring
 or
 nearshoring
 is
 not


nearly
 as
 pronounced
 compared
 to
 other


tech
 rules
 such
 as
 customerf
 facing


support
 QA
 or
 software
 engineering.
 So


while
 AI
 has
 been
 integrated
 into


cyersack
 teams
 and
 the
 layoffs
 have


indeed
 affected
 cyersack
 rules
 in
 all


fairness
 they've
 been
 affected
 just
 as


much
 as
 all
 other
 rules
 across
 the
 tech


industry
 and
 the
 most
 affected
 rules
 are


in
 manual
 monitoring
 routine
 incident


handling
 basic
 vulnerability
 management.


All
 of
 this
 is
 routine
 and
 repetitive


work
 that
 AI
 can't
 objectively
 do


better.
 Now
 let's
 see
 how
 the
 team


composition
 has
 changed
 over
 the
 years.


Here's
 a
 typical
 cyber
 security
 team


composition
 at
 a
 midsize
 technative


company
 in
 the
 US
 as
 of
 2018.


In
 2020,
 we're
 seeing
 roles
 such
 as


cloud
 security
 engineer,
 especially
 in


software
 as
 a
 service,
 infrastructure
 as


a
 service,
 and
 platform
 as
 a
 service.


This
 role
 emerged
 as
 a
 core
 role
 on
 the


team
 due
 to
 the
 explosion
 of
 cloud


adoption
 and
 remote
 work.
 GRC
 expanded


their
 workload
 as
 data
 privacy
 such
 as


GDPR,
 CCPA
 became
 more
 prominent.


Usually
 the
 teams
 range
 from
 six
 to
 18


people
 of
 dedicated
 staff
 depending
 on


the
 company's
 size,
 pace
 of
 cloud


adoption
 and
 industry
 regulations.
 In


2023,
 the
 delineation
 between
 security


architect
 and
 security
 engineer
 became


much
 more
 pronounced.
 Prior
 to
 2023,


those
 was
 often
 merged
 into
 one
 role.


Sock
 analyst
 one
 and
 two
 merged
 into


one.
 The
 introduction
 of
 chief


information
 security
 officer
 as
 a
 seuite


role.
 Security
 engineer
 scope
 of


responsibilities
 expanded
 outside
 of


network
 teams
 began
 blending
 centralized


security
 functions
 with
 embedded


specialists.
 For
 example,
 embedding


security
 analysts
 into
 product
 or
 cloud


squads.
 As
 a
 PM,
 I
 can
 attest
 to
 this.
 I


was
 a
 platform
 PM
 in
 2023
 and
 my


collaboration
 with
 security
 teams
 became


much
 closer.
 This
 was
 the
 first
 year


when
 I
 truly
 felt
 that
 push
 to
 shift


left
 concept.
 In
 case
 you
 haven't
 heard


about
 the
 shift
 left
 concept,
 it
 can


apply
 to
 numerous
 things
 really,
 but
 the


core
 concept
 is
 that
 you
 start
 thinking


about,
 in
 this
 case,
 security
 early
 on


before
 you
 release
 product
 updates,


automation
 and
 AI
 and
 alert
 triage
 and


incident
 workflows.
 Analysts


increasingly
 reviewing
 and
 tuning


automated
 findings.
 Pentesting
 and


thread
 intelligence
 to
 handle
 proactive


testing
 to
 stay
 ahead
 of
 evolving


threats.
 Typical
 team
 size
 is
 very


similar,
 7
 to
 20
 people
 of
 dedicated


security
 staff.
 2025.
 Most
 routine
 event


detection,
 alert
 triage,
 reporting,
 and


vulnerability
 scanning
 are
 handled
 by
 AI


platforms.
 The
 typical
 team
 size
 is
 5
 to


12
 dedicated
 security
 folks
 on
 the
 team.


Security
 roles
 are
 embedded
 within


product
 and
 IT
 teams
 to
 ensure
 security


is
 addressed
 in
 all
 deployments.
 Shift


left
 security
 is
 a
 standard.
 AI
 risk
 and


adversarial
 defense
 are
 major
 priorities


prompting
 new
 specialized
 rules.
 ongoing


upscaling.
 All
 team
 members
 are
 expected


to
 maintain
 high
 fluency
 in
 AI
 security


management
 and
 cloudnative
 defense.
 So


as
 you
 can
 see
 despite
 AI
 being


integrated
 into
 cyersack
 for
 quite
 a
 few


years
 now
 the
 function
 isn't
 gone,
 isn't


automated
 and
 isn't
 replaced.
 Lastly,


let's
 go
 through
 the
 cyersack
 trends
 for


the
 next
 5
 years.
 Cyber
 security
 is


widely
 cited
 as
 the
 industry
 that
 will


experience
 one
 of
 the
 highest
 shortages


in
 the
 tech
 industry
 in
 the
 next
 5


years.
 Multiple
 publications
 site
 huge


numbers.
 67%
 of
 companies
 experience


skill
 gap.
 World
 shortage
 over
 4
 million


cyber
 security
 specialists.
 70%
 of


companies
 attribute
 increased
 cyber
 risk


to
 the
 skills
 gap.
 So
 wherever
 you
 look,


you
 will
 see
 that
 cyber
 security
 is
 the


job
 of
 the
 AI
 era.
 We
 will
 talk
 about


how
 the
 requirements
 are
 changing
 for


the
 junior
 specialists.
 But
 for
 the
 love


of
 God,
 please
 stop
 panicking.
 If
 there


is
 anything
 that's
 not
 dying,
 it's
 cyber


sec.
 The
 human
 factor.
 Look,
 I
 know


everybody's
 freaking
 out
 about
 AI
 taking


over
 our
 jobs
 and
 all
 the
 doom
 and
 gloom


headlines,
 but
 honestly,
 that's
 not


what's
 happening
 in
 cyber
 security
 right


now.
 The
 reality
 is
 much
 more


interesting.
 As
 AI
 gets
 smarter,
 the


cyber
 criminals
 are
 getting
 smarter,


too.
 And
 we're
 seeing
 a
 ton
 of
 attack


vectors
 that
 did
 not
 exist
 before.
 And


we
 haven't
 even
 started
 scratching
 the


surface
 of
 how
 AI
 will
 be
 used
 as
 the


time
 goes
 on.
 We're
 still
 in
 the
 early


stages
 of
 AI
 regulation.
 The
 US
 does
 not


even
 have
 proper
 federal
 laws
 governing


it
 yet.
 But
 when
 those
 regulations
 do


hit,
 it's
 going
 to
 be
 a
 lot
 of
 work
 for


cyber
 security
 teams.
 I
 learned
 this
 the


hard
 way.
 This
 was
 years
 back
 before
 the


AI
 boom.
 I
 was
 working
 on
 a
 fintech


product
 and
 that
 product
 operated
 in


Europe.
 And
 GDPR
 literally
 drove
 me


insane.
 Every
 month,
 every
 quarter,


there
 were
 new
 rules,
 new
 regulations,


and
 new
 changes,
 and
 we'd
 have
 to
 audit


our
 entire
 product
 all
 over
 again
 to


stay
 compliant.
 And
 that
 wasn't
 even
 an


AI
 product.
 And
 attack
 surfaces
 are


exploding.
 By
 2027,
 almost
 half
 of
 chief


security
 officers
 are
 going
 to
 have
 to


expand
 way
 beyond
 traditional
 cyber


security
 because
 the
 regulatory
 pressure


and
 attack
 surfaces
 are
 exploding.
 So


instead
 of
 AI
 killing
 cyber
 security


jobs,
 it's
 actually
 making
 the
 field


more
 complex
 and
 essential
 than
 it's


ever
 been.
 How
 to
 stay
 afloat?
 Here
 is
 a


scorecard
 for
 cyber
 security
 in
 the
 age


of
 AI.
 Risk
 of
 automation
 entry
 level


and
 routine
 rules
 8
 to
 nine.
 mid-level


and
 specialized
 45
 and
 advanced
 roles


that
 require
 context,
 creativity,


reasoning,
 and
 industry
 expertise
 one
 at


most.
 Now,
 I
 would
 like
 to
 address
 the


point
 around
 junior
 specialist
 being
 out


of
 demand.
 No,
 no,
 no,
 no,
 no,
 no,
 no,


no.
 Junior
 specialists,
 the
 skill
 set
 of


which
 remained
 in
 2020
 are
 out
 of


demand.
 That's
 true.
 But
 junior
 roles


aren't
 going
 anywhere.
 They're
 just
 not


the
 same
 roles
 you
 saw
 5
 years
 ago.


Which
 skills
 will
 be
 needed
 for
 junior


specialists?
 AI
 native
 sock
 analyst


working
 with
 AI
 platforms
 to
 enhance


security
 information
 and
 event


management.
 AI
 threat
 intelligence


analyst
 focus
 on
 helping
 train
 and


validate
 AI
 models
 by
 managing
 large


data
 sets
 of
 threat
 indicators.


Automation
 and
 security
 orchestration


supporting
 the
 development
 and


maintenance
 of
 security
 automation


scripts.
 AI
 governance
 and
 compliance


associates
 most
 likely
 an
 entry-level


role
 ensuring
 AI
 systems
 used
 in


security
 are
 operating
 in
 alignment
 with


ethical
 and
 compliance
 expectations.


Security
 testing
 assistance
 testing
 the


robustness
 of
 AIdriven
 security
 tools


including
 evaluating
 their
 response
 to


adversarial
 inputs.
 Cloud
 security


support
 analysts
 working
 with
 AI


enhanced
 cloud
 security
 monitoring
 tools


to
 ensure
 the
 safety,
 availability
 and


defense
 of
 key
 cloud
 services
 and
 data


repositories.
 AI
 just
 bulldozed
 the
 busy


work,
 but
 it
 did
 not
 cancel
 cyber


security.
 It
 leveled
 it
 up.
 The
 only


gigs
 that
 are
 getting
 axed
 are
 click


here
 to
 triage
 rules.
 But
 the
 jobs
 that


ask
 you
 to
 outsmart
 an
 LLM
 powered


attack
 or
 turn
 brand
 new
 attacks
 into


bulletproof
 controls
 just
 became


missionritical.
 So
 stop
 doom
 scrolling,


start
 model
 testing,
 and
 own
 the
 space


where
 GBT
 meets
 GDPR.
 Let
 me
 know
 what


you
 guys
 think
 in
 the
 comments.
 As


always,
 I
 hope
 this
 was
 helpful.
 Till


next
 time.