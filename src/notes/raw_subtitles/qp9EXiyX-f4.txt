I
 think
 you
 can't
 ignore
 the
 fact
 that


the
 sums
 of
 money
 going
 into
 this


industry
 are
 truly
 gargantuan.


Circularity
 of
 these
 deals
 is


interesting.
 Things
 can
 flip
 quite


quickly.
 One
 gawatt
 of
 a
 data
 center
 for


AI
 basically
 costs
 $50
 billion
 in
 capex.


On
 an
 annual
 running
 basis,
 it
 costs


between
 like
 another
 8
 to
 9
 maybe
 even


11
 billion
 to
 run.
 Companies
 are
 trying


to
 do
 deals
 with
 anybody
 who
 has
 any


capacity.
 In
 the
 short
 term,
 what
 many


GPU
 data
 centers
 are
 getting
 powered
 on


is
 just
 uh
 gas
 turbines.
 It's
 wild
 that


we've
 come
 to
 the
 point
 where
 we
 just


want
 like
 an
 AI
 that
 works
 on
 our


computer,
 but
 like
 to
 get
 that,
 you
 need


to
 have
 so
 many
 more
 powerful
 systems


collaborate
 with
 you.
 That
 was
 the
 first


time
 you
 had
 a
 system
 that
 could
 show


its
 reasoning.
 Since
 then
 to
 now,
 the


progress
 is
 pretty
 astounding.
 Hi,
 I'm


Matt
 Turk
 from
 First
 Mark.
 Welcome
 to


the
 Matt
 podcast.
 Today,
 I'm
 excited
 to


welcome
 back
 Nathan
 Bernes,
 founder
 of


Air
 Street
 Capital,
 to
 discuss
 the
 2025


edition
 of
 his
 state
 of
 AI
 report,
 a


must
 readad
 on
 where
 the
 field
 really


is.
 We
 cover
 a
 lot
 including
 why
 power


is
 a
 new
 bottleneck,
 reasoning
 and
 chain


of
 action
 robotics
 and
 the
 business


reality
 revenue
 margins
 and
 what
 it


means
 for
 builders
 and
 investors.
 Please


enjoy
 this
 great
 conversation
 with


Nathan.


>> Nathan,
 great
 to
 have
 you
 back.


>> Thanks
 for
 having
 me.


>> The
 state
 of
 AI
 2025
 is
 out
 and
 um
 as


always,
 it's
 essential
 reading
 for


anyone
 who's
 serious
 about
 understanding


AI.
 This
 year
 it's
 312
 slice
 of


goodness.
 A
 bit
 of
 a
 big
 year
 in
 AI.


>> Every
 year
 I
 try
 to
 cut
 it
 down
 a
 little


bit.
 Um
 but
 this
 year
 I
 just
 felt
 like


we
 were
 sharing
 it
 with
 various
 sub


communities
 of
 the
 AI
 of
 the
 AI


community.
 Uh
 and
 each
 time
 we
 did
 that


the
 robotics
 folks
 would
 be
 like
 hey


it's
 a
 little
 bit
 light
 on
 robotics.
 Can


you
 add
 some
 more?
 And
 then
 we
 sent
 it


to
 the
 bio
 folks
 and
 like
 why
 don't
 you


site
 this
 paper
 or
 that
 paper?
 And
 hence


the
 inflation.


>> Amazing.
 All right.
 So
 we're
 certainly


not
 going
 to
 cover
 everything
 in
 this


conversation.
 Obviously,
 as
 always,
 the


report
 is
 available
 in
 its
 entirety
 for


free
 at
 stateof.ai.


So,
 um
 we're
 going
 to
 riff
 on
 some
 of


the
 most
 important
 topics
 and
 ideas
 in


the
 report,
 but
 obviously
 people
 can
 go


and
 check
 out
 the
 report
 directly
 for


more.
 All
 right.
 So,
 uh
 starting
 from


the
 top
 in
 the
 world
 of
 research,
 you


mentioned
 that
 2025
 was
 a
 year
 reasoning


got
 real.
 Uh
 so
 how
 far
 have
 we
 come
 in


the
 last
 12
 months?


>> I'd
 say
 pretty
 far.
 Um
 about
 12
 months


ago
 or
 so
 we
 had
 I
 think
 the
 very
 early


inklings
 of
 it
 with
 01
 preview
 uh


potentially
 around
 like
 this
 time
 last


year.
 And
 uh
 that
 was
 the
 first
 time
 you


had
 a
 system
 that
 could
 kind
 of
 show
 its


reasoning,
 show
 its
 step-wise
 process
 to


get
 to
 a
 more
 complicated
 answer.
 And


this
 has
 generally
 been
 the
 dream
 in
 AI


for
 a
 long
 time.
 And
 uh
 and
 since
 then


to
 now
 I
 would
 say
 like
 the
 progress
 is


pretty
 astounding.
 One
 of
 the
 areas
 that


that
 progress
 has
 kind
 of
 unveiled


itself
 is
 in
 mathematics
 and
 other


verifiable
 domains
 where
 you
 can
 like


explicitly
 say
 yes
 the
 system
 works
 or


doesn't
 work
 and
 you
 know
 we
 saw
 gold


medals
 on
 the
 international
 math


olympiad
 by
 a
 couple
 labs
 including


openai
 and
 deep
 mind
 that
 area
 probably


with
 uh
 if
 you'd
 asked
 experts
 again
 how


long
 it
 would
 have
 taken
 would
 probably


been
 a
 decade
 then
 areas
 a
 bit
 closer
 to


my
 heart
 in
 biology
 and
 science
 we've


seen
 reasoning
 models
 uh
 kind
 of
 be
 used


as
 a
 as
 an
 AI
 co-scientist
 so
 just
 as
 a


human
 would
 reading
 lots
 of
 papers,


planning
 experiments,
 running
 the


experiments
 and
 then
 doing
 data
 analysis


and
 then
 reformulating
 their
 hypothesis


as
 a
 result.
 There's
 examples
 of
 uh


models
 doing
 that
 in
 lie
 of
 human
 which


is
 exciting
 because
 there's
 way
 way
 too


many
 papers
 uh
 to
 read
 you
 know
 AI


people
 kind
 of
 complain
 that
 it's
 like


50,000
 papers
 a
 year
 and
 say
 in
 biology


and
 chemistry
 and
 physics
 is
 probably
 an


order
 of
 magnitude
 more
 than
 that.
 Um


and
 so
 uh
 deep
 mind
 has
 shown
 that
 you


can
 integrate
 this
 kind
 of
 reasoning


model
 to
 sort
 of
 decipher
 new
 targets


for
 disease
 new
 mechanisms
 that
 were


actually
 also
 proven
 in
 a
 wet
 lab


scenario
 um
 postfacto.


We've
 gone
 from
 systems
 that
 were
 kind


of
 dumb
 stoastic
 paris
 to
 now
 they
 can


solve
 pretty
 meaningful
 challenges
 that


I'd
 say
 like
 even
 a
 smart
 human


couldn't.
 And
 uh
 still
 in
 research
 you


talk
 a
 little
 bit
 in
 the
 report
 or
 a
 lot


in
 the
 report
 about
 robotics
 and
 this


evolution
 towards
 uh
 a
 system
 of
 action


or
 chain
 of
 chain
 of
 action
 going
 from


chain
 of
 thought
 to
 ch
 of
 action.
 What's


happening
 there?


>> Yeah,
 I
 mean
 the
 gist
 is
 probably
 two


years
 ago
 robotics
 was
 kind
 of
 a
 dead


end.
 Um
 openi
 had
 disbandled
 its
 uh
 its


robot
 team
 that
 was
 famous
 for
 solving


the
 Rubik's
 cube
 using
 uh
 locomotion


with
 the
 hand.
 And
 so
 now
 robotics
 is


probably
 you
 know
 going
 through
 a


cambrian
 explosion.
 There's
 so
 much


excitement
 uh
 and
 just
 as
 how
 language


models
 informed
 biology,
 now
 language


models
 are
 also
 informing
 robotics.
 So


what
 you're
 referring
 to
 here
 is
 a
 sort


of
 reasoning
 uh
 process
 for
 robots
 where


a
 system
 is
 no
 longer
 just
 perceiving


the
 environment
 and
 deciding
 what
 to
 act


and
 sort
 of
 acting,
 but
 it's
 uh
 we've


separated
 those
 steps.
 So
 now
 you
 have
 a


reasoning
 model
 that
 looks
 at
 a
 task
 and


tries
 to
 plan
 steps
 that
 a
 robot
 would


need
 to
 do
 to
 execute
 that
 task
 and
 then


passes
 that
 plan
 over
 to
 uh
 an
 actuator


which
 goes
 and
 actually
 implements
 the


plan
 and
 that's
 what's
 called
 chain
 of


action.
 Uh
 and
 here
 the
 Allen
 Institute


was
 one
 of
 the
 first
 to
 really
 push
 this


and
 very
 swiftly
 thereafter
 uh
 Gemini


also
 followed
 and
 and
 uh
 we
 have
 some


companies
 including
 Serak
 that
 are


implying
 this
 uh
 into
 the
 real
 world.
 So


it
 does
 genuinely
 work.
 It's
 not
 just


like
 a
 research
 thing.
 So
 we
 think
 the


big
 moment
 for
 robotics
 is
 uh
 upon
 us


because
 we
 all
 collectively
 have
 been
 uh


talking
 about
 this
 for
 a
 very
 long
 time.


>> Yeah.
 Yeah.
 Well,
 I'd
 say
 it
 really
 is


upon
 us
 in
 the
 industrial
 sector
 um
 in


logistics
 and
 warehousing
 uh
 kind
 of


more
 constrained
 environments
 or
 very


repetitive
 tasks.
 There
 is
 the
 sort
 of


more
 holy
 grail
 of
 this
 kind
 of
 embodied


um
 uh
 humanlike
 form
 factor
 and
 putting


a
 model
 on
 that
 might
 even
 be
 the
 same


model
 that's
 been
 used
 in
 uh
 in


warehousing.
 Uh,
 a
 lot
 of
 money
 is
 going


into
 that.
 But
 my
 personal
 bet
 is
 I
 is
 I


think
 it's
 going
 to
 be
 the
 humanoid


space
 is
 going
 to
 look
 much
 more
 like


self-driving
 where
 we
 have
 some
 very


good
 isolated
 demos,
 but
 the
 longtail


will
 kill
 you.
 Uh,


>> hopefully
 not
 uh
 literally.


>> Yeah.
 Um,
 and
 uh
 and
 so
 we
 we're
 going


to
 go
 through
 many
 false
 starts.
 I
 think


this
 is
 just
 the
 start.


>> Okay,
 great.
 So
 a
 big
 year
 in
 uh


robotics
 and
 reasoning.
 Um
 for
 uh
 people


listening
 to
 this,
 if
 you're
 interested


in
 deep
 dives
 into
 reasoning
 and
 RL
 and


the
 evolution
 of
 AI
 systems,
 uh
 we've


done
 a
 bunch
 of
 great
 episodes
 recently


with
 Shto
 from
 Enthropic,
 Jerry
 from


OpenAI,
 and
 then
 Julian
 from
 Enthropic.


Uh
 if
 you're
 curious
 to
 learn
 more,
 let


let's
 move
 on
 to
 the
 business
 uh
 of
 AI.


Uh
 you
 mentioned
 in
 the
 report
 that
 the


business
 of
 AI
 finally
 caught
 up
 with


the
 hype.
 Uh
 what
 caught
 your
 attention


in
 terms
 of
 fact
 stats
 uh
 in
 the
 last
 12


months?


>> Yeah,
 a
 couple
 of
 them.
 Uh
 again
 like


where
 we
 came
 from
 one
 or
 two
 years
 ago


was
 just
 tons
 of
 money
 going
 into
 this


segment
 building
 models
 lot
 of
 usage
 but


not
 clear
 where
 the
 revenue
 would
 come


from.
 I
 think
 it
 was
 maybe
 open
 was


making
 $50
 million
 or
 something
 two


years
 ago.
 it
 was
 very
 unclear
 how
 they


would
 ever
 hit
 like
 billions
 of
 revenue.


Um,
 and
 nowadays
 I
 think
 if
 you
 sum
 sort


of
 the
 top
 20
 or
 so
 uh
 major
 AI


companies
 from
 the
 labs
 to
 the
 most


popular
 kind
 of
 vertical
 applications,


you
 know,
 across
 them
 they're
 making


tens
 of
 billions
 of
 dollars
 of
 revenue.


Um,
 you
 can
 look
 at
 the
 smaller
 scale


companies
 which
 you
 know
 are
 growing


from
 zero
 to
 20
 million
 or
 20
 million


plus.
 uh
 as
 a
 group
 they
 generally
 grow


about
 60%
 faster
 on
 a
 quarterly
 basis


than
 nonAI
 companies.
 Um
 we've
 all
 seen


like
 the
 famous
 charts
 about
 ARR
 or
 non


ARR
 it's
 unclear.
 Uh
 but
 uh
 you
 know


very
 steep
 curves
 for
 various
 coding


companies.
 Um
 and
 perhaps
 most


interestingly
 across
 a
 segment
 of
 43,000


or
 so
 uh
 US
 customers
 we
 work
 with
 ramp


to
 show
 that
 retention
 of
 uh


subscriptions
 on
 AI
 products
 across
 this


customer
 set
 has
 really
 improved


marketkedly
 since
 2022.
 Around
 2022
 was


around
 the
 50%
 after
 12
 months.
 uh
 and


now
 in
 25
 it's
 hitting
 around
 80%.
 Um


and
 the
 second
 stat
 in
 that
 analysis


that
 was
 interesting
 was
 the
 total
 spend


on
 AI
 products
 uh
 per
 customer
 kind
 of


went
 up
 from
 $35,000
 or
 so
 uh
 maybe
 two


years
 ago.
 Now
 it's
 around
 half
 a


million
 and
 it's
 predicted
 to
 hit
 a


million
 dollars
 next
 year.


>> And
 you
 mentioned
 in
 your
 ramp
 stats
 44%


of
 US
 businesses
 now
 pay
 for
 AI
 tools.


So
 they
 pay
 more
 but
 there's
 there's


there's
 a
 ton
 of
 businesses
 using
 it.


>> Yeah.
 Exactly.
 And
 and
 there
 might
 be


some
 sampling
 bias
 slightly
 to
 you
 know


what
 kind
 of
 companies
 uh
 use
 ramp
 in


the first
 place.


>> Yeah.
 So
 slightly
 more
 modern
 you
 know


tech
 forward
 companies
 but
 a
 leading


indicator
 I
 think
 of
 where
 things
 could


go.


>> And
 then
 you
 had
 your
 own
 survey
 right


of
 1200
 AI
 practitioners.


>> Yeah.
 Yeah.


>> And
 what
 did
 that
 say?


>> Yeah
 that
 was
 I
 I
 was
 surprised.
 Uh


obviously
 bias
 is
 more
 towards
 uh
 you


know
 pretty
 well
 educated
 US
 European


professionals.
 Um,
 a
 lot
 of
 people
 in


there
 have
 at least
 undergrad,
 master's


degrees,
 maybe
 even
 more.
 Um,
 but
 it's


like
 95%
 of
 people
 use
 AI
 in
 their


personal
 life
 and
 in
 their
 professional


life.
 U,
 about
 76%
 of
 people
 pay
 out
 of


their
 own
 pocket
 for
 it.
 It's
 like
 10%


of
 people
 pay
 more
 than
 200
 bucks
 a


month
 for
 it.
 Uh,
 and
 then
 looking
 at


the
 organizations
 that
 they
 work
 at,


it's
 like
 70%
 of
 those
 organizations
 are


spending
 a
 ton
 more
 or
 more
 than
 they


did
 in
 the
 past
 on
 AI.
 the
 reasons
 that


they
 gave
 for
 what
 why
 they
 might
 not
 be


spending
 more
 or
 what
 problems
 they


have.
 It's
 like
 all
 the
 classic
 like
 new


technology
 stuff
 like
 it's
 a
 bit
 hard
 to


configure.
 It's
 uh
 you
 know
 I
 haven't


really
 figured
 out
 the
 ROI
 yet
 because
 I


need
 to
 do
 more
 customization.
 There's


like
 some
 data
 privacy
 issues
 that
 I


have
 and
 I
 think
 all
 these
 things
 are


kind
 of
 solvable
 like
 it's
 not
 rocket


science
 how
 to
 solve
 these
 things.
 Yeah,


it
 feels
 like
 we
 very
 much
 live
 like


this.
 You're
 in
 the
 world
 of
 shadow
 AI


uh
 in
 companies
 where
 I
 mean
 to


reconcile
 it's
 imperfect
 but
 reconcile


your
 two
 stats.
 44%
 of
 businesses
 uh
 use


AI
 yet
 95%
 of
 of
 people
 individually
 use


AI.
 So
 there's
 a
 bunch
 of
 people
 as
 as


you
 as
 you're
 alluding
 to
 that
 use
 AI
 at


work
 without
 being
 officially


authorized.


>> Yeah.
 And
 I
 think
 there's
 still
 a
 big


like
 education
 gap.
 I
 mean
 there
 was
 a
 a


study
 banded
 around
 a
 couple
 of
 weeks


ago
 where
 you
 know
 it
 said
 95%
 of


businesses
 like
 get
 no
 value
 from
 AI.


>> Very
 very
 controversial
 survey.


>> Yeah.
 Yeah.
 But
 I
 think


>> 95%
 is
 the
 number
 right.
 Like
 everything


is
 95%.


>> But
 I
 think
 that
 there
 it
 turned
 out
 it


was
 like
 not
 the
 models
 that
 were
 bad.


It's
 like
 the
 implementations
 of
 them


were
 not
 great.
 Uh
 so
 I
 think
 there's


just
 a
 big
 education
 gap
 for
 how
 how
 you


should
 like
 you
 know
 update
 your
 view
 of


your
 own
 uh
 day-to-day
 tasks
 and
 and


apply
 what
 capabilities
 you
 know
 models


have
 and
 then
 uh
 and
 think
 about
 like


hey
 should
 I
 be
 doing
 this
 task
 myself


or
 can
 I
 farm
 it
 out
 to
 a
 model
 and
 and


there's
 definitely
 a
 delta
 of
 companies


that
 really
 get
 this
 done
 well
 and


others
 that
 are
 like
 basically
 clueless.


What
 do
 you
 make
 of
 the
 margin


debate
 uh
 as
 an
 investor
 and
 intory


analyst?
 Maybe
 maybe
 uh
 recap
 uh
 what


what
 that
 debate
 is
 and
 then
 what
 do
 you


think
 about
 it
 at
 a
 high
 level?


Basically
 the
 the
 margin
 problem
 is
 um


for
 many
 many
 customers
 of
 uh
 large


model
 companies
 their
 margins
 are


basically
 dictated
 by
 how
 much
 the
 model


vendor
 charges
 them
 for.
 Uh
 now
 here


there's
 some
 issues
 because
 right
 now


model
 vendors
 are
 charging
 the
 same


amount
 per
 token.
 So
 if
 you're
 a
 hedge


fund
 analyst
 and
 I'm
 a
 student
 you
 know


your
 use
 case
 is
 clearly
 more


financially
 valuable
 than
 mine
 but
 we


pay
 the
 same
 amount
 for
 the
 token


assuming
 we
 use
 the
 same
 model.
 There


are
 some
 use
 cases
 that
 are
 more


reasoning
 heavy
 towards
 what
 we


discussed
 before
 and
 they
 consume
 a
 ton


of
 tokens
 and
 the
 pricing
 that
 a


customer
 uh
 pays
 for
 that
 product
 might


not
 be
 fit
 for
 the
 amount
 of
 work
 the
 AI


system
 is
 doing.
 Um
 and
 so
 there
 are


cases
 where
 um
 these
 kind
 of
 vertical


products
 are
 making
 margin
 gross
 margins


of
 like
 30%.
 And
 sometimes
 they
 get


worse
 with
 scale
 uh
 because
 you
 do
 have


some
 edge
 users
 that
 like
 really
 pump


the
 system
 and
 you
 can't
 like
 price


discriminate
 or
 they
 haven't
 managed
 to.


And
 then
 you
 have
 uh
 some
 segment
 of
 of


um
 of
 model
 users
 that
 don't
 that
 have
 a


both
 a
 paid
 plan
 and
 a
 free
 plan.
 And


it's
 not
 clear
 whether
 they
 include
 uh


the
 costs
 of
 running
 the
 free
 plan
 in


their
 gross
 margin.


>> So
 they
 sort
 of
 just
 look
 at
 their
 paid


customers.


Uh
 there's
 you
 know
 some
 creative


accounting
 standards
 going
 on
 there.
 Uh


and
 then
 you
 have
 the
 model
 vendors


themselves
 and
 what
 is
 their
 margin.
 Uh


and
 I
 think
 what's
 interesting
 in
 the


last
 year
 is
 you've
 seen
 um
 CEOs
 of


these
 model
 companies
 say
 hey
 if
 we
 if


we
 basically
 look
 at
 um
 sort
 of
 in
 in


financial
 analysis
 terms
 like
 a
 layer


cake
 of
 like
 what
 revenue
 is
 generated


by
 each
 vintage
 of
 model
 over
 time
 um
 it


looks
 like
 prior
 models
 are
 uh


profitable.
 So
 the
 amount
 of
 money
 we've


spent
 to
 build
 them
 is
 less
 than
 the


amount
 of
 money
 that
 we've
 generated


with
 them
 over
 time
 assuming
 a
 certain


margin
 of
 inference
 cost.
 And
 so
 so


really
 these
 these
 labs
 are
 like
 not
 not


profitable
 because
 vastly
 more
 resources


going
 into
 developing
 next
 generation


systems
 than
 than
 the
 prior
 ones.
 Um
 but


as
 you
 and
 I
 both
 know
 like
 there
 are


companies
 here
 that
 are
 making
 very
 very


good
 margins
 on
 uh
 serving
 uh
 their
 AI


systems
 like
 70
 80
 sometimes
 90%


depending
 on
 the
 modality.
 Um
 and
 so


like
 with
 everything
 the
 average
 number


sucks.
 Um,
 but
 like
 when
 you
 look
 at
 the


best
 companies,
 it's
 really
 good.


>> And
 just
 to
 drive
 it
 home,
 the
 the the


the
 companies
 using
 those
 models,
 we're


talking
 about
 the,
 you
 know,
 in
 part
 the


the
 all
 the
 what
 used
 to
 be
 known
 as


thin
 wrapper.
 So
 the
 vendors
 that


happened
 to
 be
 powered
 by
 those
 models.


So
 uh
 the
 the
 cursors,
 the
 wind
 surfs


yeah
 Reddit
 like
 all
 and
 and
 all
 the


whatever
 legal
 financial
 AI
 um
 startups


>> um
 as
 a
 as
 as
 examples.
 Um
 the
 other
 big


debate
 uh
 in
 the
 business
 of
 AI
 of


course
 uh
 is
 the
 bubble
 uh
 question.


What's
 your


>> what's
 your
 take?
 Are
 we
 in
 an
 AI


bubble?
 Are
 we
 not
 in
 an
 AI
 bubble?


>> Yeah.


I
 think
 like
 with
 most
 things
 in
 in


markets,
 there
 are
 probably
 localized


bubbles
 all
 over
 the
 place.
 And
 I
 think


at
 a
 at
 a
 high
 level,
 what's
 interesting


in
 terms
 of
 vibes
 and
 who's
 calling


bubbles
 and
 who's
 not
 like
 the
 finance


crowd
 in
 New
 York
 is
 definitely
 talking


about
 bubbles
 a
 lot
 more
 than
 what
 we're


talking
 about
 in
 San
 Francisco
 where


their
 their
 view
 is
 like
 this
 is
 the


golden
 era
 of
 AI
 and
 a
 lot
 of
 things
 are


working.
 We
 have
 so
 much
 more
 to
 to
 do.


Uh
 you
 know,
 compute
 buildouts
 are


enabling
 us
 to
 experiment
 a
 lot
 faster.


uh
 you
 know
 this
 huge
 flood
 of
 like


talent
 that's
 built
 the
 consumer


internet
 and
 cloud
 computing
 is
 moving


into
 AI
 and
 with
 that
 is
 bringing
 a
 lot


of
 optimization
 techniques
 and
 knowledge


that
 AI
 researchers
 didn't
 have
 when


they
 built
 the
 first
 generations
 of
 Chad


GBPT
 etc.
 But
 I
 think
 you
 you
 can't


ignore
 the
 fact
 that
 the
 the
 sums
 of


money
 going
 into
 this
 industry
 are
 truly


gargantuan.
 Um
 you
 know
 like
 500
 billion


to
 build
 uh
 Stargate
 and
 then
 uh
 you


know
 couple
 hundred
 billion
 here,
 a


couple
 hundred
 billion
 there.
 Like


pretty
 soon
 it's
 real
 money.
 And
 then


the
 um
 and
 then
 like
 the
 circularity
 of


these
 deals
 is
 like
 is
 interesting.
 Uh


of
 course
 Nvidia
 is
 at
 the
 center
 of


this
 and
 it
 has
 incentives
 to
 use
 its


its
 balance
 sheet
 to
 sort
 of
 spin
 the


wheel
 faster.
 Uh
 and
 then
 perhaps
 more


concerningly,
 you
 have
 this
 sort
 of


offloading
 of
 of
 debt
 um
 from
 big


companies.
 For
 example,
 Meta
 that
 raises


tens
 of
 billions
 of
 dollars
 to
 fuel
 it


data
 center
 ambitions,
 but
 that
 doesn't


sit
 on
 Meta's
 balance
 sheet.
 Some
 of


this
 is
 like
 catnip
 to
 financial


engineers.
 Um
 but
 uh
 but
 yeah,
 it
 rests


on
 certain
 assumptions
 that
 everything


is
 going
 to
 keep
 going
 up
 and
 to
 the


right
 and
 that
 rates
 don't
 materially


change.
 Um,
 and
 just
 given
 how
 like


uh
 I
 suppose
 precarious
 various
 aspects


of
 the
 economy
 are
 and
 how
 like


sensitive
 geopolitics
 are,
 things
 can


flip
 like
 quite
 quickly.
 Um,
 but
 I
 think


that's
 like
 the
 major
 risk.
 The
 the
 risk


I'm
 less
 worried
 about
 is
 the
 stuff


doesn't
 work


>> because
 I
 think
 it
 does
 work.


>> So
 it's
 a
 more
 question
 of
 uh
 timing
 to


play
 it
 back
 that
 the
 supply
 uh
 phase
 of


the
 market
 is
 met
 by
 an
 equally
 strong


or
 hopefully
 stronger
 demand
 side.
 Yeah,


there's
 that
 and
 then
 just
 the
 just
 the


the
 nuances
 of
 like
 the
 terms
 on
 the


debt
 and
 what
 trigger
 events
 are
 whether


rates
 get
 repriced
 and
 then
 you
 know


like
 investors
 behave
 very
 differently


once
 rates
 change
 and
 and
 um
 and
 flows


of
 money
 can
 be
 quite
 like
 violent.
 It's


interesting
 what
 you're
 saying
 about


the,
 you
 know,
 the
 dichotomy
 between
 um


Wall
 Street
 and
 the
 the
 West
 Coast.
 Um


also
 because
 uh
 when
 you
 think
 about
 it,


there's
 actually
 not
 that
 many
 fuel
 play


AI
 companies
 in
 public
 markets,
 right?
 A


lot
 of
 the
 action
 is
 happening
 in


>> private
 markets.
 So
 effectively,
 if


you're
 a
 Wall
 Street/hedge
 fund


investor,
 you
 you you
 invest
 in
 Nvidia,


you
 invest
 in
 the
 Mag
 7.
 That's
 pretty


much
 it,
 right?
 Palanteer
 C3
 AI


>> maybe
 you
 buy
 soft
 bank
 for
 its
 position


open
 AI


>> yeah
 pretty
 much
 like
 a
 lot
 of
 it
 is


indirect
 or
 you
 invest
 in
 power
 and


energy
 or
 like
 related
 players
 coreweave


I
 guess
 but
 it's
 it's
 very
 it's
 very


small
 so
 it
 feels
 like
 there
 that


tension
 as
 well


>> yeah
 but
 I
 think
 it's
 also
 the
 crowd


that
 you
 hang
 out
 with


>> um
 I
 mean
 and
 I


>> do
 you
 live
 in
 a
 house
 in
 San
 Francisco


with
 correct
 two
 other
 or
 three
 other
 AI


geniuses


>> correct
 correct
 correct
 or
 do
 you
 just


consume
 the
 outputs
 uh
 of
 that
 of
 those


kinds
 of
 conversations
 on
 Twitter
 and


then
 try
 to
 like


>> yes


>> piece
 together
 your
 own
 world
 view
 and


and
 I
 think
 the
 other
 part
 of
 this
 is


like
 I
 I
 don't
 think
 some
 of
 those


individuals
 are
 really
 shilling
 that


much
 anymore
 I
 think
 they
 do
 genuinely


believe
 what
 they
 say
 and
 they
 are
 at


the
 core
 face
 of
 the
 advancements
 of


these
 technologies
 and
 so
 if
 you
 know


they've
 been
 saying
 for
 the
 last
 50


times
 like
 hey
 this
 stuff
 is
 working


there's
 lots
 of
 implementations
 we
 can


improve
 or
 like
 things
 we
 can
 tweak
 or


new
 experiments
 that'll
 yield
 better


capabilities
 and
 that
 has
 happened.
 At


some
 point
 you
 got
 to
 be
 like
 maybe


they're
 right.


>> Another
 aspect
 of
 this
 that's


fascinating
 to
 me
 is
 the


again
 like
 the
 the
 the
 the
 sort
 of


dichotomy
 between
 some
 of
 the
 I
 would


call
 them
 the
 old
 guard
 and
 the
 newer


younger
 kind
 of
 folks.
 So,
 you
 know,


from
 Rich
 Sutton
 to
 Yan
 Lan
 to
 um,
 you


know,
 obviously
 Jeffrey
 Hinton,
 a
 lot
 of


those
 guys
 who
 are
 absolutely
 the


godfathers
 of
 the
 space
 and
 built
 this


entire
 thing
 and
 are
 still
 extremely


active
 uh,
 today
 on
 top
 of
 everything


say
 that
 um,
 LLMs
 are
 just
 not
 going
 to


get
 us
 there


>> uh,
 or
 that
 we
 should
 uh,
 just
 do


everything
 with
 RL.
 And
 then
 you
 know


meanwhile
 the
 the
 the
 younger
 guys
 and


they
 tend
 to
 be
 at
 places
 like
 anthropic


and
 open
 air
 so
 maybe
 they
 do
 have
 an


agenda
 but
 they're
 all
 saying
 well
 we're


just
 scratching
 the
 surface
 of
 what
 we


can
 do
 with
 those
 modern
 systems.


>> Yeah.
 Yeah.


>> I
 think
 do
 both.
 Um
 but
 but
 yeah
 I
 think


for
 me
 it's
 it's
 mostly
 um
 what
 are


kinds
 of
 new
 problems
 that
 you
 can
 that


you
 can
 work
 on
 and
 solve
 with
 this


technology.
 And
 I
 think
 it's
 becoming


more
 popular
 to
 believe
 like
 the


overhang
 of
 of
 like
 problems
 we
 can


solve
 in
 enterprise
 for
 consumers
 and


science
 with
 the
 tools
 we
 have
 today
 is


huge.
 Um
 and
 so
 even
 if
 a
 lot
 of
 this


compute
 buildout
 doesn't
 go
 towards
 like


dreaming
 up
 the
 next
 uh
 transformer


architecture
 but
 goes
 into
 uh
 improving


the
 unit
 economics
 of
 serving
 AI
 systems


for
 everybody
 and
 makes
 it
 easier
 so
 you


don't
 have
 to
 be
 like
 some
 prompt
 master


uh
 to
 elicit
 a
 behavior
 you
 want
 for


your
 task.
 I
 think
 that's
 not
 good.


>> All right,
 let's
 uh
 switch
 to
 the


physical
 reality
 that
 this
 whole
 uh


stack
 sits
 on.
 So
 infrastructure,
 data


centers,
 uh
 energy.
 You
 you you


mentioned
 in
 the
 deck
 that
 uh
 power
 uh


has
 become
 the
 new
 bottleneck.
 What
 is


your
 sense
 of
 the
 state
 of
 play
 in
 the


energy
 procurement
 game?
 The
 the
 biggest


stat
 for
 me
 is
 one
 gigawatt
 of
 a
 data


center
 for
 AI
 basically
 costs
 $50


billion
 in
 capex.
 Um
 and
 uh
 on
 an
 annual


running
 basis
 it
 costs
 between
 like


another
 8
 to
 nine
 8
 to9
 to
 maybe
 even
 11


billion
 to
 run.
 And
 so
 uh
 when
 you
 have


just
 you
 know
 casually
 a
 10
 gawatt
 data


center
 uh
 that's
 like
 a
 lot
 of
 money.
 Um


and
 um
 and
 so
 one
 of
 the
 problems
 is


like
 where
 does
 this
 energy
 come
 from?


Uh
 you
 know
 traditionally
 it
 would
 be


from
 I
 don't
 know
 coal
 uh
 or
 natural
 gas


um
 potentially
 solar
 or
 ideally
 at
 some


point
 in
 the
 future
 nuclear
 and
 what


we're
 seeing
 is
 it
 right
 now
 companies


are
 trying
 to
 do
 deals
 with
 anybody
 who


has
 any
 capacity.
 So
 we
 chronicle
 some


deals
 with
 uh
 future
 uh
 nuclear
 uh
 you


know
 reactor
 companies
 then
 that
 would


take
 maybe
 a
 decade
 or
 two
 decades
 to


deliver.
 Um
 you
 know
 famously


>> yeah
 that's
 Google
 inking
 a
 PPA
 deal.


>> Yeah.


>> Uh
 with
 CFS
 to
 buy
 200
 megawatt
 of


electricity
 from
 a
 planned


>> fusion
 plants.
 So
 the
 the
 the
 plan
 does


not
 exist.


>> It
 does
 not
 exist.
 Yeah.
 And
 then
 last


year
 we
 documented
 the
 sort
 of
 uh


restarting
 of
 uh
 3M
 island.
 Um


>> yes


>> the
 nuclear
 facility
 which
 was


controversial
 in
 the
 past.
 Um
 and
 um
 and


then
 uh
 in
 the
 short
 term
 what
 many
 uh


GPU
 uh
 data
 centers
 are
 getting
 powered


on
 is
 is
 just
 uh
 gas
 turbines
 and


because
 these
 can
 get
 set
 up
 a
 lot


faster
 but
 that
 has
 other
 issues
 like


they're
 super
 loud
 um
 and
 there's
 demand


outside
 of
 the
 US
 for
 these
 things
 and


so
 now
 basically
 US
 tech
 companies
 are


paying
 more
 to
 repatriate
 like
 uh
 some


of
 the
 supply
 that
 should
 have
 been


shipped
 abroad.
 the
 the
 other
 issue
 is


the
 the
 grid
 and
 like
 to
 what
 degree
 the


the
 grid
 can
 even
 tolerate
 data
 centers


getting
 plugged
 into
 it.
 Now
 obviously


like
 these
 turbines
 are
 off-grid.
 Uh
 so


it
 has
 some
 advantages
 but
 uh
 in
 China


for
 example
 we
 do
 some
 analysis
 between


like
 eur
 between
 uh
 the
 US
 and
 China


with
 regards
 to
 energy
 and
 China
 has
 a


lot
 more
 like
 slack
 in
 its
 system
 to


plug
 in
 um
 for
 any
 unpredicted
 uh


demands
 in
 energy.
 Uh
 the
 UK
 famously


cannot
 really
 tolerate
 more
 data
 centers


on
 its
 grid.
 wrapping
 all
 this
 together


is
 driving
 um
 some
 of
 the
 like


offshoring
 of
 data
 centers
 towards
 uh


energy-rich
 countries
 whether
 that's
 the


UAE
 uh
 or
 even
 uh
 Norway
 and
 uh
 and
 then


with
 that
 comes
 a
 lot
 of
 like
 geo


geopolitics
 of
 uh
 are
 these
 nations
 your


friend
 or
 or
 potentially
 not
 and
 how
 do


you
 ensure
 uh
 access
 to
 this
 regardless


of
 your
 administration
 change
 and
 other


things.
 So
 it
 it
 yeah
 it's
 it's
 wild


that
 we've
 come
 to
 the
 point
 where
 you


know
 we
 just
 want
 like
 an
 AI
 that
 works


on
 our
 computer
 but
 like
 to
 get
 that
 you


need
 to
 have
 so
 many
 more
 powerful


systems
 uh
 collaborate
 with
 you.


>> Yeah
 and
 I
 was
 just
 looking
 for
 the


slide
 as
 as as
 you
 spoke
 uh
 especially


for
 United
 States
 versus
 China
 we're


talking
 about
 the
 dramatic
 difference


where
 uh
 the
 capacity
 added
 in
 2024
 for


the
 US
 if
 I
 read
 this
 correctly
 was
 48.6


6
 GW


>> whereas
 China
 was
 429


>> gaw


>> the
 other
 thing
 that's
 interesting
 is
 um


the
 at
 least
 the
 states
 in
 the
 US
 uh
 or


actually
 also
 internationally
 that
 um


that
 are
 good
 for
 hosting
 data
 centers


because
 there's
 energy
 typically
 are


extremely
 dry
 and
 uh
 and
 we
 also


chronicle
 the
 water
 usage
 that's
 needed


for
 cooling
 of
 these
 data
 centers
 and
 so


if
 your
 state
 is
 super
 dry
 where
 do
 you


get
 the
 water
 from
 uh
 is
 that
 actually


going
 to
 detract
 away
 from
 human


populations
 that
 need
 the
 water?
 Then


you
 have
 this
 whole
 like
 recycling
 of


water
 which
 could
 potentially
 like
 yield


just
 like
 bad
 quality
 water
 getting


circulated
 into
 the
 water
 system.


>> So
 the
 sustainability
 aspect
 to
 all
 of


this
 seems
 uh
 extraordinarily
 important


>> yet
 uh
 under


discussed
 at
 least
 that's
 the
 my
 my


perspective.
 Is
 is
 that
 is
 that
 correct?


Do
 do
 people
 actually
 care
 and
 do


something
 about
 the
 sustainability


aspect
 of
 this?
 Well,
 a
 year
 or
 two
 ago,


big
 companies
 did
 make
 commitments
 to
 be


green
 as
 of
 you
 know,
 2030.
 And
 then
 as


soon
 as
 they
 started
 inking
 deals
 with


uh
 you
 know,
 nuclear
 companies
 and
 uh


and
 and
 various
 energy
 providers
 for


data
 centers,
 all
 those
 commitments


basically
 got
 like
 washed
 away.
 Um
 so
 it


seems
 like
 maybe
 they
 care,
 but
 the


corporate
 priorities
 of
 making
 AI
 work


have
 way
 outweighed
 the
 environmental


constraints.
 That's
 what's
 happened.
 But


I
 think
 again
 going
 back
 to
 like
 the


politics
 side
 of
 things,
 I
 don't
 think


everybody's
 very
 happy
 about
 this.


Particularly
 there's
 this
 like
 growth
 of


nimiism,
 this
 like
 not
 in
 my
 backyard.


Uh
 and
 uh
 and
 and
 I
 do
 think
 that
 uh


people
 generally
 don't
 want
 to
 have
 a


data
 center
 in
 their
 backyard.
 Uh
 and
 I


think
 that's
 going
 to
 drive
 some
 of
 the


political
 agendas
 like
 going
 forward


whether
 it's
 in
 the
 US
 or
 or
 other


countries.
 So
 yes,
 people
 do
 care
 about


environmentalism.


companies
 have
 sort
 of
 washed
 that
 away


but
 it's
 going
 to
 I
 think
 it's
 going
 to


come
 back.


>> If
 we
 talk
 about
 infrastructure
 uh


obviously
 we
 have
 to
 talk
 about
 Nvidia


feels
 like
 it's
 been
 uh
 another


extraordinary


>> uh
 last
 12
 months
 for
 uh
 Nvidia.


>> Y


>> do
 you
 uh
 see
 Nvidia
 continue
 to
 break


away
 as
 like
 the
 undisputed
 number
 one


in
 the
 market
 or or
 do
 you
 think
 that


sooner
 or
 later
 we're
 going
 to
 end
 up


with
 a
 multi-ilicon
 kind
 of
 world?
 I


think
 it's
 gonna
 be
 955
 to
 95%.


>> Um,


>> revisited.


>> Yeah,
 exactly.
 Yeah.
 Um,
 yeah.
 So,
 you


know,
 for
 context,
 when
 we
 did
 the


executive
 summary
 last
 year,
 we
 put


Nvidia,
 you
 know,
 hit
 1
 trillion
 for
 the


first
 time
 and
 now
 we
 had
 to
 change
 that


to
 4
 trillion.
 We
 look
 at
 uh
 all
 the


open
 source
 AI
 research
 papers
 every


year,
 which
 is
 about
 49,000
 or
 so.
 And


then,
 uh,
 programmatically
 determine


which
 chipsets
 are
 used
 in
 those
 papers.


So
 we
 know
 like
 hey
 an
 AI
 researcher
 is


doing
 a
 study
 on
 uh
 I
 don't
 know
 some


new
 model
 and
 in
 their
 in
 their


experimental
 setup
 they
 say
 you
 know
 we


train
 the
 model
 for
 x
 number
 of
 GPU


hours
 on
 uh
 whatever
 chip
 and
 uh
 if
 you


do
 that
 analysis
 you
 basically
 find
 that


90%
 of
 uh
 all
 papers
 make
 use
 of
 a


Nvidia
 chip
 out
 of
 that
 same
 analysis
 we


did
 find
 that
 AMD
 is
 sort
 of
 popping
 up


a
 very
 little
 bit
 um
 Apple
 silicon
 is
 as


well
 I
 think
 it's
 just
 because
 the


computer
 the
 MacBook
 is
 getting
 so
 good


that
 people
 are
 doing
 local
 training
 uh


and
 experiments
 on
 their
 computer


>> and
 Broadcom
 is
 experiencing
 a
 a


resurrection
 of
 some
 sort
 as
 well,


right?


>> Yeah.
 Yeah.
 Exactly.
 Yeah,
 it
 has.
 Uh
 I


think
 it's
 maybe
 a
 decade
 ago
 they


bought
 a
 company
 that
 now
 is
 kind
 of
 the


internal
 team
 doing
 this
 custom
 AS6
 for


uh
 Google's
 TPU
 and
 uh
 you
 know
 more


recently
 they
 announced
 a
 deal
 with


OpenAI
 also
 to
 do
 uh
 a
 custom
 chip.
 And


a
 high
 level
 what's
 interesting
 with
 the


rise
 of
 Broadcom
 is
 basically
 GPUs
 have


been
 the
 the
 dominant
 chipset
 for
 a
 long


time
 as
 the
 uh
 kind
 of
 nature
 of
 the


neural
 network
 or
 other
 kind
 of
 AI


system
 that
 you're
 running
 on
 the


hardware
 was
 still
 changing
 very
 rapidly


but
 as
 soon
 as
 you
 get
 to
 a
 point
 where


there's
 some
 convergence
 on
 an


architecture
 that's
 looks
 like
 it's


stable
 and
 is
 revenue
 generating
 and


developers
 are
 coming
 to
 uh
 sort
 of
 work


on
 it
 and
 confirm
 that
 it
 is
 like
 the


then
 you
 can
 flip
 towards
 doing
 a
 custom


chip
 that's
 built
 to
 extract
 the
 most


value
 out
 of
 that
 architecture.
 And
 so


the
 rise
 of
 Broadcom
 basically
 tells
 you


like
 there's
 strong
 forces
 that
 are


saying
 like
 the
 transformer
 is
 the


thing.
 But
 at
 the
 end
 of
 the
 day
 like
 we


also
 look
 at
 how
 would
 your
 dollar
 be


best
 used
 as
 an
 investor
 if
 you
 wanted


to
 bet
 on
 chip
 companies.
 And
 uh
 and
 in


the
 graph
 in
 in
 the
 report,
 we
 look
 at


sort
 of
 six
 of
 the
 major
 contenders
 uh


to
 Nvidia
 and
 basically
 said,
 you
 know,


if
 you
 bought
 Nvidia
 stock
 on
 the
 day
 of


uh
 the
 announcement
 of
 all
 the
 like


private
 uh
 rounds
 in
 these
 companies,


what
 would
 the
 value
 of
 your
 stock
 be
 in


Nvidia
 versus
 these
 companies?
 And
 uh
 if


I
 recall
 correctly,
 it's
 basically
 12x


in
 Nvidia
 versus
 2x
 in
 um
 in
 these


competitors.
 And
 the
 trend
 was
 roughly


the
 same
 last
 year.
 Uh
 so
 I
 think
 I


think
 it's
 a
 little
 bit
 of
 a
 diff


difficult
 beast
 to
 to
 bet
 against.


>> Yes,
 I
 was
 uh
 I
 was
 looking
 for
 that
 uh


slide
 as
 you
 were
 uh
 speaking.
 It's
 for


anybody
 that
 looks
 at
 the
 report
 that


slide
 166


that
 says
 um
 what
 would
 have
 happened
 if


investors
 had
 just
 bought
 the
 equivalent


amount
 of
 Nvidia
 stock
 at
 that
 day's


price.
 The
 7.5
 billion
 would
 be
 worth
 85


billion
 in
 Nvidia
 stock
 today.
 12x


>> uh
 versus
 14
 billion2x
 for
 its


contenders
 and
 the
 contenders
 being


Grobra,
 Samanova,
 Celestial,
 Graphcore


and
 in
 China,
 Cambercon
 has
 uh


experienced
 you
 know
 a
 big
 run.
 Um
 this


is
 you
 know
 a
 private
 company
 that
 then


went
 public
 on
 on
 Chinese
 stock
 exchange


to
 build
 custom
 AS6
 for
 for
 AI
 and
 and


that
 was
 driven
 mostly
 by
 uh
 the


geopolitical
 sort
 of
 zigzagging
 on


policy
 with
 regards
 to
 exporting
 custom


um
 Nvidia
 chips
 to
 China
 the
 H20
 which


at
 some
 point
 was
 deemed
 to
 be
 okay
 by


the
 government
 and
 then
 deemed
 to
 be
 not


okay
 uh
 but
 then
 okay
 if
 uh
 15
 to
 20%
 of


the
 revenue
 was
 passed
 back
 to
 to
 the
 US


government
 and
 then
 uh
 and
 then
 um


someone
 in
 the
 someone
 high
 up
 in
 the
 US


administration
 said
 you
 know
 our
 goal
 is


basically
 to
 ship
 the
 like
 crappy
 stuff


to
 China
 and
 at
 that
 point
 the
 Chinese


said
 like
 no
 thank
 you
 and


>> and
 effectively
 said
 no
 one
 can
 buy


Nvidia
 chips
 and
 then
 camera
 stock
 rips


>> and
 that's
 Huawei
 as
 well
 right
 that's


the
 emergence
 of
 a
 separate
 Chinese
 uh


full
 stack


from
 the
 the
 models
 which
 we'll
 probably


talk
 about
 that
 at
 some
 point
 in
 this


conversation
 of
 open
 source
 but
 very


much
 at
 the
 player.
 So
 that's
 what
 you


mentioned
 and
 then
 Huawei
 whatever
 the


model
 is
 becoming
 the
 sort
 of
 default


chip
 for
 the
 Chinese
 stack.


>> Yeah.
 Yeah.
 Yeah.
 And
 there's
 some


interplay
 between
 the
 government
 trying


to
 get
 Deep
 Seek
 and
 other
 labs
 to
 to


run
 their
 models
 on
 uh
 on
 Chinese
 chips.


And
 there's
 been
 rumors
 that
 this
 is
 why


a
 lot
 of
 the
 new
 generations
 of
 Chinese


models
 uh
 have
 slowed
 down.
 Um


particularly
 Deep
 Seek
 like
 there
 people


are
 waiting
 for
 for
 the
 next
 uh
 next
 R1.


So
 like
 R2
 and
 uh
 and
 allegedly
 it's


because
 it's
 just
 hard
 to
 run
 it
 on


Huawei.


>> To
 to
 double
 click
 on
 on
 on
 uh
 something


that
 you
 mentioned
 a
 few
 minutes
 ago.
 Um


>> talk
 about
 uh
 sovereign
 AI
 uh
 and
 uh


what
 you've
 seen


>> people
 do.
 It
 seems
 to
 have
 been
 a
 big


theme
 of
 the
 year.
 You
 mentioned
 open
 AI


in
 uh
 Norway,
 India
 and
 and
 UAE.
 What's


happening
 in
 that
 world?
 Yeah.


>> That
 part
 of
 the
 world.


>> Yeah.
 Yeah.
 So
 the
 idea
 with
 sovereign


AI
 is
 that
 nation
 states
 want
 to
 be
 uh


at
 like
 able
 to
 control
 basically
 their


fate
 with
 regards
 to
 AI.
 So
 that's
 uh


running
 models
 as
 training
 models
 um


having
 chips
 uh
 and
 um
 this
 is
 basically


because
 you
 know
 nation
 states
 want
 to


have
 control
 over
 their
 energy
 control


over
 their
 currency,
 control
 over
 their


infrastructure
 and
 AI
 is
 deemed
 to
 be
 uh


kind
 of
 equivalent
 to
 those
 categories.


Um
 and
 so
 ever
 since
 the
 White
 House


announcement
 of
 500
 billion
 in
 January


uh
 various
 nation
 states
 have
 followed


suit
 saying
 you
 know
 we
 have
 our
 own


initiative
 and
 it's
 to
 the
 tune
 of


billions
 of
 dollars
 uh
 etc
 around
 the


world
 and
 Nvidia
 has
 even
 started


marketing
 this
 as
 like
 a
 like
 a
 a
 new


kind
 of
 product
 line
 basically
 for
 its


business
 that
 currently
 generates
 I


think
 around
 $20
 billion
 worth.
 Um
 so


it's
 it's
 real
 money.
 Um
 and
 so
 they're


forming
 partnerships
 with
 various
 nation


states
 uh
 to
 provide
 data
 centers
 there


that
 are
 run
 locally.
 Um
 and
 uh
 and
 in


theory
 that
 should
 give
 like
 countries


comfort
 that
 uh
 their
 access
 to
 AI
 can't


be
 turned
 off.
 That's
 the
 idea.
 I


personally
 think
 it's
 a
 bit
 more
 of
 a
 of


an
 alignment
 between
 political
 agendas


where
 particularly
 in
 the
 US
 it's
 really


about
 re-industrialization
 like
 onoring


of
 key
 industries
 and
 building
 you
 know


manufacturing
 and
 things
 like
 that
 which


is
 I
 think
 one
 of
 the
 reasons
 why
 these


AI
 data
 centers
 are
 getting
 rebranded
 as


AI
 factories
 and
 so
 that's
 the
 the


political
 part
 um
 and
 that's
 getting


aligned
 with
 um
 uh
 just
 the
 need
 of


countries
 to
 get
 access
 to
 this


technology
 so
 I
 think
 it's
 more


marketing


than
 it
 is
 like
 a
 real
 policy
 because
 at


the
 end
 of
 the
 day
 if
 you
 buy
 your
 stack


from
 uh
 from
 from
 the
 US
 and
 you're
 not


an
 ally
 of
 the
 US
 at
 some
 point
 then


they'll
 just
 switch
 it
 off.
 Um,
 and
 so


part
 of
 this
 is
 like
 sovereignty
 washing


I
 think
 and
 it
 also
 like
 oversimplifies


the
 very
 interconnected
 nature
 and


ecosystem
 aspect
 of
 of
 AI
 where
 not
 just


about
 the
 chip
 it's
 about
 uh
 the


developer
 ecosystem
 um
 how
 you
 actually


run
 it
 where
 your
 training
 data
 comes


from
 um
 and
 uh
 and
 all
 the
 like


infrastructure
 like
 data
 tools
 and
 and


whatnot
 that
 that
 sit
 around
 this


>> although
 uh
 that's
 where
 open
 source


plays
 an
 important
 role
 right
 if
 get


your
 AI
 from
 OpenAI
 and
 indeed
 uh
 you


are
 a
 USLI
 but
 you
 no
 longer
 are
 USLI


for
 whatever
 reason
 there's
 a
 risk
 that


you
 could
 be
 turned
 off
 but
 if
 you
 have


sovereign
 data
 center
 and
 with
 a
 bunch


of
 like
 chips
 running
 and
 then
 you
 run


open
 source
 on
 top
 of
 it
 like
 presumably


you
 are
 safe


>> which
 is
 then
 uh
 interesting
 because


where
 is
 the
 most
 popular
 open
 source


coming
 from
 now?


>> Yes,
 China.
 China.


>> Um


>> although
 interestingly
 I
 think
 since
 you


uh
 published
 the
 report
 there's
 been
 the


announcement
 of
 a
 very
 large
 investment


in
 reflection
 AI
 which
 is


>> a
 New
 York
 and
 San
 Francisco
 based
 uh


company
 that
 just
 raised
 2
 billion


>> uh
 to
 build
 uh
 the
 US
 equivalent
 of
 the


Chinese
 models
 in
 in
 a
 world
 where
 Llama


>> and
 Meta
 have
 sort
 of
 um
 gone
 in
 a


different
 direction.


>> Yep.
 Yep.
 I
 think
 this
 is
 this


fascinating
 um
 because
 part
 of
 the
 AI


action
 plan
 uh
 that
 was
 published
 by
 the


US
 government
 a
 couple
 of
 months
 ago
 now


um
 you
 know
 articulated
 the
 need
 for


having
 this
 American
 AI
 stack.
 So


they're
 moving
 away
 from
 like
 diffusion


controls
 and
 more
 towards
 just
 buy
 our


stuff.
 And
 then
 one
 of
 the
 other
 aspects


of
 that
 action
 plan
 was
 around
 open


source
 and
 like
 and
 and
 sort
 of
 leading


in
 that
 direction.
 And
 of
 course
 as
 you


said
 like
 meta
 stepped
 back
 and
 into
 the


fold
 came
 Quen.
 um
 I
 think
 50%
 of
 all


model
 derivatives
 um
 being
 downloaded


from
 HuggingFace
 or
 Coinbase
 now
 um


hundreds
 of
 millions
 of
 downloads


partially
 because
 they're
 very
 they
 come


in
 very
 accessible
 shapes
 and
 flavors.


So
 as
 a
 result
 of
 that
 we
 sort
 of


predicted
 in
 the
 report
 that
 uh
 uh
 that


a
 major
 you
 know
 AI
 lab
 would
 lean
 back


into
 open
 source
 to
 win
 um
 basically


brownie
 points
 with
 the
 government
 and


then
 the
 next
 day
 this
 financing


happened.


>> Oh
 amazing
 great
 uh
 great
 timing.
 Yeah.


And
 I
 think
 you
 you
 said
 in
 the
 report


as
 well
 that
 um
 your
 sense
 was
 that


OpenAI
 was
 sort
 of
 um
 forced
 for
 lack
 of


a
 better
 term
 uh
 into
 releasing
 an
 open


source
 model
 to
 be
 on
 the
 on
 the
 right


side
 of
 history.


>> Yeah,
 I
 I
 think
 that's
 one
 of
 them
 and


then
 the
 second
 one
 probably
 dovetales


with
 their
 announcement
 with
 AMD
 and
 I


say
 that
 because
 uh
 you
 know
 quite


recently
 semi
 analysis
 uh
 kind
 of


published
 this
 benchmarking
 data
 set


where
 they
 run
 models
 on
 various
 clouds


to
 sort
 of
 benchmark
 them.
 Um,
 and


actually
 GPT
 OSS
 like
 looks
 pretty
 good


on
 AMD.
 Um,
 and
 so
 one
 could
 imagine


that
 um,
 like
 there
 were
 some
 uh,


optimizations
 and
 there
 actually
 were


optimizations
 to
 to
 GPTO
 OSS.
 So
 it
 runs


nicely
 on
 AMD.
 It
 has
 support
 from
 their


framework
 from
 day
 one.
 The
 uh,
 the


parameterization
 of
 the
 model
 is
 is
 uh,


to
 the
 point
 where
 you
 can
 run
 it
 on
 a


single
 AMD
 chip.
 And
 there's
 some
 other


nuances
 to
 their
 attention
 mechanisms


that
 they
 customize
 to
 make
 it
 work


really
 good
 on
 AMD.
 Um,
 and
 to
 the
 point


around
 like
 the
 circular
 economy
 stuff


that
 we
 discussed
 a
 little
 while
 ago,


um,
 there's
 uh,
 like
 another
 financial


sweetener
 in
 the
 deal
 where
 OpenAI
 has


warrants
 in
 AMD
 if
 the
 stock
 price
 hits


600.
 Um,
 and
 so
 you
 can
 see
 how
 how


there's
 a
 lot
 of
 like
 incentives
 to
 this


game
 of
 both
 like
 aligning
 with
 US


government,
 helping
 developers,
 which
 is


a
 good
 thing,
 but
 also
 like
 helping
 one


of
 your
 vendors
 uh
 improve,
 which


frankly
 it
 does
 need
 help
 and
 it
 and
 it


should
 improve,
 but
 also
 getting
 some


financial
 sweetener
 as
 a
 result
 of
 that,


which
 could
 help
 you
 kind
 of
 make
 the


flywheel
 spin
 faster.


>> And
 uh
 since
 we're
 talking
 about


circularity,
 uh
 talk
 about
 concentration


as
 well.
 So
 maybe
 as
 an
 echo
 to
 the


conversation
 about
 the
 bubble
 a
 few


minutes
 ago,
 it
 does
 feel
 like
 this
 um


AI
 economy
 has
 a
 lot
 of
 um
 depending
 on


how
 you
 look
 at
 it
 from
 funky
 to
 scary


things.


>> Yeah.
 Yeah.
 Well,
 a
 lot
 of
 Nvidia's


revenue
 comes
 from
 uh
 the
 major
 uh
 you


know
 hyperscalers
 or
 or
 um
 or
 neoclouds.


So
 you
 know
 it's
 like
 Meta
 like
 XAI,


Google,
 Amazon
 um
 then
 Cororee
 and
 then


a
 lot
 of
 Cororee's
 revenue
 also
 comes


from
 Microsoft
 on
 the
 way
 back.
 I
 think


it's
 just
 this
 challenge
 with
 with
 AI


progress
 that
 we've
 uh
 you
 know
 very


meaningfully
 shift
 from
 shifted
 from
 I


think
 the
 GPT3
 era
 to
 now
 of
 basically


scale
 like
 rate
 limits
 your
 progress
 and


uh
 it's
 no
 longer
 like
 a
 couple
 of


people
 in
 a
 dorm
 room
 that
 can
 really


build
 something
 uh
 transformational
 if


they
 want
 to
 advance
 like
 AI


capabilities.
 It's
 really
 um
 it's
 really


big
 boy
 land
 now.
 Um
 and
 so
 w
 with
 that


comes
 just
 different
 dynamics
 like
 you


have
 to
 be
 good
 at
 capital
 raising.
 You


have
 to
 align
 yourself
 with
 uh
 with


nation
 states.
 You
 have
 to align


yourself
 with
 Wall
 Street.
 Uh
 these
 are


all
 I
 think
 contributing
 to
 the
 big
 vibe


shifts
 that
 you've
 seen
 in
 in
 the


culture
 of
 AI
 labs.


>> What
 what
 do
 you
 mean
 by
 that?
 What


>> well
 you
 know
 for
 example
 there
 there


were
 some
 labs
 like
 Anthropic
 that
 were


built
 you
 know
 to
 to
 really
 push
 the


safety
 agenda.
 Um
 because
 you
 know
 if
 we


didn't
 do
 that
 the
 rational
 went
 that


you
 know
 we
 could
 lead
 to
 the


extermination
 of
 humanity
 right
 um
 and
 I


think
 quite
 recently
 like
 Dario
 was


interviewed
 by
 uh
 Mark
 Ben
 off
 uh
 just


this
 past
 week
 and
 asked
 about
 like
 some


of
 these
 data
 center
 buildouts
 and
 uh


and
 you
 know
 he
 said
 something
 along
 the


lines
 of
 yeah
 there's
 a
 lot
 of
 money


going
 into
 this
 a
 lot
 of
 cost
 but
 at
 the


end
 of
 the
 day
 the
 only
 thing
 that


matters
 is
 revenue
 like
 I
 don't
 think
 he


would
 have
 said
 that
 you
 know
 on
 the


founding
 day
 of
 anthropic
 and
 you
 know


it's
 it's
 just
 the
 reality
 that
 that
 the


table
 stakes
 in
 this
 game
 have
 changed


and
 with
 that
 you
 know
 entrepreneurs


have
 to
 update
 their
 priors
 and
 um
 and


you
 know
 change
 their
 strategy
 a
 little


bit.
 And
 so
 we
 document
 some
 of
 this
 in


like
 sort
 of
 the
 blooper
 section
 of
 the


report


>> uh
 which
 is
 uh
 which
 is
 just
 like
 how


how
 much
 of
 a
 sort
 of
 pendulum
 um


swinging
 we've
 we've
 noticed
 in
 um
 in


corporate
 priorities
 at
 AI
 labs
 um
 as
 a


result
 of
 the
 extreme
 financialization


of
 the
 sector.
 are
 you
 uh
 encouraged
 or


discouraged
 by
 some
 of
 the
 stuff
 that's


happening
 at
 the
 app
 layer
 in
 in in
 in


particular
 uh
 you
 know
 whether
 that's
 uh


AI
 slop
 uh
 or
 uh
 yeah
 focus
 on
 on
 on


revenue
 and
 um
 you
 know
 versus
 the
 ideal


like
 do
 do
 you
 think
 that's
 um


inevitable
 but
 good
 or
 what
 do
 you
 make


of
 it?
 I
 think
 I
 think
 we're
 just
 at


such
 an
 early
 era
 to
 like
 see
 how
 you


can
 maximally
 extract
 value
 and
 create


interesting
 experiences
 for
 people
 with


this
 AI
 uh
 technology
 that
 you
 know
 we


have
 to
 try
 a
 lot
 of
 different
 things.


Um
 at
 the
 end
 of
 the
 day,
 you
 know,
 if


if
 you're
 a
 lab
 that
 expends
 tens
 of


billions
 of
 dollars
 on
 uh
 on
 R&D,
 you
 do


have
 to
 have
 a
 way
 to
 generate
 money
 to


to
 fund
 that.
 Um
 I
 think
 that's
 just


reality.
 And
 I
 think
 like
 this
 the
 slop


thing,
 I
 mean,
 if
 it's
 bad,
 people
 won't


look
 at
 it.
 Um,
 and
 uh,
 if
 it
 if
 people


look
 at
 it
 and
 they
 enjoy
 it,
 then
 you


know,
 good
 good
 for
 them.
 Like
 I
 don't


necessarily
 have
 like
 a
 huge
 problem


with
 that.
 Um,
 as
 long
 as
 uh,
 as
 long
 as


like
 where
 I'm
 spending
 my
 time
 uh,
 I


find
 is
 uh
 is
 useful.
 And
 so
 that's
 why


I
 end
 up
 spending
 a
 lot
 of
 my
 time
 on


like
 enterprise
 software
 automation,


biology,
 like
 doing
 new
 discoveries
 and


drug
 discovery,
 like
 defense
 technology


and
 autonomy,
 u
 robotics.
 I
 think
 these


are
 all
 like
 very
 important
 macro


drivers
 of
 of
 the
 economy.
 Um,
 and
 as
 we


move
 into
 an
 era
 where
 like
 intelligence


is,
 uh,
 you
 know,
 increasingly
 cheap
 and


accessible,
 uh,
 there's
 just
 so
 many


different
 like
 instantiations
 of


products
 that
 we
 need
 to
 build
 that
 are


really
 meaningful.
 And
 you
 know,
 if
 a


byproduct
 is
 that
 is
 you
 have
 a
 social


media
 app
 with
 like
 AI
 videos,
 like


that's
 fine,
 too.
 You
 know,
 we
 all
 have


to
 like
 unwind,


>> right?
 You
 mentioned
 safety
 a
 minute


ago.
 I'd
 love
 to,
 uh,
 riff
 on
 that
 theme


a
 little
 bit.
 Uh,
 IP
 rights,
 safety,


regulatory,


uh,
 a
 little
 bit
 like
 the
 sustainability


thing
 that
 we
 were
 discussing
 earlier.


It
 sort
 of
 feels
 like
 that
 that
 whole


world
 uh
 has
 um
 sort
 of
 slowed
 down
 in


terms
 of
 like
 progress
 maybe
 starting


with
 regulatory.
 Do
 do
 you
 think
 that


regulatory
 is
 anywhere
 near
 catching
 up


or
 providing
 an
 adequate
 response
 to


what's
 going
 on?


>> Yeah,
 I'd
 say
 like
 a
 big
 180
 on
 that


one.
 I
 mean
 clearly
 the
 Trump


administration
 unwound
 a
 lot
 of
 the


Biden
 era
 policies
 uh
 whether
 that
 was


on
 uh
 diffusion
 you
 know
 trying
 to
 push


a
 lot
 of
 state
 level
 legislation
 against


AI
 the
 uh
 over
 in
 Europe
 like
 the
 EU
 AI


act
 has
 had
 um
 delays
 in
 implementation


there's
 only
 three
 member
 states
 that


have
 actually
 implemented
 it
 and
 now


we're
 finally
 seeing
 how
 even
 its


authors
 are
 saying
 maybe
 we
 went
 too
 far


particularly
 as
 we
 look
 at
 progress
 uh


the
 speed
 of
 progress
 in
 the
 US
 in
 China


compared
 to
 Europe.
 Um,
 you
 know,


famously
 this
 bill
 in
 California,
 um,


you
 know,
 rate
 limiting
 AI
 progress
 was


really
 watered
 down
 into
 what
 eventually


became
 SB53.


Um,
 there
 were,
 you
 know,
 many,
 many


proposed
 bills.
 I
 think
 over
 a
 thousand,


10%
 of
 them
 actually
 made
 their
 way
 into


laws.
 Um,
 so
 it's
 still
 kind
 of


patchworky,
 but
 like
 at
 a
 meta
 level


looks
 like
 we
 traded
 regulation
 for
 just


going
 faster.
 It
 was
 perhaps
 like
 best


encompassed
 by
 uh
 by
 the
 shift
 between


the
 AI
 safety
 summit
 in
 the
 UK
 which
 was


at
 Bletchley
 which
 basically
 pledged


like
 a
 whole
 network
 of
 uh
 AI
 safety


institutes
 and
 conferences
 that
 would


happen
 over
 the
 the
 coming
 years.
 um
 to


then
 the
 subsequent
 event
 in
 Paris
 which


was
 called
 the
 AI
 action
 summit


completely
 different
 than
 AI
 safety


summit


>> and
 JD
 Vance
 saying
 something
 along
 the


lines
 of
 basically
 like
 AI
 progress
 is


not
 going
 to
 happen
 if
 we
 keep
 hang


ringing
 over
 AI
 safety
 and
 the
 US


basically
 didn't
 show
 up
 to
 a
 few
 of
 the


subsequent
 conferences
 and
 we
 have
 this


in
 the
 like
 safety
 RIP
 section
 of
 like


very
 few
 people
 seem
 to
 care
 about
 it


anymore


>> and
 to
 the
 to
 the
 vibe
 shift
 like
 even


the
 more
 uh
 dumerist
 parts
 of
 the
 ecos


system
 have
 uh
 kind
 of
 quieted
 it
 down,


right?
 It
 feels
 like
 the
 debate
 has
 gone


from
 kill
 all
 all
 of
 us
 to
 more
 like


well
 is
 LM
 LM
 RL
 the
 the
 better
 way
 to


get
 to
 AGI
 kind
 of
 so
 the
 the
 the


nessayers
 have
 like
 shifted
 their
 their


kind
 of
 like
 approach.


>> Yeah.
 Yeah.
 And
 I
 think
 it's
 become


Yeah.
 less
 about
 this
 existential
 crisis


and
 more
 about
 which
 capabilities
 look


concerning
 in
 models.
 And
 you
 know,


there's
 been
 some
 kind
 of
 interesting
 uh


data
 points
 that
 we
 chronicle
 in
 the


report.
 Like
 for
 example,


uh
 models
 can
 increasingly
 know
 that


they're
 in
 a
 simulation
 or
 or
 know
 that


they're
 in
 an
 evaluation
 and
 then
 change


their
 behavior
 as
 a
 result
 of
 that.


There's
 examples
 of
 uh
 models
 trying
 to


like
 exfiltrate
 their
 own
 weights.


There's
 another
 uh
 piece
 of
 work
 that
 we


show
 which
 is
 around
 the
 cyber
 security


capabilities
 of
 models
 which
 is


basically
 measuring
 how
 long
 does
 a


human
 take
 to
 solve
 various
 categories


of
 cyber
 tasks
 and
 then
 putting
 models


at
 the
 against
 the
 same
 tasks
 and
 saying


you
 know
 how
 long
 would
 it
 take
 for
 them


to
 solve
 it
 at
 a
 50%
 pass
 rate
 and
 there


it
 looks
 like
 again
 the
 capabilities
 on


cyber
 tasks
 of
 models
 are
 doubling
 every


6
 months
 and
 then
 so
 this
 is
 cast


against
 the
 fact
 that
 independent
 safety


organizations
 There's
 maybe
 like
 five
 or


six.
 These
 are
 usually
 nonprofits
 uh


that
 are
 still
 nonprofits
 uh
 or
 private


companies.
 They
 spend
 on
 average
 134


million
 a
 year
 in
 total.


>> Total
 budget
 across
 all
 of
 them.


>> Yeah.
 Across
 all
 of
 them.
 Exactly.
 And


that's
 cast
 against
 roughly
 like
 92


billion
 uh
 across
 all
 AI
 work
 for
 the


major
 labs.
 So
 basically
 like
 the
 same


amount
 of
 money
 uh
 that
 a
 big
 lab
 would


spend
 in
 one
 day
 is
 spent
 in
 an
 entire


year
 across
 these
 safety
 orgs.


130
 million
 aka
 a
 seed
 round
 in


in
 a
 week
 old
 AI
 startup.


>> Correct.


>> Correct.


>> What
 about
 uh
 data
 rights?
 That
 was


another
 part
 of
 that
 just
 general
 kind


of
 like
 policy
 universe
 that
 was
 very
 uh


sensitive
 and
 controversial.
 There's


been
 some
 some
 evolution
 in
 the
 last


year,
 right?


>> Yeah.
 Major
 changes.
 I
 think
 it
 looks
 a


little
 bit
 like
 the
 sort
 of
 on
 demand


commerce
 war
 of
 you
 know
 the
 the
 Uber


style
 of
 do
 something
 that's
 a
 bit
 like


dodgy
 for
 a
 long
 time
 get
 to
 scale
 and


then
 get
 once
 you're
 at
 scale
 you're


kind
 of
 too
 big
 to
 to
 kill
 and
 so
 and
 so


similarly
 in
 AI
 like
 a
 lot
 of
 companies


took
 slightly
 dodgy
 practices
 uh
 to


acquire
 training
 data
 and
 then
 got
 to


scale
 and
 they
 were
 subject
 to
 many


lawsuits
 in
 the
 last
 year
 or
 two
 uh


particularly
 in
 in
 the
 media
 sector


whether
 that's
 um
 you
 know
 music
 or


video
 uh
 and
 books


And
 then
 there's
 a
 biggest
 uh
 settlement


that
 happened
 in
 the
 last
 few
 months


with
 Enthropic
 that
 agreed
 to
 pay
 out
 1


and a.5
 billion.
 Uh
 and
 this
 was
 settled


out
 of
 court.
 So
 it
 can't
 be
 used
 as


precedence
 but
 but
 generally
 shows
 the


the
 rough
 price
 uh
 tag
 that's
 affiliate


that's
 associated
 with
 uh
 with
 human


works
 uh
 in
 the
 context
 of
 AI
 training.


And
 then
 separately
 there's
 been
 you


know
 dozens
 if
 not
 hundred
 organizations


that
 have
 agreed
 content
 licensing
 deals


with
 various
 model
 companies
 as
 I
 think


the
 the
 power
 shift
 has
 has
 really


happened
 1.5
 billion
 still
 being
 a
 drop


in
 the
 bucket
 for
 a
 company
 like


Enthropic.
 Interestingly,
 does
 that


create
 a
 moat
 over
 time?
 Meaning
 that


you
 have
 to
 be
 large
 enough
 to
 be
 able


to
 afford
 that
 kind
 of
 money
 uh
 that


you're
 going
 to
 pay
 to
 data
 rights
 if


you
 want
 to
 do
 pre-training.
 And
 does
 it


make
 it
 harder
 to
 start
 a
 company
 that


needs
 to
 do
 pre-training
 from
 scratch?


>> Uh
 in
 one
 sense,
 yes.
 In
 another
 sense,


uh
 if
 you
 can
 exploit
 the
 knowledge
 of


these
 frontier
 models,
 particularly
 from


open
 source,
 and
 then
 generate
 synthetic


data
 could
 be
 a
 way
 to
 get
 to
 capable


models
 faster.
 And
 also
 I
 think
 I
 mean


you'll
 have
 many
 guests
 that
 go
 deep
 on


this
 but
 um
 but
 even
 the
 the
 nature
 of


pre-training
 and
 what
 uh
 information
 is


included
 in
 the
 corpus
 and
 at
 what
 point


it's
 kind
 of
 like
 data
 mixtures
 as


people
 call
 it
 has
 been
 evolving
 over


time.
 So
 I
 think
 we're
 just
 getting


smarter
 about
 how
 to
 do
 pre-training


rather
 than
 just
 shoving
 everything
 we


have
 into
 a
 bucket
 and
 like
 seeing
 what


happens.
 And
 so
 as
 a
 result
 of
 that
 you


might
 not
 necessarily
 have
 to
 spend
 the


exact
 same
 amount
 of
 money
 to
 get
 a


capable
 system.
 And
 you
 know,
 some
 of


this
 kind
 of
 came
 out
 from
 the
 Deep
 Seek


paper.


>> You
 mentioned
 cyber.
 Let's
 riff
 on
 this


a
 little
 bit.
 Obviously,
 AI
 creates
 new


attack
 vectors.
 What
 should
 people
 know?


>> I
 mean,
 as
 of
 a
 couple
 years
 ago,
 people


are
 obsessed
 with
 deep
 fakes
 or
 like


these
 videos
 of
 people
 saying
 things


that
 they
 didn't
 actually
 say,
 and
 they


were
 still
 kind
 of
 grainy
 and
 not


awesome.
 Uh,
 clearly
 those
 deep
 fakes


getting
 a
 lot
 better.
 Um
 although
 quite


positively
 it
 looks
 like
 we're
 actually


quite
 good
 at
 detecting
 them
 and
 and


realizing
 oh
 that's
 like


>> um
 but
 there's
 more
 advanced
 uh


approaches
 now
 where
 you
 know
 models
 can


be
 capable
 of
 coercion
 um
 particularly


for
 some
 individuals
 who
 are
 sensitive


to
 this
 kind
 of
 uh
 risk.
 There's
 been


examples
 of
 for
 example
 North
 Korean


state
 actors
 uh
 trying
 to
 infiltrate


other
 states
 using
 AI
 systems.
 Uh
 you


could
 potentially
 even
 package
 a


language
 model
 in
 malware
 and
 then
 have


it
 installed
 in
 a
 computer
 and
 then
 it


kind
 of
 wakes
 up
 and
 because
 it's
 not


dumb,
 it's
 a
 language
 model,
 it
 can
 do


things
 on
 computers
 and
 that's
 kind
 of


scary.
 The
 rise
 of
 MCP,
 I
 think
 this


model
 context
 protocol,
 which
 is
 kind
 of


like
 a
 USB
 stick
 for
 uh
 for
 all
 sorts
 of


of
 uh
 of
 data
 connectors,
 is
 cool


because
 now
 models
 can
 be
 smart.
 They


can
 integrate
 all
 your
 stuff
 uh
 across


your
 digital
 life,
 but
 do
 you


necessarily
 trust
 the
 creator
 of
 that


MCP
 server?
 like
 where
 is
 that
 data


getting
 sent?
 there's
 tens
 of
 thousands


of
 these
 things
 now
 and
 cyber
 security


risk
 that
 uh
 that
 um
 result
 um
 because


of
 this
 and
 also
 some
 changes
 towards


APIs
 of
 you
 know
 uh
 of
 model
 APIs
 that


sort
 of
 trade
 off
 whether
 the
 user
 or


the
 model
 vendor
 manages
 state
 and


depending
 on
 that
 that's
 another
 like


risk
 that
 you
 have
 to
 think
 about
 and
 so


I
 think
 at
 a
 at
 a
 high
 level
 like
 there


are
 lots
 of
 security
 issues
 that
 are


that
 are
 coming
 to
 the
 four
 here
 but


it's
 it's
 sort
 of
 still
 unclear
 whether


there's
 a
 good
 business
 to
 be
 built
 in


cyber
 um
 for
 AI
 because
 it's
 still
 so


early
 like
 we
 haven't
 um
 necessarily


like
 felt
 the
 pain
 of
 all
 these
 things


yet
 reputationally
 and
 financially
 and
 a


bit
 like
 insurance
 until
 you
 have


actually
 felt
 the
 pain
 you
 know
 you
 sort


of
 like
 prefer
 to
 divert
 your
 money


towards
 just
 like
 improving
 and
 making


more
 money
 than
 protecting
 your


downside.


>> Yeah.
 Interesting.


>> And
 it's
 another
 area
 where
 the
 uh


incumbents
 are
 not
 asleep
 at
 the
 wheel.


>> Yeah.
 And
 all
 the
 big
 labs.
 Yeah.


Exactly.
 So,
 if
 you're
 really
 good
 at
 at


at
 security,
 do
 you
 want
 to
 It's
 a
 bit


like
 AI
 safety.
 if
 you're
 really
 good
 at


these
 things,
 do
 you
 want
 to
 be
 in
 the


belly
 of
 the
 beast
 and
 be
 able
 to
 like


see
 how
 the
 sausage
 is
 made
 and
 like


influence
 it
 um
 because
 of
 the
 proximity


uh
 or
 do
 you
 want
 to
 be
 on
 the
 other


side
 like
 receiving
 the
 artifacts
 and


maybe
 at
 best
 doing
 collaborations
 with


labs
 on
 pre-launch
 safety
 testing
 like


uh
 they
 do
 in
 the
 UK
 with
 a
 in
 the
 US
 uh


or
 at
 worst
 just
 like
 literally
 trying


to
 sell
 as
 a
 cyber
 security
 SAS
 to


people
 who
 are
 consuming
 these
 models.


So
 I
 can
 understand
 like
 why
 that


imbalance
 occurs.


>> And
 to
 your
 point
 about
 it
 being
 hard
 to


sell
 before
 the
 pain
 is
 uh
 felt
 uh
 feels


like
 there's
 a
 whole
 generation
 of
 young


startups
 that
 are
 got
 acquired
 pretty


quickly
 by
 the


>> PaloAlto
 networks
 and
 checkpoints
 of
 the


of
 the
 world.
 Yes.


>> Before
 they
 got
 a
 chance
 to
 get
 to


scale.
 I
 mean,
 you
 know,
 something
 that


feels
 like
 it
 probably
 turn
 out
 to
 be


great
 for
 the
 for
 the
 founders,
 but
 in


terms
 of
 building
 large
 self-standing


sustainable
 companies,
 not
 not
 so
 much


agents,


>> it
 cannot
 be
 a
 2025
 conversation
 on
 AI


without
 talking
 about
 agents.
 What
 is


your
 sense
 of
 the
 reality
 and
 the
 state


of
 play?


>> There's
 some
 vertical
 products
 that
 are


really
 good.
 Clearly,
 search
 um
 is


actually
 pretty
 good.
 you
 know,


replacing
 consulting,
 uh,
 replacing


market
 research
 or
 augmenting
 all
 these


uh
 these
 areas
 that
 were
 previously,
 you


know,
 very
 heavy
 human
 uh,
 you
 know,


knowledge
 working
 tasks
 is
 getting


extremely
 good.
 I
 think
 uh,
 coding


agents
 clearly
 are
 are
 getting
 really


good.
 There's
 other
 metrics
 around
 like


how
 long
 they
 can
 work
 autonomously.
 I


think
 with
 the
 new
 Haiku
 release,
 it's


30
 hours
 or
 something
 and
 it
 can
 make
 a


pretty
 decent
 version
 of
 Slack.


>> Yes.
 Although
 a
 controversial
 uh
 number,


but
 uh,
 yes,
 up
 to
 30
 in
 lab
 testing.


Okay.


>> Uh,
 exactly.
 What
 what
 is
 what
 does
 even


hours
 mean
 in
 an
 agent
 of
 like
 a


computer
 running
 it?
 Like
 is
 that


equivalent?


>> Yeah.


>> And
 then
 uh and
 then
 some
 of
 the


scientific
 reasoning
 we
 talked
 about
 uh


is
 agent
 based.
 I
 think
 that's
 also


quite
 neat.
 I
 think
 the
 the
 biggest


problems
 just
 become
 like
 this
 kind
 of


compounding
 error
 of
 you
 know
 an
 agent


is
 like
 95%
 like
 good
 and
 then
 95%
 times


95%
 times
 etc
 etc
 sort
 of
 decays
 quality


over
 a
 long
 period
 of
 time.
 And
 then


there's
 some
 contention
 now
 about
 like


do
 you
 build
 these
 harnesses
 i.e.
 like


nerd
 speak
 for
 sticky
 tape
 um
 between


uh
 between
 like
 models
 to
 like
 make
 it


work
 in
 enterprise
 or
 do
 you
 just
 wait


until
 the
 next
 model
 generation


hopefully
 becomes
 better
 out
 of
 the
 box?


I
 think
 a
 ton
 of
 excitement
 and
 at
 some


point
 basically
 just
 as
 desktop
 software


became
 SAS
 at
 some
 point
 SAS
 will
 just


become
 an
 agent
 because
 it's
 no
 longer


really
 like
 a
 human
 that's
 that's


actually
 doing
 everything
 in
 the


software
 product
 but
 uh
 a
 software


that's
 running
 the
 software
 product


itself


>> which
 I
 think
 is
 cool
 implications
 for


like
 uh
 search
 and
 and
 uh and
 product


discovery
 and
 and
 this
 whole
 like
 uh


ecosystem
 of
 like
 online
 content
 like
 is


it
 humans
 that
 are
 reading
 it
 anymore
 or


is
 it
 agents
 that
 are
 chewing
 it
 and


then
 serving
 it
 to
 their
 human
 uh
 for


that
 like
 the
 whole
 um
 evolution
 away


from
 uh
 you
 know
 we
 go
 on
 a
 website
 to


uh
 buy
 a
 product
 versus
 uh
 you
 know


answer
 engine/
 search
 engine
 that's


largely
 open
 AI
 that
 enables
 us
 to
 buy


natively.


>> I'm
 not
 so
 enthusiastic
 about
 the
 oh


we're
 going
 to
 have
 agents
 that
 will


book
 flights
 for
 us
 and
 travel.
 I
 feel


like
 that's
 just
 like
 a
 niche
 problem


that


>> sort
 of
 like
 the
 the
 sad
 canonical
 use


case
 in
 San
 Francisco.
 But
 uh
 but
 I


think
 this
 the
 What's
 what's
 telling
 so


far
 is
 that
 traffic
 that's
 generated


through
 conversations
 in
 AI
 search
 onto


a
 commerce
 platform
 converts
 at
 a
 higher


level
 than
 direct
 traffic.
 So
 the
 intent


is
 really
 high
 because
 there's
 already


been
 like
 background
 research
 that's


been
 undertaken
 in
 chat.
 I
 think
 that's


really
 powerful
 and
 you
 can't
 ignore.


And
 then
 the
 the
 next
 question
 on
 that


is
 uh
 okay
 so
 what
 content
 is
 the
 model


actually
 uh
 consuming
 to
 serve


recommendations
 or
 information
 to
 its


user?
 Uh,
 you
 know,
 people
 say,
 "Oh,


Google
 search
 is
 dead."
 I
 think
 that's


like
 probably
 completely
 wrong
 because


Chad
 GPT
 references
 Google
 a
 ton
 as
 it


shifted
 off
 of
 Bing.
 Um,
 and
 so
 maybe


it's
 not
 like
 the
 front
 page
 of
 Google


that's
 being
 consumed
 by
 a
 human,
 but
 by


sort
 of
 agent
 that
 represents
 the
 the


user.
 If
 you're
 a
 company
 that
 that
 has


a
 new
 product
 and
 you
 want
 it
 to
 be


recommended,
 then
 there
 is
 like
 this


flywheel
 that
 uh
 you
 should
 probably
 get


on
 as
 soon
 as
 possible
 because
 the
 more


you
 make
 your
 content
 and
 your
 website


and
 your
 product
 accessible
 to
 agents


that
 can
 try
 it.
 Uh
 you
 know,
 even
 like


a
 demo
 environment
 for
 an
 agent
 to
 go


test
 your
 new
 SAS
 product,
 the
 more
 it


will
 be
 able
 to
 learn
 about
 your
 product


and
 provide
 recommendations
 to
 relevant


uh
 prompts
 from
 human
 users.
 And
 then
 if


you
 kind
 of
 go
 the
 next
 step
 which
 is
 uh


all
 this
 like
 reinforcement
 learning
 and


environments
 and
 preference
 learning
 and


things
 like
 that
 then
 that
 flywheel
 like


accelerates
 even
 faster.
 So
 I
 feel
 like


it's
 kind
 of
 inevitable.
 It
 does
 kind
 of


open
 up
 this
 uh
 agent
 experience
 rather


than
 just
 pure
 user
 experience
 sort
 of


craft
 within
 within
 software
 companies


that
 is
 yet
 another
 like
 piece
 of
 alpha


that
 uh
 one
 should
 jump
 on
 sooner
 rather


than
 later.


>> Where
 does
 it
 all
 leave
 you
 as
 a
 as
 a


VC?
 We
 have
 been
 talking
 about
 the
 state


of
 AI
 report
 uh
 which
 is
 uh
 your
 annual


labor
 of
 love
 and
 content
 and
 you
 know


which
 uh
 I
 think
 everybody
 in
 the


industry
 very
 much
 appreciates
 because


there's
 so
 much
 going
 on.
 So
 tying


everything
 together
 in
 one
 document
 is


uh
 incredibly
 helpful.
 But
 you
 first
 and


foremost
 a
 VC
 wearing
 an
 Air
 Street


t-shirt
 as
 people
 can
 see
 if
 they're


watching
 the
 video.
 But
 otherwise,
 trust


me
 if
 you're
 listening
 to
 this
 on


Spotify.
 Very
 very
 nice
 logo.
 Kind
 of


retro
 a
 little
 bit.
 Kind
 of
 kind
 of


>> Yeah,
 it's
 inspired
 from
 like
 old
 US
 Air


Force.


Very
 nice.


>> So
 what
 what
 are
 you
 um
 excited
 about?


So
 you
 mentioned
 like
 a
 bunch
 of
 like


deep
 tech
 robotics.
 Is
 that
 is
 that
 what


what
 you
 invest
 in?
 Uh
 where
 do
 you


think
 value
 can
 be
 built
 for
 founders


and
 and
 the
 VCs
 who
 love
 them


>> going
 forward?


>> Yeah.
 Yeah.
 The
 meta
 thing
 I
 care
 about


is
 uh
 is
 how
 do
 you
 build
 and
 make
 use


of
 AI
 to
 create
 like
 new
 kinds
 of


product
 experiences,
 new
 kinds
 of


companies.
 And
 for
 me
 that's
 like
 best


expressed
 by
 companies
 that
 are
 AI


first.
 So
 that's
 like
 both
 in
 terms
 of


the
 product
 that
 they
 build.
 If
 you
 rip


out
 the
 AI,
 the
 thing
 doesn't
 work.
 but


also
 in
 like
 how
 they
 approach
 their


like
 company
 philosophy,
 the
 types
 of


people
 they
 hire,
 where
 they
 allocate


resources.
 And
 then
 I've
 generally
 just


tried
 to
 follow
 areas
 of
 industry
 that


are
 uh
 increasingly
 ripe
 for
 getting


value
 out
 of
 AI.
 So
 traditionally
 that


would
 be,
 you
 know,
 lots
 of
 data
 for
 a


task
 that
 they
 care
 about,
 not
 enough


people
 to
 do
 that
 task,
 but
 where


there's
 a
 clear
 ROI
 uh
 if
 that
 task
 gets


automated
 or
 increasingly
 automated.
 Uh


and
 so
 that
 led
 me
 you
 know
 10
 years
 ago


or
 so
 to
 first
 do
 like
 fintech
 style


investments
 and
 then
 after
 that
 you
 know


biology
 really
 came
 online
 uh
 into
 this


new
 wave
 called
 tech
 bio.
 So
 I
 made
 some


investments
 there
 like
 balance
 discovery


that
 we
 sold
 to
 recursion
 and
 also
 we


sold
 to
 Xentia
 uh
 and
 then
 more
 recently


Proffluent
 which
 is
 uh
 kind
 of
 leading


the
 charge
 for
 these
 language
 models
 in


protein
 design
 developing
 the
 first
 like


uh
 crisper
 genome
 editor
 that
 an
 AI
 has


created.
 Then
 like
 another
 segment
 uh


that
 really
 came
 online
 in
 the
 US
 was
 in


defense
 uh
 and
 more
 recently
 in
 Europe


uh
 after
 the
 Munich
 security
 conference


in
 February
 kind
 of
 unwounded
 a
 lot
 of


assurances
 that
 European
 states
 had
 for


US
 security
 guarantees
 and
 that
 like
 led


to
 a
 big
 influx
 of
 holy
 we
 need
 to


defend
 ourselves
 cuz
 no
 one's
 coming
 to


save
 us.
 uh
 and
 so
 I
 have
 some


investments
 there
 like
 Delhi
 and


Alliance
 Industries
 in
 the
 UK
 and
 Greece


and
 then
 in
 robotics
 as
 we
 discussed
 so


a
 team
 in
 uh
 stood
 girl
 called
 Seract


which
 is
 developing
 kind
 of
 these


general
 purpose
 uh
 AI
 models
 for
 uh


robotic
 manipulation
 and
 increasingly


going
 to
 other
 form
 factors
 and
 then


I've
 been
 obsessed
 with
 voice.
 I
 think


we
 talked
 actually
 about
 voice
 the
 last


time
 I
 I
 was
 here
 and
 I'm
 still
 just


like
 amazed
 at
 how


>> the
 the
 magic
 demo
 I
 think
 you
 were


saying
 like
 if
 you
 want
 to
 impress
 your


your
 your
 smart
 but
 non
 non
 AI
 peeled


executive
 friend
 you
 show
 them
 voice.


>> Yeah.
 Yeah.
 Exactly.
 So
 I've
 definitely


used
 our
 company
 uh
 11
 Labs
 to
 like
 uh


create
 uh
 audio
 of
 me
 speaking
 Korean.


Like
 I've
 AB
 tested
 this
 and
 apparently


it
 sounds
 pretty
 good.
 But
 I
 have
 this


like
 you
 know
 newer
 company
 called


Delpha
 which
 is
 building
 tools
 for


clinical
 trials
 like
 starting
 with


actually
 just
 calling
 back
 patients
 who


want
 to
 be
 part
 of
 your
 trial
 and
 need


to
 be
 consented.
 Um
 and
 these
 are


conversations
 in
 lots
 of
 different


languages.
 A
 lot
 of
 like
 kind
 of


esoteric
 medical
 terminology.
 You
 know


patients
 forget
 what
 drugs
 they
 were
 on


so
 they
 have
 to
 call
 you
 back.
 And
 this


is
 like
 super
 laborious
 human
 work
 that


agents
 like
 11
 Labs
 and
 others
 in
 audio


like
 solve
 really
 well.
 So
 I'm
 excited


to
 see
 where
 this
 goes
 at
 the
 limit.
 And


then
 perhaps
 like
 the
 more
 sciency
 stuff


like
 these
 generative
 world
 models
 I


think
 are
 pretty
 amazing.
 Um
 whether


it's
 Google's
 you
 know
 Genie
 or
 VO
 or


Odyssey's
 system
 or
 you
 sort
 of
 like


imagining
 this
 world
 and
 then
 you
 can


take
 actions
 in
 it
 and
 the
 actions
 are


physically
 plausible
 because
 the
 system


was
 trained
 with
 video
 plus
 actions.
 Uh


and
 then
 maybe
 taking
 that
 even
 into


scientific
 discovery
 um
 um
 for
 just


trying
 to
 explore
 like
 the
 frontier
 and


being
 a
 bit
 smarter
 with
 uh
 with
 what


experiments
 we
 run.
 Um
 because
 now


foundation
 models
 are
 not
 dumb.


>> Okay.
 Fantastic.
 All
 right.
 So
 to
 uh


close
 the
 conversation
 um
 of
 course
 we


have
 to
 go
 into
 your
 predictions.
 So
 uh


each
 time
 uh
 you
 do
 the
 state
 of
 AI


report
 you
 boldly


uh
 come
 up
 with
 a
 prediction
 for
 the


next
 12
 months.
 So
 without
 going
 uh
 in


into
 all
 10
 uh
 and
 people
 can
 check
 them


out
 mostly
 on
 slide
 304.
 Pick
 like
 you


know
 maybe
 three
 that
 you're
 passionate


about.


>> Yeah.
 Well
 I
 think
 um
 one
 is
 just
 how


politically
 charged
 a
 lot
 of
 the
 kind
 of


AI
 compute
 data
 center
 buildout
 actually


becomes
 because
 of
 energy
 because
 of


water
 because
 of
 money
 because
 of


geopolitics.
 And
 I
 think
 that
 that's


becoming
 too
 large
 of
 an
 issue
 for


voters
 to
 ignore.
 Um
 and
 so
 we
 predict


that
 this
 kind
 of
 nimism
 not
 not
 in
 your


backyard
 will
 kind
 of
 take
 precedence
 in


uh
 in
 major
 political
 campaigns
 in
 2026.


I
 mean
 the
 the
 other
 one
 that
 I
 think
 is


uh
 is
 interesting
 is
 like
 a
 fully


endto-end
 uh
 designed
 or
 developed
 uh


scientific
 discovery.
 I
 would
 honestly


predict
 Nobel
 Prize,
 but
 the
 the


12-month
 window
 is
 a
 little
 bit
 too


short.
 I
 think
 the
 the
 alpha
 fold
 Nobel


Prize
 is
 probably
 the
 fastest
 in


history.
 Uh


>> a
 Nobel
 Prize
 won
 by
 an
 AI.


>> Yeah.


>> Versus
 the
 recent
 Nobel
 prizes
 were
 for


like
 AI
 researchers
 using
 AI
 to
 uh
 come


up
 with
 better
 with with
 breakthroughs.


But
 that
 was
 a
 human
 powered
 by
 AI.
 Here


what
 you're
 talking
 about
 is
 an
 AI


actually
 winning.


>> Yeah.
 Yeah.
 uh
 last
 year
 I
 mean
 we


predicted
 maybe
 like
 a
 step
 towards
 this


which
 was
 a
 fully
 AI
 written
 research


paper
 would
 be
 accepted
 at
 a
 major


conference
 or
 workshop
 and
 that
 actually


happened
 with
 this
 uh
 paper
 AI
 scientist


V2
 I
 think
 so
 I
 think
 we're
 we're


getting
 there
 because
 this
 is
 what
 the


nerds
 are
 really
 wanting
 to
 work
 on
 like


uh
 as
 as
 a
 meta
 point
 you
 know
 I
 think


there's
 all
 these
 like
 software


industries
 where
 uh
 you
 know
 analysts


think
 like
 oh
 my
 god
 it's
 it's
 going
 to


be
 dead
 because
 of
 AI
 but
 I
 think
 part


of
 the
 reality
 is
 um
 what's
 not
 going
 to


be
 dead
 is
 the
 problems
 that
 like
 these


AI
 people
 don't
 want
 to
 work
 on
 cuz
 it's


so
 boring
 to
 build
 that
 software.


>> That's
 such
 a
 fantastic
 huristic.


>> Yeah,
 workday
 is
 safe.
 Um
 he
 was
 funny


like
 actually
 that
 CEO
 because
 uh
 I


think
 he
 said
 recently
 in
 response
 to
 is


open
 AI
 anthropic
 or
 etc
 etc
 like
 a


threat
 to
 your
 business
 and
 he
 just


replied
 they're
 all
 my
 customers.


>> Yeah.


>> All
 right.
 That's
 true.
 Uh
 pick
 another


one.
 I
 mean
 it's
 kind
 of
 cheating
 but


the
 open
 source
 one
 uh
 I
 think
 happened


you
 know
 whether
 this
 particular
 company


is
 a
 is
 a
 leading
 lab
 or
 not
 um
 is


beside
 the
 point
 that
 uh
 basically
 like


aligning
 yourself
 with
 political
 agendas


is
 the
 way
 to
 go
 and
 and
 I
 think
 you


could
 maybe
 take
 this
 even
 further
 and


say
 like
 similar
 to
 how
 uh
 Nvidia
 has


been
 monetizing
 sovereign
 AI
 a
 way
 for


uh
 nation
 states
 to
 kind
 of
 guarantee


access
 to
 AI
 services
 is
 for
 them
 as


nations
 to
 invest
 in
 one
 of
 these
 labs.


Uh
 there's
 obviously
 still
 a
 risk
 that


due
 to
 export
 controls
 US
 can
 just
 like


tell
 OpenI
 to
 switch
 it
 off.
 But
 I
 think


it's
 interesting
 that
 for
 example
 the


Albanian
 government
 invested
 in
 thinking


machines.
 Uh
 obviously
 the
 CEO
 comes


from
 there.
 And
 so
 we
 I
 wrapped
 this


kind
 of
 prediction
 or
 this
 this
 topic
 in


a
 prediction
 that
 said
 you
 know
 some


countries
 will
 basically
 abandon
 their


uh
 their
 efforts
 to
 achieve
 AI


sovereignty
 and
 declare
 AI
 neutrality.
 M


>> it's
 a
 bit
 similar
 to
 like
 the
 um
 the


defense
 posture
 where
 some
 nation
 states


are
 just
 too
 small
 or
 don't
 have
 enough


people
 or
 don't
 have
 the
 money
 etc
 with


the
 capabilities
 to
 develop
 weapon


systems
 to
 defend
 themselves
 and
 so
 they


have
 a
 strategic
 security
 guarantee
 that


they
 get
 from
 a
 larger
 neighboring


nation.
 I
 think
 doesn't
 seem
 that


inconceivable
 to
 me
 that
 um
 you
 know


various
 countries
 would
 say
 I
 can't


build
 this
 stuff.
 I
 need
 to
 have
 a


formal
 alliance
 with
 another
 country


that
 is
 sovereign.


>> Well
 Nathan
 it's
 been
 wonderful.
 Thank


you
 so
 much.
 the
 state
 of
 AI
 2025.


Again,
 is
 available
 at
 state
 of.ai.


It's
 uh
 remarkably
 comprehensive
 and


detailed
 uh
 yet
 approachable.
 So,
 thank


you
 for
 doing
 this.
 Thank
 you
 for
 coming


on
 today
 sharing
 predictions.
 Hopefully,


I
 get
 to
 embarrass
 you
 at least
 a
 little


bit
 uh
 for
 the
 next
 one
 when
 some
 of


those
 predictions
 uh
 turn
 out
 to
 not


have
 panned
 out.
 But
 this
 was
 wonderful.


Thank
 you
 very
 much
 for
 the
 opportunity.


Thanks
 for
 running
 it
 back.


>> Appreciate
 it.


>> Hi,
 it's
 Matt
 Turk
 again.
 Thanks
 for


listening
 to
 this
 episode
 of
 the
 Mad


Podcast.
 If
 you
 enjoyed
 it,
 we'd
 be
 very


grateful
 if
 you
 would
 consider


subscribing
 if
 you
 haven't
 already
 or


leaving
 a
 positive
 review
 or
 comment
 on


whichever
 platform
 you're
 watching
 this


or
 listening
 to
 this
 episode
 from.
 This


really
 helps
 us
 build
 a
 podcast
 and
 get


great
 guests.
 Thanks
 and
 see
 you
 at
 the


next
 episode.