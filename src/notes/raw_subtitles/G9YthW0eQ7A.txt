Hi
 everybody.
 Uh
 Nicola
 Tangan
 from
 the


Norwegian
 Sovereign
 Wealth
 Fund
 and


today
 I
 am
 here
 with
 Ethan
 Molik,
 one
 of


my
 favorite
 professors,
 a
 professor
 at


Wharton
 and
 who
 is
 who
 was
 out
 not
 long


ago
 with
 a
 book
 on
 co
 called


co-intelligence
 living
 and
 working
 with


AI.
 And
 actually
 you
 can
 see
 it
 um


behind
 Ethan
 there
 down
 to
 down
 to
 the


right.
 If
 you
 haven't
 got
 it,
 run
 and


buy
 it.
 Um,
 Ethan,
 if
 you
 were
 uh
 a


chief
 AI
 officer


uh
 in
 a
 company
 for
 the
 next
 3
 months,


what
 kind
 of
 top
 actions
 would
 you
 take


straight
 away?
 So,
 I
 think
 that
 the
 the


most
 important
 thing
 is
 to
 get
 people


actually
 aware
 of
 where
 the


state-of-the-art
 on
 AI
 is?
 I
 talk
 to


companies
 all
 the
 time
 and
 I
 think
 that


a
 lot
 of
 executive
 level
 people
 may
 have


tried
 AI
 a
 while
 ago
 or
 didn't
 use
 it


personally
 and
 don't
 realize
 how


potentially
 transformative
 it
 is.
 Um,


and
 I
 think
 that
 I
 I
 have
 a
 sort
 of


general
 idea
 that
 you
 need
 to
 involve


your
 team
 leadership.
 You
 need
 to


involve
 a
 set
 up
 a
 lab
 that's
 doing


research.
 And
 you
 need
 to
 think
 about


how
 to
 roll
 this
 out
 to
 the
 crowd
 to


everybody
 in
 the
 organization.
 So,


you've
 got
 to
 kind
 of
 bring
 the
 whole


company
 with
 you,
 which
 is
 not
 always
 an


easy
 thing
 to
 do
 and
 how
 do
 you
 maximize


the
 opt
 organization?
 So,
 I
 think
 that's


a
 it's
 a
 really
 good
 question
 and
 I


think
 we're
 still
 figuring
 out
 the


answers,
 but
 it's
 kind
 of
 like
 any
 other


thing
 you
 want
 to
 do.
 You
 have
 to
 think


about
 incentives
 and
 you
 think
 have
 to


think
 about
 leadership,
 right?
 So
 why


are
 people
 incentivized
 to
 use
 this?
 Now


the
 thing
 that
 makes
 AI
 interesting
 is


everybody's
 already
 using
 it.
 So
 there's


a
 new
 study
 that
 just
 came
 out
 that


showed
 in
 representative
 sample
 of


Americans
 uh
 American
 workers,
 the
 usage


went
 from
 30%
 in
 February
 to
 40%
 of


people
 are
 using
 AI
 at
 work,
 a
 little


over
 40%
 as
 of
 April.
 So
 it's
 used


everywhere.
 The
 thing
 is
 people
 aren't


just
 aren't
 showing
 you
 they're
 using
 it


because
 they're
 hiding
 it.
 Uh
 because


they're
 not
 incentivized
 to
 show
 you.


they're
 worried
 they'll
 be
 fired
 if
 they


use
 it
 either
 because
 they'll
 be
 told


that
 they're
 using
 it
 improperly
 or


because
 people
 realize
 they're
 not


necessary
 or
 there's
 less
 workers


needed.
 Um,
 and
 so
 there's
 incentive


problems
 and
 then
 there's
 also
 for


everyone
 else
 who
 isn't
 using
 it,


there's
 role
 modeling
 problems.
 What
 do


I
 do
 to,
 you
 know,
 to
 get
 started?
 How


do
 I
 use
 this?
 Why
 is
 it
 important?
 So,


you've
 got
 to
 both
 deal
 with
 the


skeptics
 and
 the
 people
 already
 adopting


it
 who
 may
 not
 be
 showing
 you
 they're


using
 it
 yet.
 Why
 would
 people
 not
 want


to
 show
 that
 they
 use
 it?
 I
 mean
 here
 if


people
 don't
 use
 it,
 I'm
 like,


you
 know,
 that's
 that's
 bad,
 right?


You
 know,
 so
 if
 you
 think
 about
 the


incentives
 of
 the
 average
 worker
 who's


who's
 using
 AI,
 first
 of
 all,
 they
 look


like
 geniuses
 when
 they're
 using
 AI.
 And


one
 problem
 that
 we
 see
 is
 people
 don't


want
 to
 show
 you
 they're
 using
 it


because
 uh
 that
 makes
 them
 look
 like


they're
 not
 geniuses.
 Like
 the
 people


get
 give
 the
 AI
 credit.
 The
 second


reason
 is
 it
 in
 many
 companies
 is
 viewed


as
 a
 thing
 that
 is
 a
 cost
 cutting


measure.
 So
 if
 I
 could
 show
 you
 that
 the


AI
 does
 some
 of
 my
 work,
 do
 I
 get
 a


reward
 for
 that
 or
 do
 we
 you
 fire


employees,
 right?
 Am
 I
 do
 I
 feel
 safe
 to


reveal
 it?
 And
 a
 lot
 of
 people
 are
 just


using
 it
 to
 work
 less.
 So
 you're
 working


90%
 less.
 Am
 I
 going
 to
 show
 you
 I'm


using
 AI
 so
 I
 have
 to
 do
 more
 work
 as
 a


result?
 Am
 I
 getting
 a
 credit
 for
 doing


this?
 So
 there's
 a
 lot
 of
 incentives
 to


not
 share.
 Probably
 a
 lot
 more
 than
 to


share.
 Wow.
 How
 do
 you
 measure
 AI
 usage


in
 a
 company?


So
 the
 the
 metric
 thing
 is
 really


interesting,
 right?
 So
 what
 I
 see
 a
 lot


of
 people
 drive
 towards
 we're we're
 in
 a


world
 of
 sort
 of
 new
 innovation,
 right?


So
 it
 could
 be
 a
 little
 challenging
 um


to
 to
 have
 a
 direct
 like
 easy
 answer
 to


that
 question
 um
 of
 like
 what
 does
 AI


do?
 How
 should
 we
 be
 using
 it


immediately?
 So
 chief
 AI
 officer,
 you're


doing
 experimentation.
 That
 said,
 I


think
 raw
 usage
 actually
 matters.
 Um,
 I


mean
 the
 typical
 KPIs
 you
 see
 are
 how


many
 people
 are
 using
 our
 AI
 app


internally.
 The
 downside
 of
 that
 is
 in


most
 companies
 I
 talk
 to
 that
 maxes
 out


at
 20
 or
 30%
 of
 the
 population.
 And


that's
 because
 an
 additional
 third
 is


probably
 secretly
 using
 AI
 or
 doesn't


want
 to
 use
 your
 apps.
 Your
 apps
 aren't


good
 enough.
 And
 another
 third
 is
 kind


of
 waiting
 for
 instructions.
 Like


they're
 happy
 to
 use
 it,
 but
 they're
 the


opposite
 of
 the
 people
 who
 were
 early


adopters.
 They
 want
 clear
 rules
 about


how
 I
 should
 use
 it
 and
 why.
 So
 I
 think


you
 can
 measure
 adoption
 by
 use
 of
 your


app.
 I
 think
 you
 can
 measure
 adoption
 by


other
 internal
 measures
 of
 how
 much


you're
 using
 AI
 at
 work.
 Um,
 but
 I
 think


you
 have
 to
 be
 aware
 that
 there's
 still


this
 secret
 cyborg
 problem
 of
 people
 not


revealing
 their
 AI
 use.
 So,
 how
 are
 the


best
 companies
 going
 about
 this?
 So,
 I'm


seeing
 some
 really
 interesting
 examples


of
 of
 how
 this
 works.
 I
 can
 tell
 a
 few


of
 the
 stories.
 I
 can't
 tell
 all
 of


them.
 Um,
 one
 example
 is,
 you
 know,


radically
 changing
 incentives.
 So,
 I've


seen
 companies
 that
 offer
 $10,000


bonuses
 at
 the
 end
 of
 every
 week
 to


every
 employee
 that
 uses
 the
 employee


who
 best
 uses
 AI
 to
 automate
 their
 job,


right?
 And
 they
 think
 they're
 saving


money
 versus
 other
 approaches.
 I've
 seen


people
 build
 this
 into
 their
 hiring


process.
 So,
 before
 you
 hire
 somebody,


you
 have
 to
 your
 team
 has
 to
 try
 and
 use


AI
 to
 do
 their
 job
 and
 then
 you
 adjust


your
 uh
 your
 request
 for
 hiring
 based
 on


that
 experience
 or
 before
 you
 request


money,
 you
 need
 to
 show
 how
 you're
 using


AI
 to
 do
 it.
 Um
 I've
 Madna
 has
 this


really
 great
 example
 that
 they
 they
 put


together.
 They
 use
 AI
 for
 everything
 and


what
 they
 did
 was
 build
 around
 the


process
 of
 uh
 annual
 reviews.
 So


basically
 they
 built
 a
 whole
 series
 of


GPTs
 that
 helped
 people
 uncover
 their


own
 performances
 improvement
 needs
 and


what
 they
 had
 done
 over
 the
 year
 and


talk
 to
 the
 right
 people
 about
 their


jobs
 and
 things
 so
 they
 could
 write
 a


really
 good
 yearly
 update
 about


themselves.
 And
 they
 said,
 "Well,
 if
 you


don't
 use
 these
 GPTs,
 you're
 probably


not
 going
 to
 do
 as
 well."
 uh
 on
 your


performance
 reviews
 and
 that
 will
 hurt


your
 annual
 salary
 and
 everybody
 end
 up


using
 the
 series
 of
 things
 which


introduced
 them
 to
 AI.
 So
 putting
 these


bottlenecks
 in
 place
 where
 people
 have


to
 use
 it
 um
 thinking
 about
 building


into
 internal
 processes
 in
 a
 way
 that
 is


encourages
 positive
 use
 rather
 than


negative
 use
 those
 tend
 to
 be
 really


effective
 methods.
 So
 you
 need
 a


combination
 of
 the
 stick
 and
 the
 carrot


hair.
 I
 I
 think
 you
 do
 and
 I
 think
 you


also
 need
 role
 modeling
 right
 a
 leader


who
 uses
 AI
 will
 make
 sure
 AI
 seems


critical.
 someone
 who
 doesn't
 use
 AI
 and


says
 use
 it
 um
 is
 is
 is
 kind
 of
 be
 a


problem.
 I
 mean
 you
 mentioned
 the
 chief


AI
 officer
 at
 the
 beginning.
 One
 of
 the


things
 that
 worries
 me
 a
 little
 bit


about
 that
 is
 there
 is
 no
 ability
 to


have
 a
 chief
 AI
 officer
 really
 at
 this


point.
 I
 mean
 generative
 AI
 has
 been


around
 three
 years
 there.
 Everybody
 was


on
 their
 very
 first
 project.
 So
 if
 you


hire
 a
 chief
 AI
 officer
 that
 is
 often


somebody
 who
 is
 actually
 doing
 machine


learning
 beforehand
 which
 is
 great
 like


AI
 at
 large
 but
 not
 generative
 AI
 but


they're
 not
 going
 to
 have
 any
 idea
 of


how
 to
 make
 an
 organization
 transform


with
 AI.
 It
 has
 to
 be
 at
 the
 leadership


level.
 I
 think
 it
 has
 to
 be
 at
 the
 sea


level
 in
 the
 company.
 But
 does
 it
 make


sense
 to
 have
 a
 central
 unit
 which
 kind


of
 disperses
 uh
 the
 best
 use
 cases
 and


make
 sure
 that
 everything
 everybody
 is


is
 at
 it?
 So
 that's
 the
 concept
 of
 the


lab
 that
 I
 was
 talking
 about
 earlier.
 So


you
 do
 want
 a
 a
 centralized
 unit
 for


experimentation.
 Um
 but
 that
 that
 lab


has
 to
 be
 staffed
 partially
 by
 the
 crowd


by
 the
 people
 who
 are
 the
 best
 users


inside
 your
 company.
 And
 they're
 going


to
 be
 sort
 of
 ambidextrous.
 they're


going
 to
 be
 shipping
 out
 like
 here's
 a


great
 use
 case
 and
 also
 building
 a
 full


agentic
 system
 that
 doesn't
 quite
 work


yet
 that
 automates
 the
 entire
 job
 right


um
 but
 I
 think
 the
 traditional
 view
 of


having
 it
 produce
 things
 I
 think
 that


actually
 is
 on
 its
 way
 out
 um
 some
 of


the
 most
 interesting
 experiments
 I'm


seeing
 companies
 are
 dispersing


engineers
 from
 the
 IT
 department
 out


into
 work
 with
 subject
 matter
 experts


because
 vibe
 coding
 has
 strong


limitations
 but
 it's
 abs
 it's
 absolute


best
 when
 you
 have
 a
 senior
 coder


working
 with
 a
 subject
 matter
 expert,


you
 can
 do
 incredible
 things
 in
 a
 couple


of
 days
 that
 you
 know
 used
 to
 be
 whole


processes.
 So
 I
 think
 there's
 going
 to


be
 centralization
 of
 some
 AI
 functions,


but
 it
 has
 to
 disperse
 other
 parts
 of


the
 organization
 in
 a
 more
 decentralized


way.
 Yeah.
 Yeah.
 Yeah.
 We
 we
 um
 we
 do


that.
 But
 what
 about
 what
 about


ambassadors
 and
 people
 across
 the
 firm


being
 being
 trained
 regularly?


Yeah.
 And
 I
 think
 one
 of
 the
 things


we've
 been
 struggling
 with
 a
 lot
 as
 we


think
 about
 AI
 use
 and
 observing


companies
 has
 been
 what
 training
 means.


So
 I
 think
 one
 of
 the
 one
 of the
 things


I
 know
 this
 is
 an
 approach
 that
 you
 take


that
 I
 think
 is
 smartest
 about
 training


is
 using
 an
 opportunity
 for
 contact


hours
 with
 AI.
 I
 think
 one
 of
 the


smartest
 things
 I
 said
 in
 the
 book
 that


didn't
 always
 the
 smartest
 thing
 at
 the


time
 but
 has
 turned
 out
 to
 be
 quite


useful
 has
 been
 that
 you
 just
 need
 to


use
 AI
 to
 get
 it
 right.
 You
 need
 you


need
 to
 bring
 it
 to
 every
 work
 task
 and


you'll
 figure
 out
 what
 it's
 good
 or
 bad


at
 10
 plus
 hours.
 And
 people
 are
 very


resistant,
 even
 very
 smart,
 very


well-meaning,
 very,
 you
 know,


self-motivated
 people
 are
 often
 very


resistant
 to
 using
 this
 for
 reasons
 they


can't
 fully
 explain,
 right?
 It's
 a
 weird


technology.
 It's
 not
 that
 easy
 to
 use.


It's
 uncomfortable
 in
 some
 ways
 to
 sort


of
 confront.
 I
 I
 talk
 about
 the
 need
 for


an
 existential
 crisis.
 So,
 I
 think
 that


it's
 hard
 to
 see
 adoption
 is
 strange


that
 way,
 right?
 So,
 training
 can
 kind


of
 get
 you
 into
 adoption,
 but
 we
 don't


actually
 have
 that
 much
 we
 can
 teach


people
 about
 AI.
 like
 a
 lot
 of
 the


property
 techniques
 you
 learn
 don't


really
 work
 that
 well
 or
 aren't
 that


important
 as
 the
 model
 gets
 better.
 So


it's
 out
 of
 that
 experience
 and
 I
 think


you
 will
 develop
 this
 idea
 of
 of
 these


champions.
 People
 some
 people
 will
 just


get
 it
 and
 it's
 really
 important
 like


you
 said
 to
 get
 those
 people
 out
 there.


They're
 the
 cutting
 cutting
 edge.


They're
 the
 representatives
 of
 the
 lab


in
 the
 world.
 Well
 will
 the
 people
 who


are
 top
 performers
 without
 AI
 be
 the
 top


performers
 with
 AI?


So
 this
 is
 one
 of
 the
 biggest
 questions


we're
 facing.
 If
 you
 think
 about
 it,


there's
 four
 possibilities
 for
 what


happens
 in
 an
 AI
 world
 with
 uh
 on


skills.
 So
 the
 first
 effect
 that
 we
 saw


and
 we
 saw
 this
 in
 our
 in
 our
 study
 that


the
 Boston
 consulting
 group
 study
 I
 did


with
 my
 friends
 at
 Harvard
 and
 MIT
 and


University
 of
 Warwick
 where
 we
 found
 big


performance
 gains
 and
 this
 came
 out
 like


a
 year
 and
 a
 half
 ago
 kind
 of
 made
 a
 big


stir
 40%
 improvement
 in
 quality
 for


people
 who
 use
 GBT4
 versus
 not.
 Um
 big


speed
 improvements
 and
 a
 lot
 of
 other


studies
 like
 that
 have
 shown
 a
 leveling


effect.
 So
 bottom
 performers
 get
 the


biggest
 boost.
 When
 you
 really
 look
 at


what's
 happening,
 it's
 actually
 the
 AI


doing
 the
 work
 of
 the
 bottom
 performers,


right?
 So
 the
 AI
 is
 pretty
 good.
 So
 it


moves
 everybody
 up
 to
 the
 eighth


percentile.
 So
 one
 option
 is
 it
 boosts


the
 bottom
 performers.
 A
 second
 option


um
 that
 can
 exist
 simultaneously
 is
 the


idea
 that
 top
 performers
 get
 some
 sort


of
 massive
 returns.
 We
 have
 a
 couple
 of


studies
 show
 that,
 but
 not
 that
 many.


It's
 hard
 to
 study.
 Um
 there's
 actually


a
 uh
 one
 of the
 best
 pieces
 of
 evidence


for
 that
 was
 actually
 turned
 out
 to
 be
 a


fraudulent
 paper
 from
 MIT
 uh
 that
 that


didn't
 that
 didn't
 exist,
 right?
 But
 I


think
 there's
 a
 lot
 of
 suspicion
 that


top
 performers
 using
 AI
 can
 get
 a
 huge


boost,
 just
 harder
 to
 measure.
 So


there's
 a
 possibility
 that
 maybe
 there's


a
 hundred
 times
 return
 if
 you're
 already


a
 good
 coder.
 Um
 and
 we'll
 know
 more


about
 that
 in
 the
 near
 future.
 There's


also
 a
 possibility
 that
 um
 that
 you
 know


that
 AI
 lifts
 everybody
 up.
 So


everybody's
 performance
 goes
 up
 by
 a


similar
 amount.
 And
 then
 there
 is
 this


sort
 of
 other
 possibility
 that
 there's


AI
 whisperers
 who
 are
 just
 good
 at
 AI


and
 they're
 the
 ones
 who
 get
 all
 the


returns.
 So
 we
 don't
 know
 whether
 it's


concrating
 the
 lower
 end
 on
 the
 top
 end


whether
 it
 lifts
 everybody
 up
 or
 whe


there's
 just
 sort
 of
 magical
 AI


whisperers
 who
 are
 just
 built
 to
 do


this.
 Um
 and
 then
 agents
 are
 coming
 to


replace
 everybody
 if
 you
 listen
 to the


AI
 labs
 and
 what
 do
 you
 think?
 Do
 you


think
 that
 will
 happen?
 So
 I
 you
 know
 I


think
 I
 mean
 well
 first
 of
 all
 first
 of


all
 just
 tell
 us
 an
 agent
 what
 what


exactly
 does
 an
 agent
 do?
 Yeah.
 So
 um


nobody
 has
 a
 good
 definition
 of
 anything


in
 AI.
 So
 um
 people
 will
 if
 you're
 if


you
 are
 um
 a
 leader
 in
 a
 company
 you


will
 have
 vendors
 selling
 you
 things


with
 every
 possible
 label
 and
 they'll


say
 it's
 agentic
 and
 everything
 else


because
 there's
 no
 clear
 definition.
 But


the
 simplest
 version
 and
 that
 sort
 of


overlaps
 with
 what
 the
 labs
 think
 is


imagine
 a
 any
 AI
 system
 that
 had
 could


be
 given
 a
 goal
 and
 can
 autonomously
 go


and
 try
 and
 accomplish
 that
 goal
 without


further
 human
 intervention
 using
 its
 own


judgment
 and
 tools.
 That's
 what
 an
 agent


does.
 So
 an
 agent
 I
 would
 say
 prepare
 me


for
 this
 podcast
 and
 it
 would
 do
 all
 the


research
 necessary.
 We
 can
 even
 demo
 a


little
 agent
 right
 now
 if
 we
 wanted
 to


do
 that
 a
 little
 bit
 of
 agentic
 work.


Um,
 but
 it's
 uh
 it's
 it's
 a
 so
 it's
 a


tool
 that
 goes
 out
 and
 kind
 of
 does


things
 in
 the
 world.
 And
 the
 idea
 with


an
 agent
 is
 if
 an
 agent
 could
 go
 out
 and


do
 work
 for
 us,
 then
 I
 get
 to
 skip
 the


whole
 problem
 of
 trying
 to
 figure
 out


how
 to
 integrate
 AI
 in
 with
 my
 workers


because
 the
 AI
 will
 basically
 be
 a


worker.
 I'll
 say
 write
 this
 code
 for
 me


and
 then
 deploy
 it
 and
 then
 test
 it
 and


come
 back.
 I
 think
 we're
 further
 from


that
 than
 the
 labs
 think.
 Um,
 but
 I
 do


think
 narrow
 agents
 are
 already
 very


possible.
 Have
 you
 got
 a
 good
 one


available?
 I
 I
 mean
 I
 think
 yeah
 we


let's
 let's
 let's
 pick
 an
 agent
 for
 fun


here.
 Um
 I
 will
 actually
 share
 my
 screen


and
 I'm
 going
 to
 log
 into
 an
 agent
 while


we
 talk.
 Okay.
 So
 let's
 let's
 let's
 look


at
 an
 early
 version
 of
 an
 AI
 agent


called
 Manis.
 Um
 Manis
 is
 P
 is
 a
 is
 a


small
 Chinese
 company.
 Actually
 I
 don't


know
 how
 big
 they
 are.
 Uh
 but
 they're


they
 are
 um
 they
 are
 the
 uh
 they
 use


clawed
 as
 their
 underlying
 data
 set.


anthropics
 data
 and
 I
 just
 want
 to
 show


you
 an
 agent
 would
 do,
 right?
 So
 in
 this


case,
 I
 asked
 it
 to
 come
 up
 with
 20


ideas
 for
 marketing
 slogans
 for
 new
 mail


or
 cheese
 shop,
 select
 the
 best
 one,


build
 a
 financial
 marketing
 plan,
 build


a
 website,
 carrying
 cheeses.
 Um,
 and
 so


what
 you'll
 see
 is
 what
 the
 model


actually
 does
 here
 is
 it
 comes
 up
 with
 a


to-do
 list
 and
 then
 it
 starts
 coming
 up


with
 a
 plan.
 So
 here
 it
 comes
 with
 a


bunch
 of
 slogans
 and
 ranks
 those
 slogans


and
 then
 decides
 on
 the
 best
 one.
 Then


it
 goes
 out
 and
 actually
 does
 market


research
 on
 the
 cheese
 industry.
 Then
 it


goes
 ahead
 and
 puts
 together
 a
 whole


financial
 plan
 for
 us
 uh
 that's
 many


pages
 long.
 Uh
 then
 it
 goes
 ahead
 and
 um


and
 and
 figures
 out
 here's
 a
 to-do
 list


that
 goes
 through
 to
 do
 this.
 It
 does


market
 research.
 It
 comes
 up
 with
 a


color
 scheme
 for
 the
 site
 and
 then


ultimately
 what
 it
 does
 is
 without
 any


further
 intervention
 from
 me
 uh
 launches


a
 website
 and
 this
 is
 100%
 created
 by


the
 AI,
 right?
 I
 can
 go
 shop
 cheeses.


There's
 a
 little
 built
 a
 shopping
 cart


functionality.
 Um,
 I've
 got
 a


subscription
 model
 I
 can
 do
 that
 has


forms
 built
 in
 and
 this
 is
 without
 any


further
 intervention
 from
 me
 at
 all.


Right.
 So
 the
 idea
 So
 how
 big
 was
 your


prompt?
 How
 was
 big
 was
 your
 prompt
 here


on
 this
 one?
 Uh,
 you
 saw
 it.
 This
 was


the
 the
 prompt
 was
 literally
 this
 one.


Right.


That's
 not
 that
 complicated.
 It
 figured


out
 all
 my
 intent
 and
 everything
 else


from
 this.
 So
 this
 is
 an
 example
 of
 an


agent
 at
 work,
 right?
 And
 when
 will


these
 be
 widely
 when
 will
 these
 be


widely
 available?
 I
 mean
 this
 is


available
 right
 now
 and
 I
 would
 also


argue
 that
 um
 03
 which
 is
 the
 model
 that


everyone
 could
 use
 right
 now
 is


basically
 an
 agentic
 model
 already.
 So


if
 we
 just
 go
 to
 chatbt03
 and
 I
 can
 just


ask
 it
 a
 question
 saying
 you
 know
 um


that
 um
 you
 know
 um
 let's
 let's
 ask
 it


to
 do
 something.
 Let's
 say
 something


like
 you
 know
 um
 give
 me
 10
 ideas
 for
 a


new
 on
 trend
 uh
 shoe
 design.
 based
 on


market
 research.


Um,


uh,
 and
 develop
 pricing
 a
 pricing


strategy


and
 proforma


financials
 for
 the
 best
 one


and
 show
 me


a
 photo
 shoot
 of
 it.


Um,
 and
 I'm
 not
 so
 interested
 in
 the


prompt
 being
 amazing
 as
 to
 show
 you
 what


I
 mean
 by
 this.
 So
 this
 is
 uh
 03
 is
 an


example
 of
 both
 a
 reasoning
 model
 that


can
 that
 goes
 through
 this
 process
 of


thinking.
 We
 can
 talk
 more
 about
 why


that's
 important
 or
 interesting
 if
 that


if
 you
 want
 to.
 But
 what
 you'll
 see
 what


I
 want
 to
 show
 you
 about
 this
 is
 it's


come
 up
 with
 a
 plan,
 right?
 I'm
 going to


look
 up
 latest
 trends
 in
 footwear
 and


then
 I'll
 come
 with
 10
 designs.
 Then


I'll
 pick
 the
 best
 one.
 Then
 I'll
 create


a
 pricing
 strategy.
 So
 it's
 come
 with
 a


plan
 and
 what
 you'll
 see
 is
 that
 it's


going
 to
 go
 through
 this
 stepwise.
 So


just
 on
 that
 command
 right
 it's
 going
 to


it's
 you
 can
 see
 it's
 doing
 web
 searches


already
 about
 to
 do
 market
 research.
 Um


now
 it's
 choosing
 a
 design
 based
 on
 the


research
 that
 it
 did.
 So
 it's
 the


step-wise
 agentic
 approach
 right
 um
 that


the
 AI
 takes
 even
 for
 just
 a
 simple


command.
 This
 is
 this
 is
 kind
 of
 how
 an


agent
 works.
 So
 you
 can
 see
 it's
 doing


multiple
 web
 searches.
 Um
 it's
 it's


thinking
 about
 what
 this
 all
 means
 for


the
 financials.
 Um
 it's
 figuring
 out


you'll
 notice
 also
 that
 it
 made
 a


mistake
 in
 doing
 a
 search.
 So
 it's


looking
 for
 different
 things
 that
 it
 did


before.
 That's
 an
 agent
 at
 work.
 So
 this


agent
 could
 have
 done
 these
 whole
 pose,


right?
 And
 pretended
 to
 be
 you
 and
 me.


So
 almost
 right.
 Um
 there's
 a
 weird


disconnect.
 Video
 and
 audio
 is
 a
 little


bit
 different
 than
 uh
 than
 other


approaches
 to
 uh
 to
 AI
 um
 like
 large


language
 models
 themselves,
 but
 very


increasingly
 so.
 Yes,
 I've
 there
 you
 can


now
 bring
 a
 live
 agent
 onto
 a
 call
 and


it
 has
 a
 pretty
 good
 conversation
 with


you.
 Um,
 and
 video
 is
 live
 video
 is


getting
 much
 better.
 So,
 if
 not
 now,


within
 the
 next
 months,
 that's
 a
 pretty


plausible
 thing
 to
 be
 able
 to
 do.
 Do
 you


think
 he
 would
 do
 better
 than
 you
 and


me?
 No.
 Um,
 I
 mean,
 you
 know,
 not
 just


because
 I
 want
 to
 keep
 our
 jobs,
 right?


Um,
 and
 I'm
 not
 just
 trying
 to
 flatter


you
 because
 we
 still
 have
 interview
 left


and
 I
 want
 you
 to
 look
 make
 me
 look


good,
 but
 aside
 from
 those
 issues,


right?
 Um,
 I
 think
 the
 thing
 about
 AI
 is


that
 mostly
 it's
 not
 superhuman.
 So,


you're
 a
 very
 good
 podcaster
 and
 I
 would


say
 that
 anyway.
 Um,
 but
 if
 you're
 at


the
 top
 of
 your
 field,
 whatever
 you're


top
 at,
 you're
 definitely
 probably


better
 than
 AI.
 And
 by
 the
 way,
 we
 got


our
 our
 shoe
 here.
 Um,
 and
 so,
 um,
 I


think
 that
 it's
 not
 as
 good
 as
 us
 yet.


That's
 the
 real
 question
 is
 does
 it
 get


to
 be
 and
 does
 it
 get
 to
 be
 good
 across


as
 good
 us
 across
 every
 field
 uh
 which


we'd
 call
 artificial
 general


intelligence
 AGI
 a
 machine
 smarter
 than


a
 human
 expert
 across
 every
 field
 and


that's
 the
 biggest
 question
 in
 AI
 right


now.
 Absolutely.
 Absolutely.
 When
 will


we
 be
 there?
 Um
 so
 that
 is
 a
 thing
 I


don't
 know
 the
 answer
 to.
 If
 you
 ask
 the


AI
 labs
 they
 think
 two
 years.
 You
 ask
 AI


skeptics
 they
 think
 10
 years
 which
 is
 a


weird
 place
 to
 be
 for
 skeptics
 to
 be


like
 yeah
 this
 is
 definitely
 happening.


It's
 just
 not
 happening
 right
 now.
 Yeah.


So
 what
 what
 aspects
 of
 human
 work
 do


you
 think
 AI
 will
 complement
 and
 what


will
 it
 replace?


So
 I
 think
 that
 is
 a
 really
 interesting


question.
 Um


the
 whole
 premise
 of
 the
 book
 is
 about


co-intelligence.
 The
 idea
 that
 that
 the


machine
 you
 know
 works
 best
 with
 a
 human


that's
 the
 same
 way
 right.
 Um
 and
 so


right
 now
 because
 the
 AI
 has
 these
 has


what
 we
 call
 jagged
 frontier.
 It's


really
 good
 at
 some
 stuff
 you'd
 expect


and
 not
 good
 at
 other
 stuff.
 And
 it's


also
 missing
 functions,
 right?
 Like
 it's


hard
 to
 have
 it
 kind
 of
 connect
 the


world
 together.
 If
 I
 ask
 you
 to
 prepare


for
 the
 podcast,
 I'm
 going
 to
 get
 only


so
 far
 with
 it.
 It
 will
 probably
 give
 me


great
 preparatory
 advice,
 but
 then
 I


still
 need
 to
 go
 on
 the
 podcast
 and,
 you


know,
 and
 have
 this
 conversation
 with


you
 and
 I
 still
 that
 it's
 not
 doesn't


use
 my
 email
 well
 yet,
 so
 I
 can't
 let
 it


interact
 completely
 with
 your
 team.
 So


there's
 all
 these
 jagged
 edges
 that
 make


it
 hard
 to
 use
 as
 a
 universal
 person


replacement.
 Again,
 the
 goal
 of
 the
 AI


labs
 is
 agents
 will
 solve
 this
 problem


by
 doing
 the
 work
 for
 us.
 I
 again
 I'm


and
 I'm
 a
 little
 reluctant
 to
 believe


that
 we're
 going
 to
 be
 there
 as
 fast
 as


they
 think.
 But
 um
 I
 think
 compliments


is
 is
 pretty
 wide.
 I
 think
 the
 question


compliment
 it'll
 compliment
 us
 across
 a


wide
 range
 of
 tasks.
 I
 think
 where


you're
 weakest
 is
 where
 it
 will


substitute
 but
 almost
 at
 the
 individual


level.
 So
 if
 you're
 not
 good
 at
 idea


generation,
 the
 AI
 is
 probably
 better
 at


idea
 generation
 than
 you.
 If
 you're
 good


at
 idea
 generation,
 you
 will
 definitely


get
 value
 out
 of
 using
 AI,
 but
 you


should
 probably
 be
 using
 your
 own
 idea


generation
 as
 well.
 If
 you're
 really
 if


you
 are
 terrible
 at
 email
 communication,


the
 AI
 is
 probably
 better
 at
 that
 than


you.
 But
 that
 doesn't
 mean
 that
 you


don't
 have
 a
 role
 to
 play
 in
 making
 sure


the
 email
 shaped
 properly.


Yeah.
 No,
 I
 use
 it
 for
 a
 lot
 of
 my


emails
 just
 to
 help
 because
 my
 English


isn't
 so
 good.
 So,
 it
 just
 really


improves
 uh
 my
 emails
 a
 lot.
 Um
 now
 do


you
 think
 um


to
 which
 extent
 do
 is
 it
 now
 being
 used


for
 CFOs
 trying
 to
 cut
 cost
 and
 in
 to


which
 extent
 is
 just
 amplifying
 power


and


um
 helping
 us
 to
 do
 things
 better.
 So


this
 is
 a
 this
 is
 where
 companies
 get
 to


make
 choices
 and
 one
 of the
 things
 I


worry
 about
 with
 AI
 is
 if
 the
 leadership


isn't
 well
 informed
 in
 companies
 about


how
 they
 work
 they
 view
 this
 as
 another


normal
 technology
 in
 in
 the
 sense
 of


like
 this
 is
 a
 cost
 cutting
 measure.
 so


I
 can
 increase
 productivity
 by
 20%
 so
 I


can
 fire
 20%
 of
 my
 staff.
 I
 think


there's
 two
 things
 that
 worry
 me
 about


that
 approach
 outside
 of
 any
 sort
 of


moral
 or
 other
 kinds
 of
 concerns
 you


might
 have
 which
 is
 that
 first
 of
 all
 no


one
 knows
 how
 to
 use
 this
 right
 there
 is


no
 off-the-shelf
 product
 that
 just
 does


things
 for
 you
 with
 AI
 yet.
 Um
 they


they'll
 come
 but
 you
 have
 to
 figure
 out


how
 to
 use
 it
 inside
 your
 own
 company


and
 doing
 that
 requires
 you
 to
 actually


have
 experts
 figure
 out
 how
 it's
 used


and
 the
 experts
 of
 your
 own
 organization


your
 HR
 departments
 your
 R&D.
 So
 if
 you


start
 firing
 people
 for
 using,
 you
 know,


by
 because
 AI
 makes
 it
 more
 efficient,


everyone
 will
 just
 stop
 showing
 they're


using
 AI
 and
 you're
 going
 to
 be
 in


trouble.
 So
 I
 think
 there's
 some
 danger


in
 making
 a
 cost
 cutting
 move
 right


away.
 That
 doesn't
 mean
 people
 aren't


doing
 it.
 The
 second
 big
 danger
 for


making
 cost
 cutting
 is
 if
 you
 believe


we're
 on
 the
 edge
 of
 a
 real
 revolution


in
 how
 work
 gets
 done,
 which
 I
 I
 do,


then
 the
 idea
 that
 you're
 going
 to
 slim


yourself
 down.
 S
 if
 I
 get
 20%
 of
 per


performance
 improvement,
 I'll
 cut
 20%
 of


people
 feels
 like
 a
 really
 bad
 solution


in
 a
 world
 where
 everybody
 else
 is
 going


to
 have
 20%
 performance
 gain
 overnight.


And
 I
 so
 I
 think
 that
 organizations
 that


are
 in
 growth
 mode
 will
 tend
 to


outperform
 those
 who
 are
 using
 this
 as
 a


cost
 cutting
 technology,
 but
 we
 don't


have
 all
 the
 models
 yet.
 People
 are


still
 figuring
 this
 out.
 When
 we
 had
 a


breakfast
 recently,
 we
 talked
 about
 um


the
 role
 of
 compliance
 or
 general


counsel.
 Um
 how
 are
 you
 seeing
 that?
 So


the
 opinion
 that
 will
 probably
 get
 in


the
 most
 trouble
 is
 the
 two
 most
 not


universally
 but
 the
 two
 most
 risky


places
 to
 assign
 all
 of
 your
 AI


responsibility
 to
 is
 often
 it
 and
 legal


and
 that's
 not
 true
 in
 every
 case
 right


but
 legal
 compliance
 the
 issue
 is
 this


is
 a
 weird
 technology


um
 a
 lot
 of
 people
 know
 about
 is
 based


on
 rumor
 so
 the
 number
 of
 companies
 I


talk
 to
 that
 will
 refer
 that
 where
 the


legal
 office
 will
 refer
 to
 an
 incident


where
 Samsung's
 data
 was
 stolen
 by
 chat


GPT
 which
 never
 happened
 right
 what


actually
 happened
 was
 that
 that
 people


in
 Samsung
 were
 worried
 about
 chat
 GBT


using
 their
 data
 so
 they
 banned
 use
 in


the
 very
 early
 days
 you
 know
 so
 it's
 all


rumor
 based
 right
 now
 these
 AI
 models


are
 you
 know
 I
 can
 tell
 you
 they're


being
 used
 at
 Madna
 and
 they're
 being


used
 at
 JP
 Morgan
 like
 companies
 that


are
 very
 worried
 about
 data
 use
 with


legal
 restrictions
 are
 using
 it
 right


you
 guys
 are
 using
 AI
 there
 are
 ways
 to


get
 around
 at
 this
 point
 the
 legal
 issue


so
 if
 the
 legal
 team
 is
 holding
 you
 back


it's
 because
 they
 don't
 fully
 understand


the
 problem
 and
 on
 the
 IT
 side
 there
 are


some
 incredibly
 brilliant
 and
 innovative


IT
 people
 out
 there
 who
 will
 run
 with


this
 but
 the
 traditional
 way
 that
 it


handles
 a
 project
 right
 is
 they'll
 build


a
 product
 for
 you
 around
 this
 and
 check


out
 vendors
 and
 do
 this
 approach
 and


they'll
 keep
 they'll
 make
 AI
 an
 IT


technology
 as
 opposed
 to
 a
 everybody


technology
 and
 that's
 another
 danger
 is


if
 you
 just
 like
 we
 need
 to
 build
 an


application
 for
 AI
 but
 we
 actually
 need


to
 figure
 out
 use
 cases
 everybody
 needs


to
 be
 using
 this
 to
 get
 there
 so
 those


are
 two
 different
 danger
 spots
 they're


not
 universal
 I've
 seen
 some
 incredible


compliance
 officers
 who
 lead
 directions


with
 AI
 But
 I've
 also
 seen
 resistance


happen
 from
 there.
 Yeah.
 No,
 I
 I
 think


we
 we
 got
 uh
 tremendous
 uh
 compliance


here.
 Uh
 really
 really
 good.
 But
 it's


interesting
 because
 there
 are
 very
 few


cases
 where
 a
 compliance
 officer
 can


kill
 a
 company.
 I
 mean
 here
 if
 you
 hold


back
 the
 usage,
 you
 kill
 your
 company


because
 competition
 is
 just
 go,
 you


know,
 pulling
 apart
 by
 20%
 a
 year
 and


within
 two
 years
 you
 you're
 dead.


I
 I
 mean
 I
 I
 I
 think
 that
 that
 urgency


you
 feel
 is
 is
 really
 interesting.
 I


talked
 to
 lots
 of
 executives
 and
 you
 see


this
 light
 switch
 go
 off
 for
 them.
 A
 lot


of
 them
 are
 treating
 this
 as
 like
 they


put
 this
 down
 seven
 levels
 of
 their


organization
 or
 they've
 hired
 a


consultancy
 who's
 going
 to
 produce
 a


report
 on
 their
 AI
 readiness
 and
 then


you
 see
 the
 executives
 who
 kind
 of
 get


it
 and
 there's
 just
 night
 and
 day


because
 once
 you
 get
 what's
 happening


here
 it's
 very
 hard
 to
 not
 feel
 urgency


um
 and
 you
 know
 and
 to
 not
 be
 anxious


about
 resistance
 everywhere
 and
 that's


when
 our
 in
 our
 previous
 conversation


that's
 one
 of the
 things
 that
 struck
 me


was
 that
 feeling
 like
 oh
 this
 is
 this
 is


the
 big
 one
 and
 we
 need
 to
 figure
 this


out
 and
 organizations
 that
 haven't
 put


that
 in
 the
 list
 aren't
 going
 to
 be
 in


trouble.
 What
 proportion
 of
 companies


have
 got
 it
 now?
 You
 think?
 I
 am


surprised
 by
 how
 quickly
 the
 religion
 is


spreading,
 but
 not
 as
 many
 as
 you
 think.


I
 mean,
 I
 I
 talked
 to
 a
 lot
 of
 top


executives.
 I
 would
 say,
 you
 know,
 it's


gone
 from
 like
 2
 or
 3%
 of
 people,
 you


know,
 getting
 it
 to
 we're
 at
 20%
 of


executives
 in
 a
 lot
 of the
 firms
 that


should
 feel
 urgency
 feeling
 it.
 Um,
 but


that's
 a
 pretty
 big
 increase
 in
 a
 short


time.
 So,
 I
 mean,
 this
 technology
 is


remarkably
 rapidly
 adopted.
 Slight


change
 of
 uh
 um
 topic.
 How
 do
 you
 um


stay
 updated
 through
 these


extraordinarily
 fast
 changing
 times?
 Uh


so
 I
 think
 I'm
 probably
 one
 of
 the
 most


kind
 of
 uh
 you
 know
 current
 people
 on


using
 this.
 I've
 got
 I've
 got
 this


virtuous
 cycle
 going
 right
 which
 is
 as


somebody
 who
 does
 a
 lot
 of
 work
 in
 AI


and
 is
 influential
 in
 the
 space
 all
 the


AI
 labs
 come
 to
 me.
 I
 don't
 take
 money


from
 them
 but
 they
 all
 give
 me
 early


access
 to
 stuff
 so
 I
 know
 what's
 coming.


I'm
 on
 all
 these
 weird
 private
 Discords


and
 conversations.
 I'm
 on
 X
 and
 blue
 sky


and
 so
 but
 you
 know
 I'm
 a
 professor
 who


is
 on
 sobatical
 and
 spends
 a
 lot
 of
 time


thinking
 about
 AI
 stuff
 and
 I'm
 having


trouble
 keeping
 up.
 Um
 I
 think
 keeping


up
 is
 challenging.
 At
 the
 other
 hand
 I


don't
 think
 you
 need
 to
 that
 much.


Right.
 I
 actually
 think
 if
 you
 go
 with


like
 a
 chat
 GPT
 or
 Gemini
 and
 just
 use


it
 a
 bunch.
 Um
 those
 gen
 tend
 to
 have


the
 really
 up-to-date
 models
 but
 it's


hard
 to
 kind
 of
 keep
 up
 otherwise.
 I


mean
 I've
 got
 a
 newsletter
 so
 people
 can


subscribe
 to
 that.
 Um
 but
 there
 isn't


one
 sort
 of
 you
 know
 great
 source
 on


this
 and
 AI
 is
 still
 it's
 sort
 of
 like


how
 it's
 treated
 in
 organizations
 for
 a


lot
 of
 publications
 it's
 like
 one
 it's


spread
 across
 multiple
 parts
 of
 their


organization
 so
 it's
 reported
 a
 little


bit
 in
 politics
 a
 little
 bit
 technology


a
 little
 bit
 in
 business
 so
 nobody


really
 has
 a
 full
 picture
 I
 think


including
 people
 in
 the
 AI
 labs
 people


move
 from
 one
 company
 to
 the
 other
 right


and
 it
 seems
 like
 these
 models
 are
 not


ahead
 for
 a
 long
 period
 of
 time
 and
 they


are
 being
 overtaken
 all
 the
 time
 by


other
 things
 right
 do
 you
 expect
 this


will
 this
 something
 is
 Is
 this
 something


that
 will
 continue?
 So
 a
 lot
 of


questions
 of
 the
 future
 are
 unclear.
 I


think
 you
 know
 so
 the
 frontier
 models


the
 best
 models
 only
 one
 point.
 There's


only
 a
 few
 companies
 that
 can
 afford
 to


make
 them
 at
 this
 point.
 And
 so


generally
 you
 want
 to
 stay
 close
 to
 one


one
 of
 the
 model
 makers,
 right?
 So
 the


people
 who
 make
 frontier
 uh
 closed


source
 models
 are
 you
 know
 OpenAI
 and


Anthropic
 and
 Google
 by
 and
 large
 right?


There
 are
 some
 other
 options
 out
 there,


but
 those
 are
 sort
 of
 the
 three
 big


closed
 source
 ones.
 Generally,
 if
 you
 go


with
 one
 of
 those,
 they're
 they're
 going


to
 stay
 in
 the
 frontier
 for
 the


foreseeable
 future.
 There's
 not
 a
 reason


to
 suspect
 they're
 they
 might
 fall
 four


months
 behind
 for
 a
 little
 while.
 If


that
 matters
 to
 you,
 that's
 what
 your


lab
 is
 supposed
 to
 be
 doing
 in
 your


company
 is
 like
 how
 good
 is
 the
 new


model.
 Should
 we
 switch
 over?
 Somebody


else
 has
 to
 be
 doing
 that
 testing
 247.


Another
 thing
 always
 surprised
 me
 in


companies
 is
 how
 few
 of
 them
 have
 people


assigned
 247
 to
 just
 working
 with
 AI.


like
 it
 just
 lots
 of
 other
 departments


that
 work
 on
 things,
 but
 there's
 very


few
 people
 whose
 job
 is
 to
 stay
 on
 top


of
 these
 things.
 So,
 uh
 you're
 in
 the


lead,
 you
 get
 all
 these
 stuff,
 you're


invited
 to,
 uh
 pre-releases.


What
 when
 you
 now
 look
 into
 the
 future


here,
 what
 is
 what's
 been
 the
 biggest


surprise
 for
 you
 lately?


So,
 I
 think
 the
 biggest
 surprise
 for
 a


lot
 of
 us
 has
 been
 this
 idea
 of
 reasoner


models
 that
 you
 kind
 of
 see
 here,
 right?


So
 I
 showed
 you
 a
 little
 bit
 of
 this
 as


an
 example
 earlier,
 but
 it
 turns
 out


that
 models
 that
 sort
 of
 think
 out
 loud


outperform
 those
 that
 don't.
 This
 and


this
 very
 kind
 of
 simple
 trick
 has


increased
 the
 ability
 of
 AI
 by
 a


tremendous
 amount.
 So
 I
 think
 the


capability
 curve
 is
 coming
 faster
 than
 I


expected
 to.
 Um
 and
 that
 was
 that's
 been


a
 big
 surprise.
 And
 then
 the
 other
 side


of
 it
 that's
 been
 a
 big
 surprise
 is
 how


fast
 adoption
 has
 occurred.
 So
 um
 this


is
 a
 very
 fast
 adopting
 technology


according
 to
 any
 historical
 precedent.


We're
 probably
 up
 to
 a
 billion
 people


using,
 you
 know,
 chat
 GPT
 at
 this
 point.


The
 last
 numbers
 they
 released
 were


somewhere
 between
 500
 million
 and
 a


billion
 people.
 There's
 another
 few


hundred
 million
 using
 other
 models.


Like,
 this
 is
 an
 insanely
 high
 adoption


rate
 for
 a
 technology
 that
 sometimes


doesn't
 work
 or,
 you
 know,
 is
 weird
 to


use
 and
 where
 we
 don't
 quite
 know
 what


it's
 good
 or
 bad
 for
 yet.
 And
 so,
 I
 I


think
 that
 the
 speed
 of
 adoption
 and
 the


speed
 of
 capability
 gain
 are
 both
 faster


than
 I
 thought.
 by
 the
 end
 of
 the
 year,


what
 is
 it
 that
 it
 can
 do
 that
 it
 can't


do
 now?
 So,
 I
 think
 the
 the
 arbitrary,


you
 know,
 end
 of
 year
 deadline
 comes


right
 in
 the
 middle
 of
 where
 agentic


systems
 may
 actually
 be
 useful
 for


things,
 you
 know,
 so
 we're
 starting
 to


see
 these
 narrow
 purpose
 agents
 work


quite
 well.
 So,
 if
 you
 use
 AI
 for
 um
 you


know,
 for
 coding
 work,
 u
 for
 example,


you're
 starting
 to
 see
 that
 be
 very


useful.
 But
 the
 agents
 where
 you
 just


say
 fix
 the
 code
 for
 me
 still
 kind
 of


flawed.
 Um,
 a
 narrow
 agent
 like
 deep


research
 is
 a
 very
 good
 research
 agent


already
 and
 replaces
 a
 lot
 of
 what
 you'd


have
 an
 analyst
 do
 and
 increasingly
 will


go
 into
 territory
 that
 was
 lawyer


territory
 in
 other
 places
 of
 doing


research
 and
 analysis
 and
 pulling
 stuff


together.
 We're
 not
 quite
 there
 yet
 but


it's
 getting
 there.
 So
 I
 think
 the


question
 is
 how
 quickly
 you
 could
 just


assign
 an
 agent
 do
 this
 job
 for
 me
 and


it
 does
 a
 reasonably
 good
 pass
 that
 you


still
 need
 a
 human
 interaction
 with
 and


I
 think
 we
 might
 be
 there
 for
 many
 jobs


before
 the
 end
 of
 the
 year.
 When
 can
 I


say,
 uh,
 hey,
 I'm
 going
 to
 be
 in
 New


York
 first
 week
 of
 November.
 Please
 look


up
 the
 10
 best
 Mexican
 restaurants
 and


book
 a
 table
 7:30.
 I
 mean,
 I
 think
 we're


there
 already.
 That's
 that's
 not
 a


that's
 that's
 not
 a
 hard
 problem.
 Uh,


the
 only
 question
 is
 the
 book
 a


restaurant.
 And
 if
 you
 use
 Manis,
 it


would
 probably
 be
 able
 to
 email
 that


person
 or
 do
 that.
 That
 that's
 an
 easy


one.
 Um,
 and
 and
 I
 think
 your
 current
 AI


will
 do
 everything.
 Book
 the
 table
 for


you.
 And
 that's
 example
 of
 a
 connector


that
 we
 just
 need
 to
 connect.
 It
 does


voice.
 Uh
 in
 fact
 um
 Google
 has
 been


even
 before
 generative
 AI
 took
 off
 has
 a


model
 where
 you
 you
 if
 you
 you
 try
 and


book
 a
 table
 at
 a
 restaurant
 that
 uh


that
 doesn't
 take
 reservations
 it
 will


call
 and
 have
 a
 voice
 call
 them
 and
 an


AI
 try
 and
 book
 the
 reservation
 for
 you.


So
 that's
 already
 there.
 But
 one
 of
 the


interesting
 things
 about
 AI
 is
 right,


it's
 already
 there
 almost,
 right?
 Like


you
 can't
 just
 ask
 chatbt
 to
 do
 it.


There's
 a
 little
 bit
 of
 hoops
 to
 jump


through.
 So
 it's
 not
 a
 capability


problem.
 It's
 a
 user
 experience
 problem.


It's
 a
 UI
 problem.
 It's
 a
 communication


problem.
 And
 that's
 I
 think
 AI
 ability


far
 outstrips
 our
 ability
 to
 use
 it.
 Now


you
 wrote
 about
 um
 cybernetic
 teammate.


Um
 when
 when
 have
 you
 seen
 teammates


most
 strikingly
 outperform
 a
 human


colleague?


So
 this
 is
 again
 a
 case
 of
 of


co-intelligence
 right
 of
 working
 with


the
 AI.
 So
 the
 cyberneck
 teammate
 paper


we
 uh
 again
 with
 uh
 with
 my
 colleagues


at
 Harvard
 and
 MIT
 University
 of
 Warwick


and
 uh
 and
 at
 Penn
 we
 went
 out
 and
 uh
 we


did
 an
 experiment
 proctor
 and
 gamble


where
 they
 gave
 us
 776
 of
 their


employees
 and
 we
 did
 real
 work
 that
 they


actually
 do.
 So
 you
 know
 um
 whether


that's
 product
 analysis
 work
 or
 product


development
 or
 marketing
 and
 we
 had
 them


either
 work
 alone
 or
 in
 cross
 functional


teams
 of
 two
 with
 one
 marketing
 person,


one
 business
 person
 and
 one
 uh
 technical


person
 and
 what
 we
 found
 was
 that


individuals
 working
 alone
 um
 with
 AI
 had


the
 same
 performance
 statistically
 as


teams
 of
 two
 and
 they
 also
 produced
 more


diverse
 ideas
 uh
 than
 than
 if
 they
 were


working
 alone
 and
 they
 were
 happier.
 So


that's
 the
 sort
 of
 cybernetic
 teammate


idea,
 right,
 of
 working
 with
 the
 AI
 to


do
 things.
 I
 think
 a
 lot
 of
 people
 are


already
 doing
 cybernetic
 team
 work,


right?
 I
 I
 I
 know
 you
 are.
 You
 consult


AI
 about
 all
 sorts
 of
 things.
 Now
 you


have
 a
 small
 team
 working
 for
 you,
 you


know,
 a
 panel
 of
 experts.
 So
 I
 think


that
 people
 who
 use
 this,
 this
 is
 the


natural
 way
 to
 use
 AI
 actually
 is
 as
 a


teammate
 where
 it's
 helping
 you
 and


you're
 filling
 goals
 on
 it.
 So
 I
 think


we're
 we're
 seeing
 pretty
 big
 gains


across
 the
 board
 from
 that
 approach.
 How


can
 we
 best
 develop
 um
 the
 people
 in
 uh


in
 the
 usage
 of
 this?
 What's
 the
 best


way
 to
 really
 drive
 I
 mean
 we
 talked
 a


bit
 about
 the
 institution
 and
 how
 you


drive
 the
 institution
 forward.
 How
 do


you
 what's
 the
 best
 way
 to
 drive
 the


individuals?


So
 I
 think
 that
 um
 we
 are
 still
 learning


about
 how
 to
 do
 that.
 I
 this
 is
 not
 like


traditional
 training
 that
 we
 give
 you


four
 or
 five
 rules
 for
 using
 AI.
 I
 mean,


I
 do
 think
 there's
 some
 things
 to
 learn,


but
 a
 lot
 of
 training
 focuses
 on
 like


prompting
 techniques,
 and
 prompting


techniques
 turn
 out
 to
 be
 less
 and
 less


important
 as
 time
 goes
 on.
 AI
 models
 are


very
 Why
 is
 that
 becoming
 less


important?
 Well,
 two
 things
 I
 think
 are


happening.
 One
 is
 the
 models
 are
 getting


better
 and
 larger,
 better
 models
 get


your
 intent
 better.
 And
 the
 second
 is
 it


turns
 out
 we
 just
 don't
 know
 a
 lot
 about


prompting.
 It's
 very
 contingent.
 We
 have


actually
 a
 little
 study
 that
 we
 did
 at


the
 generative
 AI
 labs
 at
 Wharton
 where


we
 measured
 um
 the
 accuracy
 of
 AI
 and


answering
 questions
 if
 you
 were
 polite


to
 it
 versus
 if
 you
 were
 mean
 to
 it.
 Um


and
 it
 turns
 out
 that
 politeness
 matters


a
 huge
 amount
 on
 certain
 answers.
 So
 if


you
 do
 a
 hundred
 tests
 on
 a
 particular


math
 problem,
 it
 turns
 out
 in
 that
 math


problem
 if
 you
 say
 please,
 you
 get
 a


more
 accurate
 answers
 than
 if
 you
 don't


say
 please,
 right?
 But
 it
 turns
 out
 on
 a


separate
 math
 problem,
 saying
 please


makes
 it
 do
 worse
 and
 yelling
 at
 it
 does


better.
 and
 we
 don't
 know
 why
 it
 works


in
 one
 case
 but
 not
 the
 other.
 So
 the


average
 effect
 is
 zero
 basically.
 Uh
 but


the
 individual
 question
 effect
 is
 quite


large.
 So
 if
 we
 told
 people
 oh
 always
 be


polite
 or
 always
 use
 this
 approach
 it's


sometimes
 going
 to
 work
 sometimes
 going


to
 backfire.
 And
 so
 I
 have
 so
 I
 I


normally
 say
 please
 so
 I
 should
 just
 not


do
 it.
 It
 doesn't
 seem
 to
 help.
 But
 you


know
 I
 but
 then
 again
 it's
 I
 I
 think


there's
 value
 in
 the
 mental
 model
 of


treating
 AI
 like
 a
 person.
 And
 if
 please


helps
 you
 do
 that
 even
 though
 it's
 not
 a


person
 then
 I
 think
 it's
 no
 problem.
 And


it's
 just
 kind
 of
 hard
 otherwise,
 right?


It
 feels
 weird
 to
 just
 order
 your


computer
 around.
 And
 then
 if
 you
 if
 you


talk
 to
 people
 who
 really
 believe
 super


intelligence
 is
 coming
 soon,
 you
 better


be
 polite
 now
 because
 they
 they'll
 know.


Um,
 how
 do
 you
 how
 do
 you
 test
 for
 uh
 AI


literacy
 when
 you
 interview
 people
 uh
 in


a
 job
 interview?


I
 want
 to
 avoid
 overindexing
 on
 today's


literacy
 because
 we
 don't
 have
 a


definition
 of
 AI
 literacy.
 I
 mean,
 I


teach
 AI
 and
 I
 we
 don't
 have
 a


definition
 of
 being
 AI
 literate.
 It


tends
 to
 be
 you're
 an
 AI
 user
 and
 then


the
 question
 is
 are
 you
 a
 sophisticated


user
 or
 not?
 Does
 that
 matter
 to
 you?


Because
 it
 might
 turn
 out
 that
 they're


not
 a
 sophisticated
 user
 but
 a
 small


amount
 of
 experience
 with
 a


sophisticated
 user
 will
 make
 them
 good.


It's
 a
 if
 we're
 judging
 AI
 literacy


today,
 you're
 really
 judging
 people's


independent
 ability
 to
 go
 out
 and
 figure


out
 ways
 to
 use
 AI
 in
 their
 job.
 And


that
 can
 be
 valuable,
 but
 that
 doesn't


always
 tie
 in
 with
 subject
 matter


expertise
 and
 other
 issues.
 So
 I
 would


just
 ask
 people
 at
 this
 point,
 show
 me,


you
 know,
 I
 when
 we
 were
 hiring
 people


for
 the
 general
 AI
 lab,
 we
 would
 both


ask
 them
 how
 they
 used
 AI.
 We
 would
 give


them
 a
 task
 and
 say,
 use
 AI
 to


accomplish
 the
 impossible
 task
 and
 get


as
 far
 as
 you
 can
 in
 an
 hour,
 right?
 Um,


and
 we
 would
 also
 be
 asking
 people


about,
 you
 know,
 actually
 interviewing


them
 about
 what's
 working,
 what
 isn't


for
 their
 AI
 use
 and
 having
 them
 show
 us


some
 of
 that.
 So
 I
 mean,
 I
 think
 you


would
 judge
 AI,
 but
 that's
 kind
 of
 an


example
 of
 usage
 and
 creativity
 with
 AI.


And
 we're
 an
 AI
 lab,
 so
 we
 kind
 of
 need


those
 people.
 I
 worry
 at
 this
 stage


about
 companies
 picking
 AI
 literacy
 as


the
 major
 issue.
 One
 of
 the
 things
 we


found
 from
 the
 BCG
 study
 was
 that
 more


junior
 people
 were
 actually
 worse
 at


using
 AI
 in
 the
 organization
 than
 more


senior
 people.
 They
 may
 have
 gotten
 AI


but
 they
 didn't
 understand
 the


organization.
 So
 they
 would
 produce
 a


document
 and
 say
 this
 is
 a
 great
 memo


and
 then
 someone
 with
 20
 years
 of


experience
 would
 look
 at
 the
 memo
 and


say
 no
 it
 needs
 to
 be
 better
 in
 these


following
 six
 ways.
 They
 would
 have
 been


better
 using
 AI
 than
 the
 junior
 person.


So
 I
 I
 worry
 it
 kind
 of
 goes
 back
 to


that
 chief
 AI
 officer
 example
 you
 gave


earlier.
 Companies
 are
 trying
 to
 hire


their
 way
 out
 of
 this
 problem
 and
 I


don't
 think
 there's
 a
 way
 of
 hiring
 your


way
 out
 of
 the
 problem
 without
 the


executives
 also
 engaging
 deeply
 and


making
 some
 decisions
 about
 what
 AI


means
 in
 their
 organization.
 What


personality
 type
 do
 you
 think
 will
 adopt


the
 best?


So
 the
 model
 I
 we
 we
 talk
 about
 agency
 a


lot.
 Uh
 we
 don't
 fully
 know
 what
 it


means.
 I
 I
 teach
 entrepreneurship.
 So


it's
 you
 know
 there's
 an
 entrepreneurial


action
 or
 entrepreneurial
 you
 know


tendency
 to
 entrepreneurship
 that
 I


think
 is
 the
 same
 thing
 as
 agency
 which


is
 a
 feeling
 that
 you
 have
 control
 over


your
 environment
 a
 kind
 of
 locus
 of


control
 that
 you
 are
 in
 control
 of
 your


own
 destiny
 and
 you
 should
 seek
 out


opportunities
 to
 do
 things
 that
 are


different
 or
 better
 or
 improve
 and
 and


that
 is
 not
 something
 everybody
 has
 that


seems
 to
 be
 playing
 a
 role
 in
 AI
 but
 we


don't
 have
 measurements
 of
 it
 so
 I'm
 a


social
 scientist
 I'm
 making
 stuff
 up


here
 which
 always
 makes
 me
 feel
 bad


because
 we
 don't
 have
 a
 measure
 I
 don't


have
 an
 AI


measurement
 that
 makes
 people
 that
 it


can
 tell
 you
 but
 there
 is
 this
 sort
 of


agentic
 sense
 on
 the
 other
 hand
 some
 of


the
 most
 entrepreneurial
 interesting


people
 I
 know
 are
 late
 adopters
 of
 AI


for
 whatever
 reason
 they
 hit
 a
 barrier


when
 they
 were
 using
 it
 and
 I'm
 not
 sure


what
 that
 is
 so
 you
 know
 again
 I
 we


don't
 have
 easy
 answers
 to
 almost
 any


question
 about
 AI
 at
 this
 point


uh
 two
 uh
 uh
 slightly
 different
 ones
 uh


how
 do
 you
 see
 the
 regulation
 in
 the


Europe
 versus
 the
 US
 so
 I'm
 not
 a


regulation
 expert


But
 um
 I
 I
 will
 tell
 you
 that
 one
 of
 the


interesting
 things
 that
 happened
 with


the
 release
 of
 DeepSseek,
 which
 is
 a


Chinese
 open-
 source
 model
 um
 R1,
 DeepC


R1
 specifically,
 was
 it
 was
 the
 first


time
 a
 Chinese
 model
 was
 on
 the
 frontier


of
 capabilities.
 It
 did
 not
 beat


American
 models.
 They're
 better
 again
 at


this
 point,
 but
 clo
 it's
 a
 typical


closed
 source,
 open
 source.
 are
 a
 few


months
 behind
 but
 a
 very
 good
 model
 that


caused
 a
 bit
 of
 bit
 of
 a
 panic
 in
 the
 US


that
 I
 don't
 think
 was
 warranted


necessarily
 um
 of
 uh
 even
 from
 a
 great


powers
 competition
 standpoint
 um
 but


that
 sort
 of
 um
 that
 plus
 the
 new


administration
 I
 think
 has
 created
 this


opportunity
 where
 there's
 very
 little


regulation
 I
 in
 fact
 one
 of
 the
 um
 one


of
 the
 bills
 in
 front
 of
 Congress
 right


now
 in
 the
 US
 is
 that
 there
 is
 um
 would


ban
 AI
 regulation
 at
 the
 state
 level
 for


the
 next
 10
 years
 and
 I
 don't know


whether
 that
 passes
 or
 not
 but
 I
 think


there
 is
 a
 desire
 put
 the
 foot
 in
 the


accelerator
 and
 less
 regulation
 and
 more


sort
 of
 letting
 AI
 rip.
 Um
 I
 think
 that


my
 impression
 from
 talking
 to
 people
 in


Europe
 has
 been
 there
 has
 been
 a
 move
 to


less
 regulation
 from
 a
 very
 regulated


viewpoint.
 I
 think
 part
 of
 this
 came


down
 to
 the
 idea
 that
 a
 lot
 of the


initial
 regulation
 was
 based
 around


existential
 risk
 which
 I
 think
 is


important
 um
 but
 we
 don't
 know
 how
 to


measure
 and
 um
 and
 now
 I
 think
 we
 have


to
 start
 moving
 towards
 a
 place
 where


we're
 regulating
 harm.
 So,
 even
 though


there
 was
 this
 um
 there's
 a
 bill
 saying


you
 can't
 regulate
 AI,
 another
 bill
 went


through
 Congress
 um
 banning
 deep
 fakes.


So,
 I
 think
 we're
 going
 to
 have
 to


regulate
 the
 outcomes
 of
 AI,
 but
 I
 think


that
 Europe
 is
 still
 a
 much
 tighter


regulatory
 environment,
 but
 is
 probably


looser
 than
 it
 was
 a
 couple
 years
 ago
 on


the
 AI
 front.
 You
 mentioned
 existential


risk.
 Is
 there
 an
 existential
 risk?
 I


have
 no
 idea,
 but
 a
 lot
 of
 very
 smart


people
 think
 there
 is.
 You
 know,
 for
 me


it's
 I
 the
 idea
 that
 AI
 gets
 smart


enough
 that
 takes
 over
 the
 world
 doesn't


feel
 feel
 real
 to
 me,
 but
 that
 doesn't


mean
 that
 it
 isn't,
 right?
 And
 I
 as
 as
 a


as
 a
 as
 a
 good
 sort
 of
 uh
 you
 know


social
 scientist,
 right?
 I
 have
 to


realize
 my
 own
 views
 are
 kind
 of


secondary
 to
 what
 is
 what
 does
 smart


people
 say
 if
 we
 have
 a
 forecasting


contest.
 And
 there's
 a
 lot
 of
 the


founders
 of
 AI
 think
 that
 it's
 a


existential
 danger
 to
 humanity.
 A
 lot
 of


very
 smart
 people
 think
 it
 that
 way.
 So


we
 have
 to
 view
 it
 as
 an
 existential


risk
 as
 well.
 The
 problem
 is
 we
 don't


know
 what
 form
 that
 takes
 and
 we
 don't


know
 what
 the
 level
 is.
 Like
 originally


a
 GPD4
 or
 GPD,
 you
 know,
 uh
 03
 class


model
 was
 considered
 an
 existential
 risk


level
 when
 before
 we
 had
 these
 things.


Now
 we
 have
 them.
 We're
 like
 these


aren't
 going
 to
 let
 anyone
 take
 over
 the


world
 or
 spontaneously
 go
 out
 and
 and


destroy
 the
 economy.
 So
 is
 there
 a


magical
 point
 to
 where
 that
 happens?
 I
 I


just
 don't
 know.


Well,
 Ethan,
 this
 has
 been
 uh
 uh
 40
 uh


incredible
 minutes.
 you
 are
 at
 the
 at


the
 very
 forefront
 of
 the
 very


forefront.
 Uh
 it's
 been
 uh
 so


interesting
 talking
 to
 you.
 So
 uh
 keep


up
 the
 good
 work.
 Look
 forward
 to
 to


staying
 in
 touch
 and
 see
 what
 what
 the


future
 brings.
 Thank
 you.
 It's
 a


pleasure
 being
 here
 and
 I
 will
 say
 it's


it's
 exciting
 to
 talk
 to
 people
 who
 get


the
 AI
 thing
 because
 I
 think
 it
 is


important
 and
 spreading
 that
 news
 is


important.
 We
 can't
 go
 with
 eyes
 closed.


We
 have
 to
 make
 decisions
 about
 the


future
 and
 you
 can
 only
 do
 that
 if
 you


are
 using
 these
 things.
 Absolutely


fantastic.


[Music]