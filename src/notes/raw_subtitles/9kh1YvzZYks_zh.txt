大家好
那今天就跟大家系统完整的去讲一下
A/B实验
可以帮助你直接到达A/B实验的
最顶级认知
那我为什么有这样的自信呢
就是因为我其实在亚马逊
在Meta都做过
在那个时候
我就很早地意识到了A/B实验的作用
然后出了很多A/B实验相关的视频
那我现在所在的公司
Statsig就是市面上最领先的
A/B实验软件
或者说A/B实验platform的提供商
是一个SaaS公司
像OpenAI、Anthropic、Atlassian、Notion、Figma 这样的公司
都是我们的客户
而且我在这里边作为一个evangelist
我的工作就是去
不光要跟我们的客户
还要跟很多业界的所谓的industry leader(业界领袖 )
去不断地进行学术上和应用上的交流
像不是我们客户的Lyft、DoorDash、Netflix等等的公司
我个人都有非常深度的交流
所以说我完全知道
整个业绩的水平是什么样子
和我的水平是什么样子
那我们就直接开始
我会分几个地方讲啊
第一个问题是为什么要做实验
实验的价值是什么
这个其实和很多人想的不一样
第二点我会围绕着实验的目标
去介绍
这个实验体系到底应该是怎么设置
我们应该怎么样子
围绕这个目标去打造我们的实验体系
第三我会讲解A/B实验里边
最基础最重要的统计知识
hypothesis testing(假设检验)
和为什么
在课本上讲的hypothesis testing(假设检验)是错的
他把来自于Fisher(费雪)的p value framework(p值框架)
和来自于Newman Pearson(纽曼-皮尔逊)
的hypothesis testing framework(假设检验框架)
inconsistent(一致)ly(不一致)的blend(混合) 在了一起
所以说就产生了很多误解
你基本上学到的
所有的关于hypothesis testing(假设检验)在A/B实验中的应用
因为这个不consistent(一致)的foundation
基本上都是错的
所以说我们要建立一个正确的基础
在那之上
我会介绍三种相对advanced(高级的)的test(测试)吧
一个是 CUPED(通过回归调整的方差缩减方法)
也就是 regression adjustment(回归调整)
一个是Bayesian (贝叶斯方法)
就是贝叶斯和frequentist(频率学派)
和频率学派到底有什么区别
它们到底是怎么回事儿
和我们为什么要做sequential testing(序贯检验)
对于其他的比如说switchback(轮换实验)
Grid search(网格搜索）
geo testing(地理测试)这些东西
我会大概讲一下它们到底是干什么的
但是不会重点去讲
好直接开始
第一个我们为什么要做实验
很多人有一个误解
就是我们做实验
是为了看到这个实验是正向的
然后去决定这个东西要不要launch(上线)
但是我要给大家强调的一点呢
就是 the value of experimentation(实验的价值) 
come from surprises(惊喜)
你做实验的目标
不是为了去confirm(证实)你原有的好的想法
而是应该去挑战你的想法
当你一个好的想法被你的实验验证了
其实实验本身没有提供任何的价值
所有的价值都是这个好想法的
但是你以为的一个好想法被实验发现
这是一个坏想法
或者说
你一个觉得没有什么东西的想法
被实验发现这是一个非常好的想法
这才是实验的价值
Ron Kohavi(罗恩·科哈维)的那本书里边
他就讲了
Bing search(必应搜索)做了一个非常非常小的改动
结果带来了好几亿美元的销售提升
这正反两面都是实验的价值
而且在 Ron Kohavi(罗恩·科哈维)的书里边和 paper(论文)里边
他也有讲过
在他任职的这些公司里边
基本上在一开始
那个hypothesis(假设)的成功率是3%-30%
基本上就是20%
所以说实验的价值是来自于surprise(惊喜)
然后你在80%的情况下都会被surprise(惊喜)
也就是说你在做这个实验的时候
你如果把你的 hypothesis(假设)写下来
就是我做这个feature(功能)
它可以带来什么样的指标变化
一般我们会去做一个feature(功能)
都是因为它会带来正向的指标变化
然后80%你在做实验的时候
都会发现并不成立
那这件事情为什么很重要呢
因为你假设你的matrix(指标)是这样增长的
但是你如果你不知道
你什么launch(上线)的feature(功能)是正向的
或者负向的
你就会有很多东西你以为是正向的
结果是负向的
那你指标的增长呢
它就是往上往下
往上往下
这样的东西是很难compound(累积)
如果说你做好了实验
你哪怕不因为实验
而多做什么其他的东西
你只是把那些negative impact(负面影响)的
feature(功能)给kill(砍掉)了
那你就可以去得到一个更高的指数增长
这是实验的最根本的意义
value of experimentation come from surprises
(实验的价值源于惊喜)
所以我们应该想方设法地
提高实验的coverage(覆盖率)
我们希望每一个新做的feature(功能)
都是被实验的
而不是说我觉得这个想法是好的
我对它有信心
所以我去做实验
我们看到很多这种ad hoc(临时)做实验的公司
其实都是这样的结果就是
他们只把他们有信心的东西
拿上去做实验
这其实基本上是没有什么意义的
那这个时候可能有的同学说了
就是100%的东西做实验
这个可能吗
我告诉你是绝对可能的
而且像Meta这样的公司就是这样做的
以及我们Statsig很多客户
包括OpenAI等等公司也是这么做的
那不用我们产品不是Meta的公司
到我现在为止我知道了一个是Canva
就是网页Photoshop的那个Canva
他是这么做的
这里边有一个核心的technical insight(技术洞察)
怎么样才能做到这件事情呢
就是你要把feature gate(功能开关)和实验
设计成一个object(对象)
在Meta里边
这个叫Gatekeeper(看门人)和Delta(增量测试)
总之就是feature gate(功能开关)
是一个conditional rule(条件规则)
去决定你这个feature(功能)
到底能不能被用户看见
你可以设置各种条件
比如说是不是内部的员工
你如果只需要内部test(测试)的时候
你这个feature(功能)只被内部的员工看到
公司外面的人看不到的
你可以比如说我在加拿大上10%
或者说我在美国上50%
你都可以去设置对应的conditional rule(条件规则)
或者说iOS(苹果操作系统)
或者说是这个Android(安卓操作系统)
其实所有的100%的用户
你都会得到这个code(代码)
但是你的这个feature gate(功能开关)
它其实是在上面之上的一层configuration(配置)
它控制这个用户
到底能不能看到对应的feature(功能)
这其实起码在美国的公司里边
已经是个标配了
就是你现在去launch(上线)一个feature(功能)
基本上都是要通过feature gates(功能开关)的方式
去stage roll out(分阶段发布)
也就是说
逐步的去把这个feature(功能)先launch(上线)给1%的人
看看有没有bug(漏洞)
然后10% 然后100%
去年CrowdStrike那个机场蓝屏事故
就是因为他们没有去用feature gate(功能开关)
这也被网上很多人骂
就是这么基本的
到2024年了
竟然这么基本的东西还不用
它已经是一个默认的
developer(开发者)的best practice(最佳实践)了
那在这种情况下
就是你一个feature gate(功能开关)
你可以决定一个用户看到
还是没有看到一个feature(功能)
那你在这之上加上randomization(随机化)
就会变成一个A/B实验
所以说你在底层系统
设计的时候
你把feature gate(功能开关)和 experiment(实验)
设计成同样的一个object(对象)
那你只要把feature gate(功能开关)
再加上一个randomization(随机化)
然后再加上你的stats engine(统计引擎)
去进行对应的统计计算
你就能做到100%的feature(功能)
全都可以开实验
因为你的feature(功能)
不需要再有additional set up(额外设置)了
就是当工程师build(构建)一个feature(功能)
他在roll out(发布)过程中
他在使用这个feature gate(功能开关)
他自然而然的
你就免费的得到了对应的实验
你只需要最后再通过你的系统
把stats engine(统计引擎)把这个指标体系给放进来
你就可以去选择
任何一个通过feature gate(功能开关)发射的feature(功能)
你到底需不需要看它的实验的readout(读出结果)
这是底层的infra（基础设施 ）
这也就是为什么
Meta的A/B实验体系可以这么厉害
那这样的一个infra（基础设施 ）
它其实背后
还带来了一个A/B实验非常重要的
文化的属性
这个文化的属性
就是
可以给底层的工程师们非常强的agency(自主权)
而不需要大家consensus(达成共识)之后再去build(构建)
是如果你不做实验的话
一般公司的这种文化就是
我们大家先讨论
讨论得到了一个consensus(共识)
或者说有一个planning(规划)
然后工程师们去做对应的东西
但是这个时候
这个consensus building(建立共识)其实会花很长的时间
会花好几个周
你如果使用实验的话
你就会发现你roll out(发布)这个feature(功能)本身
它的这个范围是可控的
那绝大多数的公司
会选择这样的一条路径
也就是说我们test behind a gate(在开关后测试)
或者 test behind an experiment(在实验后测试)
我们先把这个东西的demo(演示)给做出来
然后我们去选择
比如说我们内部先去实验一下
然后我们去开放给1%的用户
看看他是不是有很大的不好的效果
如果说他没有很大的不好的效果
我们看看10%
这个时候可能就有足够的用户
看看它在你这个metrics(指标)上到底是好是坏
或者说好多少坏多少
如果说再好的话
再继续的去launch(上线)到更多的用户
然后直到launch(上线)到100%
然后50%test(测试组)
50%是control(对照组)
在我们确定了
对这个feature(功能)确实是好的之后
我们再把它这个treatment(实验组)
就是这个新建的这个feature(功能)
launch(上线)到100%的用户
那这样的好处就是
当我们在讨论
这个feature(功能)到底应不应该launch(上线)
或者launch(上线)到百分之多少的时候
我们是带着data(数据)来的
然后我们是带着这个feature(功能)
到底是什么东西来的
我们这个东西已经做好了
我们就不需要去讨论那么多
有的没的了
你不然的话
其实为什么80%的hypothesis(假设)都是错的
我这个在采访MIT(麻省理工学院)教授Kevin的时候
他有讲过
就是他们做的实验90%也是错的
然后我问他为什么
他说因为我们现在的所有的产品
都是在做难的事情
如果说我们做简单的东西
就是你有100%的成功率的话
那说明你做的东西根本就不值得做
说实话
因为我们这个产品已经很成熟了
我们生态已经很复杂了
我们做的这个improvement(改进)都很难
所以说人的大脑是没有办法
在做这个事情之前
就能predict(预测)所有东西的
我在这里边有一个例子
就是我在给那些公司们做案例的时候
就有一个公司
Rec Room和我们的real customer study(真实客户研究)
他们的UI(用户界面)变化了
然后做成了一个非常崭新的UI(用户界面)
结果他们的key metric(关键指标)
就是number of chat threads created(创建的聊天线程数)
就一个巨大的下降
然后你发现了这个巨大的下降了以后
你再去看那个展现的非常好的UI(用户界面)
你就知道了
这个message(消息)这个button(按钮)
其实是本来在一个中间
非常显著的东西
被放到角落里了
虽然它是一个单独的button(按钮)
但是它其实是在角落里边
大家找不到
看到了这个数据
然后你再看一下这个解释
你觉得非常make sense(合理)
但是你不看这个数据的时候
你光看那个UI(用户界面)
我相信没有任何一个人
可以看出来这个问题
这也是徐老师跟我们一直强调的
intellectual honesty(智识诚实)
人其实的这个认知是非常狭隘的
我们认知世界的方式也是非常浅的
我们人脑是不太适合应对复杂环境的
所以说实验为什么必要
它给我们带来intellectual honesty(智识诚实)
它可以帮助我们通过验证
通过事实告诉我们
我们想法哪里是不够的
来给我们带来价值
以及它可以带来一个更好的engineer(工程师)
更有agency(自主权)的文化
就是大家可以去更快的去做事情
而不是把时间花在讨论一些
争论一些没有人知道对错的东西上
这是为什么要做实验
那第二点我稍稍就讲到了
就是围绕
这样的一个目标
我们应该做什么样子的实验体系
第一就是像我刚刚说的
你的feature gate(功能开关)和experiment(实验)
应该是一个object(对象)
其实我在给其他公司做培训的时候
我会讲实验其实是有三个步骤的
就是你要做一个实验系统的话
一般大家会有三步
其实A/B实验是一个最容易开始
但是最难scale(扩展)的系统之一
你想开始的话
我们任何的一个data scientist(数据科学家)
给我们一个notebook(笔记本文件)
我们都可以做实验
甚至不要给我notebook(笔记本文件)
你给我一个Google sheet
给我一个Excel
我就可以给你做实验
不就是把一堆东西treatment(实验组)一堆东西control(对照组)
然后做一个t-test(t检验)
算一下standard error(标准误差)
那些数学都是非常非常简单的数学
然后你用notebook(笔记本文件)
似乎就可以automate(自动化)这件事情
但是这个事情其实是非常容易出错的
而且你每个人再去重新做一下的话
就会发现结果又很不一样
你的randomization(随机化)
你做这个assignment(分配)的时候也很容易出错
所以说第二步一般大家是去自动化
这中间的数据
就是所有的计算我自动化
然后所有的pipeline(流水线)我尽可能自动化
这就会让你在一个公司里边
可以从一年做5个实验
变成一年做50个实验
但是这一步还不够嘛
就是因为你这个时候
每一个实验
仍然需要工程师去帮你set up(设置)
对应的experiment(实验)
以及你的这个
很多时候指标
数据质量就会越来越下降
那你就需要用一个这种scalable(可扩展的)
experimentation(实验化)的infra(基础设施)
你要把feature gates(功能开关)
和experiments(实验)给结合起来
那这个时候
工程师不需要再花时间
去additional set up(额外设置)experiments(实验)
experiments are default on (实验默认开启)
那你就可以从50个实验scale(扩展)到
5千个5万个50万个实验
那就取决于你的公司
到底是在launch(上线)多少feature(功能)了
这个时候做实验
并不会让你做任何事情变慢
因为你所有的实验都是免费的
在这个阶段的公司
他们的constraint(约束)是他们有多少新的ideas(想法)
实验本身就不构成任何的constraint(约束)
当你有了这样一个system(系统)之后
我在我的里边还讲
就是数据质量又变得很重要
你的data(数据)是需要trustworthy(可信的)
大家相信这个实验的过程
但是大家不相信data(数据)也是没有办法
我在腾讯
其实也做了很多这个数据清理的工作
我会发现你一开始可以把数据做好
但是随着时间推移
数据又会变差
为什么
因为数据其实是有logging table(日志表)
然后有metrics(指标)
这两个呢
大家看到的都是table(表)
但是在这之间啊
就是有非常多的convoluted pipelines(复杂流水线)
然后有很多code(代码)
这些code(代码)其实是非常难maintain(维护)的
然后这个pipeline data(流水线数据)
是非常fragmented(碎片化的)
而且analytics(分析)的tenure(任期)一般是1-1.5年
所以说你在这里边做的很多东西啊
人走了你也不知道他到底是什么了
然后你就没有办法改
你上层改了一个东西
结果6层之后
6个step(步骤)之后
你就发现在别的地方出错了
而且所有的数据都对不起来
就是你要去对revenue(收入)
然后你要去对什么
active user(活跃用户)
在这些非常复杂的convoluted pipelines(复杂流水线)里边
想找到一个source of truth(真实源)
其实是非常难的一件事情
那我们公司提供的产品
就是一个metrics catalog(指标目录)
它用一层layer(层)
然后用一个产品化的东西
visualize(可视化)拖拉拽的方式
去让你去定义好你的logging table(日志表)之后
我可以在你定义好的这个logging table(日志表)上
去进行各种各样的aggregation(聚合)
进行各种各样的group by(分组)
进行各种各样的filtering(过滤)
然后甚至去set up(设置)一些对应的time window(时间窗口)
它的这些基本的操作
就可以满足百分之八十九十
甚至对于绝大多数的公司
它其实可以满足100%
从logging(日志记录)到metrics(指标)这一步
那你的所有的指标
都是在这样一个产品里边
centralized define(集中定义)之后
你就完全可以做到end to end traceable(端到端可追溯)
就是你看到的任何一个指标revenue(收入)
你打开revenue(收入)你就知道了
它是来自于哪个table(表)
我是怎么样子做的
这个加减乘除怎么样做的计算
我到底是count(计数)sum(求和)
count distinct(去重计数)
percentile(百分位)还是其他的计算方式
我的这个filter(过滤)的设置是不是合理
你完全是end to end traceable(端到端可追溯)
然后每个人都能读懂
那你在这个时候
你的data(数据)就是trustworthy(可信)的
你有了一个
simple definition on the experiment
实验上的简单定义
然后你有了一个trustworthy data(可信数据)
你就可以想方设法的
让你的实验的coverage(覆盖率)是100%
你可以多做实验
然后你就可以做到像前面那样所说的
让实验去帮助你提高开发的速度
帮助你了解你每一个launch(上线)的
feature(功能)到底是一个什么样的效果
这就是第二点
你应该怎么样去设计你的实验体系
那这个时候
就是很多data scientists(数据科学家)起的反作用了
data scientists(数据科学家)
尤其是junior data scientists(初级数据科学家)
或者说是一些我叫它
pedantic data scientists(学究型数据科学家)
就是这种学院派的
这种data scientists(数据科学家)
有一个非常不好的习惯
就是他们会认为自己的这个职业的价值
是建立在把事情做复杂上
而不是把事情做简单上
把事情做得越简单
越standardized(标准化)
你才可以让这个实验更scalable(可扩展)
明白吧你把这个实验做复杂了
你要问你
到底你得到的这个价值是什么
它值不值得
因为你要把这个东西做复杂
而导致其他人看不懂
而导致你的实验的速度下降
而导致你的结果更难communicate(沟通)
更难被business side(业务方)buy in(接受)
如果说是这样的话
你就不应该去做这个复杂的东西
除非你这个复杂的东西
是解决一个真实存在的问题
我就看到很多这个data scientists(数据科学家)啊
就是看到这个实验
第一反应就是
我们要不要去做什么nonparametric(非参数检验)呀
然后我们要不要去做各种各样的
就是各种paper(论文)上说的新的实验的方式
要不要用reinforcement learning(强化学习)啊
然后要不要用GenAI(生成式AI)啊
我觉得这都是没有去认识到
实验的价值到底是什么
然后是希望拿着一个锤子
去找一个钉子去用
从而建立自己的职业价值
就是我在之前的视频有讲过
harder things are more valuable(越难越有价值)
是一个巨大的misconception(误解)
这个是我们学校里边带来的
根深蒂固的一个思维误区
我们一定要战胜这个思维误区
我们要知道不是
harder things are more valuable
越难越有价值
more valuable things are more valuable
有价值的东西更有价值 
那什么东西更valuable(有价值)
就是你要让实验去尽可能多的
去覆盖你的new feature development(新功能开发)
然后去不断得到surprises(惊喜)
然后去帮助你更客观的更定量的
然后用causal data(因果数据)
去指导你的产品的发展
好这个是第二大点
就是
我们应该怎么样子去设计实验体系
那第三点也就是对应的统计知识了
在这里边
我希望给镜头前的同学们
普及一些必要的统计知识
也就是说当我们这个实验我刚刚说了
要想方设法的做更多更快的时候
我们作为数据科学家
需要怎么样子be rigorous(严谨)
怎么样子提高整个决策系统的决策质量
那第一点
就是我们要对hypothesis testing(假设检验)
和对power(统计功效)
对minimum detectable delta(最小可检测差异)
对sample size(样本量)有一个非常明确的理解
这个理解为什么是重要的
因为我们实验永远面对一个trade-off(权衡)
就是我们是假定sample size(样本量)
这个东西是给定的啊
就是sample size(样本量)一般是跟你的business(业务)相关
你的business(业务)有多少sample size(样本量)
你也很难去增加sample size(样本量)
那在这种情况下
你遇到的trade-off(权衡)就是说
当你跑这个实验越长
你就能be able to detect(能够检测)a smaller effect(更小的效果)
you can be more accurate(你可以更准确)
you can get more signal(你可以得到更多信号)
whatever it means(不管它意味着什么)
这几个说法都是指向同样一件事情
就是你实验跑的越久
你得到的信号就越强
然后你就能detect(检测)一个更小的effect(效果)
那假设你的这个feature launch(上线的功能)
本身是非常impactful(有影响力的)
它可以10%的incremental(增量)
那这个时候你可能跑个几天
你就知道了
它是一个非常好的feature(功能)
你就直接launch(上线)就好了
真正的就是我们作为数据科学家
需要面对的问题
一般是这种
就是比如说你一个像Meta这样的公司
它0.1% 0.2%的这个effect(效果)能不能detect(检测)
像一个普通公司
可能0.5% 1% 2%的这种effect(效果)能不能detect(检测)
那在这种情况下
就是你如果做一些事情的话
就会导致你一个周两个周是可以detect(检测)的
然后你如果不做这些事情的话
就会发现可能要有5个周
6个周才能detect(检测)
那这里边有几个重要的点
第一个呢
就是concurrent experiment(并行实验)是可以的
就是你应该run(运行)很多experiment(实验)
interaction effect(交互效应)不是一个大问题
也就是说当一个用户
他在实验A
也在实验B
那实验A的readout(读出结果)和实验B的readout(读出结果)
是准的吗
我们在academia(学术界)里边
会把这个东西当成一个big deal(大事)
但是
其实你如果真正的去看empirical data(经验数据)的话
会发现它出现的问题是非常非常少的
它不值得我们为此而去实验
先跑了实验A才能跑实验B
你实验A和实验B可以一起跑
只要他们是正交的就没有问题
你可以1万个实验一起跑
只要他们是正交的就没有问题
如果说你担心他们出现问题的话
还有这种叫interaction effects detection(交互效应检测)
就是所谓的interaction(交互)
就是一个用户
他既在实验A的treatment(实验组)里边
又在实验B的treatment(实验组)里边
那他们这个two by two(2X2)
就是treat(实验组)-treat(实验组- control(对照组)-control(对照组)
然后treat(实验组)-control(对照组)-control(对照组)-treat(实验组)
他们的这个test effect(测试效果)到底是什么
然后你就可以知道
它到底这个treatment effect(处理效果)
是什么东西带来的
只有在很少的情况下
这种interaction effect(交互效应)是有问题的
比如说你的这个
实验A是红色字
实验B是红色背景
那这个实验A加实验B
就什么都看不见了
这种时候是有问题的
那在这种情况下
你做实验设计的时候也应该call out(指出)
但是其实这种情况在实际生活中
是非常非常少的
不要因为这种非常extreme(极端的)的情况
去不跑concurrent experiment(并行实验)
你要去勇敢地去跑concurrent experiment(并行实验)
这样可以极大地增加你实验的速度
你同样的一个时间
你就可以多跑很多实验
那第二个呢
就是你要去做variance reduction(方差缩减)
你要想方设法的去reduce(减少)你的variance(方差)
那在这之前
我可能就必须要讲hypothesis testing(假设检验)了
我在这期视频里面
我觉得因为它是一个真的
从头到尾要讲清楚的话
必须要15分钟以上的东西
所以说
我去把我的那期英文视频放在这儿
大家感兴趣可以去看
我回头也有机会的话
我也会出一期中文视频
总之就是你的hypothesis testing(假设检验)会告诉你
sample size(样本量)
minimum detectable effect(最小可检测效果)
null hypothesis(零假设)
alternative hypothesis(备择假设)
alpha(显著性水平)
beta(第二类错误概率)
power(统计功效)都有什么关系
那在你知道了这些关系之后
我们会发现sample size(样本量)其实已经给定了
然后你的这个test(测试)本身
你的feature(功能)决定了你的effect(效果)是什么
那我们要想做的呢
是想方设法的降低这个
minimum detectable effect(最小可检测效果)
从而缩短我们实验的时间
或者缩短我们实验对sample size(样本量)的要求
那在这种情况下
data scientist(数据科学家)唯一能做的就是
reduce variance(减少方差)
reduce noise(减少噪音) from the experiment(来自实验)
那怎么样子去reduce variance(减少方差)呢
基本上最好用的方法
就是regression adjustment(回归调整)
或者说是CUPED(通过回归调整的方差缩减方法)
而且更稍稍更advanced(高级的)一点的东西
就是这种multivariate regression adjustment(多元回归调整)
或者说是我们公司把它命名叫CURE
也就是
你不光可以用pre-experimental data(实验前数据)
去predict(预测)post-experiment data(实验后数据)
去reduce variance(减少方差)
你还可以用这个user(用户)
或者说这个units(实验单元)的其他属性
去做regression fitting(回归拟合)
然后从而去降低variance(方差)
关于CUPED(通过回归调整的方差缩减方法)
我也有一期三四十分钟的英文视频
跟Meta research scientist(Meta研究科学家) 
Kenneth Huang(肯尼思·黄)
他是之前UC Berkeley(加州大学伯克利分校)
的math PhD(数学博士)
然后在Meta做research scientist(研究科学家)
出了一期视频
他也做了很多相关的论文和研究
我们那期视频里边讲的非常清楚
我在这里边如果感兴趣的话
可以去看那期video(视频)
总之就是
CUPED(通过回归调整的方差缩减方法)其实在很大一定程度上
就是difference in difference(双重差分)的思路
但是它可以在每一个unit level(单元级别)上
去进行这样的regression adjustment(回归调整)
所以它可以极大地降低variance(方差)
但是你做完CUPED(通过回归调整的方差缩减方法)之后
其实你能再继续降低的variance(方差)
已经不多了
你可以大概理解
就是说CUPED(通过回归调整的方差缩减方法)可以帮助你降低80%
你应该降低的variance(方差)
所以说你没有做CUPED(通过回归调整的方差缩减方法)的话
你应该做CUPED(通过回归调整的方差缩减方法)
如果你做完CUPED(通过回归调整的方差缩减方法)的话
其实也没有那么多值得做的了
就不要花太多的时间精力
去想那么多fancy technique(花哨技术)
搞什么deep learning(深度学习)之类的东西
去试图降低variance(方差)了
不值得
这是CUPED(通过回归调整的方差缩减方法)
然后接下来是Bayesian(贝叶斯)和frequentist(频率学派)
Bayesian(贝叶斯)和frequentist(频率学派)
这又是一个那些pedantic data scientists(学究型数据科学家)
特别喜欢讲的话题
就是他们觉得这个Bayesian(贝叶斯方法)
是一个特别了不起的东西
然后是一个特别值得说的事情
但是我说啊
就是Bayesian(贝叶斯方法)它的好处是
它和frequentist(频率学派)其实是不同的 philosophy(哲学)
然后Bayesian(贝叶斯方法)
它可以给你带来一个非常自洽的解释体系
这是它的好处
我跟Kenneth(肯尼思)也有一个关于Bayesian(贝叶斯方法)的
40分钟的视频
感兴趣的话也可以去看
但是这里边很重要的
大家要了解到的一点啊
就是Bayesian(贝叶斯方法)和frequentist(频率学派)做法
它其实不会改变你的数据
就是你的实验数据
还是你的实验数据
没有改变任何东西
他们只是对于同样data(数据)的
不同的interpretation(解释)而已
如果你用的Bayesian(贝叶斯方法)
是一个no prior(无信息先验)的Bayesian(贝叶斯方法)
然后是没有informative(信息性)
就informativeness-less（较少信息的）
的这个Bayesian(贝叶斯方法)的话
其实你们会发现
就是他们虽然会带来不同的解释
但是他们所有的这个数据
包括他们背后的decision rule(决策规则)
全都是一模一样的
那我们就知道了
就是这就是一个baseline(基线)
就是Bayesian(贝叶斯方法)和frequentist(频率学派)
其实没有什么特别大的不同
那接下来有不同的点
就是我们所谓的Bayesian with priors(带有先验的贝叶斯方法)
那Bayesian with priors(带有先验的贝叶斯方法)又有两种
第一个
就是它对这个point estimation(点估计)是有一个 prior(先验)
就是比如说
我之前觉得这个东西应该是2%
所以说我的这个之后
实验数据不是从0开始算
而是从2%开始算
那这显而易见就会带来一个问题
就是你怎么去define(定义)你的这个prior(先验)
假设我一个VP(副总裁)说
我就是想要这个feature(功能) launch(上线)
比如说我给他一个10%的这个prior(先验)
那你这个实验可能collect(收集)很多data(数据)
你只能把它从10%move(移动)到 9%
那你不管怎么样都是launch(上线)
但是你如果给一个Frequentist（频率学派）的话
它这个实验数据可能就是从0%到负的1%
你就会发现这个东西不应该launch(上线)
那你这个prior(先验)到底谁对谁错呢
我觉得这个是非常dangerous(危险的)
非常容易被滥用的
所以说整个field(领域)里边
很少有人去推荐这个
关于point estimation(点估计)的prior(先验)
那另外一个点
是关于你的这个confidence interval(置信区间)的prior(先验)
这个其实是有意义的
就是
你不应该去过度地launch(上线)太多data(数据)
那这件事情是有意义的
这件事情有意义的点是什么呢
就是我们又回到这个frequentist view(频率学派的观点)
frequentist view(频率学派的观点)是我同样一个test(测试)
如果做100遍
然后这个confidence interval(置信区间)是95%呢
我的interval(区间)
都会在这个confidence interval(置信区间)之内
可是这有一个问题啊
就是那我这个100遍里边
每一次都不是我的true value(真实值)
也就是我的这个实验它得到了
一个point estimate(点估计)
这个point estimate(点估计)
几乎100%的
不是你的这真正的treatment effect(处理效应)
那它带来一个什么样的问题呢
带来的问题就是
当你做很多个实验的时候
你这个实验加起来
就会出现很多1+1不等于2
1+1小于2的问题
以及
你就会launch(上线)很多本身不该launch(上线)的东西
所以说你的false discovery rate(错误发现率)是很高的
但是这个东西不光是有Bayesian(贝叶斯方法)可以解决
你frequentist(频率学派)加上一个简单的rule（规则）
就可以解决
我推荐Cunningham的paper(论文)
如果你感兴趣detail(细节)的话
我可以把对应的这些东西
发到评论下面
或者说我以后再专门出一期视频
去把这个事情讲清楚
但是如果说你只需要得到一个conclusion(结论)
并且你相信我的话
你就知道了
Bayesian(贝叶斯方法)和frequentist(频率学派)
其实只不过是
对于同一数据的不同解释
它们背后有不同的哲学
他们最后没有改变数据
所以说
他我觉得真的不是一个那么大的deal(大事)
他们也很容易被一些简单的方法
去bridge(弥合)他们之间的difference(差异)
就最后他们得到的decision rule(决策规则)也是一样的
他们带来的decision(决定)也是一样的
根本不值得
大家去进行那么大的一个讨论
第三点就是sequential testing(序贯检验)
而且我借着sequential testing(序贯检验)的这个话题
去讲一下
我们要做的一件很重要的事情
就是去减少false discovery rate(错误发现率)
我在这里边可以问大家一个问题啊
就是一个本身应该launch(上线)的experiment(实验)
没有被launch(上线)
和一个本身不该被launch(上线)的experiment(实验)
launch(上线)了
哪一个危害更大
就是它本身可能是一个很好的结果
但是它没有被launch(上线)
然后它本身可能是一个不好的结果
但是它launch(上线)了
哪个危害更大
一般是后面这个危害更大
为什么呢
因为你的实验
其实一般都是便宜的
但是你的experiment(实验)被launch(上线)了之后
它是贵的
它这个贵体现在我可能要花更多的钱
我可能要影响更多的用户
也体现在我的这个代码
现在进入了代码库里边
它就成为了
日后很长一段时间的维护成本
所以说当你launch(上线)一个experiment(实验)的时候
它的这个成本
和你做的实验本身
是非常不成比例的
这里边贵很多
所以说你launch(上线)了一个不好的东西
它其实成本是非常高的
这也就是所谓的
我们为什么要去
control你的false discovery rate(控制你的错误发现率)
那你为什么会产生
false discovery rate(错误发现率)呢
就有很多原因
包括p-hacking(p值操纵)
然后包括你的这个数据不rigorous（数据工作不严谨）
但是其中有一个非常常见的原因
就是peeking(偷看数据)
就是你在做实验之前
你做了sample size calculation(样本量计算)
你做了power analysis(功效分析)
你发现我需要两个周的时间
我可以得到比如说2%的
minimum detectable effect(最小可检测效果)
然后我说这个实验要做两个周
结果你在第一个周的时候你发现欸
这个实验3%了
statistically significantly positive(统计显著正向)了
我这个时候我就说那我去把它launch(上线)吧
这就是一个peeking(偷看数据)
然后你在peeking(偷看数据)的状态下
去做的这个decision(决定)
大概率会导致false discovery(错误发现)
或者说长期来看
一定会提高你的false discovery rate(错误发现率)
为什么
因为你想想
假设你的这个experiment(实验)
就是intuitively(直觉上)去解释的话
你的每个实验的点
它其实都是这么一个observation(观测值)
就像我刚刚说的
你每一个这个point estimate(点估计)
都是自己带着一个confidence interval(置信区间)的
而不是一个真的那个100%的
你实验的true effect(真实效应)那个point estimate(点估计)
所以说它就有可能是正好跳到了
这个confidence interval(置信区间)的上面
或者说跳出了这个confidence interval(置信区间)
导致它正了
那这个时候你再observe(观察)一段时间
因为有更多的data(数据)进来
他可能又回去了
就是又回到了那个不显著的区间
可是人本身又是带有bias(偏见)的
所以说人看到了一个
statistically positive result(统计显著的正向结果)
他就想说去直接launch(上线)
不管是PM(产品经理) DS(数据科学家)
还是engineer(工程师)
因为大家升职
就是在launch(上线)一些新feature(功能)上嘛
所以说你就会带着这个bias(偏见)
然后带着这样的一个false discovery(错误发现)
那你去做这件事情
长期就会提高你的false discovery rate(错误发现率)
那sequential testing(序贯检验)所做的事情呢
就是他去spend你的power(消耗你的统计功效)
大家就这么理解
spend Beta(消耗第二类错误概率)
就相当于spend你的power(消耗你的统计功效)
那就是在一开始的时候
他给你一个更宽的confidence interval(置信区间)
让你更难得到一个significant (显著)的结果
到实验越来越往后呢
它的这个confidence interval(置信区间)
就越来越趋近于
他不做sequential testing(序贯检验)的结果
如果说你的实验你算好了
然后duration(持续时间)
比如这是两个周
那你在两个周之后你的这个
sequential testing adjusted confidence interval
(序贯检验调整的置信区间)
就和你的没有adjusted(调整)的confidence interval(置信区间)
变成一致的
就变成一样宽了
那这个approach(方法)
就可以帮助大家去减少false discovery的rate(错误发现概率)
而且它背后还有一个很重要的philosophy(哲学)
就是你的这个adjustment(调整)
越conservative(保守)越好
就是你在一开始的那个confidence interval(置信区间)
越宽越好
当然这不是无限宽啊
就是在算好了之后的情况下越宽越好
为什么
你要assume无限的peeking(假设无限偷看)
在sequential testing literature(序贯检验文献)里边
又有一大堆这个讨论
就是什么beta-spending(β消耗)
alpha-spending(α消耗)
其实绝大多数讨论的就是
我怎么样去spend(消耗)
我的这个Beta(第二类错误概率)
我应该是一个线性衰减啊
还是怎么样
我应该怎么样去
assume我的peeking plan(假设我的偷看计划)
在实际中我觉得这些东西都不make sense(合理)
实际中其实你就应该assume(假设)
大家是无限的peeking(偷看)的
大家会每天都去看
大家想什么时候看就去看
你不太可能在一开始做这个实验之前
你就去set up(设定)一个这个peeking的rule(偷看规则)
你就假设大家无限的去看就好了
那在这种情况下
它其实也是一个非常好的decision rule(决策规则)
因为你的实验一般不应该ship early(过早上线)
但是你可以abandon early(提前终止)
也就是说
当你的这个负向的结果就是它statsig negative(显著负向）
超过你的confidence interval(置信区间)的时候
你就可以去kill the experiment(终止实验)
因为这个时候一般是有一个bug(漏洞)
或者是有一个非常不好的
负向的用户体验
你是可以去kill(终止)这件事情的
但是我们不需要
你的test(测试)可以非常sensitive(敏感)的
早期去探测到一个positive的effect(正向效果)
因为这个东西其实没什么长期的好处
你就等这个实验到了
它两个周该到的时间
然后你再去做这个launch decision(上线决定)就好了
这个在management(管理学)中
我觉得是一个应该这样子
去properly motivate(正确激励)大家
所以说你综合管理学
综合人性
你就是应该用一个非常conservative(保守的)
sequential testing(序贯检验)
去adjust(调整)你的confidence interval(置信区间)
去penalize peeking(惩罚偷看)
从而系统性地降低你的false discovery rate(错误发现率)
以上就是我觉得非常重要的
几个不同的test(测试)
CUPED(通过回归调整的方差缩减方法)
Bayesian(贝叶斯方法)和sequential testing(序贯检验)
那其他的还有一些test(测试)
如果大家感兴趣的话
不管是switchback test(轮换实验)啊
还是grid search（网格搜索）啊
还是search interleaving（搜索交错）这样的test(测试)
感兴趣的话欢迎在下面留言
我们有机会也可以再跟大家聊一下
今天就把一些主要的观点跟大家讲了
我知道这个东西讲的也很深
但是我相信
对于一个如果做实验的数据科学家
或者PM(产品经理)或者engineer(工程师)
这些内容都是有用的
我这边天色也晚了
希望大家喜欢我身边的这一盆篝火
那我们这期视频就到这
我在这里边诶
还有一个酒壶跟大家干一杯
我们下期再见