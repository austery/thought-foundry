欢迎收听《硅谷101》
我是泓君
Today
we're announcing the Sora app
powered by the all-new Sora 2
9月的最后一天Sora2发布
它可以把一句话
变成一段10秒的短视频
而好莱坞完全由AI创作的演员
Tilly Norwood
它诞生6个多月
就获得了6.5万的粉丝
I'm built on everything
that came before me
她发自拍 代言品牌
却从来没有真实存在过
My jeans are binary
所以我们看到一个趋势
数字人它正在成为新的内容生产者
但是我们说在屏幕上
生成一段2D的视频
到一个3D的数字人
实现一个比较稳定的实时的互动
这中间其实还是
有很多的技术壁垒的
本期嘉宾柴金祥教授
他是2000年就已经进入了
卡内基梅隆大学去研究机器人
但是因为机器人
它的应用与落地都非常的困难
所以他们团队反而成为了
世界上最早用AI做3D动画的团队
在这18年的时间里
他几乎都在做同样的研究
从机器人到好莱坞的AI动画
到今天其实我们又在讨论一个
非常前沿的问题就是
3D数字人的模型
是不是又可以反过来去驱动机器人
所以这听起来
其实有一点点像一种轮回
但也是一种新的开始
这一集我们就来讨论一下
这轮的人工智能浪潮
到底是如何去改变
3D数字人这个行业与机器人领域的
而在好莱坞与游戏产业里
到底谁又是这项技术的受益者
今天跟我在一起的嘉宾
是魔珐科技的创始人与CEO
柴金祥教授
Hello 柴教授您好
Hello 大家好
我以前是在美国当教授
是2018年的时候回去
创立了魔珐科技
做了大概有7年多的时间
很高兴今天有机会
和大家分享一下
关于3D数字人
和巨神智能的一些观点
因为正好是在采访您前几天
就是硅谷大家都在关注的一个大事
就是Sora2放出来了
然后它做成了一个
类似于社交媒体的形式
就是我最近是被Sam Altman刷屏了
好像每个人都会拿它去做一段demo
包括我们前几天刚刚开了
《硅谷101》的科技大会
我们就生成了一段
让Sam Altman帮我们去宣传
我们大会的Sora2的视频
看起来它在屏幕里面的形象
这是一个比较数字人的形象
这个对你们的业务会有影响吗
我自己大概也去快速地体验一下
我觉得Sora2相比Sora1的话
进步是蛮大的
无论从画质也好
包括新的一种视频的那种形态
我觉得这里面一个核心的点
其实还是一个
文生视频的能力了
它主要的形态是以人为中心的
以前可能Sora1的时候
还是有风景
各种其他的一些
视频的内容的形态
它可以让视频里的人
做各种各样的事情
跳舞也好
坐在那跟你交流也好
吃东西也好等等等等
我也大概用了一下
第一个感觉的话
其实视频生成的
现在还是10秒钟的时间
还是没有跳出
被时间的限制文生视频
第二个点其实也特别特别重要
大家一直在说物理上的一致性
基本上大家看
刷屏的时候很多效果
其实还是蛮好的
但你真正自己做的时候
还是有很多瑕疵
太多了
他那个视频里面有皮卡丘
跟一个唐老鸭
在总统竞选的一段辩论
他可以在原视频上改
我就说把这个辩论变成一个
在《硅谷101》上关于AGI的辩论
主题是Alignment2025
是我们活动的主题
但你仔细去看的话
它后面的Alignment
那个字就是错的
就开始乱码了
是 还有一个点特别重要
对视频这样的内容创作者来说
你不仅想生成视频
它的背景里面如果有字错了
或者人物的有一致性的问题
那你最想做的
说我能不能edited一下
能把它变好
其实它现在这个能力也还没有
更重要的是
它现在是容许你用prompt
去生成这个视频
你没有能力去精细化地去控制
这个人的动作 表情等等等等
有一个点它是特别的好
它第一次让人看到了
如果有一个大模型
其实你可以让人做各种各样的动作
在视频这个层面上
那我们是在做3D数字人
这方面的研究包括产品
我们认为假如说最后我们像做人
人可以在交流 跳舞
可以在娱乐大家
最后的大模型会是什么形态
它的训练数据会是什么形态
你看到Sora2他又说
我用所有的视频作为输入
作为训练数据
我就可以做这个
最近Genie3出来了以后
其实是
它其实是3D的生成了
给你一种交互型的感觉是吧
但它不是人
它是关于这个场景相关的
到最后如果咱们做大模型
如果做人的话
我们会觉得
最后可能需要2D加3D的
所有的训练技术在一起
我们是希望你生成这个人的时候
不仅是没有这个10秒钟的限制
你还希望它没有瑕疵
物理上是准确的
你能控制它
最好它是实时的而且成本很低
因为我们自己
现在在做3D数字人的时候
除了我们3D的训练数据
其实我们也已经开始用
大量的一些视频的数据一起结合
作为训练数据来做
这个大模型的整个
3D数字人的表达力的模型
你看视频这个数据
如果你的模型做得好
其实还是有一定的生存能力的
以前我看Sora1的时候
就觉得好像不行
因为你觉得Sora1
都是场景式的生成
然后Sora2里面
它基本上因为你要让视频有生命力
就必须有一个主体
这个主体要么是人要么是动物
是的
然后它的生成看起来也比较立体
所以其实我简单总结一下
Sora2跟你们的整个的
3D数字人的生成
最大的区别是
它是文生视频
你们相当于是文生3D
然后这个3D
它可以是在VR领域里面进行展示的
比如说我戴着一个VR头盔
我可以360度地去看到这个人
同时这个3D
未来可不可以用于机器人
这个我们待会也可以去讨论一下
核心是这个区别
是 就是2D跟3D之间的区别
Sora2还是文生2D的视频
如果3D的话
你放在VR AI里面
它就跟我们现实生活中是一样的
那3D还有一个好处
它能让你控制
就像人一样
你让它怎么动就怎么动
但你2D因为在
我们叫像素这个层面
其实要对它进行精准人的
动作表情的控制
相对来说会比较难
因为我看见你们公司的数字人
其实也会用于这种屏幕的展示
有一点我可能很难区分的是
我知道很多公司的
那个展示屏的数字人
都是你们来做的
假设我进到一个展厅
看到一个屏幕上的
非常立体的数字人
它有动作声音表情
跟我看到Sam Altman
在一个视频里的数字人
就是我们说除了时长的这个区别
它在核心的技术上
它的区别是什么呢
一个区别
在屏幕上这个数字人
其实它担当的角色是
人跟机器之间交流的一个载体
那人跟机器交流的时候
其实你是实时互动的
我们是希望一般来说
端对端小于2秒钟
或1.5秒的延时才可以做
不能说像你生成一个视频
要等个10分钟 5分钟
这是不可能的
如果再往下走呢
屏幕里这个数字人
如果是在展厅里面
你希望所有的介绍
回答问题它的动作不能出错
如果有一点瑕疵
那你肯定觉得这个不行
所以这里面跟Sora2
有一个很大的区别
你不能有瑕疵
你在物理上是准确的
不能有瑕疵
物理上准确指的是
人他的表情动作
他有一致性
他不会突然出现说
我的胳膊突然衔接不上了
不能是这样子的
不能是说
大家以前可能看得比较多
当你用文生视频去做的时候
手指是个特别难的事情
经常手指会多出来一点
或者从这一帧的时候OK
可能到5秒钟的时候
忽然多了一个手指
或多出来了一截
或穿插也好
那你在实际的交互中
特别是一个人的时候
他是一个服务人员
或者他是个销售人员
跟你讲解产品的时候
你肯定是不希望这个体验很差的
他一定要准确
最后一个点
当你把这样的3D的数字人
部署在一个终端上的时候
你的成本不应该高
因为终端本来今天来说
它本身这个屏幕
可能也就一万人民币
如果你说生成这个视频
给它交互了20分钟
即使它能实时做
他说一年放在那
我也得花很多钱
那就没法做了
但今天从Sora的角度
或Sora2文生视频的角度来说
其实这个成本它是不能扩展的
它的成本是多高
用你们的这个成本是多高
为什么成本之间
会有这样的一个差距
我不一定能给一个具体的数字
但我可以告诉你一个量级
我们现在比语音合成的成本
比如说语音合成
现在大模型做的
我比它成本可能是几十分之一吧
这里面就很核心的一个点
就是2D跟3D之间的区别
其实3D对人类来说
其实我要去描述一个人
他的动作表情
其实他只要有几百个参数就行了
人的肌肉可能就是大几百块
你只要去控制一些肌肉就可以了
你下一步就是用3D的渲染
把它3D的内容变成视频
然后要3D的解算
因为不仅有人的表情动作
还有头发 衣服
我们需要有物理解算
这两个事情如果你用AI来做
其实我们最大的一个核心是说
你内容生成以后
你要用游戏的引擎
非常昂贵的GPU来做
当我们把这两个事情
用AI渲染跟解算做了
这就使得咱们的成本
主要就是生成
每一帧生成这几百个参数的成本
跟大模型生成Token
其实是一样的
所以它的成本就非常非常低
如果说你从文生视频
因为你是没有结构化信息
你全是像素
所以在这个事情上
使得你整个的推理
整个生产的过程
你的成本会非常非常高
所以我理解
现在你们之所以能把成本降下来
是因为你们有一个自己的端模型
可以这样理解吗
是 我们有一个怎么把文本
变成我们所谓的3D多模态
表达能力的一个模型
其实就是从文本生成语音
表情的参数
动作的参数
肢体比如手势的参数
我们把这些参数传到终端
终端就可以是Pad
或者是终端一个大屏上
我们用AI渲染
给AI解算把它变成视频
这个渲染其实因为我们用AI做的
所以它对于
终端算力的要求是极低的
我们现在都可以用一个
比如说国内这种几百块钱的芯片
比如说RK3566 瑞芯微的
我们在端上就可以跑了
比如说它要跟人做实时互动跟问答
这种还是在端模型上
还是说你后面
除了你自己的这个端模型
在表达的内容上
你会去接大模型
这是个很好的问题
我在跟你交流的过程中
首先我的眼睛看到你
我的耳朵听到你
这个我们叫做感知
大模型其实是有理解跟决策能力的
然后我们做那个事情
是把文本直接变成了语音跟我姿态
身体的动作 表情 手势
相当于一个人
他不仅仅只是有语音
也不仅仅只是有表情
或者表情比较木讷
他是动作 语言 手势都是一体
就是人与人之间的交互
现在你ChatGPT的话
你可以输入声音图片
它最后输出文字
我们做的是说
是文字到3D的多模态这个输出
比如说咱们俩要交流
就是人跟一个数字人
它其实需要两个模型现在
一个是就是像ChatGPT这样的
多模态到文本的模型
第二个是从文本
再到多模态的3D多模态的模型
就语音的输出
动作 表情 手势的输出
我们只有自己垂域的大模型
但我们也可以用
比如说现在国内
像千文的也好
DeepSeek的也好
或者豆包的模型也好
跟我们接在一起形成端对端的
人与数字人之间的这种
像人一样交流的一种体验
所以你们从多模态到文本是
可以用大模型来做
用大模型来做
然后从文本到多模态
就是你们自己的这个端模型
自己的我们叫做
文生3D多模态大模型
这已经是一个产品
可以发布星云平台
是的
这个产品我们会在10月份发布
现在我们是在测试testing mode
然后我们现在可能有几百个的
B端的企业客户在测试
也有付费了已经
我们预计时间会在两周后吧
发布我们的文生3D多模态这个模型
因为我们自己在做的过程
做了很长很长时间
从我回到20多年前
我读研究生开始
到今天我们花了很多的精力做
我们希望大家不要重复造轮子
能够把这个能力
提供给所有的开发者
能够把我们的能力
集成到他们的应用中去
了解
我自己觉得很有意思的一点就是
因为我知道你们公司
之前其实是在做3D数字人的
所以我理解
随着就是你们要发的这个星云平台
所以你们其实就是从一家
3D数字人的公司
到了一家3D数字人的平台公司
我这样的理解是对的吗
差不多 我觉得差不多
对 是的
之前我在NVIDIA的发布会上
Jensen Huang他会非常自豪地说
你看到的我不是真的我
然后他是一个自己的
虚拟的3D数字人跟大家介绍
比如说他后面有一个壁炉
然后他在前面介绍
渲染得非常非常的真实
他经常会用他自己的虚拟人
去讲他们的渲染能力有多强大
他们的显卡有多强大
他那个的成本大概有多少
这个成本其实蛮高的
但你问的问题特别特别好
因为他今天做的
其实还是视频的输出
通常来说造这个人
如果像老黄造成这样子的话
通常是需要研发团队
配合美术团队
一个team来做这个事情
按照业界它的成本
基本上在美国的话
找国内最顶尖的美术团队来做
基本上在10万美金左右
10万美金一个人
对 差不多
做到就是他们发布会的那个效果
逼真效果
然后再包含视频
它只包含把这个人造出来
视频如果要做
可能成本也会按秒算
这个其实在我们通常会讲
3D数字人其实还是在
专业级的内容生产
就还没有到每一个人都能生产
这样的3D数字人
能生成这样的视频
对 我记得其实每次去
那个游戏的展会
会感受非常明显
大家怎么去造那个3D数字人
以前我们是让一个演员
他会有很多的动作捕捉的团队
同时会有一个环形的摄像机
把你身体的每一个部位都拍
再来建模
再一步一步地把它还原出来
这是不是也经常是好莱坞使用
或者游戏公司使用到的一种方式
对 刚才讲到了专业级的造人
无论是3A级游戏公司
包括好莱坞的阿凡达
或者老黄这样的数字人
其实整体来说它是两部分的东西
第一部分 我要把这个人造出来
像你一般会我们叫扫描
你会有很多相机在那
你坐在那
你做各种表情
把你人的整个的几何
几何词的意思
就像雕塑雕你人的这个形象一样
然后再把人表面我们叫纹理
包括这个材质把它给重建出来
然后生成这个人
包括人本身的肌肉
我们用学术化的语言来说
叫建模跟绑定
第二步你要让它动起来
你看到就是身上穿一件动捕的衣服
上面有各种点
旁边有很大的一圈相机
能把你的动作捕捉下来
再去驱动刚才那个
照完那个人
再用渲染引擎
或者用离线的渲染的引擎输出视频
其实它整个过程
从建模绑定照这个人到动画
让这个人动起来
再到后面输出这个人的视频
整个过程都是
非常非常expensive的
这一套我理解是在
大模型之前的时代
好莱坞跟游戏公司
经常会用到的一种方式
现在有了模型
这一套在这两个行业里面
仍然是主流吗
还是说他们其实也在探索
我能不能用3D直接去生成人
其实这个问题特别特别好
这就说到这个行业的一个特性
其实3D内容本身的AI化
它取决于两个事情
一个叫高质量的数据
一个是AI的算法
是不是能对3D的内容做大模型
咱们今天看到了
所有的影视动画公司游戏公司
他们比较擅长的是做内容
把美术把3D的模型做得很好很逼真
但绝大部分这些公司
应该说AI的能力基本是缺乏的
因为它走的是跟我们现在
互联网公司跟科技公司两条线
它两条线之间的交叉是很少很少的
其实他们当然也希望拥抱AI
但是今天他们在这方面的能力
是欠缺的
AI公司当然算法能力很强
但它其实是没有数据的
但是如果说是3D的内容
首先得解决
你得有大量的3D的高质量的内容
你才能做大模型
所以这是他们的目标
但其实做起来
现在对他们来说
就是两个行业没有交叉
就是大模型公司
缺这些好莱坞制作公司的数据
然后这些好莱坞制作公司
缺AI的算法
我可以这样理解吗
是 基本上是这样
但我看也有一些公司
开始在尝试做了
你们其实我理解
在这一轮AI浪潮之前
你们做这个数字人
跟积累这样的数据时间也很久了
是的 我们是2018年成立的
当时最主要做的是
我们为B端的公司
比如说游戏公司
或者影视动画公司或者企业
像做3D的虚拟偶像的
为他们去提供3D的内容制作的
那时候其实做用AI加美术
一起来提升效率提升质量
然后在这个过程中
当然AI的能力也在提升
我觉得大家都要突破的一个点
就是3D内容的高质量数据
你没有数据
你AI算法再怎么厉害都没法干
对 从2018年到现在是2025年
你们大概积累了多少数据
可以透露吗
就像我们动画数据
我们前面是为企业服务了
后面我们就自己来做动画数据
我们现在如果像
3D高质量的动画数据
我们在1000多个小时左右
其实这个数据
可能跟视频的数据来讲
或者文本的数据来讲是小的
但是如果你考虑到它的成本
一条数据大概要多少的成本
大概比如说像我们现在要的
比如高质量的
人脸的动画 手势 表情这些
我们叫动画数据
一秒钟至少在1000人民币左右
在国内
这个一方面
当然你说成本
其实还有一个点
你得找到团队
有非常强的能力把质量做得这么高
所以整体来说
它的成本它本身的数据的量
其实是很难很难
在短时间内积累起来的
很有意思
所以数据是你能训练成这样的一个
模型的一个核心要素
我觉得数据是最最核心的
如果你没有数据
其他任何的研发都没法做
因为我们现在有的是3D的数据
刚才其实我们也讲
我们其实还有的是有视频的数据
视频的数据是哪里来
举个例子
你现在在网上看到的
有人在走路也好
有人在跟人交流也好
这个就是纯粹的视频的数据
它是没有3D信息的
但是另外3D的数据
其实我们现在开始把两者融合起来
去做模型的训练
OK 有意思
你为什么当时会选
3D数字人这个领域
我是2000年去卡梅读博士
当时在机器人研究所
我就做的是这个方向
当时我的博士论文就做的是
怎么能够创建一个
可交互的3D数字人
怎么用AI去做动画
我们那个团队
应该是世界上最早用AI做动画的
因为那时候也刚凑巧
运动捕捉刚刚在2000年的时候
你有了动画数据你就可以去做AI了
所以从那个时间点开始
我开始做3D动画3D数字人
2006年毕业去Texas A&M当教授
其实也一直在做这个方向
那时候做动画主要在
我们叫图形学
图形学专门是为影视动画公司
游戏公司这个行业服务的
所以那时候我们发了很多论文
全是关于3D数字人
跟3D动画相关的
创业其实2018年
也是做了同样的事情
所以这个事情应该说
坚持了有二十几年吧
当然在学校里做的
还是以研究为主了
然后我知道您的PHD的导师
是Jessica Hodgins
她其实主要是研究人形机器人
还有3D的数字动画的
而且她的博士生导师
是Marc Raibert
是Boston Dynamic的创始人
现在最有名的机器人公司
也是特别早的一家机器人公司
所以看起来整个的3D生成
它最开始的应用
就是在好莱坞领域的
我导师Jessica Hodgins
她CMU毕业
也是卡梅1989年博士毕业
Jessica以前是在博士的时候
她是做机器人的
那时候机器人也叫人形机器人
但只有一个脚
人形机器人只有一个脚
为什么只有一个脚
因为两个脚平衡太难了
其实你也看到过
现在人形机器人其实在几年前
两个脚的人形机器还会跌倒是吧
平衡是一个非常重要的问题
她那时候做的是
用物理运动控制的方式
动力学的方式
控制机器人走跑跳
单腿的是吧
她毕业了以后很奇怪
她进到的方向是到了图形学或动画
这两个方向大家可能觉得
好像没有联系
其实她当时想法是说
我在实际世界中能让机器人动起来
那我是不是用同样的方法
能让虚拟世界中的3D的数字人
能让它动画能够动起来
所以她是全世界第一个
用物理运动控制的方法
来做数字人的动画的
她到了
她是叫Georgia Tech做教授
她就说我们叫做
基于物理的仿真跟控制做动画
然后她是2000年的时候
又回到了卡梅当教授
但2000年动画数据慢慢有了
刚才讲的运动捕捉的出现
然后她又开始
我就是她在卡梅带的最早的博士
我们是那时候是最早用AI做动画
因为你有了数据了
然后她又做动画
做完了以后后来觉得
这个动画挺好的
用AI去做
反过来是不是还能去做Robotics
这个行业现在大家可能
知道的很多做Robotics
做很厉害的人
其实以前都是做动画的
比如说Sergey Levine
他是Pi的联合创始人
也是伯克利的教授
但你肯定都不知道
他是在斯坦福拿了博士学位
他在斯坦福读博士的时候
就是做动画的
他是用物理的方式
用运动控制动力学的方式来做动画
他毕业了以后说
我这个能做动画
我也能做机器人
他后来当教授的时候
就是开始做机器人
难怪Pi他们的核心思想是
要解决整个机器人的大脑的问题
就是软件层的问题
他就是希望通过模型层
来指挥机器人
我觉得这个跟他最开始
不是从硬件研究开始的
他是用机器人去做动画
听起来是一脉相承的
是的 的确是的
我再给你举一个例子
我还有一个很好的朋友
叫Karen Liu
她现在在斯坦福当教授
她是同时做Animation
做Robotics
她以前是在Georgia Tech
当教授
也是做Animation
做Robotics
我们还有其他那个时候
做Animation的人
后面都做Robotics
或Robotics and animation
这两个领域是非常非常相通的
因为都是3D
一个在虚拟世界一个在物理世界
你都是要驱动人
都是让机器人像现在这样的人一样
能够去驱动它
为什么那时候很多人做动画
因为动画这个事情
相对来说会比机器人会简单一些
因为机器人你是有个本体的
你搭个硬件就老半天
动画在三维的世界当中
你至少不需要搭这个硬件
第二点限之间其实受很多的限制
比如说重力或这个房间的限制
或者这个机器人硬件的限制
动画这个事情实际上没有限制
所以那时候其实就有
很多做物理的人开始做动画
做动画这方面也分成几派
一派即物理来做
那比较有名的Jessica肯定也是了
包括我们在UBC的
Michiel van de Panne
他是我博士的委员会的成员
他一直做Controller
做运动控制的
那时候做动画的中心其实也在卡梅
Karen Liu
她的导师叫Zoran Popović
她其实是从卡梅毕业的
那个时候做物理的
整个的动画这一拨人
其实人很少很少
那时候国内基本上没有人做动画
可能欧洲也没人做
其实在美国可能最主要就是
那么两三个组了
后面动画有一个大的飞跃
是从2000年开始的
那时候最主要的原因是
做动画的时候有数据了
运动捕捉把数据有了以后
这个事情其实是使得
慢慢慢慢大家说可以用AI做
那时候比较早
现在叫强化学习
我记得最早的做动画的论文
应该是2004年还是2005年
就用强化学习去做动画
其实虚拟世界跟实际世界
是差不多的
它唯一的区别就是
实际世界中有硬件的限制
但底层的方法其实很类似很类似
我们在讲小脑做的事情
动作的规划
运动的控制
这个流派到现在
动画的也有人在做
Robotics也有人在做
如果到现在最新东西出来
我们叫VLA
视觉 语言 动作模型
这是一个新的
这个讲的是大脑
但小脑这个事情
其实在动画跟机器人是蛮类似的
很有意思
我们之前聊很多好莱坞节目的时候
就有听众问我说
《硅谷101》
不应该是一档技术节目吗
然后你们在讨论AI的时候
不是应该多聊聊技术吗
我就说其实好莱坞是还蛮重要的
驱动整个的科技向前发展的一层
而且很多AI技术
它最开始用到的
就是在电影制作上
是
你们有没有想过
比如说把你们的整个的
3D数字人的产品
用到更多的好莱坞造人
比如说你们公司
只是用生成的这种方式
因为你们已经训练了自己的端模型
你是可以输出一个数字人的模型的
其实底层的技术你就有了
就可以去把一个不太动的演员
让他活动起来
我觉得这可能是对
整个好莱坞的一次降维打击
就是我们刚刚提到了很多
他们怎么去用AI技术
跟机器人的技术
去互相地促进跟发展的
现在听起来
那一套技术已经是一个
有一点点落实的技术
虽然说我们现在生成效果
还没有那么好
但是我觉得现在整个进展很惊艳了
是的
其实你刚才讲到一个
非常非常重要的点
当我们讲一项技术的时候
其实这里面有几个关键的点
一个是它的质量
好莱坞质量可能最高的
再往下是3A级游戏
再往下可能是我们在生活中有一些
如果说交互做的比较简单的
第二个就是我们在讲的成本
第三个事情其实又讲到了
它的应用场景在哪里
如果你要做好莱坞这个方向
它的高保真 它的质量
可能是特别特别重要
因为它可以等100个小时
或200个小时
或花更多的钱去等你的高质量
但是在实时交互里面
它可能是说
我今天我等不了你那么多时间
我就要马上能看到这个结果
能够给它交互
我在质量上
可能不一定要像好莱坞
那么高的质量
但是可以做好莱坞的IP的衍生
对 衍生品肯定可以
当然如果好莱坞要做
这方面也可以做
你需要更高质量的3D的数据
来做这个AI的大模型
这块东西在我们自己
在行进路径上
我们可能更先后的顺序
对于我们自己来说
可能先是到日常生活中
比如说交互 服务 陪伴
再到游戏 再到好莱坞
因为难度来说
其实好莱坞如果要做那个
那你的难度是很高很高
因为你的质量要很高
但能生产这个高质量数据的人
全世界可能就没几个
正好是在我们采访前几天
我看好莱坞他们已经造了一个
叫Tilly Norwood的女演员
这个女演员
她是完全由AI生成的
但是如果你去关注她的INS
她其实看起来跟真人就非常的像
她每天也会自己喝咖啡
也有自拍照
然后也有自己的生活
如果你只看她的社交媒体
你是很难区别
她是一个真实的演员
还是一个数字造出来的演员的
像这种技术以你们的平台
比如说开发者再接一个你们的API
可以做到吗
还是说它需要更多的
其他的方向的辅助
它现在的做法
其实还是我们PGC制作的方法
它还是2D
它其实只有文生视频
它是文生视频的方式
对 但你们如果来做降维打击
对 但是这里面有一个点是
在元宇宙比较火的过程中
其实美国有一个虚拟偶像
叫Lil Miquela
她在INS上
可能有个一两百万的粉丝
她可能比今天你刚才讲到的
Tilly Norwood的粉丝
要多很多很多
刚开始大家都不知道
她是个虚拟的偶像
所以我们今天在讲
这个方式其实在讲更多社媒运营
怎么能生产这种专业的内容
去打造一个人设
但这里面有一个
特别要注意的一个点
咱们今天这样文生视频的过程中
因为你不能保证
每次生成的视频是100%准确的
但它可以有时间
因为它如果要每天
发布一张图片的话
或一段视频的话
它每天可以我生成100段
从中挑一个就可以了
如果是在这样的情况下
如果你要去做Real-Time
是不可以的
那我们反过来再来看
我们现在这套技术
如果post到比如说
比如说她要开一个现场演唱会
当然是可以做的
文生视频有一个好处
因为它是基于视频来训练的
你觉得这个真实感好真
虽然可能有一些
物理上有的时候会不准确
我们现在采取了3D的方式
做的时候其实我们可能不是
像做的跟现实界的
那个真实感一模一样的
我们其实还是在于交互性上
了解 了解
就是它更有一个实时性
如果是要实时性
它在训练上它要最侧重的是什么呢
实时性里面
我觉得它的核心的点我们一直在讲
这个延迟 这个时间
比如说文本输入的延迟
是特别特别重要
如果你的时间要花
比如说10分钟1分钟或30秒
或者一秒钟
我们基本上我们现在做到
是500毫秒到600毫秒之间
如果说你是文生视频的
它就没有这个需求
等个5分钟可以
等个10分钟可以
还有一个你部署的时候也很重要
因为你是个实时交互的一个
用户在跟它沟通交流的时候
很有可能我同时有100个用户
或1000个用户1万个用户
给这个3D的AI数字人在做交互
如果说每一个人生成的内容
都会不一样给交互
如果你的成本很高
如果同时有1000个人
你要乘个1000倍这个成本
就是1000个用户
跟同一个数字人交互
它可能就是一个高并发的场景
高并发 是的
所以你在后面就是要去做
额外的服务器的部署的这一类
如果说你今天成本又很高
延时又很长
那根本是没有可能做了
对 问一个稍稍有一点敏感的问题
你可以选择答不答
你们现在整个的API接口放出去
我相信它肯定有一个
基础的接入成本
你觉得它是能赚钱的吗
这肯定的
因为我们在真正的
发布这个平台之前
因为我们已经有B端客户了
你国内做AI公司
你得商业上这个账得算得过来
除非你是字节 阿里 腾讯是吧
所以在这里面就很核心的一个点
也是我们在过去的半年里面
一个最大的突破吧
从我们的交互能力也好 API也好
半年前其实我们已经做好了
但是我们那时候成本很高
就是刚才讲到服务一个人的成本
当时要一张显卡
基本上是两三万
所以那时有很多很多的
B端的客户进来说
你这个东西能不能让我用一下
然后一问我们这个价格是这个
人家不用了
所以这个成本是怎么降下来的
因为我们是3D的内容
3D内容有一个特别特别重要的
所有的影视动画公司
游戏公司逃出去
一定得有渲染引擎跟解算的引擎
这个我太懂了
因为我们做视频
那个渲染真的是太耗时间了
对 如果你3D的内容
如果要支持实时
每一路一张显卡
就是为了做3D的渲染跟解算
那么我们用的
可能最好的引擎叫Unreal
但成本放在那
我们当时一直在想
如果说我没有把这个成本
这张显卡给干掉
我们再谈应用
真正地让大家都用
比如说在刚才讲的
展厅里的大屏也好
手机上也好
Pad上或电视机上根本不可能
其实我以前是觉得解决不了的
当然技术有的时候就是很奇怪
忽然想到了一个方法
我们非常幸运吧
把渲染跟解算用AI做好了
不需要渲染引擎
不需要渲染引擎所需要的显卡
我们可以在非常非常便宜的端上
可能一两百
两三百块钱的这个芯片上
我就可以做渲染跟解算
所以你用AI的方式
端到端的模型
解决了渲染的问题
渲染问题只是其中的一个
前面还有一个问题是说
从文本生成3D的动画表情
所需要的参数跟语音
其实你要通过渲染
跟解算的方式才能做的
以前需要显卡
实际上我们是两部分的
我们就要分成这个模型
第一部分解决的是文本到语音
到3D的表情动作姿态
第二部分 通过3D的动作表情
姿态的参数输入
让输出了它对应的实时的视频
这样使得我们成本
就比语音的生成的成本还低
那你觉得如果你能做到这件事情
把整个渲染的成本大幅降低
这次的整个的生成式AI技术
对Unreal这些游戏引擎公司
会是一次冲击吗
对NVIDIA它可能就是
一个左手跟右手的关系
它那一部分失去的卡
这部分补回来了
我认为对游戏公司来说
更多的是个机会
不一定对Unreal是个特别好的事情
但对游戏公司
因为每个游戏公司今天
特别你3A级游戏
你去run的时候
你一定是得云端有显卡
或者在手机上你得有算力比较强
不然手机也经常很热
你玩的时候
所以这个事情对于游戏公司来说
可能是一个好事
对于渲染跟解算
引擎所需要的
将来是不是用AI的方式
就可以把这个事情给解决掉
不需要引擎
你不需要体验卡就可以玩游戏了
那游戏肯定是到时候也开始无处不在
或者将来真的有元宇宙的时候
大家在这个虚拟世界中的时候
它的成本就会很低很低也许
那你觉得现在用AI的方式
去解决渲染的问题
它的解决质量
跟原有的游戏公司的渲染的质量
大概到了一个什么样的进度位
对于我们这个特定的应用场景
基本上是一样的
因为我们在做这个事情
你的输入的训练数据
就是用最高质量的游戏引擎渲染的
然后你只是有大量的数据
同时去逼近
跟原先用游戏引擎的效果而已
包括我们自己做了并列对比
就是左边是用游戏引擎
右边是用AI
没有一个人能看出来
左边跟右边之间的区别
那这个非常的颠覆 这个
对 这个对于我们来说
是个非常非常
特别是我们今天说
我们希望把3D数字人
放到每一个终端
每一个屏幕
它就是一个最最重要的事情
也许我们从技术上
我们说文生3D的
多模态的大模型我们能做
但是你真的要部署下去的时候
低成本这个事情
它就是一个最最重要的问题
对于游戏公司自己
他们也有很多的游戏人物
他们也需要大量的渲染
然后他们也需要很多的卡
对 它可以预渲染
其实还是需要卡
或者叫游戏引擎
就像我们生成训练数据一样
或者大家今天看到
比如说做具身智能机器人
你要采集很多数据
但采集完了训练完了以后
你就不需要
这个数据就在实时
比如说在机器人去抓东西的时候
你就只是基于模型去做而已
你就不需要这个数据了
所以他们还是模式不一样
他们对实时性的要求没有那么高
就是游戏公司的AI渲染的问题
游戏公司的AI渲染
我觉得将来也一定会走向
到最后实时玩游戏的时候
不一定要真正的游戏引擎
我认为最后可能是用大模型
这种端的能够针对某个特定游戏
某个特定应用场景的
这样的一个AI的渲染引擎
就可以做了
也许这个渲染引擎
会比咱们今天用游戏引擎
跟用解算渲染的方法可能更便宜
为什么这样我听下来觉得
Unreal跟Epic Games是
如果不赶紧更新是有点危险的
但前面训练数据
还是要从他们获得
但实时的时候就不一定需要他们
其实你看到Genie3是吧
他有很多训练数据
就是用游戏引擎生产出来的
当它生成视频的时候
它现在说我有3D的这种感觉
你可以跟它交互
这时候它其实不需要用新引擎了
你觉得现在如果
接入你们的这一部分开发者
他可以现在用这套3D数字人的平台
去做一些什么样的事情
它的场景有哪些呢
我觉得这是一个非常非常好的问题
我们真正在做这个平台的过程中
其实我们已经有很多客户合作过
或者是找过我们
那么我们自己会看到了
一个最最重要的应用
因为现在大家可能在国内
大家慢慢已经大模型了
将来有一天
可能大模型会出现在各种终端
在你的手机 平板 PC
或者在你的线下大屏
或者我们现在有很多小的全息屏
放在桌子上的陪伴的
假如说大模型再出现是终端了
你怎么跟它交互
你交互难道今天
还是在文本框里打字吗
或者用语音跟它说话
对着空气讲话一样
我现在觉得打字的效率太低了
就是很多时候
尤其是在一些突发跟实时的场景下
可能是我越来越依赖模型了
来不及
是的 是这样子
有一个非常有名的心理学家
1970年的时候有一个发现说
人与人之间的沟通交流
可能百分之五六十是视觉信号
语音信号占百分之三四十
语言这个信号可能占7%才
在交流的过程中
所以我们一个最大的应用场景
今天在后续的
就是我们想把我们的3D数字人
这个能跟用户交流的
通过语音 动作 表情姿态
就是让他到每一个屏幕上去
从非常大的这种显示屏
或展厅的屏幕
到电视机的屏幕上
再到电脑 手机 车机
到最后的迷你的全息屏
当你跟它交流的过程中
其实你就像跟人交流一样
有一个有意思的点是
大家现在看到大模型
它的交互从文本到文本的输出
文本到图片的输出
我觉得这个全部是在
ChatGPT发布的时候
我们可以说Open AI定义了
它的交互方式
但是其实我们看到
现在整个Open AI
也在升级这一套的交互方式
所以你觉得未来的交互方式
它可能就是一个数字人
对数字人的这样的一个交互
就是像人跟人之间的交互一样
而不应该是一个文本对语音
或者文本对视频的
这样的一个交互
是 我觉得将来咱们人跟机器
或人跟屏幕的交互
一定是人跟人之间的交互一样
今天ChatGPT刚才讲到了
他们其实做了多模态到文本的
也做了文本到视频
文本到图片
就差把这两个串起来了
但是它没有到文本到多模态表达
如果加上了多模态到文本
两边串起来
完全就像我们现实生活中一样
我看到你的表情
听到你的说话
我自己知道要说什么
同时我有表情动作声音
每个人都要渲染一个自己的模型吗
我觉得将来
每个人可能会有一个分身
至少我觉得企业来说
它肯定会有统一的一个形象
比如说我是做客户服务的
所有的用户
企业都知道这个是
这个企业的客户服务
或者它是一个品牌官
企业的虚拟人的一个形象
个人肯定也会有
个人我们叫个人的分身
大家跟你沟通交流
比如说泓君
你可能对某方面非常专业
你是个专家
你将来肯定会有一个
你自己的分身
你休息的时候
你同样可以跟别人去沟通交流
提供你的反馈等等等等
如果我们把你们现在的模型
放在一起综合去看这个能力的话
你觉得它最强的一点是什么
就比如说我们自己现在在看到
很多的2D的视频渲染的时候
我觉得最大的一个痛点
在前几年可能是这个口型对不上
它有一种虚假感
或者眼神它很空洞
你觉得现在你们的这个3D数字人
在应用到不同行业的时候
大家最大的痛点是什么
你们是怎么解决的
我觉得这个问题非常好
我们自己在跟客户沟通交流的时候
我们收到的反馈
永远是几个问题
第一个问题就是你提到的质量好吧
一个是它的语音
动作表情它的唇形是不是自然
是不是像真人一样
另外一个事情就是延时
我跟它聊的时候
是不是我说一句话
它等5秒钟才回来
我肯定没有这个耐心了
第三个事情
其实他们非常非常关心它的成本
如果非常非常昂贵
基本上从客户的角度
因为他是要考虑
这个投资回报率的
体验是提升了是吧
但是如果付出的成本很高
对他来说他也不一定愿意去做
所以我们从整个的核心的点来说
这三个问题是我们真正在落地
我们要规模化的过程中
我们叫三座大山吧
如果还有一个点可能是说
我们想让这个具身智能数字人
能够到多终端
无论是说大屏上 小屏上
手机 APP 支持并发
这里面可能牵涉到不同的操作系统
不同的芯片的算力
我们解决这个问题的方式
质量跟延时
最主要用的是我们的大模型
提升它的能力
质量这个事情
当然训练数据是最重要
如果你动画的训练数据
这个人3D人的质量很差
你就根本做不好
另外就是大模型本身的能力
你能不能通过文本去生成语音
表情 动作包括唇形
能不能让它匹配
同时我还能从文本里面
提取一些情绪
比如说他笑或者打个招呼
它能够自动生成这些关键的意图
包括你的TTS
语音生成是不是也是有情绪的
这个事情其实牵涉到
大模型怎么能够让它的能力
能够产生高质量的输出
对 像语音生成它也是有情绪的
这种你们怎么考虑
你们自己做这一块
还是说直接调用大模型的能力
我们这块是自己做
就是从文本生成语音
跟所有的表情动作姿态
是会自己做的
这一部分输出从文本到多模态输出
全是我们自己做的
你们之前的数据积累
我理解其实就是外形的数据
动作的数据 表情的数据可能都有
语音的数据也是有的
一样有的
对 一样有
我们自己其实是有一个工作室
里面可以采集各种的动作表情数据
同时我们就有自己的工作室
去录制这个最高质量的语音数据
因为有的时候比如说
我跟你交流的过程中
我的语音跟我的表情动作是匹配的
我同时要把这个数据同时录下来
而不是说我今天语音归语音
动作或表情
所以你录的时候
这个数据就是要语音跟唇形
是在一起的
那你怎么考虑哪些环节自己做
哪些环节接模型
因为我觉得现在整个语音的应用
包括模型在语音层的进化
已经做得非常好了
也有很多语音的开源模型
跟接口出来
是 我们现在对于文本
去生成语音 动作 表情这一部分
我们自己一定会自己做
因为我们现在这个特定的应用场景
其实在现在的
很多语音的场景是没有的
举个非常简单的例子
我们在销售陪练的时候
我需要有一个医生是某一种风格的
或者我今天在做陪伴的时候
他可能是一个某一种特定人设
我们叫小奶狗
比如说举个例子是吧
他的声音是特别了
所以你如果只是去调用别人的声音
没有去匹配他的人设
我们很多场景是做不了的
所以你们会针对一些特定的场景
去做一些特定的声音训练
比如说有哪些场景
我们现在做的分B端给C端了
B端里面可能会有不同
比如说我说客户服务的
他说话的声音
或者我们现在做教练
比如说我是一个销售的培训的教练
或者我是面试官
这些其实是B端都会有些不一样
有些可能要求专业
有些可能是稍微能够有一些严谨的
到C端可能更会多样一些
比如说今天是做陪伴的
可能会有卡通形象的陪伴
他的声音可能像小孩一样
萌萌的
对 所以我们在这一块
因为很多的现在已有的TTS
它的应用场景
没有像我们多样化
我们自己在整个做下来
一个感觉是说
如果你用通用的
其实很多时候
进到垂直场景是不行的
你一定要做自己
因为你不能等着他帮你来做
我们就像一套套模板一样
客户如果有文本大模型了以后
我们就直接调用我的整个文生的
多模态这部分就行了
或者客户说
我自己已经有语音了
我不需要你的语音也可以
你直接调用我的能力
你都可以
如果你什么都没有
那我都提供
对 我们刚刚其实聊的
很大的一部分都是在AI的技术
如何去做虚拟的世界
反过来 你们现在训练的这个模型
它可以去操控机器人
你有试过吗
我们试过
我们在做所有3D数字人
跟3D动画一个很好的点就是
它能够驱动机器人
比如说我是个3D数字人
能跟你交流 是吧
你问我的时候我能听懂你
然后我知道用什么样的语音
生成语音 动作 表情跟姿态
对一个机器人来说
我可以同样用这套东西去驱动它
机器人也可以做
实时的语音 动作 手势
只是现在机器人没有脸部
所以它表情表现不出来
它没有脸部的肌肉
对 因为现在机器人就是个蓝领
将来机器人如果做陪伴
如果是做白领的工作
比如说它是个销售它是个老师
它可能也需要表情
首先我知道这个机器人
比如说我跟你交流的时候
我的手势应该怎么动
表情应该怎么动
我的姿态应该怎么动
下一步就是说
我们叫做用模仿学习
就像NVIDIA那种方法
我能够去做仿真
直接能够拿驱动跟你做交流
太有意思了
然后你们现在在真实的应用中
就比如说
你现在用你的这个模型的数据
接到机器人上去
你觉得对他的哪一部分的提高最大
因为我们可能说
机器人是没有表情的对不对
然后他的手势是可以动的
是
你可以同时驱动手跟脚吗
还是只能驱动上半身
我们可以
你们可以同时驱动手跟脚
告诉你一个特别有意思的事情
国内现在比如说我们合作的过程中
因为我们生成的是
从脸 手包括腿部的动作其实全有
现在很多机器人公司
其实他建这个机器人的时候
其实他的平衡还没有做那么好
就使得我给了他这个动作
他可能也是用强化学习
再加simulation去做
因为我们提供了API给他们了以后
他们在这方面可能
如果做得特别好的
可能也能够驱动起来
因为上身其实有很多的动作
就是它有一定的泛化性
但其实这个事情
我觉得其实没有那么的难
就像我们爬楼梯也一样
我的动作能够通过我们的能力
能够生产出来
我就在simulation环境里面
加上强化学习
让它能够去复制这个动作
一点问题都没有
所以机器人的平衡问题
是我们收集的这些3D人的3D数据
它只是动作姿态的
但是它并没有力的反馈
然后你只要加入到力这一点
就可能会出现平衡的问题
摔跤的问题
我觉得你好专业
没有 没有
我在尝试理解
这里面是两个核心的点
就是说你要驱动一个机器人
一个叫做运动学
我们叫Kinematics
还有一个叫Dynamics
叫动力学
第一步比如说我要抓一个杯子
我首先知道我抓杯子
手应该它的pose
它的姿态应该怎么动去抓它
第二个事情
动力学其实解决的是
我要用多少的力
能够按照我想的那个路径
那个姿态去抓这个事情
所以我们先做Kinematics
大家很多时候叫做运动规划
做模型planning
也是做这个事情的
一般来说两者之间可以结合起来
所以我理解其实机器人公司
在寻求合作的时候
它两个都是需要的
第一个可能他们自己现在
如果从零起步
做一家机器人公司
它最缺的就是数据
然后你们有数据的模型
就已经训练好了
因为我们聚焦是交互
从我们平台的角度来说下一步
我们今年吧
应该会发布一个3D动作的大模型
比如说它可以爬楼梯
或者你今天直接给它说
你往前走五步
趴在地上然后再爬起来再跑
它就能自动能生产出来
3D的动作的数据
这个动作数据当然可以用来做
机器人整个的训练了
因为它今天要去捕捉
其实这个数据有的时候
如果我们有这样的
动作大模型了以后
它也不一定要捕捉
因为你捕捉
也是获取这样的数据而已
了解
因为我看波士顿动力的机器人
就是这种爬楼梯旋转搬箱子
都已经做得非常的成熟了
但是他们其实
我理解他是在大模型公司
还没有出来之前
这家公司在机器人领域
就已经研发了很多年
他用了各种的方式去做
你现在其实是用AI的模型
再去驱动的这一套
就是爬楼梯的动作
你觉得这两者之间
我们看到机器人表现的
是同样的技术爬楼梯
但是它的技术路径是完全不一样的
还是说相似的
我觉得你刚才讲到一个
很有意思的点
就是波士顿动力
它以前能做爬楼梯
但是有一个点我想指出是说
它以前爬楼梯的时候
它的泛化能力并不强
比如说你给它不同的楼梯
高度是不一样的
它不一定每种楼梯都能爬得很好
对 因为它给你秀demo的时候
永远给你秀的是
同一个楼梯
对 所以这里面有一个特别重要的
我们叫泛化性
我相信今天做人形机器人
或做机器人的大家都会讲到
我的数据生成了以后
我能不能做我数据里做不到的事情
这个里面就非常重要
就是说爬楼梯吧
每个楼梯其实有一个高度
有多少层楼梯
包括楼梯本身的摩擦力是多少
摩擦系数有多少
这个其实都是一些泛化的参数
今天你有没有能力
今天说给你任何一个楼梯
你都能爬得特别稳
另外是不是你能给我说
我能控制它
爬得快一点爬得慢一点
这个事情其实在今天来说
我觉得还是一个难的问题
其实也是来自于数据
假设说你今天所有的数据
比如爬各种楼梯的高度的
不同的快慢的
我今天去做这个事情
其实也没有那么的难
我们如果现在做了一个核心的点
我们说在虚拟世界里面
包括我们后面要发布的
3D动画的大模型
其实也是要来生产出动画的数据
让它爬楼梯
所有东西都见过了
太有意思了
所以你们其实也是在做
机器人动作的泛化性
你看一种是机器人动作的泛化性
我们也在做数字人动作的泛化性
其实这两个是一样的
你觉得用AI的方式去做机器人
就是AI跟机器人
它又经过了哪些变迁呢
就像你说的
可能最开始大家还没有想到
要用AI的方式去做机器人
后来又开始在AI中
加入了强化学习去做机器人
最早的时候
AI机器人这个方向很难很难
特别是对于人形机器人
我们叫biped
就是两只脚要
它最难的问题是平衡
另外一个问题就是抓取
那个时候做人形机器人
最主要是在日本
有一段时间很火
本田 叫ASIMO
那时候工程师要调一个
它走路的动作
你都不知道后面有多少工程师
在调这个参数
我们叫控制器
怎么用这个力去控制它
让它在不同的表面上
能够像人一样走路
这个参数而且也没那么稳定
如果你把平面稍微改一改
可能就跌倒了
Learning的东西
AI的东西其实是不多的
那时候就做控制器
所以早期机器人的发展
它其实主要是控制
就是为了让机器人不跌倒
不跌倒 平衡
如果它能走不跌倒
太了不起了那时候
然后后面大家说光这么走不行
你能不能就是有一定的泛化能力
我走路的时候能不能在不同的平面
不同的表面
或者你的走路的速度都能够不一样
这个事情如果你没有用AI的方法做
你基本上不可能做的
你觉得现在的机器人
跟你当时学机器人的时候
20年前进化有多少
我觉得进化还是蛮大的
就是以前让一个机器人
有两只脚的能够跑
走跑跳觉得这个事好难好难
但你其实看看
看到国内很多做人形机器人公司
运动会拿个遥控器控制它
还是能走的
跑也能跑
大部分的问题是能解决了
这个事情在20年前基本不可能
它的balance平衡太难了
但它是通过远程操控的方式解决的
对 即使通过远程操控的方式
它还是要解决我说的
刚才动力学控制那个问题
我觉得控制这个事情
如果你有视觉 语言 动作大模型
它就不需要拿个遥控器了
但我们小脑控制这个事情
让它走不跌倒
这个事情其实蛮难的
所以但是现在进步就是说
一方面是数据
另一方面就是强化学习
simulation这样的环境
像NVIDIA
这就是技术的进步
能力开放出来了以后
大家都在这个
simulation环境都能去做
你发觉其实也没有那么的难了
是的
那机器人走路不摔倒
这个是现在一个做机器人的公司
普遍能达到的水平
还是说只有头部几家公司能达到
对于稍微OK的团队
我觉得是没什么问题的
就已经都解决了
但是有一个点就是
你的泛化到底有多强
你指的走路不摔倒
是在他们日常的训练中
特定的场景走路不摔倒
如果新的场景
保不定你还是会摔倒
那你觉得现在这个世界上
能让机器人走路不摔倒
在部分场景中实现的公司有多少
如果说完全不摔倒
在新的应用场景其实蛮难的
我不知道现在有吗
能够做到泛化能力很强
它能很鲁棒 不跌倒
其实基于我的认知来说
可能现在还没有吧
如果有那我可能要学习一下我觉得
真的 就爬楼梯这么个事情
我今天就可以设置任何爬楼梯的
它不一定以前见过
我不相信今天世界上有任何一个
人性机器人公司能够做到
所以我们其实只是解决了
在平面走的问题
特定场景平面走的问题
应该叫特定的场景下
包括你现在看还有一个事情
是grasping
就抓东西
抓取在我们那个时候
比较早的时候用人形手去抓东西
其实不多的
包括机器人在整个的业界你去看
很多时候它是个吸盘
毕竟这个东西我吸它就行了
但你现在可能很多人可以做抓取
像人形手一样
比如说拿筷子夹东西
这个事情其实也是一个
非常非常难的问题
还是要大脑加小脑的
大脑首先得看到这个东西
我应该怎么去抓它
到后面用小脑真正去控制
你的筷子去夹它
我觉得这个事情也非常非常难
今天你现在看到的都是demo而已
我认为真正在一个
特定的应用场景下
稍微有一点点泛化性
但是如果把它再往外
外延一些泛化
今天来说还是很难
我们10月5号的这个活动您也去了
然后我们现场其实是有机器人
给大家开可乐的
头一天他们在彩排的时候
中间我就放了一瓶可乐上去
我说我也要试这个
放完以后他说
你得把可乐转一个方向
他说那个环要对着它的手指
如果你不把环对准的话
那个机器人它的手的灵活度
还很难去把它转一个方向打开
是 真的
你这个还是在一个特定的环境
它已经布置好了
你更不要说它进入家庭
那在这个家庭的环境中
更是各种各样
灯光包括受限制那就更难
所以我觉得这条路
只是说大家现在看到了
大脑我们叫VLA这个模型
有可能可以去解决这个问题
但是不是100%能解决
其实也没有人知道
如果可以解决
到底要多少的数据
才能达到一定的泛化能力
一定的鲁棒性去解决
大家只是觉得相信Scaling Laws
相信大模型将会有一天能够解决
但这里面的挑战是很大很大的
是 所以从你的角度
你觉得现在世界上
最好的机器人公司是谁 为什么
我觉得是这样
做机器人它有不同的流派
有做本体的
比如说有做硬件的
有做小脑的
也有做大脑的
我自己觉得还说不到有多好
因为多好有不同的定义
你今天在做研究
你这条路已经有一些
promising results
还是说你今天已经落地了
也许你今天这条路
感觉看上去很有希望
因为最后发觉你这条路是死的
你暂时的领先并不是最终的领先
你像现在国内其实有不同的流派
像宇树可能做的是机器人本体加小脑
他不做大脑
大脑是指什么
大脑就是说现在做VOA
叠衣服这种
小脑就是说你让爬个楼梯
跳个舞 跑个步
在这一块里面有做本体的
有做控制的
就是控制我们叫小脑
就是运动规划 运动控制
动力学整个这一套
还有做大脑的
我觉得至少我现在还没有
已经看到了曙光了
可能我比较悲观吧
它可能也会像任何其他领域
比如说无论是VR AR也好
还是AI领域也会有起起落落
因为这是Robotics第一波浪潮
无人驾驶其实也有起起落落
但从长期的角度来说
那肯定是前景光明
从短期来说可能还是有很多挑战
你觉得机器人模型
要达到GPT-3时刻需要多久
这个其实我没有
那么强的经验和认知吧
我觉得今天的数据要泛化能力
至少要很长一段时间
今天我看到的这些
还没有让我非常清晰地
能够判断两年或者三年
但我觉得10年
可能有希望
这个问题可能能解决
10年是很长的时间了
所以这也是为什么
你们公司在做的时候
其实你没有直接去选
我去切机器人这个赛道
反而是说我们把3D跟机器人的
交叉的领域
数字世界里的3D我们来做一做
如果我让3D数字人在数字世界里
在VR空间
或在屏幕上能跟人
像人与人之间交流
也是在这个数字世界里
能够抓取东西
能走路能爬楼梯
那本身在数字世界已经很有用了
它已经可以有这个
Real-world application了
也可以有商业的落地的
反过来如果这些做了以后
作为做Robotics来说
也是一个很有价值的
因为我们在讲小脑这个事情的时候
你的控制运动学 动力学
你先得知道怎么动
然后再去决定用强化学
是用怎么样的力
让它能够去做这个事情
我觉得做research它是一个
今天Robotics是一个非常好的方向
因为有太多东西可以尝试了
如果从商业化的角度来说
我自己觉得其实挑战蛮多的
如果你要商业化落地
至少从人形机器人的话
我觉得白领可能会比蓝领更快
是是 你刚刚提到在数字世界里面
它可能也会涉及到一些力的反馈
会有
比如说好莱坞动画里面
我们把一个苹果
一个南瓜甩过去
它变成一个南瓜酱
它怎么炸开
那个就是
就是物理
其实物理还有一个点比如说
你是个数字人或3D的角色
你从二层楼跳到一层楼
你跳下去的时候
你跟地面之间的整个的反馈
怎么滚动一定要满足物理
我们这个大模型的动画
如果生成了以后
它本身就可以用物理的方式
让它在虚拟世界中去仿真它
同样的方式
其实也可以在虚拟世界中
用强化学习的方式
去生成这个控制器
同样的方式
我可以在实际世界中这么做
本身的逻辑是很通的
但我有一个问题
如果我们把动画世界里的数据
收集来学习
我知道一个人
从楼梯上掉下去以后
怎么弹怎么滚的
但是我不知道为什么
我也不知道这个里面有多少力
但是就是看见了这些现象
然后用这些现象跟这些数据
去训练出一个大模型
它能反馈能模拟
我们还是不知道力是多少
就是我们说规模化法则
如果跟所有的大模型都是黑盒模型
但是我们再把这个场景
拉回到现实里面来
我们要去让一个机器人
砸到一个东西或者拿到一个东西
这个力我不知道现在在现实数据中
是不是就是要反复调控跟算出来的
所以它就必须有这个力的数据
我觉得人他真正在现实生活中
我们去举一个杯子
我们也不需要去计算它的力
这就是我们的一个经验习惯
就是我们有这样的一个感知就好了
这是我总体的意思
大概就是过去整个机器人
它的研究包括它的力学的反馈
还是在用白盒的方式去做
但是整个模型在用黑盒
跟一套更加经验主义的方式去做
就是为什么我们觉得
现在已有的方式上做的时候
到真正你要泛化到一个实际世界中
去抓取各种东西的时候
它的挑战会非常非常大
因为它的泛化里面的东西太多
就是我们今天讲整个的过程中
你在学力的控制的函数
以前的方式是要自己算的吗
或者一个一个的自己
对 现在就是用强化学习的方式
现在用强化学习
就是大家不需要知道为什么
我只要有足够多的数据跟它reward
它就慢慢慢慢就能够做
但这个问题是说
我抓杯子只是我很小的一个例子
这个世界上有多少
所以我就说这个事情就是希望
将来有一个基座的大模型
我足够多的数据了以后
大家能够去一个特定的场景
我能去调优这个模型
能够在这个环境里面把它
慢慢把它做好
但其实是很难
你像我们学会抓东西
我们学会走路跑步
我们花了多长时间
是的 我自己听下来
就是我对机器人领域
这一波最大的进展
我是觉得整个研究的方式
它从白盒模型的研究
变成了黑盒模型的研究
从我们必须知道每一个细节
它的受力点是多少
靠这种计算跟一个一个细节
调配的方式的研究
变成了我们一个端到端的模型输出
我们不知道里面是怎么运作的
但是它可以
我们在讲强化学习的时候
就在讲这个事情
这是一个最最大的点
就是以前的时候
那套东西就是更多是显示的
比如说我要去抓这个东西
我大概知道要什么力 预先算好
不是说我在这个过程中
我根据实际世界的情况
包括表面第一次抓的时候的感受
我能够持续去调整
它一定是Reward Function​​在后面
这条路来说一定是打开了
以前对机器人来说
觉得怎么做
感觉好像也没有希望那种感觉
好难 那种方法一定是
不能扩大规模的
但今天其实大家为什么觉得
虽然我作为一个外行来说
我自己会觉得很难
你说是3年还是5年
但是从长期的角度来说是有希望的
这套方法它在大语言模型也好
在其他方向上也好
其实已经展示了它的一个能力
如果在机器人这个方向上
如果你有足够多的数据
是有可能能解决这个问题的
它的天花板就是大家能看到
是有可能有一天能做到
我们真的像大家想象的一样
机器人能干各种各样的活
在各种复杂的场景里面
中间是不是在这个过程中
会遇到大家想象不到的问题
还会遇到低谷
其实我不知道
看起来现在是一个
大家刚找到一条新的路的
那个兴奋感的时候
但是它的结果是不是能收敛
是不是一直能看到效果
是
这可能就是中间起起落落的过程
是的 是的
好 谢谢柴教授
好 谢谢
好的
这就是我们今天的节目
很可惜
就今天我们在录制的时候
是播客不是视频
所以其实很难去实时地展示
跟感受一下
这个3D数字人的效果
也希望未来我们视频
可以出一个呈现的数字人
给大家看看感受一下
所以如果大家对
比如说像3D的AI数字人
到底可以用于哪些好玩的领域
去做一些哪些好玩的事情
有更多的想法
欢迎给我们写评论多多交流
我们的博客听众
可以在小宇宙 苹果博客
Spotify上来收听订阅我们
如果大家想看字幕版
也可以在YouTube
或者bilibili上来订阅我们
未来我们也会推出
我们的newsletter
在硅谷举办一些线下活动
如果大家对我们的线下活动感兴趣
可以在我们的Shownotes里面
订阅我们的newsletter
我是泓君
感谢大家的收听