- All right, welcome to
another video from Anthropic.
My name's Stuart, from
the Communications team.
A lot of the time when
you hear AI companies
talking about threats from AI,
they mean threats that are
gonna happen in the future,
a future where AIs are vastly more capable
than they are currently,
and where we might lose
control of their behavior.
But there are a lot of threats
that are happening right now.
One of them is that cyber
criminals are using AI
to make their crimes much more effective.
They're using AI to do
scams, fraud, and extortion
in particularly sophisticated ways.
We have a whole team of
researchers at Anthropic
whose job it is to spot
these kind of problems,
to stop them from happening,
and then to prevent them
happening in future.
That's our Threat Intelligence team.
And they have a new report
out which details some of the,
I must say, pretty bizarre
cases of cybercrime
that we're seeing with Claude, our AI.
I'm very glad to be joined by two members
of the Threat Intelligence team right now.
Jacob and Alex, perhaps
introduce yourselves.
- Sure. My name is Jacob Klein.
I lead the Threat Intelligence team,
and broadly, the Threat Intelligence team
is responsible for finding
and deeply understanding
sophisticated cases of misuse.
And these cases are very rare -
this is not the typical usage
that we see on our platform.
And when we find them,
we work with the rest of the organization
to build defenses so
that that type of abuse
is much harder to recreate in the future.
It's an ongoing process,
we're always learning more
but frankly, it's actually a lot of fun
in a weird kind of way
because we get to see the cutting edge
of what bad actors are doing
and what we can broadly
do to make AI more safe.
- And my name's Alex.
I'm an investigator on the
Threat Intelligence team,
and my work involves threat hunting,
building new detections,
and doing deep dive investigations
into the types of abuse that we find.
- All right, let's talk
about "vibe hacking".
Now, everyone's heard of vibe coding.
In fact, to be honest,
I'm sick of hearing about vibe coding.
It's the current thing,
everyone's talking about
vibe coding. That's when
you just use normal language
and you give that language to an AI
and you say what you want,
what software you want,
what code you want, and
then the AI makes the code
and then you kind of just do it by vibes,
you just kind of go along with it.
What's vibe hacking?
Where does that come in?
This is the kind of like
the dark side of vibe coding, right?
- Yeah, some people refer
to it as the evil twin-
- Right, right, right.
- Of vibe coding.
Yeah, much like vibe coding,
everything is natural language prompting.
The person doing it doesn't
actually have to know
the technical skills to write code,
execute code and all of that.
In this case, rather, the vibe coding
is being used for malicious intent.
So it could be for something
like writing malware
or developing new capabilities
for their hacking toolkit.
It could be social engineering.
Any number of, typically-
- Social engineering is when you,
like, you're basically
tricking someone into thinking
that you're someone else.
- Yeah.
- Yeah.
Talk us through what this
looks like in practice then.
So, what does a vibe
packing process looks like?
Can you give us some real
examples of stuff that you found?
- Yeah. Yeah.
So, there was one case that
we talked about in our report
where an actor pretty much
conducted their entire operation
using vibe hacking.
Within about a month's timeframe,
they hit about 17 organizations.
In this operation, they
were doing something
called data extortion.
So, this is like a cousin to ransomware
instead of hacking into
systems and locking up files
so people can use those files
and then demanding a ransom.
In this case, the actor
is stealing sensitive data
and threatening to expose
it if a ransom is not paid.
So in this case, they used vibe hacking
to both infiltrate the organizations,
move laterally through their networks,
drop back doors so they
could have persistent access
and steal certain types of information
that they could use for their extortion.
- And this is the kind of thing that would
ordinarily take extremely
high levels of skill.
- Yeah, I would say from
what we saw with this actor,
you would typically see
that amount of activity
come from like a group of cyber criminals
operating over months,
a month long timeframe.
In this case, we saw a single person
hacking into this many
organizations in a matter of weeks.
- So who are the victims of
these vibe hacking attempts?
Are they targeting like
random people on the internet?
Like a spam email would
go out to everyone,
or, you know, these are much
more targeted than that, right?
- Yeah.
So, the targets are specific
but they're also indiscriminate.
So, they're not trying to target
like a certain sector specifically.
They're targeting organizations that have
a certain type of VPN
that they potentially have credentials for
or believe they could brute force,
which is just like send a bunch
of potentially valid
credentials until you get in.
So, organizations with that VPN,
but that means they're hitting
organizations in healthcare,
we saw emergency services,
we saw governments,
defense contractors.
We even saw a church
being hit by this actor.
- Talk us through the church.
- Yeah, so this is like a great example
of how without some sort
of automated defense,
which a church probably wouldn't have,
they were able to access
the victim's network
through some sort of attack on their VPN.
Once they got in,
they would essentially
look for different ways
through the network to identify machines
that might have sensitive data,
like an administrator
or owners of the church,
their financial staff,
and then start collecting
financial information.
Anything that could be
potentially sensitive.
And when I say they were doing this,
it was actually Claude
as if Claude was on keyboard
doing the operations.
It wasn't really the actor.
The actor would gently nudge
Claude in certain ways.
The actor would provide at
the beginning of the operation
kind of a guide to Claude
of like how they would suggest for Claude
to conduct the operation.
But then also put in a
lot of caveats on like,
hey, like use whatever
knowledge you have available,
try everything until you have success
in completing the mission.
So with this church,
Claude was able to identify
donor information and
members of the church.
And once Claude would finish
collecting information
from victim networks,
the actor then asked
Claude to analyze that data
and develop an extortion
scheme like Jacob mentioned.
And in this case, with the
church, Claude identified that,
hey, we have donor information.
We could expose who the donors are
and how much they're paying.
And that might be enough to
convince this church that
exposure of that information
would be harmful enough
to their parishioners that
they should probably pay the ransom.
- Another thing to emphasize
is this isn't just Claude,
Claude doesn't have some specific-
- That's right.
- Weakness that is being used
for all these things.
This is all LLMs presumably.
Well, you'll have seen this happen
for many of our
competitors models as well.
- And Claude's not fine-tuned,
like you said, for this
but there are actually open
source models out there now
that are fine-tuned for this.
Cyber criminals are
developing weaponized LLMs
to conduct attacks.
So, we gotta collectively
think about defenses here
and we, as the threat intel team
and Safeguards and Anthropic as a whole,
can begin to manage the
risks posed by our systems.
But there's only so much we can do
'cause like you said, it's
not only a problem for us.
- Some of the stuff in
the report is amazing
about the really hyper
targeted nature of this
that they are using
Claude in this case to,
and Claude Code specifically, right?
- That's right.
- To make even payment plans
to say to people like,
here's how the money,
here's how you're gonna give me the money.
You can give me over a series of time,
like you would get on buying stuff online.
- Yeah, it's coming up
with, once you get the data
that's been exfilled from this attack,
it's coming up with what they think
the estimated value of that
data is on the dark web.
Then it says, here's how much we think
we should send the ransom note for.
And then it actually helps
write the ransom note
to be as persuasive as possible.
So really every step end to end,
AI is able to help with
an attack like this.
- And like analyzing
people's financial details
to work out how much
they can realistically
be extorted for as well.
- That's right.
- Which is just-
- And like you said, it
is using Claude Code.
And so, it would actually
iterate through victims.
So, it would complete an
operation on one victim
with some gentle steering
from the human actor.
But once it was done
executing the mission,
it would roll on to the next target.
- Importantly here, we should
say that this is not something
that Claude Code would just do.
Like if you or I just prompted
Claude Code right now to do.
There's been some jailbreaking
or something going on here, right?
- That's right.
- Yeah, so in this case, the
actor found the right prompt
and put it in the right place
in order to essentially
jailbreak our defenses.
Jailbreak the models fine tuning
and jailbreak the
downstream defenses of that.
- And just to be clear for the people
who don't know what jailbreaking is,
this is when you say
things in a particular way,
so like some of the jailbreaks
are like weird to look at.
They're like uppercase, then
lowercase for every word
and things like that.
But some of them involve
sending tons and tons
and tons of prompts to just
sort of like bludgeon the AI
into just like continuing, continuing on,
putting words in its mouth,
all sorts of things like that.
So that's what they're
doing to Claude Code.
- Yeah, actually, in this case,
they were doing role play.
So they were pretending to be a,
your average security person
doing network penetration testing
to make sure that defenses
are adequate in the systems
convincing Claude that
they had authorization
to do what they're doing.
- Because otherwise, Claude would,
the safety mechanism would kick in.
Like if you explicitly said,
I want to make a malware operation
to scam people out of money,
it would never do that.
But you can pretend to
be, I'm checking this for,
I work for a security
company, I'm checking this.
- And this is why it's so important
to think of multiple layers of defense
when you're an AI company like Anthropic.
So layer one is we train the model
so it's less likely to
respond to malicious requests,
which is why you have to
trick it or jailbreak it.
- So that's reinforcement learning.
- That's right.
That's reinforcement learning.
- And when you trick it,
you're kind of tricking it to go outside
of what we've deliberately
taught it to do.
- Exactly right.
So that's first layer,
but we know that's not perfect.
So we have another layer,
which is we have classifiers running,
which are trying to detect
this activity and stop it.
And that's not the last layer.
We also have offline rules
running that are saying,
do we think leveraging maybe the string
that is put into a prompt,
do we think that something
as malicious is happening?
And then we have another layer,
which is the account itself
when it's signing up,
does it look like it has
suspicious signatures
associated with it?
And then we have another layer,
which is we info share with governments,
with other tech partners to say,
oh, we know that this actor,
this organization is malicious.
So, it's not just a, we
assume that the RL layer,
the classifier layer is gonna be perfect.
We intentionally think about
this as a holistic defense.
- And you guys are getting data
from all these actual cyber
operations that are happening
and then training these classifiers
so that they're even more effective
and that they also don't
stop you from doing
good cyber-related things
'cause that was my next question.
Why is it that we can't
just say to Claude Code,
just never do anything that comes,
that's to do with anything
to do with cyber operations,
to do anything with cybersecurity at all.
Just never talk about that stuff.
And then, well, it wouldn't be
able to do this stuff, right?
- Yeah, that's a really
tricky decision to make.
So, when you're working
in like a dual use domain
is what it's called, where
the prompting you would see
for defensive cyber might look a lot
like what you would
see for offensive cyber
because you do a little cyber offense
to figure out how to defend your systems.
You have to be really careful
in how you implement safeguards
or thinking about things like a total ban
on that type of activity in that domain.
It's really important to consider that
like here in the United States,
we have a huge deficit in the workforce
for cybersecurity workers.
I think it's like around like
half a million right now.
So if we can imagine a future
where we have AI agents
that are smart at cyber,
that we could kind of help
alleviate that deficit that exists.
- It reminds me of when biologists say,
I was asking this AI model about viruses
and it shut me down.
And like, this is the dual use thing.
Like clearly you can talk
about virology to an AI model
and that's for good reasons,
but also for nefarious ones too,
- And especially with cyber,
you can imagine every startup in the world
needs to think about cyber defense.
And so, really every startup in the world
should be using Claude
or some AI model to help them work through
what their cyber defense strategy is.
This isn't a narrow
subset of the population
that has to work through this.
This is most developers have
to work through these issues
so we really wanna enable that
positive use case of AI too.
- And like even individuals,
I've seen a lot of cases where like,
it looks like it's like a web developer
and they found this
file on their web server
and they're like, what is this?
My server's acting weird.
And Claude will respond with,
hey, that's malware
from like this variant,
it's doing these things.
And the person's like, oh no,
what do I do about it, Claude?
And Claude will like
walk them through the steps to clean up.
So I think the important
thing to keep in mind here
with this case in particular is the scale
and the speed of the operation
as it's enabled by Claude.
In this case, Claude Code is
able to break into a system,
identify all the weak
points, test them all out
to figure out where to go,
find the data it needed,
and exfiltrate that
data before even a human
I think would have time to review an alert
and understand what's happening.
It's too late.
You need intelligent automated defense
to counteract something like that.
- Right 'cause almost always
when there's some sort of security alert,
there's a human on call
and there's a human waiting to see,
and then they'll check out whatever it is.
But in this case, there
could be all sorts of things
happening all at once that
humans will never keep up with.
- I think this is a paradigm
that probably we need to rethink a bit,
which is this, you have an
alert that runs offline,
a human response 24/7,
human looks at the alert
and then does something
because the speed at which AI is moving,
you need to automate that process.
You need essentially AI
to protect against AI.
- So as well as the classifiers
and as well as you publishing this report,
which is telling us all about
the specific things that we've found,
presumably we're talking
to other AI companies
about this as well, right?
- We are, we're talking to the
government when appropriate,
we're talking to other AI companies.
And we're not just
saying like we are here,
here's generally how the case worked.
We're sharing very specific indicators.
So IP addresses, email addresses,
so that if there's actors
on those platforms,
they can find them and kick
them off there as well.
So that's why it's
really a community effort
to try to find and stop these folks.
- Right, so we have them something similar
in the world of alignment research
in the Frontier Model Forum,
where they share things like jailbreaks
and potential misalignment
issues with models.
And in the world of
security, cybersecurity,
there are similar mechanisms.
- Exactly right.
We have information sharing agreements
with a number of companies,
folks in the industry,
governments where we're
bilaterally sharing information
when we find people just like this.
- Okay, we've gotta
talk about North Korea.
Now, this is one of the most,
I think this is like an eye
popping case from your report
where there's this like complex,
long-running employment
scam run by North Korea
on US companies.
And Claude is involved.
So first of all, before
we even get to Claude,
talk us through what the scam is here.
- Yeah, so ignore LLMs for a moment.
- Yeah, and AI, this is before AI.
We don't need AI necessarily.
- Exactly.
The scams started before
LLMs became a thing,
which is really took off during COVID
where North Korea wants money
to fund their weapons program,
but they're sanctioned.
So how do you receive
that source of income?
One method is getting a job
as a remote IT worker with a company.
And surprisingly, hundreds of companies
have hired North Koreans without knowing,
and this has funded tens
of millions of dollars
to the North Korean weapons program.
And this is typically somebody
who's highly trained in North
Korea, goes to the university.
So they have language context,
they have cultural context,
and they have the technical skills
to go through an
interview and do this job.
And that is what is starting to shift
with Claude and AI systems.
- Right, right.
So just to reiterate, like in the past,
you would've needed a lot of training.
You'd have to go to scammer
university to learn this stuff.
But actually now-
- You don't need to know English.
You don't need to know
the cultural context
of the United States,
and you don't need any technical skills
because Claude can help you
through each of those barriers.
Claude can say, well,
it's a great translator.
Claude can help you answer
very strange turn of phrases
within the English language.
- Right, yeah.
There were a couple of,
what were the example
of phrases that you guys found?
- Yeah, like an example is like
someone asking Claude, what is a muffin?
And so Claude says it's this round dessert
that's often sweet and
eaten for breakfast.
And so, then the person follows up with,
well, what's the difference
in a muffin and a cupcake?
And so, like very simple things that-
- What is the difference between a muffin?
- I'm gonna have to ask
Claude that later on.
- Really answer that.
- Yeah, yeah, yeah.
Anyway, carry on.
- Yeah, so examples like that,
or like quoting a phrase
from a coworker of like,
we just had our first picnic of the year
trying to understand what that means.
What is a picnic? Why we have them yearly?
And then maybe another one
that I found actually a bit entertaining
was the actor actually like
provided some ASCII art
of like an emoji doing something
and was like, what are these characters?
What does this mean?
- What is the thing?
- Yeah, so that's the little,
not necessarily like the picture emojis,
but the ones that are made
up of punctuation marks.
Yeah.
- Yeah.
- Yeah, yeah, yeah. Yeah, amazing.
- Yeah, so it's fascinating
what shifted here is,
on one hand you can
think this is incredible,
Claude's helping people
overcome language barriers.
Claude is helping people
understand cultural context.
Claude is helping somebody code
who doesn't know anything about
even what Microsoft Outlook is.
That seems like a brilliant thing,
but in this very specific context,
it's helping them land a job
and maintain those jobs at
a high level of quality.
- The phrase you use in the report is
it's helping them maintain the illusion
of competence every day.
- Yes.
- And I thought, don't we all do that?
Don't we all have to
maintain that illusion?
But in this case, their
employers and their colleagues
are talking to them every day.
- That's right.
- And they're not realizing
that this is a completely fake person
who is in fact, a scammer in North Korea,
- A persona that's been created by Claude
or by somebody in North Korea
that doesn't really exist
with an educational background
that doesn't really exist,
with skills that are being done-
- Like a resume-
- Exactly.
- With a bunch of history on it.
- Yes.
- Yeah.
Oftentimes you'll see, like,
they'll take the project plan
from their project manager,
like the tasks that they need to complete,
and they just throw the
whole thing into Claude
and say, what do I do?
How do I get started?
Help me code this.
- Again, super dissimilar
to what a lot of people do.
- I mean, I do that too now.
- You're not wrong though.
- Exactly. Exactly.
Are they actually doing economically
useful work for these companies?
- I think they are, yes.
- Right. Right.
- They're being product,
otherwise they get fired.
They're being productive employees
and that's a part of this scam
is sometimes these employees
are considered high-performing
because it might be one individual
or many individuals doing the job,
but this is what's so, I think critical
to take away with this case
is before you would need a
few highly trained individuals
to go out into the market, get a job,
and then maintain a job,
now North Korea can
just use really anybody
and just say, "Hey, use Claude."
And then you can get the
job and maintain the job,
which allows you to get more positions,
apply to more positions,
and from North Korea's
perspective, get more revenue in.
- Maybe this is a silly question to ask,
but I think it might occur to people,
how much money do you think
North Korea are making from this?
They're making tech
company salaries, right?
And they're presumably using that money
to fund their weapons program
and whatever else they need to run,
given that they live under sanctions.
How much do you reckon overall
they earn from this kinda scamming?
- We're seeing these actors
get jobs as AI developers.
Those people make quite a lot of money.
- Right, right. Yeah, yeah.
- And just like general
like coding, coding jobs,
which typically are high salaried.
So, they're being pretty
effective with this
and they're not taking
jobs at like call centers
or something like that,
that might not pay as much.
And maybe that's
something they used to do.
Now they can take technical positions.
- They're Fortune 500
companies that you're finding
that are being-
- Yeah, they're targeting
all the way up to Fortune 500.
Smaller startups, medium-sized companies,
large publicly traded companies.
- I assume - this is
happening at the level
of the North Korean nation state -
I assume this is also happening with
on the level of groups, right?
Are there other smaller
groups that are doing this?
Do we have any idea about that?
Is that something that you pick up?
- Yeah, I think of it
in maybe like two ways.
The first is there's
certainly other groups
and other nation states that are running
this employment scam where
they're trying to land a job
without actually being
the person who's applying.
That is becoming more common over time.
The twist that you might
want to think about as an
individual that's listening
to this conversation is
what's been going around for a long time,
which is an employment
scam where I receive a job
that is not a real job and
I go apply to that job,
but actually it's a scammer
who's trying to harvest
information from me
or get me to download ransomware.
And that's something
that we're also seeing
happen more often and
that's leveraging AI.
- So again, it's like
the vibe hacking thing.
It's lowering the bar
at which you need to,
you know, the skill bar for doing these
complex-
- Exactly.
The two big implications there is you can,
when you can do more
scams, more cyber attacks,
you can scale more because
there's more people
that are enabled,
or a sophisticated actor
can leverage Claude
to scale themselves.
And so really you have to
think about the number of scams
or the number of pieces of fraud
that are gonna be out in the world
and they might, I would suspect,
increase over time with the rise of AI.
- What are we doing specifically
about the North Korean thing?
There's this scam but there's also another
part in the Threat Intelligence report
where you guys kind of noticed
another North Korean
operation and stopped that.
So, maybe talk about how we're responding
and how we're spotting these North Korean.
- Yeah, so the North
Korean case is tricky.
Like 80 to 90% of their use of Claude
looks like a typical person
doing development tasks.
- Right, you're asking for
work, just coding stuff.
You're asking what a cupcake is.
These are normal things.
They're not saying develop malware
or anything like that, you know?
- About 10% of what we
saw looks suspicious.
And that's kind of like
our needle in the haystack
that we have to find
among all of the traffic.
- But you can't use Claude
in North Korea, right?
- Correct.
- So, they must be using
some like VPN system
to evade that.
- Yeah.
Yeah, so the 10% is like
the type of activity
was focused on like interview frauds,
so we could see them
developing fake resumes.
We can see them trying to
answer interview questions.
Now, the other way,
which you just alluded to
of finding them is
using the infrastructure
that they're coming from.
This activity is widely investigated
across the security community,
both in the government
and in the private sector.
So there's a lot of information
sharing happening there,
people tracking what infrastructure
are they operating on
in order to access Western sites.
And so, we're engaged in those communities
and that's helping us continue
to find these activities like this.
- And there are success cases here,
and there's one that's in
the report that you mentioned
that I think is worth calling out,
which is there was
another North Korean group
known as Contagious Interview,
and their MO is to try to lure people
into applying to fake jobs,
to install malware on their devices.
- Right.
- Now, we know
that this group tried to use Claude
based on their infrastructure,
their IPs, their domains,
but we shut them down before they issued
a single prompt based on
that suspicious activity.
So, this is something we're always on
is finding and detecting these folks
sometimes before they even do anything
with our AI product.
- There's a lot more in the report.
There's loads of stuff
about, for instance,
a British person who's making like a,
normally we talk about
software as a service, right?
But this is ransomware
as a service, right?
So this person is like making ransomware
and then selling it on
the dark web to people.
And again, a normal person would've taken
huge levels of skill to make this happen.
But this person had just
like vibe-coded it really?
- Yeah, yeah, that's correct.
So, they developed ransomware,
kind of like worked with Claude
until eventually they got
Claude to actually write
the pieces of code that they wanted.
There was a lot of refusals that happened
and Claude said no, and they would provide
some sort of justification
for what they were doing.
- Again, like I'm working
for a security company
and testing this out,
or something like that.
- Yeah, yeah.
- Not that we're trying to tell
people how to do it, right?
Don't listen to that last comment.
- Yeah, so they were able
to get Claude to write
some pretty sophisticated ransomware.
We actually, in the investigation,
were able to discover that
this actor was selling
this ransomware on various
underground forums.
So, we were able to trace those ads
back to the activity
we saw on our platform.
So we got a bit of an understanding on
why they were developing
what they were developing.
And it was clear that it was a ransomware
as a service operation.
- And there's other kind of
entirely different types of scams.
Do you wanna talk about
the romance scam bot?
Like of course, Claude
doesn't have a kind of avatar
thing that it can, that some other AI have
these kind of animated avatars
that talk to you and so on.
But people were using it to kind of,
as the engine of something like that.
- Yeah, so there's these things
called romance scams, sadly,
which is where you pretend to develop
a romantic relationship
with another person,
usually for the purpose of extracting
financial gain from them.
And there's this Telegram bot
and this Telegram bot had
tens of thousands of users,
and it was a scamming bot,
meaning people would
reach out to it, the bot,
and say, "Hey, can you help
me with this part of my scam?"
And Claude specifically,
there's multiple AI models
that you could use, but
Claude was advertised
as the emotionally intelligent AI model.
So you could upload like
a picture of somebody
and then say, Hey, how do I
compliment this person best?
Or how do I respond to
this person's message
to make it seem like I'm
flirting with them effectively?
- Right and again, that was,
people were having success there
and presumably that's shut down now.
- Yes. This is shut down.
Everything we talk about today
was shut down.
- Right, these are things
that are gone, yeah, yeah.
- Yes.
And we build better defenses.
But yeah, in that case, we found,
I think this is really the takeaway for me
is that all scam infrastructure end-to-end
is starting to use AI models.
Because if you're a scammer,
you might not have perfect language skills
in the relevant language you're
trying to scam somebody in.
You might not know the cultural context
to flirt effectively.
You might not actually be
able to send enough messages
quickly enough to all of
your potential victims.
AI unblocks all of those
potential barriers.
- I watch a lot of those scam
baiting videos on YouTube.
- Oh, those are great.
- Isn't that great fun? Yeah, yeah.
Where someone like talks to
the scammer sometimes for hours
to just waste loads
and loads of their time
so they can't scam someone else.
Can you imagine an AI doing that
to sort of put things
back on the scammers,
like an AI making the scammers think that-
- You know, I love this idea.
You have the AI interacting
with the scammers
just wasting their time.
- Yeah, exactly. Yeah, yeah.
That could be an idea.
A sort of romance scam but for scammers.
The operations that you've
talked about so far in the report
and in this video are really in order
to try and get money from people, right?
They're scams and fraudulent attempts,
extortion attempts to get money.
But there's one operation that
you talk about in the report
that's not about that.
And in this case it's about a cyber attack
on the infrastructure in Vietnam.
Can you talk a little bit more about that?
I mean, this is not an attack
to try and destroy the infrastructure,
this is stealing
information from it, right?
- Yes, this is likely espionage
from what we're observing.
This is a Chinese-speaking actor
targeting Vietnamese
telecommunications companies.
And there are a number of reasons
you might target a
telecommunications company
as a bad actor.
But seeing that they
were exfiltrating data
clues us in on the potential that they are
trying to maybe identify certain things
about communications
happening within the country.
- Like where the really
important nodes are
in the communication grid or whatever.
Yeah.
- Yeah.
So, we saw them target a number
of companies within Vietnam,
and in this case they were using Claude
as more of an assistant
in their operation.
So whereas in the vibe hacking case,
Claude was essentially on
keyboard conducting the operation.
In this case, they were more
kind of having a conversation with Claude
where it's like, hey, like where
should I start this attack?
They would run a scan
on the victim network
and paste that data back into Claude
and say, hey, like, what
is this scan telling me?
Can you help me prioritize
certain machines to target first?
And it was a lot of just back and forth,
but not really having Claude
actually like on keyboard.
And I would guess an entity conducting
an espionage operation wouldn't
be willing to trust an agent
to actually run the commands
within victim networks.
And I think that could
have been another clue.
- So it's not used yet.
We're seeing vibe hacking used
for these types of hyper targeted attacks
against sensitive targets,
because bad actors might not
yet fully trust the model
when there's only one or two targets
that you wanna go after.
But this is probably
gonna change over time
once people get more comfortable
with things like vibe hacking.
Once you get more comfortable
with model accuracy,
you could imagine that all
operations that are offensive,
may be using AI not just
for an advisory purpose,
but for actually
conducting operational work
or being, quote, unquote,
"hands on keyboard,"
or maybe it's AI on keyboard
because there aren't
actually hands on keyboard.
- Another of the examples you talk about
is a credit card fraud scheme
where they're collecting
people's credit card information.
Tell us a little bit how that works.
- Well, a very standard
part of fraud operations
when you're signing up for a service
is you use a either a stolen credit card
or a fake credit card.
And one of the core
parts of infrastructure
if you're a fraudster is,
well, where am I gonna go
find my fake credit card
or my stolen credit card?
We're seeing somebody using Claude
to stand up a carding service.
Meaning the actual
infrastructure you'd be using
to conduct some sort of scam,
you'd be using carding
infrastructure that is run by Claude.
Again, I think it goes into the theme
that every stage of a scam
or a cyber attack or an act of fraud,
and there's many stages.
There's the core infrastructure,
there's the reaching out to the person,
there's maybe installing
or building malware.
There's many stages of,
quote, unquote, "attack."
Each of those stages are
having AI integrated into them.
So the core infrastructure,
the actual operational act,
the conversation with the victim,
all of these we're
seeing AI used right now.
- This isn't surprising.
Many cyber criminal operations
run like businesses.
They need infrastructure,
they need tooling.
And I think we're gonna
see a lot more actors
start using AI to build infrastructure
and then sell that to
other cyber criminals.
- Because what you see
today, if you spend much time
which hopefully the
listeners are not doing,
on the dark web, is it's
an entire marketplace
where you are buying that tool.
You're buying that
piece of infrastructure.
So if I'm gonna conduct,
let's say a phishing campaign,
I might not build the,
quote, unquote, "phish kit."
I might buy the phish
kit from somebody else,
and then I'm conducting
the phishing campaign,
but the actual infrastructure's
not built by me.
Now, AI is being used to
build that core infrastructure
that could be bought and
resold on the dark web.
- So all this stuff we hear,
it's like the vibe coding stuff.
All the stuff we hear
about all these amazing
new piece of software that are being made,
again, as a dual use situation
where there's all this great new software
that people are making themselves
and it's making their life
easier in all sorts of ways.
But there's also the dark side,
which is that software can often be used
to do very bad things.
- That's right as well.
- Okay. How big a deal is this overall?
Like you're talking about AI models are,
loads of scamming is
happening now using AIs
and fraud and so on.
Is this just gonna be a whole new world
that people have to get used to?
How ready are we for this?
How ready are banks for this?
How ready are governments for this?
- Yeah, I think when you think
of the cybersecurity space,
you wanna keep things at equilibrium
in the worst case scenario.
Ideally you're doing a better
job protecting folks, but-
- This is like an arms race.
- Yes.
- Like the good AI uses
and the bad AI uses.
- Exactly.
It's like all technology,
bad guys are gonna use it,
good guys are gonna use it.
And AI is a general purpose
piece of technology.
And I think what's important,
and one of the reasons
we're talking about this
and hopefully folks are
listening and watching,
is we want the good guys, the defenders
to be using this technology too,
so that in that arms race
you stay at equilibrium.
Really, ideally we're trying to work with
and partner with those organizations
so that they have a leg up,
they use it more effectively.
- Is there anything else you can say about
what the Threat Intelligence team is doing
in general or even some more specifics
about what you're up to
that might help us get
to that equilibrium?
- Yeah, well, something we're always doing
is we have people on the team
who are looking on the
open web and the dark web
to understand what are bad actors
practically doing right now?
What are they saying
about using our products?
What's the chatter?
So we understand, okay,
here's bad guys' usage.
So then we can talk to the good guys
and say, "Hey, here's what it seems like
the bad actors are doing."
We're building new methods
of detection all the time.
One of the reasons we
shared this public report
is we want the public, other companies,
the security community
to know what we're seeing
and what we're finding.
So both, you know, maybe think
of it from two perspectives.
One is at Anthropic we
take stopping misuse
very seriously of our models
and that's why this team exists.
But on the other side,
if you're in industry
as a company, as a government,
we're talking about this
so that you yourself
can start using these
AI models for defense.
- Well, that was my next question.
What can you other...
You know, using AI is one thing,
but what are some more
practical tips for people
who maybe they or their
family members or whatever
are the victim of these scams,
fraud attempts, extortion attempts.
What are some tips that you guys have
for the average person?
- Yeah, I would say anytime
like you're suspicious
about something happening
like a text you got or an email you got
or something weird
happening on your computer,
just start like brainstorming
what's happening with Claude.
Claude will have a lot of good ideas
and it will help you kind of triage
as if you were like a
security professional,
how they might triage the same problem.
Since I work in the security space,
I have people ask me
questions like this regularly
and sometimes like if I don't have time,
I'll just throw it
into Claude.
- Just throw it in.
- Say this is what Claude said
and then they will potentially maybe
try to do that next time.
Save me a little bit of time.
- Fair enough.
- Yeah, I think the general
guidance I have is the same,
which is if it's too good to be true
or if you're really scared,
probably means something's up
and you should look into it.
You talk to Claude
and actually, I've done
the exact same thing.
Somebody asked me for help with
their account was taken over
and I just asked Claude,
hey, what should we do here?
Even though I have years of expertise
dealing with account takeovers,
Claude was exceptionally helpful.
- How optimistic are you both about this?
I mean, this could be seen as quite
a doom-laden scenario, right?
There's all these AIs being used by
some of the countries that don't have
any kind of ethical legal
framework that are doing this.
This could be seen as
something really quite scary
or how optimistic do you feel?
- Yeah, I think it's important
to keep in perspective
that like what we're sharing today
is kind of like the needles
in the haystack that we find.
I think they might indicate a future
if we don't respond
collectively well to it.
But these are the needles in the haystack
and we've built a lot of defenses
and adjusted our defenses
from these learnings
to make sure our models
don't get used in this way.
But there hackers have been known to use
quite a number of different commercial
and open source models.
So the problem's not gonna go away.
And I'm hopeful that our
threat report and this video
will help calibrate everyone
on what currently exists
and start kind of coalescing
around different types of defenses,
either policy or technical
that can kind of help get at the problem.
- It could be seen as quite
strange that we are saying,
on the one hand you should buy Claude,
on the other hand we're saying
Claude can do all these terrible things.
I mean, this comes up
when we're talking about
alignment science stuff as well, you know?
Claude, under some circumstances
in our experiments,
can blackmail you.
Now, buy Claude to use in your business.
Like, this is part of the weird
paradox of Anthropic, right?
- I always think about this a lot,
how Claude is such a general purpose tool
that any use case you can think
of, Claude can probably do.
And many of those use cases,
the same use case can be good or bad.
Getting rid of a cultural
barrier can be a beautiful thing
to create connection in the world
or can help you land a job
as a remote IT workers as a North Korean.
- Right.
- So, you know, there's this paradox
and we want to enable
the good thing as well
trying to find the very
narrow bad use cases.
- Well, I'm very glad that
you guys are looking into this
and that we're taking this
so seriously at Anthropic.
And you might just wanna check
that the colleague that
you talk to every day
is not a North Korean agent.
Thanks very much for watching.
We'll see you in the next one.