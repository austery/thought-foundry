大家好
欢迎来到我的频道
昨天呢做了那期加里马库斯的视频啊
很多人在底下留言啊
就是说呀
这个马库斯根本就不懂人工智能
现在AI已经很好用了
你就是想要去黑这个ChatGPT
我这得跟大家解释一下啊
我可是这个大语言模型的忠实用户
基本上
市面上你能想到的这些顶尖模型
我都有付费使用
我有买这个ChatGPT的
200刀一个月的会员
然后呢Gemini我也买了一个
那个Ultra应该也是200刀一个月
然后还有Claude和perplexity啊
当然perplexity是买这个Zoom会员送的啊
这个就没有付钱了
所以呢基本上
我对于这个AI技术是非常认可的
因为我觉得它确实在很多方面
能够帮你提升工作效率
但是呢我觉得呃
加里马库斯的批评也是很到位的啊
事实上我也测试了好几个
就是关于ChatGPT
它现在目前没有办法能做到的
这个功能啊
它确实存在这些问题
那我们今天呢
就想给大家解读一下啊
加里马库斯在20年前写的这本书
《代数大脑》
呃基本上在这本书中呢
其实就已经展现了
他现在对于这个神经网络技术的不足
的批评观点基本上就没变
那我们直接进入今天的主题吧
我们都听说过啊
大脑像一个复杂的神经网络
那如果这是错的呢
今天的AI巨头
啊比如说ChatGPT啊
都是基于这个神经网络
但他们为什么会犯下这些低级错误呢
20年前啊
一位认知科学家就预言了这一切
今天呢我们深入解读一下
加里马库斯的代数大脑
揭开一个颠覆你常识的真相
啊你的智能核心或许不是模式识别
而是一套强大的代数系统
准备好我们就进入这一场
大脑的底层探秘之旅
首先朋友们
你们有没有想过一个问题啊
一个7个月大的婴儿
话还不会说
路还不会走
竟然能够像一个逻辑学家一样
发现抽象的语法规则
这听起来是不是有点反常识啊
我们总被告知啊
大脑嘛就像一个巨大的神经网络
通过海量的经验学习
慢慢的识别模式
我们今天引以为傲的人工智能
比如说ChatGPT5
不就是这么工作的吗
但如果我告诉你啊
我们深信不疑的这个神经网络
可能从根本上
就解释不了
人类智能最核心的那部分能力呢
如果说啊
你的大脑深处
其实有一个更古老
更强大的代数引擎呢
我们今天就聊一聊
这本20多年前出版的
在今天却越发具有这个预言性的神作
这本书呢
将带我们潜入智能的底层
去探索一个被大家很多人忽视的
就是理解我们自己
以及真正通用人工智能AGI的关键
相信看完本期节目呢
大家对于智能的理解啊
会有更深层次的进步
要理解这本书的厉害之处呢
我们先得回到认知科学领域啊
一场持续了几十年的华山论剑
这个论剑的双方呢
就像什么剑宗和气宗
对吧在这里头呢
两大派第一派叫做符号主义
第二派叫做连接主义
这个符号主义啊
这一派的大佬认为啊
大脑就像一台经典的计算机
智能的核心是什么
就是处理符号
就像计算机处理0和1
我们大脑处理的是概念
规则这些心理符号
比如啊所有的狗都会叫
这是一条规则
遇到一条新狗
我们就能够运用这条规则
推测出它也会叫
简单清晰
有逻辑。第二派呢
就是连接派啊
他们觉得把大脑比作计算机太土了
大脑明明是由几十亿个神经元
相互连接组成的
所以呢智能不是靠什么规则
而是神经元网络在经验中学习
通过调节神经元之间的连接权重
逐渐形成一种能力
你看啊
这是不是更符合生物学的事实
也更高级了呢
时间到了上世纪80年代
随着一本叫做《并行分布式处理》
PDP的书横空出世
连接主义迎来了高光时刻
大家突然发现啊
这种受神经网络启发的模型
好像真的能够模拟很多
过去难以解释的认知现象
比如说语言学习
从那以后啊
连接主义一路高歌猛进
直到今天成为了人工智能的绝对主流
我们现在用的
所有大语言模型
本质上都是连接主义思想的产物
他们都是规模巨大
结构复杂的神经网络
这就带来一个核心问题啊
也就是
《代数大脑》这本书想要挑战的终极问题
既然连接主义这么成功
我们是不是可以彻底的
抛弃符号主义了呢
人类智能
真的就是一个超级复杂的神经网络吗
加里马库斯响亮的回答不对
为了搞清楚马库斯的论证啊
我们必须得花一分钟
首先了解连接主义的当家花旦
多层感知器MLP啊
我记得这个英文好像是呃
Multi layer perceptron啊
这个我后面查一查
我不知道说的对不对啊
到底是怎么工作的呢
你看啊你可以把它想象成
一个超级复杂的调光系统
最底下一层呢
是输入节点
就像一层开关
比如说我们要识别一张猫的图片
有可能代表胡须的开关就打开
代表有尖耳朵的开关也打开
最上面一层呢
是输出节点
就像最终亮的灯泡
可能一个灯泡代表猫
一个灯泡代表狗
最有意思的是
中间这一层
叫做隐藏层
他就像无数个错综复杂的调光器
和线路连接着输入开关和输出灯泡
每个连接线路上都有一个权重
决定了这条线路的信号到底有多强
当输入的开关打开时
信号可以通过这些带权重的线路
传到隐藏层
隐藏层再把信号传到输出层
最终亮的那个灯泡就是网络的答案
比如猫这个灯泡最亮
那么网络就判断这是一只猫
那这个神奇的系统是怎么学习的呢
那最常用的方法叫做反向传播
backpropagation
这个名字听起来很唬人啊
但是打个比方
你就秒懂了
想象一个学生正在做题啊
他刚给出一个答案
网络输出哎
老师就告诉他正确答案应该是什么
目标输出哎
学生一看
哎呀
我的答案和正确答案之间有差距啊
这个差距在网络里头就叫做误差
怎么办呢
学生就得反思啊
我到底是哪个知识点没掌握好呢
于是他就从答案开始
一层层的往回找原因
修改自己的笔记
这个修改笔记的过程呢
就是在网络调整那些连接的权重
一次次重复这个过程
网络里的权重就会被调整的越来越好
误差越来越小
他就学会了
你看这过程是不是很吸引人
他不需要你预设任何规则
只要给他足够多的数据和反馈
他就能够自己学习
感觉上
这可比硬邦邦的符号规则聪明多了吧
也更像是我们人类学习的方式
对吧
这个核心呢
其实也就是机器学习的这个原理啊
好
背景铺垫完了
现在主角要登场了
马库斯认为啊
要真正理解人类智能
我们不能只看连接主义的表面风光
必须直面符号
加工思想这三个核心支柱
这三个支柱
才代表我们智能的代数本质
第一我们的大脑
能够表示变量之间的抽象关系
简单来说
就是我们能够理解和使用规则
比如给动词加ED
变成过去
式，past verb等于verb加ED
这里的verb就是一个变量
你可以代入任何动词
比如说walk jump
这些规则都成立
第二就是
我们的大脑
拥有递归和结构化的表示系统
这什么意思呢
桌子上的书和书上的桌子
虽然用的词都一样
但我们清楚的知道
这是两个完全不同的意思
因为
我们大脑不是一个简单处理一堆词
而是在处理他们之间的连接关系
而这种结构可以无限嵌套
就像俄罗斯套娃一样
第三
我们的大脑能够明确区分个体和种类
我们知道狗是一个类别
也知道我家那条叫旺财的狗
是一个独一无二的个体
这听起来好像很简单
但对于计算系统来说
其实是一个巨大的挑战
现在最核心的问题来了
那个看起来很厉害
能够从数据中学习的多层感知器
它能实现这三个核心能力吗
马库斯的答案是不能
或者说标准的多层感知器
在这些人类智能的核心领域存在
根本性的缺陷
接下来的内容
就是这本书最精彩的部分
马库斯用一系列精巧的思想实验
和真实的认知心理学研究
像一位侦探一样层层剥茧
向我们展示
为什么那个看似万能的神经网络
其实并不能解释我们大脑里
那个真正的智能引擎
首先我们来看一个最简单的思想实验
也是梳理一个非常核心的例子
大家看屏幕上的这个表格
我给大家看几组输入和
输出输入1010输出1010输入0100输出0100
规律很简单吧
好那现在问题来了
我给你一个新的输入 1111
你觉得输出应该是什么
我猜 99%的朋友
都会毫不犹豫地回答1111
对吧因为
我们瞬间就发现了一个抽象的规则
输出等于输入
或者用数学的话说
这就是一个恒等函数F（x）= x
我们能够把这个规则
自由地泛化到所有没见过的新例子上
这种能力就叫自由泛化
好我们再把同样的问题
交给一个标准的多层感知器
你猜怎么着
经过训练后啊
你给他输入1111
他可能输出的是1110
为什么会这样呢
这就触及到
这类神经网络的一个致命弱点
马库斯称之为训练独立性
你看啊在这个网络在训练的时候
发现所有的训练样本里头
最右边那一列的输出永远是0
所以他学到的潜规则是
不管输入啥
我输出的最右边那一位大概率就是0
他根本就没有学到那个抽象的
输出等于输入的代数规则
打个比方啊
就像一个只会死记硬背的学生
你给他100道例题
他都背了下来
但考试的时候你换了个新题
只要这个题型他没见过
他就懵了
他没有掌握背后的公式
而我们人类恰恰相反
我们就天生擅长找那个公式
这个小小的例子
就暴露出了标准的神经网络和
人类智能之间的一个巨大鸿沟
你可能觉得
刚才那个0和1的例子太抽象了
别急啊更有意思的来了
我们来看看
开头提到那个7个月大的婴儿实验
科学家给一群7个月大的宝宝
听一些毫无意义的音节序列
一组宝宝听的是a b a结构的句子
比如拉踢拉
另一组听的是ABB结构
比如说拉踢踢
就这么听2分钟啊
然后神奇的事情发生了
科学家开始给宝宝播放
全新的音节组成的句子
你猜怎么着
听过ABA的宝宝
当他们听到全新的ABA句的时候
比如说噢非噢的时候
就没什么反应
但一旦听到ABB结构的奥菲菲
他们就会表现出明显的惊讶
盯着喇叭更长的时间
这意味着什么
这意味着这些话都说不明白的婴儿
竟然在短短的2分钟内
超越声音本身
提取了一个抽象的代数规则
第一项和第三项相同
并且
能够把这个规则应用到全新的声音上
这简直太惊人了
这种强大的规则提取能力
在儿童学习语言的过程中随处可见
最经典的例子就是学习英语的过去式
我们大家都知道啊
大部分动词的过去式都是加e d
比如说walk变成walked
但还有一小撮不规则的
比如说sing变成sang
go变成went
有意思的是呢
小孩子在学习说话的时候
经常会犯一种聪明的错误
他们可能会先说ate
但过一段时间呢
他们反而会说eaten
为什么呢
因为大脑发现一个更通用的规则动词
加ED然后呢
试图把这个规则应用到所有动词上
哪怕那些是不规则的
而很多早期的连接主义模型
就很难解释这个现象
他们要么
很难学会这个通用的加ED规则
要么在泛化的时候
就会搞出一些很奇怪的混合词
比如说把Splin变成了一个Splind
而不是我们人类常会说的Splind
或者是Splang
你看这再次说明
我们的语言系统里头
似乎内置了一个处理抽象规则的模块
和一个负责处理记忆特殊例外的模块
这是一种双轨制
而不是一个大一统的神经网络
好的解决了规则问题
我们再来看看第二个核心支柱
结构化表示
我们前面提到了桌子上的书
和书上的桌子
在我们看来
这两个意思天差地别
但是对于一个简单的神经网络来说
可能就傻眼了
因为他看到的可能就是书桌子上
这几个概念被激活了
至于谁在谁上面
这个结构信息就丢失了
这个问题在AI领域被称为是“叠加灾难”
当你试图用同一组资源
比如说一堆神经元
去表达多个实体和他们之间的关系时
信息就会互相干扰
变成一锅粥
为了解决这个问题
马库斯在书里头
提了一个非常有趣的概念
叫做树苗
你可以把它想象成
我们大脑里头
预先装了一堆文件结构模板
每个模板都有固定的
槽位比如说施动者动作承受者
当我们理解这一句话时
就把对应的概念填到这些槽位里头
这样一来
结构信息就不会丢失了
桌子上的书
就是把书填到主体槽
把桌子填到位置槽
反之亦然
这个想法
就为大脑如何在神经层面
实现结构化表示
提供了一种可能的解释
最后我们再来看第3个
也是最容易被忽视的一点
区分个体和种类
你看啊一个标准的神经网络
它通过特征来识别物体
比如说四条腿
有胡须会喵喵叫
它就识别为猫
但问题来了
如果现在有两只长得一模一样的猫
菲利克斯和莫里斯站在你面前
神经网络怎么区分它俩
对网络来说
他们两个特征完全一样
所以他们俩就是同一个东西
网络无法理解
这是两个完全不同的个体这样的概念
而我们大脑呢
大脑有个神奇的能力
大脑有个神奇的能力
就是给每一个遇到的个体
贴上一个独一无二的心理标签
并且在时间和空间中持续追踪
这个标签
就像电影变脸里
无论是尼古拉斯凯奇
还是约翰特拉沃尔塔
还是约翰特拉沃尔塔
怎么换脸
我们始终清楚谁是好人
谁是坏人
因为我们追踪那个是持续存在的个体
而不是他表面的特征
这个能力是客体的永久性
是计数甚至是社会关系的基础
而一个无法区分个体
和种类的系统
是无法真正理解
我们
这个由无数独特个体组成的世界的
好了我们讲到这里呢
大家可能会觉得
马库斯说的这些都很有道理
但是呢这本书《代数大脑》
毕竟是20多年前的书了
今天的神经网络
特别是那些新的大语言模型啊
已经比那时候强大太多了
他们是不是已经解决了这些问题呢
有意思的事就在这里
答案是并没有完全解决
你看
今天大模型非常擅长识别和生成模式
这是联结主义的强项
但是呢他们也暴露出了很多弱点
他们会一本正经的胡说八道
幻觉，缺乏真正的逻辑推理能力
而且有时候会因为输入的一点点变化
就得出完全错误的结论
脆弱性
这不正是马库斯当年指出的
那个根本性缺陷
在今天的体现吗
他们仍然很难完美的处理抽象规则
复杂结构和个体追踪
所以呢
代数大脑的观点在今天非但没有过时
反而变得更加重要
告诉我们
通往真正通用人工智能道路
可能不是把神经网络做的更大
而需要把符号主义的代数能力
和连接主义的学习能力结合起来
这就是现在AI研究的前沿方
向之一神经符号AI
那么了解了我们大脑的代数引擎
对我们普通人有什么用呢
哎这用处可就大了
第一呢可以改善我们的学习方式
你要分清楚
你是像神经网络一样死记硬背
还是像代数大脑一样掌握公式
下次学习新知识
别光记结论
多问几个为什么
去寻找背后那可以自由泛化的规则
这才是真正的高效学习
第二是提升你解决问题的能力
遇到一个问题
先判断一下
这是一个需要模式识别的问题
还是需要逻辑推理的问题
如果是前者
你需要多找案例
凭感觉和经验
如果是后者
你就得静下心来
一步步分析结构
运用规则
把大脑两个系统都用在刀刃上
第三更清晰地看待AI
下次再看到天花乱坠的AI宣传
你就可以多一分批判性思考
问问自己
它是在做高级的模式匹配
还是
真的具备了理解结构和规则的能力
这能够帮助你更好地运用AI
而不是被它所忽悠
所以我回到我们最初的问题
我们大脑到底是什么
再说大脑给了我们一个新的启示
它既不是一台冷冰冰的逻辑计算机
也不仅仅是一台混沌的神经网络
它是一个无比精妙的混合系统
它既有连接主义系统的
强大的学习和模式识别能力
又有符号主义系统精准的规则
操作和结构表示能力
这就像一个伟大的艺术家
他既对色彩和光影有直觉连接主义
又对透视和构图有严谨知识符号主义
两者结合
才诞生了伟大的作品
理解了这一点
我们不仅距离创造真正的人工智能
又更近了一步
更重要的是
我们能够更深的体验到
我们的心智的奇迹
我们大脑里都运用着这个代数引擎
它赋予我们学习语言理解世界
进行创造的能力
这本身
就是一件值得惊叹和感恩的事情
最后呢聊一聊对这本书的批评啊
很多人认为啊
这本书出版于21世纪初
其中呢
马库斯批判的一些具体的模型和论文
啊现在已经被认为是过时了
机器学习领域已经取得了长足的进步
更新的
深度学习模型能够完成一些啊
曾经被认为是不可能的任务
一些读者也发现啊
如果没有专业背景
很难理解
书中关于反向传播模型的技术细节
尽管有这些批
评呢但是很多评论者一致认为啊
代数大脑这本书提出的理论
思考和思维方式
仍然具有很好的现实意义
好的今天的分享就到这里了
希望这本代数大脑
能为你打开一扇新的窗
让你看到智能背后呢更深邃的逻辑
如果你对这个话题感兴趣的话
强烈推荐去读一下原书
本期节目就录到这里了
非常感谢大家观看
我们下期节目再见