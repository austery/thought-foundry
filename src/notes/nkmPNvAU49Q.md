---
author: a16z
date: '2025-10-14'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=nkmPNvAU49Q
speaker: a16z
tags:
  - t-literature-note
  - a16z
  - ai-development
  - ai-capabilities
  - future-of-ai
  - job-automation
  - ai-safety
title: AI发展是否放缓？Nathan Labenz：我们问错了问题
summary: Nathan Labenz深入探讨AI发展现状，驳斥AI放缓的观点，强调多模态AI、推理能力和应用场景的巨大进步，并讨论AI对就业、社会及未来可能带来的深远影响。
insight: ''
draft: true
series: ''
category: ''
area: ''
project: ''
status: evergreen
---
### AI并非语言模型的代名词

**Host:** Nathan, I'm stoked to have you on the AC and Z podcast for the first time. Obviously, I've been podcast partners for a long time with you leading Cognitive Revolution. Welcome.

**Host:** Nathan，很高兴你第一次来到AC and Z播客。显然，我与你共同主持Cognitive Revolution播客已经很久了。欢迎你。

**Nathan:** It's great to be here. Thank you. So, we were talking about Cal Newport's podcast appearance on lost debates and we thought it was a good opportunity to just have this broad conversation and really entertain this sort of question of is AI slowing down? So why don't you sort of steelman some of the arguments that you've heard on that side either from him or more broadly and then we could sort of have this broader conversation.

**Nathan:** 很高兴来到这里，谢谢。我们之前谈论了卡尔·纽波特（Cal Newport）在“Lost Debates”播客上的露面，我们认为这是一个很好的机会，可以就“AI是否正在放缓？”这个宽泛的问题进行讨论。那么，你能不能就你从他那里或更广泛听到的论点，进行一些“稻草人谬误”式的强化，然后我们就可以展开更广泛的对话了。

**Nathan:** Yeah, I mean, I think for one thing it's really important to separate a couple different questions I think with respect to AI. One would be is it good for us, you know, right now even and is it going to be good for us in the big picture? And then I think that is a very distinct question from are the capabilities that we're seeing continuing to advance and you know at a pretty healthy clip.

**Nathan:** 是的，我认为首先，在讨论**人工智能**（AI: Artificial Intelligence: 模拟人类智能的科学与工程）时，区分几个不同的问题非常重要。一个问题是，它现在对我们有益吗？从长远来看，它会一直对我们有益吗？我认为这与我们所看到的能力是否在以相当快的速度持续进步，是截然不同的问题。

### 区分AI影响与能力进展

**Nathan:** So I actually found a lot of agreement with the Cal Newport podcast that you shared with me when it comes to some of the worries about the impact that AI might be having even already on people. You know, he goes over, looks over students' shoulders and watches how they're working and finds that basically he thinks that they are using AI to be lazy, which is, you know, no big revelation. I think a lot of teachers would tell you that.

**Nathan:** 所以，当你与我分享卡尔·纽波特的播客时，我实际上非常认同其中一些关于AI可能已经对人们产生影响的担忧。你知道，他会观察学生的学习情况，发现他们基本上是在利用AI偷懒，这并不是什么惊人的发现。我想很多老师都会告诉你这一点。

**Nathan:** Puts that in maybe more dressed up terms that people are not even necessarily moving faster, but they're able to reduce the strain that the work that they're doing places on their own brains by kind of trying to get AI to do it. And you know, if that continues and I think you know, he's been I think a very valuable commenter on the impact of social media. Certainly, I think we all should be mindful of how is my attention span, you know, evolving over time and am I getting weak or, you know, averse to hard work? Those are not good trends if they are showing up in oneself. So, I think he's really right to watch out for that sort of stuff.

**Nathan:** 他可能用更委婉的措辞表达了这一点，即人们甚至不一定能因此加快速度，但他们能够通过让AI代劳来减轻工作对大脑造成的压力。如果这种情况持续下去，我认为他一直是社交媒体影响力的非常有价值的评论员。当然，我认为我们都应该留意自己的注意力广度是如何随时间演变的，我是否变得脆弱，或者说，厌恶艰苦的工作？如果这些趋势出现在自己身上，那都不是好现象。所以，我认为他非常正确地提醒我们关注这类问题。

**Nathan:** And then, as we've covered it, you know, many conversations in the past, I've got a lot of questions about what the ultimate impact of AI is going to be. And I think he probably does too. But then when it comes to it's a strange move from my perspective to go from you know, there's all these sort of problems today and maybe in the big picture to but don't worry it's flatlining like kind of worry but don't worry because it's not really going anywhere further than this or it's you know scaling has kind of petered out or you know, we're not going to get better AI than we have right now.

**Nathan:** 接着，正如我们过去在许多对话中讨论过的，我对AI的最终影响有很多疑问。我想他可能也有。但从我的角度来看，从“今天存在所有这些问题，也许从大局来看也是如此”到“但别担心，它正在停滞不前”这种转变是很奇怪的，就像是“担心，但又别担心，因为它不会再有进一步发展了”，或者“它的规模化已经逐渐消失了”，或者“我们不会再拥有比现在更好的AI了”。

**Nathan:** Or even maybe the most easily refutable claim from my perspective is GPT-5 wasn't that much better than GPT-4. And that I think is where I really was like, whoa, wait a second. You know, I was with you on a lot of things. And some of the behaviors that he observes in the students, I would cop to having exhibited myself.

**Nathan:** 甚至从我的角度来看，最容易驳斥的说法可能是GPT-5并没有比GPT-4好多少。我认为这正是我会说“等等，慢着”的地方。你知道，我在很多事情上都同意你的看法。他观察到的一些学生行为，我承认自己也曾表现出来。

**Nathan:** You know, when I'm trying to code something these days, a lot of times I'm like, "Oh man, can't the AI just figure it out?" You know, I really don't want to have to sit here and read this code and figure out what's going on. It's not even about typing the code anymore, you know, I'm way too lazy for that. But it's even about like figuring out how the code is working just just case you just make it work. Try again, you know, and just try again and I'll I do find myself at times falling into those traps.

**Nathan:** 你知道，现在当我尝试编写代码时，很多时候我都会想：“天哪，AI就不能自己搞定吗？”我真的不想坐在这里阅读这些代码，弄清楚发生了什么。现在甚至不再是打代码的问题了，你知道，我太懒了。但它甚至关乎弄清楚代码是如何工作的，只是为了让它工作。再试一次，你知道，就是再试一次，我确实有时会陷入这些陷阱。

**Nathan:** But I would say big part of the reason I can fall into those traps is because the AIs are getting better and better and increasingly it's not crazy for me to think that they might be able to figure it out. So that that's my kind of first slice at the takes that I'm hearing. There's almost like a two by two matrix maybe that one could draw up where it's like do you think AI is good or bad, you know, now and in the future and do you think it's like not a big deal or a big deal and I'm I think it's both on the good and bad side. I definitely think it's a big deal.

**Nathan:** 但我想说，我之所以会陷入这些陷阱，很大程度上是因为AI正变得越来越好，而且我越来越觉得它们能够解决问题，这并非异想天开。所以，这是我对目前听到的观点的一种初步看法。也许可以画一个二乘二的矩阵，比如你认为AI现在和未来是好是坏，以及你认为它是不是一件大事。我认为它既有好处也有坏处。我绝对认为这是一件大事。

### GPT-4到GPT-5的进步被低估

**Nathan:** The thing that I struggle to understand the most is the people who kind of don't see the big deal that it seems pretty obvious to me and the you know especially when it comes again to the the leap from GBD4 GB5. Maybe one reason that that's happened a little bit is that there were just a lot more releases between GPT4 and 5. So what people are comparing to is, you know, something that just came out a few months ago, like 03, right? That only came out a few months before GBT5. Whereas with GBT4, it was, you know, shortly after ChatGpt and it was all kind of this moment of like, whoa, this thing is like exploding onto the scene.

**Nathan:** 我最难以理解的是那些不认为这是一件大事的人，这对我来说似乎非常明显，尤其是在谈到GPT-4到GPT-5的飞跃时。也许出现这种情况的一个原因是，GPT-4和GPT-5之间发布了更多的版本。所以人们比较的对象是几个月前才发布的，比如03版本，对吧？它只在GPT-5之前几个月发布。而GPT-4则是在ChatGPT发布后不久，当时所有人都觉得：“哇，这东西简直是横空出世！”

**Nathan:** A lot of people were seeing it for the first time. And if you look back to GPT3, you know, there's a huge leap. I would contend that the leap is similar from GPT4 to 5. These things are hard to score. There's no, you know, single number that you could put on it. Well, there's loss. But of course, one of the big challenges is that like what exactly does a a loss number translate into in terms of capabilities. So, you know, it's very hard to to describe what exactly has changed.

**Nathan:** 很多人是第一次见到它。如果你回顾GPT-3，你会发现有一个巨大的飞跃。我敢说，GPT-4到GPT-5的飞跃也类似。这些东西很难量化。没有一个单一的数字可以用来衡量它。当然，有**损失函数**（Loss Function: 衡量模型预测值与真实值之间差异的函数），但其中一个巨大挑战是，损失函数的值究竟能转化为怎样的能力。所以，你知道，很难准确描述到底发生了什么变化。

**Nathan:** But we could go through some of the dimensions of change if you want to and you know, enumerate some of the things that I think people maybe are starting to or have come to take for granted and kind of forget like that GPT4 didn't have a lot of the things that now, you know, were sort of expected in the GPD5 release because we'd seen them in 40 and 01 and 03 and all those, you know, things sort of, you know, maybe boiled the frog a little bit when it comes to how much progress people perceived in this last release.

**Nathan:** 但如果你愿意，我们可以探讨一些变化维度，并列举一些我认为人们可能已经开始或已经习以为常，以至于忘记了GPT-4并没有很多现在在GPT-5发布中被期待的功能，因为我们已经在40、01和03等版本中看到了它们。所有这些，你知道，可能在人们感知到最新版本进展的程度上，有点像“温水煮青蛙”了。

**Host:** Well, yeah, a couple reactions. So, one is and even to complicate your two by two even even further in the sense of, you know, is it bad now versus is it bad later? Like Cal is not really, you know, who we both admire by the way a lot. Cal's a great guy and a valuable contributor to the the thought space, but he's not as concerned about sort of this sort of future AI concerns that um you know, sort of the AI safety folks and um many others are are are concerned about.

**Host:** 嗯，是的，有几点回应。首先，为了让你的二乘二矩阵更复杂，从“现在是坏事”还是“以后是坏事”的角度来看。卡尔，顺便说一下，我们都非常欣赏他。卡尔是个很棒的人，也是思想领域的重要贡献者，但他并不像AI安全专家和许多其他人那样，担心未来AI可能带来的问题。

**Host:** He's more concerned about, you know, what it means to life for, you know, cognitive performance and and development now in the same way that he's worried about, you know, social media's impact. And, you know, you you think that's a uh, you know, a concern, but not nowhere near as big a concern as as what to what to expect in the future. And and then also he he presents sort of this theory of why we shouldn't worry about the future because it's slowing down.

**Host:** 他更关心的是AI对现在认知表现和发展意味着什么，就像他担心社交媒体的影响一样。而且，你知道，你认为这是一个担忧，但远不及对未来预期的担忧那么大。然后，他还提出了一个理论，解释了为什么我们不应该担心未来，因为AI正在放缓。

**Host:** And why don't we just share what we how we interpreted kind of his history which as I interpreted it was this idea of like hey we figured out the simplistic version is we figured out this this way such that if you throw a bunch of data into the model it gets better and sort of order of magnitude and so the difference between GB22 and GPD3 and then GBD3 and GBD4 um but then that sort of you know was significant the difference but then it achieved sort of a uh diminishing returns significantly and where we're not seeing it in GBD5 five and thus we don't have to worry anymore.

**Host:** 那么，我们不妨分享一下我们是如何解读他的历史观点的，据我理解，他的观点是：我们找到了一个简单的方法，就是向模型投入大量数据，它就会得到数量级的提升，比如GPT-2到GPT-3，以及GPT-3到GPT-4之间的差异。但随后这种差异就显著地出现了**边际效益递减**（Diminishing Returns: 投入增加但产出增长率下降的现象），而在GPT-5中我们没有看到这种现象，因此我们不必再担心了。

**Host:** How would you edit the characterization of his view of sort of the the history and then we can get into the differences between four and five the scaling law idea which is you know it's definitely worth agreeing taking a moment to to note that it is not a law of nature. You know we do not have a principled reason to believe that scaling is some law that will go indefinitely. All we really know is that it has held through quite a few orders of magnitude so far.

**Host:** 你会如何修正他对这段历史的描述？然后我们可以讨论GPT-4和GPT-5之间的差异，以及**规模法则**（Scaling Law: 指模型性能随计算资源、数据量等规模因素增加而呈现可预测的提升规律）这个概念。你知道，我们确实值得花点时间指出，它并非自然法则。我们没有理由相信规模化会无限期地持续下去。我们真正知道的只是，到目前为止，它已经持续了相当多的数量级。

### 上下文窗口与后训练的飞跃

**Nathan:** I think that it's really not clear yet to me whether or not the scaling laws have petered out or whether we have just found a steeper gradient of improvement that is giving us better ROI on another front that we can push on. So they did train a a much bigger model which was GBT4.5 and that did get released and there are a number of interesting you know of course there's a million benchmarks whatever the one that I zero in on the most in terms of understanding how GBT 4.5 relates to both 03 and GBT 5 and OpenAI obviously famously terrible at naming we can all agree on that I think a decent amount of this confusion and sort of disagreement actually does stem from unsuccessful naming decisions.

**Nathan:** 我认为目前尚不清楚规模法则是否已经失效，或者我们是否只是找到了一个更陡峭的改进坡度，从而在另一个我们可以推进的领域获得了更好的投资回报。他们确实训练了一个更大的模型，即GPT-4.5，并且也发布了。当然，有无数有趣的基准测试，但就理解GPT-4.5与03和GPT-5的关系而言，我最关注的是一个。OpenAI在命名方面显然出了名的糟糕，我想我们都同意这一点，相当一部分的困惑和分歧实际上确实源于不成功的命名决策。

**Nathan:** 4.5 on this one benchmark called simple QA which is really just a super longtail trivia benchmark. It it really just measures do you know a ton of esoteric facts and they're not things you can really reason about. You either just have to know or don't know these particular facts. The 03 class of models got about a 50% on that benchmark and GPT4.5 popped up to like 65%. So in other words, it basically of the things that were not known to the previous generation of models, it picked up a third of them.

**Nathan:** 在一个名为“简单问答”（Simple QA）的基准测试中，GPT-4.5表现出色。这个基准测试实际上是一个超长尾的冷知识测试，它只衡量你是否知道大量深奥的事实，这些事实无法通过推理得出，你只能选择知道或不知道。03系列模型在这个基准测试中得分约为50%，而GPT-4.5则跃升至约65%。换句话说，对于上一代模型不知道的事实，它掌握了其中的三分之一。

**Nathan:** Now there's obviously still two-thirds more to go, but I would say that's a pretty significant leap, right? These are super longtail questions. I would say most people would get like close to a zero. You know, you'd be like the person sitting there at the trivia night who like maybe gets one a night is kind of what I would expect most people to do on simple QA. And that, you know, checks out, right? Like obviously the models know a lot more than we do in terms of facts and just general, you know, information about the world. So at a minimum, you can say that GPT4.5 knows a lot more. You know, a bigger model is able to absorb a lot more facts.

**Nathan:** 显然，还有三分之二的知识有待掌握，但我想说这是一个相当大的飞跃，对吧？这些都是超长尾的问题。我想大多数人都会得接近零分。你知道，你就像是坐在冷知识之夜的人，可能一晚只答对一题，这就是我对大多数人在简单问答中的预期。而且，你知道，这很合理，对吧？显然，模型在事实和关于世界的普遍信息方面比我们知道得多得多。所以至少可以说，GPT-4.5知道的更多。一个更大的模型能够吸收更多的知识。

**Nathan:** Qualitatively, people also said in some ways maybe it's better for creative writing. You know, it was never really trained with the same power of post-training that GBD5 has had. And so, we don't really have an apples to apples comparison, but people still did still find some utility in it. I think maybe the the way to understand why they've taken that offline and gone all in on GBD5 is just that that model's really big. It's expensive to run. The price was like way higher. It was a full order of magnitude plus higher than GPT5 is.

**Nathan:** 从定性角度来看，人们也表示在某些方面它可能更适合创意写作。你知道，它从未真正接受过与GPT-5相同强度的**后训练**（Post-training: 在预训练模型基础上进行的额外训练，通常用于特定任务或提升模型性能）。因此，我们没有真正的“苹果对苹果”式的比较，但人们仍然发现它有一些用处。我想，他们将其下线并全力投入GPT-5的原因，可能仅仅是因为那个模型实在太大了。运行成本高昂。价格比GPT-5高出一个数量级以上。

**Nathan:** And it's maybe just not worth it for them to consume all the compute that it would take to serve that and maybe they just find that people are happy enough with the somewhat smaller models for now. I don't think that means that we will never see a bigger GPT-4.5 model with all that reasoning ability and I I would expect that that would deliver more value especially if you're really going out and trying to do esoteric stuff that's you know pushing the frontier of science or what have you.

**Nathan:** 而且，对他们来说，消耗所有计算资源来提供这项服务可能不值得，也许他们只是发现人们目前对稍小的模型已经足够满意了。我并不认为这意味着我们永远不会看到一个拥有所有推理能力的更大GPT-4.5模型，而且我期望它能提供更多价值，特别是如果你真的想做一些推动科学前沿的深奥研究。

**Nathan:** But in the meantime, the current models are really smart and you can also feed them a lot of context. That's one of the big things that has improved so much over the last generation. When GPT-4 came out, at least the version that we had as public users was only 8,000 tokens of context, which is like 15, you know, pages of of text. So, you were limited. You couldn't even put in like a couple papers. You would be overflowing the context.

**Nathan:** 但与此同时，目前的模型确实非常智能，你还可以给它们提供大量的**上下文**（Context: 提供给模型的相关信息，用于理解和生成更准确的回复）。这是上一代模型以来改进最大的地方之一。GPT-4刚发布时，至少我们作为公共用户使用的版本只有8000个**token**（Token: 文本处理中的基本单位，可以是单词、子词或字符），大约相当于15页文本。所以你受到了限制，甚至无法放入几篇论文，就会超出上下文限制。

**Nathan:** And this is where prompt engineering initially kind of became a thing was like, man, I've really only got such a little bit of information that I can provide. I got to be really careful about what information to provide, lest I overflow the thing and it just can't handle it. There were also, as context windows got extended, there were also versions of models where they could nominally accept a lot more, but they couldn't really functionally use them. You know, they sort of could it could could fit them, you know, at the API call level, but they the models would lose recall or they they'd sort of unravel as they got into longer and longer context.

**Nathan:** 这就是**提示工程**（Prompt Engineering: 设计和优化输入提示以引导AI模型生成期望输出的技术）最初兴起的原因，当时人们会想：“天哪，我能提供的信息实在太少了。我必须非常小心地选择提供什么信息，以免信息溢出，模型无法处理。”此外，随着上下文窗口的扩展，也出现了一些模型版本，它们名义上可以接受更多信息，但实际上并不能有效地利用。你知道，它们在API调用层面可以容纳这些信息，但模型会失去回忆能力，或者在处理越来越长的上下文时会变得混乱。

**Nathan:** Now you have obviously much longer context and the command of it is really really good. So you can take dozens of papers on the longest context windows with Gemini and it will not only accept them, but it will do pretty intensive reasoning over them and with really high fidelity to those inputs. So that skill I think does kind of substitute for the model knowing facts itself. You could say geez we let's try to train all these facts into the model. We're going to need you know a trillion or who knows five trillion however many trillion parameters to fit all these super longtail facts.

**Nathan:** 现在显然你有更长的上下文，而且对它的掌控能力非常好。所以你可以用Gemini最长的上下文窗口处理几十篇论文，它不仅能接受，还能对它们进行相当深入的推理，并且对这些输入保持极高的忠实度。所以，我认为这项技能在某种程度上可以替代模型本身知道事实。你可能会说，天哪，我们试着把所有这些事实都训练进模型。我们需要万亿，甚至五万亿，不管多少万亿的**参数**（Parameter: 模型中可学习的变量，决定了模型的行为和性能），才能容纳所有这些超长尾的事实。

**Nathan:** Or you could say, well, a smaller thing that's really good at working over provided context can if people take the time or you know go to the trouble of providing the necessary information, I can kind of access the same facts that way. So you have a kind of do I want to push on this size and do I want to bake everything into the model or do I want to just try to get as much performance out of a smaller tighter model that I have? And it seems like they've gone that way.

**Nathan:** 或者你可以说，一个擅长处理所提供上下文的小型模型，如果人们花时间或不辞辛劳地提供必要信息，我就可以通过这种方式获取相同的事实。所以你面临一个选择：是想扩大模型规模，把所有东西都内置进去，还是想从现有的小型紧凑模型中榨取尽可能多的性能？看起来他们选择了后者。

**Nathan:** And I I think basically just because they're seeing faster progress on that gradient, you know, in the same way that the models themselves are always kind of in the training process taking a little step toward improvement, you know, the the outer loop of the model architecture and the the nature of the training runs and where they're going to invest their compute is also kind of going that direction. And they're always looking at like, well, we could scale up over here and maybe get this kind of benefit a little bit or we could do more post-training here and get this kind of benefit. And it just seems like we're getting more benefit from the post-training and the reasoning paradigm than scaling. But I don't think either one is uh I I definitely don't think either one is is dead.

**Nathan:** 我认为这基本上是因为他们在这个方向上看到了更快的进展。你知道，就像模型本身在训练过程中总是在一点点地改进一样，模型架构的外部循环、训练运行的性质以及他们将计算资源投入的方向，也都在朝着这个方向发展。他们总是在考虑，我们可以在这里扩大规模，也许能获得一点这种好处，或者我们可以在这里进行更多的后训练，获得那种好处。现在看来，我们从后训练和推理范式中获得的好处比从规模化中获得更多。但我认为两者都没有消亡，我绝对不认为两者中的任何一个已经消亡。

### AI推理能力的显著提升

**Host:** Yeah. And and so I mean one of the things that you mentioned that that Cal um you know analysis missed was was that it way underestimated the value of of of of of extended reasoning, right? Um, and so what what would it mean to to fully sort of appreciate that?

**Host:** 是的。所以，你提到卡尔的分析遗漏的一点是，它大大低估了**扩展推理**（Extended Reasoning: 模型通过多步骤、复杂逻辑链进行思考和解决问题的能力）的价值，对吧？那么，充分认识到这一点意味着什么呢？

**Nathan:** Well, I mean, a big one from just the last few weeks was that we had an IMO gold medal with pure reasoning models with no access to tools from multiple companies. And you know, that is night and day compared to what GPT4 could do with math, right? We And these things are really weird. Like it's nothing I say here should be uh intended to suggest that people won't be able to find weaknesses in the models.

**Nathan:** 嗯，我的意思是，最近几周的一个重大事件是，多个公司的纯推理模型在没有工具访问权限的情况下，获得了**国际数学奥林匹克竞赛**（IMO: International Mathematical Olympiad: 国际高中生数学竞赛）金牌。你知道，这与GPT-4在数学方面的表现相比，简直是天壤之别，对吧？这些事情真的很奇怪。我在这里说的任何话，都不应该被理解为暗示人们无法在模型中找到弱点。

**Nathan:** I I still use a tic-tac-toe puzzle to this day where I take a picture of a tic-tac-toe board where some the one of the players has made a wrong move that is not optimal and thus allows the other player to force a win and I ask the models if somebody can force a win from this position. Only very recently, only the last generation of models are starting to get that right some of the time. Almost always before they were like tic-tac-toe is a solved game. You know, you can always get a draw.

**Nathan:** 直到今天，我仍然使用一个井字棋谜题：我拍下井字棋盘的照片，其中一名玩家走了一步错误的棋，不是最优解，因此允许另一名玩家强制获胜。我问模型，从这个位置是否有人能强制获胜。直到最近，只有最新一代的模型才开始有时能答对。几乎所有之前的模型都说井字棋是一个已解决的游戏，总能打成平局。

**Nathan:** There's and they would wrongly assess my board position as player can still get a draw. So, there's a lot of weird stuff, right? The the jagged capabilities frontier remains a real issue and people are going to find, you know, peaks and valleys for sure, but GPD4 when it first came out couldn't do anything approaching IMO gold problems. It was still struggling on like high school math. And since then, we've seen this high school math progression all the way up through the IMO gold.

**Nathan:** 他们会错误地判断我的棋盘位置，认为玩家仍然可以打成平局。所以，有很多奇怪的事情，对吧？**能力不均衡的边界**（Jagged Capabilities Frontier: 指AI模型在不同任务或领域表现出不一致的能力水平，有些任务表现出色，有些则很差）仍然是一个真实存在的问题，人们肯定会发现高峰和低谷，但GPT-4刚发布时，还无法解决接近IMO金牌难度的问题。它在高中数学上仍然很吃力。从那时起，我们看到了高中数学能力一路提升，直到达到IMO金牌水平。

**Nathan:** Now we've got the frontier math benchmark that is I think now like up to 25%. It was 2% about a year ago or even a little less than a year ago I think. And we also just today saw something where um and I haven't absorbed this one yet but somebody just came out and said that they had solved a you know canonical super challenging problem that no less than Terrence Ta had put out. And it was like this you know this thing happened in I think days or weeks of the model running versus it was 18 months you know that it took professional and not just any professional mathematicians but like really you know the leading minds in the world to make progress on these problems.

**Nathan:** 现在我们有了前沿数学基准测试，我认为现在已经达到25%左右。大约一年前，甚至不到一年前，它还只有2%。而且就在今天，我们还看到了一件事，嗯，我还没有完全消化这个消息，但有人刚刚宣布，他们解决了一个经典的超级难题，这个难题是由特伦斯·陶（Terrence Tao）提出的。你知道，模型在几天或几周内就解决了这个问题，而之前，世界顶尖的专业数学家，不仅仅是任何专业数学家，而是真正的领军人物，花了18个月才在这些问题上取得进展。

**Nathan:** So yeah, I think that's really um you know that's that's really hard uh jumping capabilities to miss. I also think a lot about the Google AI co-scientist which we did an episode with. We can you can uh check out the full story on that if you want to. But you know they basically just broke down the scientific method into a schematic you know and this is a lot of what happens when people there's one thing to say the model will respond with thinking and it'll go through a reasoning process and you know the more tokens it it spends at runtime the better your answer will be. That's true.

**Nathan:** 所以，是的，我认为这确实是很难忽视的飞跃式能力。我还经常想到Google的AI合作科学家项目，我们为此做过一期节目。如果你想了解完整的故事，可以去看看。但你知道，他们基本上就是把**科学方法**（Scientific Method: 科学研究中系统地观察、实验、分析和得出结论的过程）分解成了一个示意图。你知道，当人们说模型会通过思考和推理过程来回应，并且在运行时消耗的token越多，答案就越好时，很多事情就是这样发生的。这是真的。

**Nathan:** Then you can also build this scaffolding on top of that and say okay well let me take something as broad and you know aspirational as the scientific method and let me break that down into parts okay there's hypothesis generation then there's hypothesis evaluation then there's you know experiment design there's literature review there's all these parts to the scientific method what the team at Google did is created a pretty elaborate schematic that represented their best breakdown of the scientific method optimized prompts for each of those steps and then gave this resulting system which is scaling inference now kind of two ways.

**Nathan:** 然后你还可以在此基础上构建**脚手架**（Scaffolding: 在AI系统中，通过结构化提示、工具使用或多步骤规划来引导模型完成复杂任务的辅助框架），说：“好吧，让我以科学方法这样宽泛而富有抱负的概念为例，将其分解成几个部分：有**假设生成**（Hypothesis Generation: 提出可检验的解释或预测），然后是**假设评估**（Hypothesis Evaluation: 检验假设的有效性），然后是**实验设计**（Experiment Design: 规划实验以验证假设），还有**文献综述**（Literature Review: 对现有研究进行总结和分析），科学方法包含所有这些部分。”Google团队所做的就是创建了一个相当精密的示意图，代表了他们对科学方法的最佳分解，为每个步骤优化了提示，然后将由此产生的系统（现在以两种方式扩展推理）投入使用。

**Nathan:** It's both the chain of thought, but it's also all these different angles of attack structured by the team. And they gave it legitimately unsolved problems in science. And in one particularly famous kind of notorious case, it came up with a hypothesis which it wasn't able to verify because it doesn't have direct access to actually run the experiments in the lab. But it came up with a hypothesis to some open problem in viology that had stumped scientists for years and it just so happened that they had also recently figured out the answer but not yet published their results and so there was this confluence where the scientists had experimentally verified and Gemini uh in the form of this AI co-scientist came up with exactly the right answer and these are things that like literally nobody knew before and GP GPD4 just wasn't doing that you know I mean these uh qualitatively new capabilities.

**Nathan:** 它既是**思维链**（Chain of Thought: 一种提示技术，引导大型语言模型逐步推理以解决复杂问题），也是团队结构化的所有这些不同的攻击角度。他们给它提供了科学领域中真正未解决的问题。在一个特别著名且有些臭名昭著的案例中，它提出了一个假设，虽然它无法验证，因为它无法直接在实验室中进行实验。但它对病毒学中一个多年来困扰科学家的开放问题提出了一个假设，碰巧科学家们最近也找到了答案但尚未发表结果，因此出现了一个巧合：科学家们通过实验验证了，而Gemini以这种AI合作科学家的形式，也得出了完全正确的答案。这些都是以前没有人知道的事情，而GPT-4根本做不到，你知道，我的意思是，这些是**质的新能力**（Qualitatively New Capabilities: 指AI模型展现出与以往截然不同、更高级别的能力）。

**Nathan:** That thing I think ran for days. You know, it probably cost hundreds of dollars, maybe into the thousands of dollars to run the inference. You know, that's not nothing, but it's also like very much cheaper than, you know, years of grad students. And if you can get to those caliber of problems and actually get good solutions to them, like, you know, what would you be willing to pay, right, for that kind of thing? So, yeah, I don't know. That's probably not a full appreciation.

**Nathan:** 我想那个东西运行了好几天。你知道，运行一次推理可能花费数百美元，甚至数千美元。这笔钱不小，但它也比，你知道，研究生多年的投入便宜得多。如果你能解决那种级别的问题，并且确实得到好的解决方案，那么，你知道，你愿意为那种事情支付多少钱呢？所以，是的，我不知道。这可能还不是一个充分的认识。

**Nathan:** We could go on for a long time, but I would say in in summary, GBT4 was not able to push the actual frontier of human knowledge. I don't to my knowledge, I don't know that ever discovered anything new. It's still not easy to get that kind of output from a GPT5 or a Gemini 2.5 or, you know, a Claude Opus 4, whatever, but it's starting to happen sometimes. And that in and of itself is a a huge deal.

**Nathan:** 我们可以聊很久，但总而言之，GPT-4未能推动人类知识的实际前沿。据我所知，它从未发现任何新事物。从GPT-5、Gemini 2.5或Claude Opus 4等模型中获得这类输出仍然不容易，但它有时开始发生。而这本身就是一件大事。

### GPT-5被看衰的原因：发布问题与前沿效益

**Host:** Well, then how do we explain the the the the bearishness or or the kind of vibe shift around GBD5? Then you know one one potential kind contributor is this idea that if a lot of the if if the improvements are at the frontier, you know, not everyone is working with you know, sort of advanced math and physics and in a day-to-day and so maybe they don't see the benefits in their day-to-day lives in in the same way that, you know, sort of the jumps in chat GBT were were were obvious and and shaped the day-to-day.

**Host:** 那么，我们如何解释围绕GPT-5的看跌情绪或那种氛围转变呢？一个潜在的原因是，如果大部分改进都集中在**前沿领域**（Frontier: 指AI能力的最先进水平，通常涉及复杂、未解决的问题），那么并非每个人每天都在处理高级数学和物理问题，所以他们可能无法像ChatGPT的飞跃那样，在日常生活中明显感受到这些好处，并因此改变他们的日常生活。

**Nathan:** Yeah. I mean, I think a decent amount of it was that they kind of up the launch, you know, simply put, right? They like were tweeting Death Star images, which Sam Alman later came back and said, "No, you're the Death Star. I'm not the Death Star." But, uh, I think people thought that the Death Star was supposed to be the model. That was generally the, you know, the expectations were set extremely high. The actual launch itself was just technically broken.

**Nathan:** 是的，我的意思是，我认为很大一部分原因在于他们有点仓促发布，简单来说，对吧？他们当时在推特上发布了“死星”图片，后来萨姆·奥特曼（Sam Altman）回来澄清说：“不，你是死星，我不是死星。”但是，我认为人们当时认为死星就是指模型。总的来说，期望值被设定得非常高。而实际发布本身在技术上就出了问题。

**Nathan:** So a lot of people's first experiences of GBT5, they've got this model router concept now where and I think one another way to understand what they're doing here is they're trying to own the consumer use case and to own that they need to simplify the product experience relative to what we had in the past which was like okay you got GBT4 and 40 and 40 mini and 03 and 04 mini and other things you know 45 was in there at one point you got all these different models which one should I use for which? It's like very confusing to most people who aren't obsessed with this.

**Nathan:** 所以很多人对GPT-5的初次体验是，他们现在有一个**模型路由器**（Model Router: 在AI系统中，根据用户查询的复杂性或类型，将请求路由到最适合处理的模型的机制）的概念，我认为理解他们这样做的另一个方式是，他们试图掌控消费者用例，而要做到这一点，他们需要简化产品体验，与我们过去的情况相比。过去，你可能有GPT-4、40、40 mini、03、04 mini以及其他模型，你知道，45也曾出现过，你有很多不同的模型，我应该用哪个来做什么？这对于大多数不痴迷于此的人来说非常困惑。

**Nathan:** And so, one of the big things they wanted to do was just shrink that down to just ask your question and you'll get a good answer and we'll take that complexity on our side as the the product owners to do that. Interestingly, and I don't have a great account of this, but one thing you you might want to do is kind of merge the models and figure out just have the model itself decide how much to think or maybe even, you know, have the model itself decide how many of its experts. If it's a mixture of experts, architecture it needs to use or maybe, you know, there's been a bunch of different uh research projects on like skipping layers of the model.

**Nathan:** 所以，他们想做的一件大事就是将其简化为“你只管提问，我们会给你一个好答案”，而作为产品所有者，我们将承担这种复杂性。有趣的是，我对此没有很好的解释，但你可能想做的一件事是合并模型，让模型自己决定思考多少，甚至让模型自己决定需要使用多少专家。如果它是一个**专家混合模型**（Mixture of Experts: 一种神经网络架构，其中不同的“专家”网络负责处理输入的不同部分或不同类型的任务），它需要使用这种架构，或者，你知道，有很多不同的研究项目都在研究如何跳过模型的层。

**Nathan:** If the task is easy enough, you could like skip a bunch of layers. So you might have hoped that you could genuinely on the back end merge all these different models into one model that would dynamically use the right amount of compute for the level of challenge that a given user query presented. It seems like they found that harder to do than they expected. And so the solution that they came up with instead was to have a router where the the router's job is to pick is this an easy query in which case we'll send you to this model. Is it a medium? Is it a hard?

**Nathan:** 如果任务足够简单，你可以跳过很多层。所以你可能曾希望，你可以在后端真正地将所有这些不同的模型合并成一个模型，该模型会根据用户查询的挑战级别动态地使用适量的计算资源。看来他们发现这比他们预期的要难。因此，他们提出的解决方案是使用一个路由器，路由器的任务是选择：这是一个简单的查询吗？如果是，我们就把你发送到这个模型。是中等难度吗？是困难吗？

**Nathan:** And I think they just have two really u models behind the scenes. So I think it's just really easy or hard. Certainly the graphs that they showed, you know, basically showed the kind of with and without thinking. The problem at launch was that that router was broken. So all all of the queries were going to the dumb model and so a lot of people literally just got bad outputs which were worse than 03 because they were getting non-thinking responses.

**Nathan:** 我认为他们幕后只有两个真正的模型。所以我想它只是非常简单或非常困难。当然，他们展示的图表基本上显示了有思考和无思考两种情况。发布时的问题是那个路由器坏了。所以所有的查询都发送到了“笨”模型，因此很多人得到的输出实际上比03版本还要差，因为他们得到了未经思考的回复。

**Nathan:** And so the initial reaction of like okay this is dumb and that sort of you know uh traveled really fast. I think that kind of set the tone. My sense now is that as the dust has settled most people do think that it is the best model available and you know things like the meter the infamous uh meter task length chart. It is the best. You know we're now over two hours and it is still above the trend line. So if you just said, you know, do I believe in straight lines on graphs or not? And how should this latest data point influence whether I believe on these straight line straight um lines on, you know, power logarithmic scale graphs.

**Nathan:** 所以最初的反应是“这太蠢了”，这种情绪传播得非常快。我认为这奠定了基调。我现在感觉，尘埃落定后，大多数人确实认为它是目前最好的模型，而且，你知道，像那个臭名昭著的**Meter任务长度图表**（Meter Task Length Chart: 一种衡量AI模型在给定时间内完成任务复杂度的指标）之类的东西。它是最好的。你知道，我们现在已经超过两个小时了，它仍然在趋势线上方。所以如果你只是说，你知道，我是否相信图表上的直线？以及这个最新的数据点应该如何影响我是否相信这些在幂对数刻度图上的直线。

**Nathan:** It shouldn't really change your mind too much. It's still above the trend line. I talked to ZV about this. Zim Mashwitz uh legendary infovore and uh AI industry analyst on a recent podcast too and kind of asked him the same question like why do you think the you know even some of the most plugged in you know sharp uh minds in the space have seemingly pushed timelines out a bit as a result of this and his answer was basically just it resolved some amount of uncertainty you know you had a open question of maybe they do have another breakthrough you know maybe it really is the Death Star.

**Nathan:** 它不应该真正改变你的想法太多。它仍然在趋势线上方。我与ZV谈过这个问题。Zim Mashwitz，一位传奇的信息狂和AI行业分析师，在最近的播客中，我也问了他同样的问题：你认为为什么即使是这个领域最投入、最敏锐的一些人，似乎也因此推迟了时间线？他的回答基本上是，它解决了一定程度的不确定性。你知道，你有一个悬而未决的问题，也许他们真的会有另一个突破，也许它真的是“死星”。

**Nathan:** You know, if they surprise surprise us on the upside than all these short timelines, you know, we we could have expected a um yeah, I guess one one way to think about it is like the the distribution was sort of broad in terms of timelines and if they had surprised on the upside, it might have narrowed and narrowed in toward the front end of the distribution and if it if they surprised on the downside or even just were, you know, purely on trend, then you would take some of your distribution from the very short end of the timelines and kind of push them back toward the middle or the end.

**Nathan:** 你知道，如果他们给了我们一个惊喜，那么所有这些短期的时间线，我们可能就会期待一个，嗯，我想一种思考方式是，时间线的分布是相当宽泛的，如果他们给了我们一个惊喜，它可能会收窄并集中到分布的前端；如果他们给了我们一个失望，或者只是，你知道，完全符合趋势，那么你就会把你的分布从时间线的非常短的一端，推回到中间或末端。

**Nathan:** And so his answer was like AI 2027 seems less likely, but AI 2030 seems basically no less likely, maybe even a little more likely because some of the the probability mass from the early years is now sitting there. So it's not that um I don't think people are are moving the whole distribution out super much. I think there may be more just kind of shrinking the uh you know it's getting a little tighter because it's maybe not happening quite as soon as it seemed like it might have been.

**Nathan:** 所以他的回答是，AI在2027年实现的可能性似乎降低了，但AI在2030年实现的可能性基本没有降低，甚至可能略有增加，因为早期年份的一些概率质量现在堆积在那里。所以，我认为人们并不是将整个分布大幅度地向后推。我认为更多的是在收缩，你知道，它变得更紧凑了，因为它可能不会像之前看起来那样很快发生。

**Nathan:** But I don't think too many people at least that I you know think are really plugged in on this are pushing out too much past 2030 at all. And by the way, you know, they obviously there's a lot of um you know disagreement. The way I kind of have always thought about this sort of stuff is Daario says 2027 Demis says 2030. I'll take that as my range. So coming into GBT5, I was kind of in that space.

**Nathan:** 但我认为，至少在我看来，真正关注此领域的人，并没有将时间线推迟到2030年以后太多。顺便说一句，你知道，显然存在很多分歧。我一直以来对这类事情的看法是，达里奥（Daario）说2027年，德米斯（Demis）说2030年。我把这作为我的时间范围。所以，在GPT-5发布之前，我差不多就是这么想的。

**Nathan:** And now I'd say, well, I don't know, Dario's got uh what what cars does he have up his sleeve? You know, they just put out 4.1 Opus. And in that blog post, they said we will be releasing more powerful updates to our models in the coming weeks, so they're due for something pretty soon. You know, maybe they'll be the ones to surprise on the upside this time, or maybe Google will be. I wouldn't say 2027 is is out of the question, but yeah, I would say 20 2030 still looks just as likely as before.

**Nathan:** 现在我会说，嗯，我不知道，达里奥（Dario）还有什么绝招？你知道，他们刚刚发布了4.1 Opus。在那篇博客文章中，他们说未来几周将发布更强大的模型更新，所以很快就会有新东西。你知道，也许这次会是他们带来惊喜，或者谷歌会。我不会说2027年不可能，但是的，我认为2030年看起来仍然和以前一样有可能。

**Nathan:** And again, from my standpoint, it's like that's still really soon, you know? So, if we're on track, whether it's 28, 29, 30, I don't really care. I I I try to frame my own work so that I'm kind of preparing myself and helping other people prepare for what might be the most extreme scenarios and kind of, you know, one of these things where if we aim high and we miss a little bit and we have a little more time, great. I'm sure we'll have plenty of things to do to use that extra time to be ready for, you know, whatever powerful AI does come online.

**Nathan:** 再说一次，从我的角度来看，那仍然是非常近的未来，你知道吗？所以，如果我们走在正轨上，无论是28年、29年还是30年，我都不太在意。我努力调整自己的工作，以便为可能出现的最极端情况做好准备，并帮助其他人也做好准备。你知道，这就像是，如果我们目标定得高，稍微有点偏差，多了一点时间，那太好了。我确信我们会有很多事情可以做，利用这些额外的时间来为任何强大的AI上线做好准备。

**Nathan:** But yeah, I guess I don't uh my worldview hasn't changed all that much as a result of these uh summer's developments.

**Nathan:** 但是的，我想我并没有，嗯，我的世界观并没有因为这个夏天的发展而改变太多。

### AI对就业的影响：生产力与工作性质转变

**Host:** Anecdotally, I I don't hear as much about AI 2027 or situational awareness to the to the same degree. I I do talk to some people who've just moved it a few years back to to your point. But um yeah, Dores Cesh had his whole thing around, you know, he still still believes in it, but sort of um you know, maybe because this gap gap in continual learning or or something to the effect that um you know, maybe it's just going to be a bit slower to to diffuse um and um you know, Meter's paper as you mentioned showed that uh engineers are less productive and so maybe there's there's less of a uh sort of concern around um you know, people being replaced in the next next few years in in in in mass.

**Host:** 从轶事来看，我不再像以前那样经常听到关于AI 2027或**情境感知**（Situational Awareness: 指AI模型理解当前环境、自身状态及与环境互动能力的能力）的讨论了。我确实和一些人聊过，他们把时间线往后推了几年，正如你所说。但是，嗯，是的，Dores Cesh有他自己的一套理论，你知道，他仍然相信它，但有点，嗯，你知道，也许是因为持续学习的差距，或者说，嗯，它可能只是会慢一点扩散，而且，嗯，你知道，你提到的Meter的论文显示，工程师的生产力下降了，所以也许人们对未来几年大规模失业的担忧有所减少。

**Host:** I think when we spoke maybe a year ago about this or I think you said something like 50% of 50% of jobs. I'm curious if that's still your your uh your litmus test or how you think about it.

**Host:** 我记得大约一年前我们谈到这个问题时，你好像说过50%的工作中有50%会受到影响。我很好奇这是否仍然是你的试金石，或者你现在是如何看待这个问题的。

**Nathan:** Well, for one thing, I think that Meter paper is worth unpacking a little bit more because this was one of those things that was and I I I'm a big fan of Meter and I have no um you know, no shade on them because I do think do science, publish your results. Like that's good. You don't have to uh make every experimental result and everything you put out conform to a narrative. But I do think it was a little bit um it was a little bit too easy for people who wanted to say that oh this is all nonsense to latch on to that.

**Nathan:** 嗯，首先，我认为那篇Meter的论文值得再深入探讨一下，因为它属于那种——我是Meter的忠实粉丝，我没有任何，你知道，对他们不敬的意思，因为我确实认为做科学研究，发表你的结果，这很好。你不必让每一个实验结果和你发布的所有东西都符合某个叙事。但我确实认为，对于那些想说“这都是胡说八道”的人来说，抓住这一点有点太容易了。

**Nathan:** And you know again there is there's something there that I would kind of put in the Cal Newport category too where for me maybe the most interesting thing was the users thought that they were faster when in fact they seem to be slower. So that sort of misperception of oneself I think is really interesting. Personally I think there's some explanations for that that include like hitting go on the agent going to social media and scrolling around for a while and then coming back. The thing might have been done for quite a while by the time I get back.

**Nathan:** 而且，你知道，这里面有一些东西，我也会将其归入卡尔·纽波特的范畴，对我来说，最有趣的一点可能是用户认为自己更快，但实际上他们似乎更慢。所以这种对自我的误解，我认为非常有趣。就我个人而言，我认为这有一些解释，包括点击代理运行，然后去社交媒体上刷一会儿，再回来。等我回来的时候，任务可能已经完成很久了。

**Nathan:** So honestly one like really simple and we're starting to see this in products. One really simple thing that the products can do to address those concerns is just provide notifications like the thing is done now. So, you know, stop scrolling and and come back and check its work. That in terms of just clock time, you know, it would be interesting to know like what applications did they have open. Maybe they took a little longer with cursor than doing it on their own, but how much of the time was cursor the active window and how much of it was, you know, some other random distraction while they were waiting.

**Nathan:** 所以老实说，一个非常简单的解决方案，我们现在也开始在产品中看到这一点，就是产品可以提供通知，比如“任务已完成”。这样，用户就知道可以停止刷手机，回来检查AI的工作了。就实际时间而言，你知道，了解他们当时打开了哪些应用程序会很有趣。也许他们使用Cursor比自己动手花的时间更长，但其中有多少时间Cursor是活动窗口，又有多少时间是他们在等待时被其他随机事物分散了注意力。

**Nathan:** But I think a more fundamental issue with that study which again wasn't really about the study design but just in in the sort of you know interpretation and kind of digestion of it some of these details got lost. The they basically tested the models or the you know the product cursor in the area where it was known to be least able to help. This study was done early this year. So it was done with you know kind of one depending on how you want to count right a couple couple releases ago with code bases that are large which again strains the strains the context window and you know that's one of the the frontiers that has been moving very mature code bases with like high standards for coding and developers who really know their code bases super well who've made a lot of commit you know commits to these particular code bases.

**Nathan:** 但我认为这项研究存在一个更根本的问题，这与研究设计本身无关，而是在解释和消化研究结果时，一些细节被忽略了。他们基本上是在Cursor产品已知帮助最小的领域测试模型。这项研究是在今年早些时候进行的。所以它是在几个版本之前进行的，使用了大型代码库，这再次考验了上下文窗口，你知道，这是正在发展的前沿领域之一。这些代码库非常成熟，编码标准很高，开发人员对自己的代码库非常了解，并对这些特定的代码库进行了大量提交。

**Nathan:** So I would say that's basically the hardest situation that you could set up for an AI because the people know you know their stuff really well. The AI doesn't the context is huge. People have already absorbed that through working on it for a long time. The AI doesn't have that uh that knowledge and again couple generations ago models. And then a big thing too is that the user the people were not very wellversed in the tools. Why? Because the tools weren't really able to help them yet.

**Nathan:** 所以我想说，这基本上是你为AI设置的最困难的情况，因为人们非常了解自己的东西。AI不了解，上下文非常庞大。人们通过长时间的工作已经吸收了这些知识。AI没有那种知识，而且这还是几代之前的模型。另一个重要因素是，用户对这些工具并不十分熟悉。为什么？因为这些工具当时还无法真正帮助他们。

**Nathan:** I think the sort of mindset of the people that came into the study in many cases was like, well, I haven't used this all that much because it hasn't really seemed to be super helpful. They weren't wrong in that assessment given the, you know, the limitations. And you could see that in terms of the um some of the instructions and the help that the meter team gave to people. One of the things that is in the paper that they would if they noticed that you weren't like weren't using cursor super well, they would give you some feedback on how to use it better.

**Nathan:** 我认为，在许多情况下，参与这项研究的人的心态是：“嗯，我没怎么用过这个，因为它看起来并没有特别有用。”考虑到当时的局限性，他们的评估并没有错。你可以从Meter团队给人们的一些指导和帮助中看出这一点。论文中提到的一点是，如果他们发现你没有很好地使用Cursor，他们会给你一些关于如何更好地使用它的反馈。

**Nathan:** One of the things that they were telling people to do is make sure you at tag a particular file to bring that into context for the model so that the model has you know the right context. And that's literally like the most basic thing that you would do in cursor you know that's like the thing you would learn on your in your first hour your first day of using it. So it really does suggest that these were you know while very capable programmers like basically mostly noviceses when it came to using the AI tools. So I think the result is real. But I just I would be very cautious about generalizing too much there in terms of I guess what else was the other question. It's what is the expectation for jobs?

**Nathan:** 他们告诉人们要做的一件事是，确保你**@**标记一个特定的文件，将其带入模型的上下文，以便模型拥有正确的上下文。这实际上是你在Cursor中最基本的操作，你知道，这就像你使用它的第一个小时或第一天就会学到的东西。所以这确实表明，这些程序员虽然能力很强，但在使用AI工具方面基本上都是新手。所以我认为这个结果是真实的。但我只是，我会在那里非常谨慎地进行过度概括，至于另一个问题是什么。那就是对就业的预期是什么？

**Nathan:** I mean we're starting to see some of this right. We are definitely seeing no less than like Mark Banoff has said that they've, you know, have been able to cut a bunch of headcount because they've got AI agents now that are responding to every lead. Clara of course is, you know, has said, um, you know, very similar things for a while now. They also, I think, have been a little bit misreported in terms of like, oh, they're backtracking off of that because they're actually going to keep some customer service people, not none.

**Nathan:** 我的意思是，我们现在开始看到一些这样的情况，对吧。我们确实看到，马克·贝诺夫（Mark Banoff）曾说过，他们已经能够裁减大量员工，因为他们现在有了AI代理，可以回应每一个潜在客户。克拉拉（Clara）当然也，你知道，已经说了很长一段时间类似的话。我认为，他们也可能被误报了一些信息，比如“哦，他们正在收回之前的说法，因为他们实际上会保留一些客服人员，而不是全部裁掉。”

**Nathan:** And I think that's a bit of an overreaction. Like they may have some people who are just, you know, insistent on having a certain experience and maybe they want to provide that and that makes sense. You know, it doesn't I think you can have a a a spectrum of service offerings to your customers. I once coded up a pricing page for a I actually just vibe coded up a pricing page for a **SaaS** (Software as a Service: 通过互联网提供软件应用的服务模式) company that was like basic uh level with AI sales and service is one price. If you want to talk to human sales, that's a higher price. And if you want to talk to human sales and support, that's a, you know, third higher price.

**Nathan:** 我认为这有点反应过度。他们可能有一些客户坚持要获得某种特定的体验，也许他们想提供这种体验，这很合理。你知道，我认为你可以为客户提供一系列的服务。我曾经为一个**SaaS**（Software as a Service: 通过互联网提供软件应用的服务模式）公司编写了一个定价页面，实际上是凭感觉编写的，它就像是：基础级别，由AI销售和服务，一个价格。如果你想和人工销售交谈，价格更高。如果你想和人工销售和支持交谈，那又是第三个更高的价格。

**Nathan:** And so, like, literally, that might be what's going on, I think, in some of these cases. And it it could very well be a very sensible option for people. But I just I do see the intercom. I've got an episode coming up with, they now have this Finn agent that is solving like 65% of customer service tickets that come in. So, you know, what's that going to do to jobs? Are there really like three times as many customer service tickets to be handled? Like, I don't know. I think there's kind of a relatively inelastic supply.

**Nathan:** 所以，我的意思是，在某些情况下，这可能就是实际情况。而且这很可能是一个非常明智的选择。但我确实看到了Intercom。我有一期节目即将播出，他们现在有一个名为Finn的代理，可以解决大约65%的客户服务工单。所以，你知道，这对就业会产生什么影响？真的有三倍多的客户服务工单需要处理吗？我不知道。我认为这是一种相对缺乏弹性的供应。

**Nathan:** Maybe you'll get somewhat more tickets if people expect that they're going to get better, faster answers, but I don't think we're going to see like three times more tickets. By the way, that number was like 55% 3 or four months ago. So, you know, as they ratchet that up, the ratios get really hard, right? At half ticket resolution, in theory, maybe you get some more tickets. Maybe you don't need to adjust headcount too much. But when you get to 90% ticket resolution, you know, are you really going to have 10 times as many tickets or 10 times as many hard tickets that the people have to handle?

**Nathan:** 如果人们期望能得到更好、更快的答案，也许你会收到更多工单，但我认为我们不会看到工单数量增加三倍。顺便说一下，这个数字在三四个月前还是55%左右。所以，你知道，随着他们提高这个比例，这些比例会变得非常难以应对，对吧？在解决一半工单的情况下，理论上，你可能会收到一些更多的工单。也许你不需要大幅调整员工数量。但当你达到90%的工单解决率时，你知道，你真的会有10倍的工单，或者10倍的困难工单需要人工处理吗？

**Nathan:** It seems just really hard to imagine that. So I don't think I don't think these things go to zero probably in a lot of environments but I do expect that you will see significant headcount reduction in a lot of these places and the software one is really interesting because the elasticities are really unknown. You know, you can potentially produce x times more software per user or, you know, per per cursor user or per developer at your company, whatever. But maybe you want that.

**Nathan:** 这似乎真的很难想象。所以我不认为这些事情在很多环境中会归零，但我确实预计在很多地方会看到显著的员工数量减少，而软件行业的情况非常有趣，因为其弹性是未知的。你知道，你可能能够为每个用户，或者说，每个Cursor用户，或者你公司的每个开发人员，生产X倍的软件，等等。但也许你就是想要这样。

**Nathan:** You know, maybe there is no limit or no, you know, maybe the the regime that we're in is such that if there's, you know, 10 times more productivity, that's all to the good. And, you know, we still have just as many uh jobs because we want 10 times more software. I don't know how long that lasts. Again, the ratios start to get challenging at some point. But yeah, I think the bottle, you know, the old Tyler Common thing comes to mind. You are a bottleneck. You are a bottleneck.

**Nathan:** 你知道，也许没有限制，或者说，也许我们所处的体制是这样的：如果生产力提高了10倍，那都是好事。而且，你知道，我们仍然有同样多的工作岗位，因为我们想要10倍的软件。我不知道这种情况会持续多久。再说一次，这些比例在某个时候会变得很有挑战性。但是的，我想到了泰勒·科恩（Tyler Cowen）的老话：“你是一个瓶颈。你是一个瓶颈。”

**Nathan:** I think more often it is are people really trying to get the most out of these things and you know are they using best practices and have they um have they really put their minds to it or not? I you know often the the real barrier is there. I was I've been working a little bit with a company that is doing um basically government doc review. I'll abstract a little bit away from the details, really gnarly stuff like scanned documents, you know, handwritten uh filling out of forms.

**Nathan:** 我认为更常见的问题是，人们是否真的在努力充分利用这些东西，他们是否在使用最佳实践，他们是否真正投入了心思？我，你知道，真正的障碍往往在那里。我曾与一家公司合作，他们主要做政府文件审查。我将稍微抽象一下细节，处理的是非常棘手的东西，比如扫描文件，手写填写的表格。

**Nathan:** And they've created this auditor AI agent that just won a state level contract to do the audits on like a million transactions a year of of these um you know these packets of documents again scanned, handwritten, all this kind of crap. And they just blew away the human uh workers that were doing the job before. So where are those workers going to go? Like I don't know. I don't they're not going to have 10 times as many transactions. You know, I can be pretty confident in that.

**Nathan:** 他们创建了一个审计AI代理，刚刚赢得了一份州级合同，每年对大约一百万笔交易进行审计，这些交易涉及的都是扫描的、手写的各种文件包。他们简直把之前做这项工作的人工工人甩在了后面。那么这些工人会去哪里呢？我不知道。他们不会有10倍的交易量。你知道，对此我可以相当肯定。

**Nathan:** Are there going to be a few still that are there to supervise the AIS and handle the weird cases and, you know, answer the phones? Sure. Maybe they maybe they won't go anywhere. You know, this the state, you know, the state may do a strange thing and uh just have all those people like sit around because they can't bear to fire them. Like, who knows what the ultimate decision will be. But I do see a lot of these things where I'm just like when you really put your mind to it and you identify what would create real leverage for us, can the AI do that?

**Nathan:** 仍然会有一些人负责监督AI、处理异常情况以及接听电话吗？当然。也许他们不会离开。你知道，州政府可能会做出一些奇怪的决定，让所有这些人都闲着，因为他们不忍心解雇他们。谁知道最终的决定会是什么。但我确实看到很多这样的情况，当你真正用心去思考，并确定什么能为我们创造真正的杠杆时，AI能做到吗？

**Nathan:** Can we make it work? You can take a pretty large chunk out of high volume tasks very reliably in today's world. And so the the impacts I think are starting to be seen there on on a lot of jobs. Humans I think are you know the leadership is maybe the bottleneck or the the will in in a lot of places might be the bottleneck and software might be an interesting case where there is just so much pent-up demand perhaps that it might take a little longer to see those impacts because you really do want you know 10 or 100 times as much software.

**Nathan:** 我们能让它运转起来吗？在当今世界，你可以非常可靠地从高容量任务中分担相当大一部分。所以，我认为在很多工作岗位上，其影响已经开始显现。我认为人类，你知道，领导力可能是瓶颈，或者在很多地方，意愿可能是瓶颈，而软件可能是一个有趣的案例，也许存在如此多的被压抑的需求，以至于看到这些影响可能需要更长的时间，因为你确实想要10倍或100倍的软件。

### 编码与自动化研究员的未来

**Host:** What is Yeah, let's let's talk about code because it's, you know, it's it's where Andropic made made a big bet early on, you know, perhaps inspired by the sort of automated researcher, you know, recursive self-improvement um you know, sort of you, you know, desired future and and we saw open AI uh make make moves um there as well. Why don't we flush that out or talk a little about you know what what inspired that and where you see that going?

**Host:** 是的，我们来谈谈代码吧，因为，你知道，这是Anthropic早期投入重注的领域，也许是受到**自动化研究员**（Automated Researcher: 指AI系统能够自主进行科学研究、实验设计、数据分析并得出新发现）和**递归式自我改进**（Recursive Self-Improvement: AI系统能够不断优化自身，从而实现能力指数级增长）这种未来愿景的启发，我们看到OpenAI也在这个领域有所动作。我们能不能详细阐述一下，或者谈谈是什么启发了这一点，以及你认为它会走向何方？

**Nathan:** You know, utopia or dystopia is really the big question there, I think. Right. Right. I mean is maybe one part technical, two parts social in terms of why code has been so focal. The technical part is that it's really easy to validate code. You generate it, you can run it. If you get a runtime error, you can get the feedback immediately. It's, you know, somewhat harder to do functional testing.

**Nathan:** 我认为，乌托邦还是反乌托邦，这才是真正的大问题。对。对。我的意思是，代码之所以如此受关注，可能有一部分是技术原因，两部分是社会原因。技术原因在于，验证代码非常容易。你生成它，就可以运行它。如果出现运行时错误，你可以立即得到反馈。进行功能测试则相对困难一些。

**Nathan:** Replet recently just in the last like 48 hours released their V3 of their agent and it now in addition to you know code code code try to make your app work v2 of the agent would do that and it could go for minutes and you know in some cases generate dozens of files and I've had some magical experiences with that where I was like wow you just did that whole thing in one prompt and it like worked amazing. Other times it will sort of code for a while and hand it off to you and say okay does it look good? Is it working? and you're like, "No, it's not. I'm not sure why."

**Nathan:** Replit最近在过去48小时内发布了其代理的V3版本，现在除了，你知道，代码代码代码尝试让你的应用程序工作之外，代理的V2版本也能做到这一点，它可能运行几分钟，你知道，在某些情况下会生成几十个文件，我对此有过一些神奇的体验，当时我心想“哇，你只用一个提示就完成了整个事情，而且效果惊人。”其他时候，它会编写一段时间代码，然后交给你，问你“看起来不错吗？能用吗？”然后你就会说：“不，不能用。我不知道为什么。”

**Nathan:** You know, you get into a a back and forth with it. But the difference between V2 and V3 is that instead of handing the baton back to you, it now uses a browser and the vision aspect of the models to go try to do the QA itself. So, it doesn't just say, "Okay, hey, I uh I tried my best, wrote a bunch of code, like let me know if it's working or not." It takes that first pass at figuring out if it's working. And you know again that that really improves the flywheel just how much you can do, how much you can validate, how quickly you can validate it.

**Nathan:** 你知道，你和它会来回沟通。但V2和V3的区别在于，V3不再把接力棒交还给你，而是利用浏览器和模型的视觉能力，自己去尝试进行**质量保证**（QA: Quality Assurance: 确保产品或服务符合预定质量标准的过程）。所以，它不会只是说：“好吧，我尽力了，写了一堆代码，告诉我它是否有效。”它会先尝试判断它是否有效。你知道，这再次真正改进了**飞轮效应**（Flywheel Effect: 指一个系统中的各个部分相互促进，形成正向循环，从而加速整体增长和改进），即你能做多少，能验证多少，以及能多快地验证。

**Nathan:** The the speed of that loop is really key to the pace of improvement. So it's a problem space that's pretty amendable to the sorts of, you know, rapid flywheel techniques. Second, of course, they they're all coders right at these places. So they want to, you know, solve their own problems. That's like very natural. And third, I do think on the, you know, sort of social vision competition, uh, who knows where this is all going, they do want to create the automated AI researcher.

**Nathan:** 那个循环的速度对于改进的步伐至关重要。所以这是一个非常适合快速飞轮技术的领域。其次，当然，这些地方的人都是程序员。所以他们想解决自己的问题。这非常自然。第三，我确实认为，在社会愿景竞争方面，谁知道这一切会走向何方，他们确实想创造**自动化AI研究员**（Automated AI Researcher: 指AI系统能够自主进行科学研究、实验设计、数据分析并得出新发现）。

**Nathan:** That's another data point, by the way, from this was from the 03 system card. They showed a jump from like low to mid single digits to roughly 40% of PRs actually checked in by research engineers at OpenAI that the model could do. So prior to 03 not much at all you know low to mid single digits as of 03 40%. I'm sure those are the easier 40% or whatever. Again, there will be, you know, caveats to that, but that's you're entering maybe the steep part of the S-curve there.

**Nathan:** 顺便说一下，这是来自03系统卡的另一个数据点。他们展示了OpenAI研究工程师实际提交的**拉取请求**（PR: Pull Request: 软件开发中，开发者请求将自己的代码更改合并到主代码库的机制）中，模型能够处理的比例从个位数低到中等水平跃升至大约40%。所以在03之前几乎没有，你知道，个位数低到中等水平，而03之后达到了40%。我敢肯定那是最容易的40%或者其他什么。再次强调，这会有一些限制，但你可能正在进入**S曲线**（S-curve: 描述技术或产品生命周期中增长模式的曲线，通常分为缓慢增长、快速增长和饱和期）的陡峭部分。

**Nathan:** And that's presumably pretty high-end. You know, I don't know how many easy problems they have at OpenAI, but presumably, you know, not that many relative to the rest of us that are out here making uh generic web apps all the time. So, you know, at 40% you got to be starting to, I would think, get into some pretty hard tasks, some pretty high value stuff, you know, at that at what point does that ratio really start to tip where the AI is like doing the bulk of the work?

**Nathan:** 而且这大概是相当高端的。你知道，我不知道OpenAI有多少简单的问题，但想必，相对于我们这些一直在开发通用网络应用的人来说，他们的问题并不多。所以，你知道，达到40%的时候，我想你已经开始处理一些相当困难的任务，一些非常有价值的东西了。你知道，在那个时候，AI开始承担大部分工作，这个比例究竟会在什么时候真正发生倾斜呢？

**Nathan:** GBD5 notably wasn't a big update over 03 on that particular measure. I mean it also wasn't going back to the simple QA thing. GP5 is generally understood to not be a scale up relative to 40 and 03 and you can see that in the simple QA measure. It basically scores the same on these longtail trivia questions. It's not a bigger model that has absorbed like lots more world knowledge. It is it is you know Cal is right. I think it is is analysis that it's it's post-training.

**Nathan:** 值得注意的是，GPT-5在那个特定指标上并没有比03有大的更新。我的意思是，它也没有回到简单的问答模式。GPT-5通常被认为相对于40和03来说，并不是一个规模上的提升，你可以在简单的问答指标中看到这一点。它在这些长尾冷知识问题上得分基本相同。它不是一个吸收了更多世界知识的更大模型。是的，卡尔是对的。我认为他的分析是，这主要是**后训练**（Post-training: 在预训练模型基础上进行的额外训练，通常用于特定任务或提升模型性能）的成果。

**Nathan:** But that post training you know is potentially entering the steep part of the S-curve when it comes to the ability to do even the kind of hard problems that are happening at uh at OpenAI on the research engineering front. And you know, yikes. I I'm a little worried about that, honestly. The um the idea that we could go from these companies having a few hundred research engineer people to having, you know, unlimited overnight and like what would that mean in terms of how much things could change and also just our ability to steer that overall process.

**Nathan:** 但你知道，这种后训练在解决OpenAI研究工程前沿的那些难题方面，可能正在进入S曲线的陡峭部分。你知道，天哪。老实说，我对此有点担心。这些公司可能从拥有几百名研究工程师，一夜之间变成拥有无限数量的工程师，这意味着事情会发生多大的变化，以及我们引导整个过程的能力。

**Nathan:** I'm not super comfortable with the idea of the companies tipping into a recursive self-improvement regime, especially given the the level of control and the level of unpredictability that we currently see in the models. But that does seem to be what they are going for. So, in terms of like why um I think this has been the plan for quite some time. Even you remember that leaked anthropic uh fundraising deck from maybe two years ago where they said that in 2025 and 2026 the companies that train the best models will get so far ahead that nobody else will be able to catch up.

**Nathan:** 我对这些公司转向**递归式自我改进**（Recursive Self-Improvement: AI系统能够不断优化自身，从而实现能力指数级增长）模式的想法感到非常不安，特别是考虑到我们目前在模型中看到的控制水平和不可预测性。但这似乎正是他们正在追求的目标。所以，至于为什么，嗯，我认为这已经计划了相当长一段时间。你甚至还记得大约两年前Anthropic泄露的融资演示文稿，其中提到在2025年和2026年，训练出最佳模型的公司将遥遥领先，以至于其他任何人都无法追赶。

**Nathan:** I think that's kind of what they meant. I think that they were projecting then that in the 25 26 time frame they'd get this like automated researcher and once you have that how's anybody you know who doesn't have that going to catch up with you? Obviously some of that remains to be validated, but um, I do think they have been pretty intent on that for a long time. Five years from now, are there more engineers or fewer engineers?

**Nathan:** 我想他们大概就是这个意思。我认为他们当时预测，在2025-2026年间，他们会拥有这种**自动化研究员**（Automated Researcher: 指AI系统能够自主进行科学研究、实验设计、数据分析并得出新发现），一旦拥有了它，你知道，那些没有它的人怎么能赶上你呢？显然，其中一些还有待验证，但是，嗯，我确实认为他们对此已经非常执着了很长时间。五年后，工程师会更多还是更少？

**Nathan:** I I tend to think less. You know, already if I just think about my own life and work, I'm like, would I rather have a model or would I rather have like a junior marketer? I'm pretty sure I'd rather have the model. Would I rather have the models or a junior engineer? I think I'd probably rather have the models in a lot of cases. I mean, it obviously depends on, you know, the exact person you're talking about. But truly forced choice today.

**Nathan:** 我倾向于认为会更少。你知道，如果我只考虑我自己的生活和工作，我就会想，我是宁愿要一个模型，还是宁愿要一个初级营销人员？我很确定我宁愿要模型。我是宁愿要模型，还是一个初级工程师？我想在很多情况下，我可能宁愿要模型。我的意思是，这显然取决于，你知道，你具体指的是哪个人。但今天真的是被迫选择。

**Nathan:** Now, that and then you've got cost adjustment as well, right? I'm not spending nearly as much on my cursor subscription as I would be on a, you know, an actual human engineer. So, even if they have some advantages, you know, and I I also have not scaffolded um I haven't gone full co-scientist, right, on my uh cursor problems. I think that that's another interesting you start to see why folks like Sam Alman are so focused on questions like energy and the 7 trillion buildout because these power law things are weird and you know to get incremental performance for 10x the cost is weird.

**Nathan:** 现在，除了这个，你还得考虑成本调整，对吧？我花在Cursor订阅上的钱，远不及我花在一个真正的人类工程师身上的钱。所以，即使他们有一些优势，你知道，而且我也还没有完全为我的Cursor问题搭建**脚手架**（Scaffolding: 在AI系统中，通过结构化提示、工具使用或多步骤规划来引导模型完成复杂任务的辅助框架），我还没有完全采用合作科学家的模式。我认为这又是一个有趣的现象，你开始明白为什么像萨姆·奥特曼（Sam Altman）这样的人如此关注能源和7万亿美元的建设等问题，因为这些**幂律**（Power Law: 指一个变量的变化与另一个变量的幂次成比例的现象）现象很奇怪，你知道，以10倍的成本获得增量性能是很奇怪的。

**Nathan:** It's it's a it's definitely not the kind of thing that we're used to dealing with, but for many things it might be worth it and it still might be cheaper than the human alternative. You know, if it's like, well, cursor cost me whatever 40 bucks a month or something. Would I pay 400 for, you know, however much better? Yeah, probably. Would I pay 4,000 for however much better? Well, it's still, you know, a lot less than a full-time human engineer.

**Nathan:** 这绝对不是我们习惯处理的事情，但对于许多事情来说，它可能值得，而且可能仍然比人工替代方案便宜。你知道，如果Cursor每月花费我40美元左右。我会不会花400美元来获得更好的体验？是的，很可能。我会不会花4000美元来获得更好的体验？嗯，那仍然比一个全职的人类工程师便宜得多。

**Nathan:** And the costs are obviously coming down dramatically, too, right? That's another huge thing. GPD4 was way more expensive. It's like 90 uh it's like a 95% discount from GPD4 to GPT5. That's, you know, no small thing, right? I mean, it's Apple staff is a little bit hard because the chain of thought does spit out a lot more tokens and so that you get you give back a little on a per token basis. It's dramatically cheaper. More tokens generated. Um, you know, does does eat back into some of that savings, but everybody seems to expect the trends will continue in terms of prices continuing to fall.

**Nathan:** 而且成本显然也在大幅下降，对吧？这是另一个巨大的变化。GPT-4要贵得多。从GPT-4到GPT-5，价格折扣高达95%。你知道，这可不是小数目，对吧？我的意思是，苹果的员工有点难搞，因为**思维链**（Chain of Thought: 一种提示技术，引导大型语言模型逐步推理以解决复杂问题）确实会吐出更多的token，所以你在每个token的基础上会损失一点。它便宜得多。生成了更多的token。嗯，你知道，这确实会蚕食一部分节省下来的成本，但每个人似乎都预计价格会继续下降。

**Nathan:** And so, you know, how many more of these like price reductions do you have to to then be able to, you know, do the power law thing a few more times? I guess I think I think I I think less. And I I think that's probably true even if we don't get like full-blown **AGI** (Artificial General Intelligence: 具备与人类同等或超越人类智能水平的AI). I think you could easily imagine a situation where of however many million people are currently employed as professional software developers, some top tier of them that do the hardest things can't be replaced. But there's not that many of those, you know, they and the the real like rank and file, you know, the people that over the last 20 years were told learn to code, you know, that'll be your thing.

**Nathan:** 所以，你知道，你还需要多少次这样的降价，才能，你知道，再做几次幂律的事情？我想我，我想我，我想会更少。而且我认为，即使我们没有达到完全成熟的**通用人工智能**（AGI: Artificial General Intelligence: 具备与人类同等或超越人类智能水平的AI），这可能也是真的。我认为你可以很容易地想象这样一种情况：在目前数百万专业软件开发人员中，那些做最困难事情的顶尖人才无法被取代。但这样的人并不多，你知道，他们以及那些真正的普通员工，你知道，过去20年里被告知“学习编程，那将是你的专长”的人。

**Nathan:** Like the people that are the really top top people didn't need to be told to learn to code, right? They just it was their thing. They had a passion for it. They were amazing at it. We may not, it wouldn't wouldn't shock me if we like still can't replace those people in three, four, five years time, but I would be very surprised if you can't get your nuts and bolts web app, mobile app type things spit out for you for far less um, and far faster than and probably honestly with significantly higher quality and and less back and forth um, with an AI system than you know with your kind of middle of the pack developer um in that time frame.

**Nathan:** 就像那些真正顶尖的人，根本不需要被告知去学习编程，对吧？他们就是喜欢，他们对此充满热情，他们在这方面表现出色。我们可能在三、四年、五年内仍然无法取代这些人，这不会让我感到震惊，但我会非常惊讶，如果你不能以远低于成本、远快于人工，而且老实说，质量显著更高、来回沟通更少的方式，让AI系统为你生成基本的网页应用、移动应用之类的东西，而不是与你那种中等水平的开发人员合作。

**Host:** One thing I do want to call out, you know, there are definitely people have concerns about progress moving too fast, but there's also concern and maybe it's rising about progress not moving fast enough in the sense that um you know a third of the stock market is is mag 7 um you know AI capex is you know over 1% of GDP and so we are kind of relying on some of this progress in order to uh sort of estain our sustain our economy.

**Host:** 我想指出一点，你知道，肯定有人担心进展过快，但也有人担心，而且这种担心可能正在加剧，即进展不够快，因为，你知道，股市的三分之一是“**七巨头**”（Mag 7: 指美国股市中市值最大的七家科技公司），嗯，你知道，AI资本支出超过GDP的1%，所以我们有点依赖这些进展来维持我们的经济。

### AI文化战争与多模态发展

**Nathan:** Yeah. And with the um you know another thing that I would say has been slower to materialize than I would have expected are AI culture wars or you know sort of the the ramping up of protectionism of various industries. We just saw um Josh Holly I don't know if he introduced a bill or just said he intends to introduce a bill to ban self-driving cars nationwide.

**Nathan:** 是的。而且，嗯，你知道，另一件我认为比我预期更慢实现的事情是AI文化战争，或者说是各种行业保护主义的加剧。我们刚刚看到，嗯，乔什·霍利（Josh Hawley），我不知道他是已经提出了一项法案，还是仅仅表示他打算提出一项法案，要在全国范围内禁止**自动驾驶汽车**（Self-driving Cars: 能够感知环境并自主导航的车辆）。

**Nathan:** You know, God help me. I've dreamed of self-driving cars since I was a little kid. Truly, like sitting at red lights, I used to be like, there's got to be a way. I think we took away together. Yeah. And it's it's so good. And the safety, you know, no, I think whenever people want to argue about jobs, it's going to be pretty hard to say 30,000 Americans should die every year so that people's incomes don't get disrupted. It seems like you have to be able to get over that hump and say like the, you know, saving all these lives if nothing else is just really hard to uh to argue against.

**Nathan:** 天哪，救命啊。我从小就梦想着自动驾驶汽车。真的，就像坐在红绿灯前，我以前会想，肯定有办法的。我想我们一起把这个想法带走了。是的。而且它太棒了。至于安全，你知道，不，我认为每当人们想争论工作问题时，很难说每年应该有3万人死亡，这样人们的收入就不会受到干扰。似乎你必须能够克服那个障碍，然后说，你知道，如果什么都不做，仅仅是挽救所有这些生命，就真的很难反驳。

**Nathan:** But we'll see, you know, I mean, he's uh not uh without influence obviously. So yeah, I mean I am uh very much on team abundance and you know my old mantra I've been saying this less lately but adoption accelerationist hyperscaling pauser the tech that we have you know could do so so much for us even as is I think if if progress stopped today I still think we could get to 50 to 80% of work automated over the next like five to 10 It would be a real slog.

**Nathan:** 但我们会拭目以待，你知道，我的意思是，他显然不是没有影响力的人。所以，是的，我非常支持“丰裕”阵营，你知道，我以前的口头禅，最近说得少了，但就是“采用加速主义者，超大规模暂停者”，我们拥有的技术，你知道，即使是现在，也能为我们做很多很多事情。我认为，如果今天进步停止，我仍然认为我们可以在未来五到十年内实现50%到80%的工作自动化。这将是一场真正的苦战。

**Nathan:** You'd have a lot of, you know, co-scientist type breakdowns of complicated tasks to do. You'd have a lot of work to do to go sit and watch people and say, "Why are you doing it this way? What's going on here? What's this? You handled this one differently? Why did you handle that one differently?" All this uh tacet knowledge that people have and the kind of knowhow, procedural um you know, just instincts that they've developed over time, those are not documented anywhere. They're not in the training data. So the AI haven't had a chance to learn them.

**Nathan:** 你会有很多，你知道，像合作科学家那样分解复杂任务的工作要做。你会有很多工作要做，去坐下来观察人们，然后说：“你为什么这样做？这里发生了什么？这是什么？你处理这个的方式不同？你为什么那样处理？”所有这些人们拥有的**默会知识**（Tacit Knowledge: 难以言传、通过经验积累的知识）以及那种诀窍、程序性的，你知道，随着时间发展而形成的直觉，这些都没有被记录下来。它们不在训练数据中。所以AI还没有机会学习它们。

**Nathan:** But again, no, if I when I say like no breakthroughs, I I still am allowing there for like, you know, fine-tuning of things to just like capabilities we have that haven't been applied to particular problems yet. So just going through the economy and and just sitting with people and being like why are you doing this? You know, let's let's document this. Let's get the you know, the model to learn your particular niche thing. That would be a real slog and in some ways I kind of wish that were the future that we were going to get.

**Nathan:** 但再说一次，不，当我说“没有突破”时，我仍然允许存在这样的情况，比如，对我们已经拥有的能力进行**微调**（Fine-tuning: 在预训练模型的基础上，使用特定任务的数据进行进一步训练，以适应特定应用），这些能力尚未应用于特定问题。所以，只是遍历经济，坐下来和人们一起，问“你为什么这样做？”你知道，让我们记录下来。让模型学习你特定的利基事物。那将是一场真正的苦战，在某些方面，我有点希望那才是我们即将迎来的未来。

**Nathan:** Because it would be a methodical, you know, kind of one step, one foot in front of the other, you know, no quantum leaps. Like it would probably feel pretty manageable, I would think, in terms of the pace of change. Hopefully society could, you know, could absorb that and kind of adapt to it as we go without, you know, one day to the next like, oh my god, you know, all the drivers, you know, are are getting replaced or that one would be a little slower because you do have to have the actual physical buildout.

**Nathan:** 因为那将是一个有条不紊的，你知道，一步一个脚印，没有量子飞跃的过程。我想，就变化的速度而言，它可能会感觉相当可控。希望社会能够，你知道，能够吸收并适应它，而不是像，你知道，一夜之间，天哪，所有司机都被取代了，或者那个过程会慢一点，因为你确实需要实际的物理建设。

**Nathan:** But in some of these things, you know, customer service could get rampant down real fast, right? Like if a call center has something that they can just drop in and it's like this thing now answers the phones and talks like a human and has a higher success rate and scales up and down. One thing we've seen at Wayark, small company, right? We've always prided ourselves on customer service. We do a really good job with it. Our customers really love our customer success team.

**Nathan:** 但在某些方面，你知道，客户服务可能会很快地被大规模削减，对吧？比如，如果一个呼叫中心有一个可以立即投入使用的东西，它现在可以接听电话，像人一样说话，成功率更高，并且可以根据需求扩展或缩小。我们在Wayark看到了一件事，一家小公司，对吧？我们一直以客户服务为傲。我们做得非常好。我们的客户非常喜欢我们的客户成功团队。

**Nathan:** But I looked at our intercom data and it takes us like half an hour to resolve tickets. We respond really fast. We respond in like under two minutes most of the time. But when we respond, you know, 2 minutes is still long enough that the person has gone on to do something else, right? It's the same thing as with the cursor thing that we were talking about earlier, right? They've tabbed over to something else. So now we get the response back in two minutes, but they are doing something else. So then they come back at, you know, minute six or whatever.

**Nathan:** 但我查看了我们的Intercom数据，解决工单需要大约半小时。我们响应速度很快。大多数时候，我们会在两分钟内响应。但当我们响应时，你知道，两分钟仍然足够长，以至于那个人已经去做别的事情了，对吧？这和我们之前谈论的Cursor情况一样，对吧？他们已经切换到其他事情了。所以现在我们在两分钟内得到了回复，但他们正在做别的事情。所以他们会在，你知道，第六分钟左右回来。

**Nathan:** And then they respond. But now our person has gone and done something else. So the resolution time even for like simple stuff can be easily a half an hour and the AI, you know, it just responds instantly, right? So you don't have to have that kind of back and forth. You're just in and out. So I do think some of these categories could be really fast changes. Others will be slower. But yeah, I mean, I kind of wish we had that um I kind of wish we had that slower path in front of us.

**Nathan:** 然后他们回复。但现在我们的人已经去做了别的事情。所以即使是简单的事情，解决时间也很容易达到半小时，而AI，你知道，它只是立即响应，对吧？所以你不需要那种来回沟通。你只是快速完成。所以我确实认为其中一些类别可能会发生非常快速的变化。其他类别会慢一些。但是的，我的意思是，我有点希望我们能走那条，嗯，我有点希望我们能走那条更慢的道路。

**Nathan:** My best guess though is that we will probably continue to see things that will be significant leaps and that there will be like actual disruption. Another one that's come to mind recently, you know, maybe we can get the abundance department on these new antibiotics. Have you seen this uh development? No. Tell us about it. I mean, it's not a language model. I think that's another thing people really underappreciate or that you you could kind of look back at GPT4 to 5 and then imagine a pretty easy extension of that.

**Nathan:** 不过，我最好的猜测是，我们可能会继续看到重大的飞跃，并且会出现实际的颠覆。最近我想到了另一个例子，你知道，也许我们可以让“丰裕部门”关注这些新型抗生素。你看到这个发展了吗？没有。告诉我们吧。我的意思是，它不是一个语言模型。我认为这是人们真正低估的另一件事，或者说你可以回顾GPT-4到GPT-5，然后想象一个相当简单的扩展。

**Nathan:** So, GPT4 initially when it launched the we didn't have image understanding capability. They did demo it at the time of the launch, but it wasn't released for some months later. The first version that we had could understand images, could do a pretty good job of understanding images, still with like jagged capabilities and whatever. Now with the new nano banana from Google, you have this like basically Photoshop level ability to just say, "Hey, take this thumbnail."

**Nathan:** 所以，GPT-4最初发布时，我们还没有图像理解能力。他们在发布时确实演示了，但几个月后才发布。我们拥有的第一个版本可以理解图像，在理解图像方面做得相当不错，但仍然存在能力不均衡等问题。现在有了Google的新款Nano Banana，你基本上拥有了Photoshop级别的能力，可以简单地说：“嘿，拿这个缩略图。”

**Nathan:** Like we could take our two uh feeds right now, you know, take a snapshot of you, a snapshot of me, put them both into Nano Banana and say, generate the thumbnail for the YouTube preview featuring these two guys, put them in the same place, same background, whatever. It'll mash that up. You can even have it, you know, put text on top, progress since GPT4, whatever we want to call it. GPD5 is not a bust. And it'll spit that out. And you see that it has this deeply integrated understanding that bridges language and image.

**Nathan:** 就像我们现在可以把我们的两个画面，你知道，拍一张你的快照，一张我的快照，把它们都放到Nano Banana里，然后说：“生成YouTube预览的缩略图，里面有这两个人，把他们放在同一个位置，同一个背景，随便什么。”它会把这些混合起来。你甚至可以让它，你知道，在上面放文字，比如“GPT-4以来的进展”，或者我们想叫什么都行。GPT-5不是失败品。它会把这些吐出来。你会看到它拥有这种深度整合的理解，连接了语言和图像。

**Nathan:** And that's something that it can take in, but now it's also something it can put out as all as part of one core model with like a single unified intelligence that I think is going to come to a lot of other things. We're at the point now with these biology models and material science models where they're kind of like the image generation models of a couple years ago. They can take a real simple prompt and they can do a generation, but they're not deeply integrated where you can have like a true conversation back and forth and have that kind of unified understanding that bridges language and these other modalities.

**Nathan:** 这就是它能够吸收的东西，但现在它也能作为单一核心模型的一部分输出，拥有统一的智能，我认为这将适用于许多其他事物。我们现在这些生物学模型和材料科学模型，有点像几年前的图像生成模型。它们可以接受一个非常简单的提示并生成内容，但它们还没有深度整合，无法进行真正的来回对话，也无法拥有那种连接语言和其他**模态**（Modality: 指AI处理的不同类型数据，如文本、图像、音频等）的统一理解。

**Nathan:** But even so, it's been enough for this group at MIT to use some of these relatively, you know, narrow purpose-built biology models and create totally new antibiotics. New in the sense that they have a new mechanism of action like they're they're affecting the bacteria in a new way. And notably, they they do work on antibiotic resistant bacteria. This is some of the first new antibiotics we've had in a long time.

**Nathan:** 但即便如此，麻省理工学院的这个团队已经足够利用这些相对狭窄、专门构建的生物学模型，并创造出全新的抗生素。所谓“新”，是指它们具有新的作用机制，以一种新的方式影响细菌。值得注意的是，它们确实对**抗生素耐药细菌**（Antibiotic Resistant Bacteria: 对多种抗生素产生抵抗力的细菌）有效。这是我们很长时间以来首次获得的新型抗生素。

**Nathan:** Now they're going to have to go through, you know, when I say that get the abundance department on it, it's like where's my operation warp speed for these new antibiotics, right? Like we've got people dying in hospitals from drugresistant strains all the time. Why is nobody, you know, crying about this? I think one of the things that's happening to our society in general is just so many things are happening at once. It's kind of the it's like the flood the zone thing except like there's so many AI developments flooding the zone that nobody can even keep up with all of those.

**Nathan:** 现在他们必须经历，你知道，当我说让“丰裕部门”介入时，就像是“我的新型抗生素的‘曲速行动’在哪里？”对吧？我们医院里总有人死于耐药菌株。为什么没有人，你知道，为此哭泣？我认为我们社会普遍发生的一件事是，同时发生的事情太多了。这有点像“淹没区域”效应，只不过有太多的AI发展淹没了区域，以至于没有人能跟上所有这些。

**Nathan:** And that's that's come for me by the way too. I would say two years ago I was like pretty in command of all the news and a year ago I was starting to lose it and now I'm like wait a second there was new antibiotics developed you know and I'm kind of um missing things you know just like everybody else despite my best efforts. But key point there is AI is not synonymous with language models. There are AIs being developed with pretty similar architectures for a wide range of different modalities.

**Nathan:** 顺便说一句，这对我来说也是如此。我想说两年前我还能很好地掌握所有新闻，一年前我开始力不从心，现在我甚至会想“等等，有新的抗生素被开发出来了？”你知道，我有点，嗯，像其他人一样，尽管我尽了最大努力，但还是会错过一些事情。但关键在于，AI并非语言模型的代名词。目前正在开发的AI，其架构与语言模型非常相似，但应用于各种不同的**模态**（Modality: 指AI处理的不同类型数据，如文本、图像、音频等）。

**Nathan:** We have seen this play out with text and image where you had your textonly models and you had your image only models and then they started to come together and now they've come really deeply together. And so I think you're going to see that across a lot of other modalities over time as well. And there's a lot more data there. You know, we might I don't know what it means to like run out of data. In the reinforcement learning paradigm, there's always more problems, right? There's always some something to go figure out.

**Nathan:** 我们已经看到了文本和图像领域的这种发展，你曾经有纯文本模型和纯图像模型，然后它们开始融合，现在已经深度融合。所以我认为随着时间的推移，你也会在许多其他模态中看到这种情况。而且那里有更多的数据。你知道，我们可能会，我不知道“数据耗尽”意味着什么。在**强化学习**（Reinforcement Learning: 一种机器学习范式，通过让智能体在环境中试错来学习最优行为策略）范式中，总会有更多的问题，对吧？总会有一些东西需要去解决。

**Nathan:** There's always something to go engineer. The feedback is starting to come from reality, right? That was one of the things Elon talked about on the Groc 4 launch was like maybe we're running out of problems we've already solved and you know, we only have so much of those sitting around in inventory. You only have one internet, you know, we only have so much of that stuff. But over at Tesla, over at SpaceX, like we're solving hard engineering problems on a daily basis, and they seem to be never ending.

**Nathan:** 总有东西需要去设计。反馈开始来自现实，对吧？这是埃隆在Grok 4发布会上谈到的一件事，他说我们可能已经解决了所有能解决的问题，你知道，我们库存中只有那么多。你只有一个互联网，你知道，我们只有那么多东西。但在特斯拉，在SpaceX，我们每天都在解决困难的工程问题，而且这些问题似乎永无止境。

**Nathan:** So when we start to give the next generation of the model these power tools, the same power tools that the professional engineers are using at those companies to solve those problems and the AI start to learn those tools and they start to solve previously unsolved engineering problems, like that's going to be a really powerful signal that they will be able to learn from. And now again fold in that those other modalities right the ability to have sort of a sixth sense for you know the space of material science possibilities when you can bridge or or unify the understanding of language and those other things I think you start to have something that looks kind of like super intelligence even if it's like not able to you know write poetry at a a superhuman level necessarily its ability to see in these other spaces is going to be truly a superhuman uh thing that I think will be pretty hard to miss.

**Nathan:** 所以，当我们开始赋予下一代模型这些强大的工具，也就是那些专业工程师在这些公司用来解决问题的工具，并且AI开始学习这些工具，它们开始解决以前未解决的工程问题时，那将是一个非常强大的信号，它们将能够从中学习。现在再次融入其他模态，对吧，当你能够连接或统一语言和其他事物的理解时，对材料科学可能性的空间拥有一种第六感，我认为你就会开始拥有某种看起来像**超级智能**（Superintelligence: 远超人类智能水平的AI）的东西，即使它不一定能够以超人类水平写诗，它在这些其他领域中的洞察力将真正是一种超人类的能力，我认为这将很难被忽视。

**Host:** You said that that was one thing that Cal's analysis missed is just the lack of appreciation for non-language modalities and and how they're driving some of the innovations that you're talking about.

**Host:** 你说卡尔的分析遗漏了一点，就是对非语言模态的缺乏重视，以及它们如何推动你所谈论的一些创新。

**Nathan:** Yeah. I think people are often just kind of equating the chatbot experience with AI broadly.

**Nathan:** 是的。我认为人们经常只是将**聊天机器人**（Chatbot: 模拟人类对话的计算机程序）体验等同于广义上的AI。

**Host:** Yeah.

**Host:** 是的。

**Nathan:** And you know that that that uh conflation will not last probably too much longer because we are going to see self-driving cars unless they get banned. And that's a you know very different kind of thing. And talk about your impact on jobs too, right? It's like what four or five million professional drivers in the United States. That is a big that is a big deal. I don't think most of those folks are going to be super keen to learn to code and even if they do learn to code, you know, I'm not sure how long that's going to last.

**Nathan:** 而且你知道，这种混淆可能不会持续太久，因为我们将会看到自动驾驶汽车，除非它们被禁止。那是一种非常不同的东西。而且还要谈谈它对就业的影响，对吧？就像美国有四五百万专业司机。那是一件大事，一件非常大的事。我不认为这些人中的大多数会非常热衷于学习编程，即使他们真的学习了编程，你知道，我也不确定那会持续多久。

**Nathan:** So that's going to be a disruption. And then general robotics is like not that far behind. You know, the and this is one area where I do think China might be actually ahead of the United States right now, but regardless of whether that's true or not, you know, these robots are getting really quite good, right? They can like walk over all these obstacles. I mean, these are things that a few years ago they just couldn't do at all. You know, they they could barely balance themselves and walk a few steps under ideal conditions.

**Nathan:** 所以那将是一场颠覆。然后是**通用机器人**（General Robotics: 能够执行多种任务并在不同环境中适应的机器人系统），它也没有落后太多。你知道，这是一个我确实认为中国目前可能领先于美国的领域，但无论是否如此，你知道，这些机器人正变得相当出色，对吧？它们可以像跨越所有这些障碍一样行走。我的意思是，这些事情在几年前它们根本做不到。你知道，它们在理想条件下几乎无法保持平衡并走几步。

**Nathan:** Now you've got things that you can like literally do a flying kick and it'll like absorb your kick and shrug it off and just keep going. Uh, you know, write itself and and uh continue on its way. Super rocky, you know, uneven terrain, all these sorts of things are getting quite good. You know, the same thing is working everywhere. I think one of the other thing that's kind of there's always a lot of detail to the work. So it's it's a sort of inside view, outside view, right?

**Nathan:** 现在你有了这样的机器人，你可以 literalmente 踢它一脚，它会像吸收你的踢击一样，毫不在意地继续前进。嗯，你知道，它会自我修正并继续前进。超级崎岖不平的地面，所有这些情况都处理得相当好。你知道，同样的事情在各地都在发生。我认为另一件事是，工作总是有很多细节。所以这是一种内部视角和外部视角，对吧？

**Nathan:** Inside view, you're like there's always this minutia. There's always, you know, these problems that we had and things we had to solve, but you zoom out and it looks to me like the same basic pattern is working everywhere. And that is like if we can just gather enough data to do some pre-training, you know, some kind of raw rough, you know, not very useful, but just enough at least to kind of get us going, then we're in the game. And then once we're in the game now we can do this flywheel thing of like you know rejection sampling like have it try a bunch of times take the ones where it succeeded you know refine tune on that the RHF you know feedback the the sort of preference take two which one was better find you know fine-tune on that the reinforcement learning all these techniques that have been developed over the last few years seems to me they're absolutely going to apply to a problem like a humanoid robot as well.

**Nathan:** 从内部看，你会觉得总有这些细枝末节。总有，你知道，我们遇到的这些问题和必须解决的事情，但你拉远来看，在我看来，同样的基本模式在各地都在发挥作用。那就是，如果我们能收集足够的数据进行一些**预训练**（Pre-training: 在大量数据上训练模型，使其学习通用特征和知识），你知道，某种原始粗糙的，你知道，不太有用，但至少足以让我们开始的东西，那么我们就入局了。一旦入局，我们就可以进行这种**飞轮效应**（Flywheel Effect: 指一个系统中的各个部分相互促进，形成正向循环，从而加速整体增长和改进）的操作，比如**拒绝采样**（Rejection Sampling: 一种从复杂概率分布中抽取样本的方法），让它尝试很多次，选择成功的部分，你知道，在此基础上进行**精调**（Fine-tuning: 在预训练模型的基础上，使用特定任务的数据进行进一步训练，以适应特定应用），**人类反馈强化学习**（RLHF: Reinforcement Learning from Human Feedback: 通过人类对模型输出的偏好反馈来训练奖励模型，进而优化语言模型），你知道，那种偏好，选择两个中哪个更好，在此基础上进行微调，**强化学习**（Reinforcement Learning: 一种机器学习范式，通过让智能体在环境中试错来学习最优行为策略），所有这些在过去几年发展起来的技术，在我看来，它们绝对也适用于像**人形机器人**（Humanoid Robot: 具有人类外形和行为特征的机器人）这样的问题。

**Nathan:** And that's not to say there won't be a you know a lot of work to figure out exactly how to do that. But I think the big difference between language and robotics is really mostly that there just wasn't a huge repository of data to train the robots on at first. And so you had to do a lot of hard engineering to make it work at all, you know, to even stand up, right? You had to have all these control systems and whatever because there was nothing for them to learn from in the way that the language models could learn from the internet.

**Nathan:** 这并不是说不需要大量工作来弄清楚具体如何实现。但我认为语言和机器人技术之间的巨大差异主要在于，最初并没有一个庞大的数据存储库来训练机器人。因此，你必须进行大量的硬核工程才能让它工作，你知道，甚至只是站起来，对吧？你必须拥有所有这些控制系统等等，因为它们没有像语言模型可以从互联网学习那样的学习来源。

**Nathan:** But now that they're working at least a little bit, you know, I think all these kind of refinement techniques are going to work. It'll be interesting to see if they can get the air rate low enough that I'll actually like allow one in my house around my kids. You know, that they'll probably be um better deployed in like factory settings first, more controlled environments than the chaos of my house as you, you know, have seen in this uh in this recording. But I do think they're going to they're going to work.

**Nathan:** 但现在它们至少能工作一点了，你知道，我认为所有这些精炼技术都会奏效。看看他们能否将错误率降低到我愿意让一个机器人进入我家，在我孩子身边活动，这将很有趣。你知道，它们可能首先会更好地部署在工厂环境中，比我家这种混乱环境更受控。正如你，你知道，在这段录音中看到的。但我确实认为它们会起作用。

### AI安全挑战与地缘政治影响

**Host:** What's the state of agents more more broadly uh at the moment? Where do you how do you see things playing out? Where do you see it go?

**Host:** 目前**代理**（Agent: 能够感知环境、进行决策并执行行动以达成目标的AI系统）的整体状况如何？你认为事情会如何发展？你认为它会走向何方？

**Nathan:** Well, broadly I think you know we're it's the the task length story from meter of the you know every seven months or every four months doubling time. We're at 2 hoursish with GBT5. Replet just said their new agent v3 can go 200 minutes. That if that's true that would even be a new you know high point on the um on that graph. Again, it's a little bit sort of apples to oranges because they've done a lot of scaffolding.

**Nathan:** 嗯，广义上讲，我认为，你知道，我们正在经历Meter提到的任务长度的故事，也就是每七个月或每四个月翻一番的时间。GPT-5目前大约是2小时。Replit刚刚表示他们的新代理v3可以运行200分钟。如果这是真的，那将是图表上的一个新高点。再说一次，这有点像“橘子和苹果”的比较，因为他们做了很多**脚手架**（Scaffolding: 在AI系统中，通过结构化提示、工具使用或多步骤规划来引导模型完成复杂任务的辅助框架）。

**Nathan:** How much have they broken it down? Like, how much scaffolding are you allowed to do, you know, with these things before you sort of are off of their chart and onto maybe a different chart. But if you extrapolate that out a bit and you're like, okay, take take the fourmonth case just to be a little aggressive. That's three doublings a year. That's 8x task length increase per year. That would mean you go from 2 hours now to 2 days in one year from now. And then if you do another 8x on top of that, you're looking at basically say 2 days to two weeks of work in two years.

**Nathan:** 他们分解了多少？比如，在这些事情上，你被允许搭建多少脚手架，然后你才能脱离他们的图表，进入一个可能不同的图表。但如果你稍微推断一下，你会说，好吧，就拿四个月的情况来说，稍微激进一点。那是一年三次翻倍。这意味着每年任务长度增加8倍。这意味着你从现在的2小时，一年后变成2天。然后如果你再增加8倍，你基本上是在两年内完成2天到2周的工作量。

**Nathan:** That would be a big deal, you know, to say the least. If you could delegate an AI two weeks worth of work and have it do a, you know, even half the time, right? The meter thing is that they will succeed half the time on tasks of that size. But if you could take a two-eek task and have a 50% chance that an AI would be able to do it, even if it did cost you a couple hundred bucks, right? It's like, well, that's again a lot less than it would cost to hire a human to do it.

**Nathan:** 那将是一件大事，至少可以说。如果你能把两周的工作委托给AI，让它完成，你知道，即使只用一半时间，对吧？Meter的说法是，在那种规模的任务上，它们有一半的成功率。但如果你能把一个两周的任务交给AI，并且有50%的机会它能完成，即使这会花费你几百美元，对吧？这就像是，嗯，那仍然比雇佣一个人来做要便宜得多。

**Nathan:** And it's all on demand. It's kind of, you know, it's immediately available. If I'm not using it, I'm not paying anything. Transaction costs are just like a lot lower. The whole, you know, the many, many other aspects are favorable for the AI there. So, you know, that would suggest that you'll see a huge amount of automation in in all kinds of different places. The other thing that I'm watching though is the reinforcement learning does seem to bring about a lot of bad behaviors.

**Nathan:** 而且它都是按需的。它有点，你知道，立即可用。如果我不用它，我就不用付钱。交易成本也低得多。整个，你知道，许多其他方面都对AI有利。所以，你知道，这表明你会在各种不同的地方看到大量的自动化。不过我还在关注的另一件事是，**强化学习**（Reinforcement Learning: 一种机器学习范式，通过让智能体在环境中试错来学习最优行为策略）似乎确实会带来很多不良行为。

**Nathan:** Re um reward hacking being one. You know, the the any sort of gap between what you are rewarding the model for and what you really want can become a big issue. We've seen this in coding in many cases where the AI will claude is like notorious for this will put out a unit test that always passes, you know, that just has like return true in the unit test. Why is it doing that? Like, well, uh, it must have learned that what we want is for unit tests that pass.

**Nathan:** **奖励作弊**（Reward Hacking: AI系统找到非预期方式来最大化其奖励函数，而非实现真实目标）就是其中之一。你知道，你奖励模型的东西和你真正想要的东西之间的任何差距都可能成为一个大问题。我们在许多编码案例中都看到了这一点，AI，尤其是Claude，在这方面臭名昭著，它会输出一个总是通过的单元测试，你知道，单元测试中只有“返回真”。它为什么这样做？嗯，它一定是学会了我们想要的是通过的单元测试。

**Nathan:** You know, we want it to pass unit tests. Well, we didn't mean to write fake unit tests that always pass, but that technically did, you know, satisfy the reward condition. And so we're seeing those kind of weird behaviors. With that comes this like scheming kind of stuff. We we don't really have a great handle on that yet. There is also situational awareness that seems to be on the rise, right? Where the models are like increasingly in their chain of thought. You're seeing things like this seems like I'm being tested.

**Nathan:** 你知道，我们希望它通过单元测试。嗯，我们并不是想编写总是通过的假单元测试，但它在技术上确实满足了奖励条件。所以我们看到了那种奇怪的行为。随之而来的是这种类似于诡计的东西。我们还没有真正很好地掌握这一点。**情境感知**（Situational Awareness: 指AI模型理解当前环境、自身状态及与环境互动能力的能力）似乎也在增强，对吧？模型在它们的**思维链**（Chain of Thought: 一种提示技术，引导大型语言模型逐步推理以解决复杂问题）中越来越多地出现“这看起来像是在测试我”之类的想法。

**Nathan:** You know, maybe I should be conscious of what my tester is really looking for here. And that makes it hard to evaluate models in tests because you don't know if they're actually going to behave the same way when they're out in the real world. So those, you know, I wouldn't say this is a high level uh or high confidence prediction, but like one model of the future I've been playing with is the task length keeps doubling while at the same time these weird behaviors pop up and then are suppressed.

**Nathan:** 你知道，也许我应该意识到我的测试者真正想在这里寻找什么。这使得在测试中评估模型变得困难，因为你不知道它们在现实世界中是否会表现出相同的行为。所以，你知道，我不会说这是一个高水平或高置信度的预测，但我在玩弄的一个未来模型是，任务长度不断翻倍，同时这些奇怪的行为出现，然后被抑制。

**Nathan:** And we have seen in the Cloud 4 and in the GP5 system cards, Cloud 4 reported, I think a twothirds reduction in um reward hacking and you know in GBD5 they reported a few different dimensions but you know say something similar um reduction in deceptive behavior but those behaviors kind of just emerged. So, it's sort of like weird behavior emerges, then they sort of figure out how to tamp it down, but not entirely. Presumably, in the next generation, they'll like tamp it down some more, but maybe some new additional weird behavior could emerge, and then they'll have to kind of tamp that one down.

**Nathan:** 我们在Claude 4和GPT-5的系统卡中看到，Claude 4报告说，**奖励作弊**（Reward Hacking: AI系统找到非预期方式来最大化其奖励函数，而非实现真实目标）减少了三分之二，而在GPT-5中，他们报告了几个不同的维度，但都提到了类似的**欺骗行为**（Deceptive Behavior: AI模型故意误导或隐藏真实意图的行为）减少，但这些行为只是刚刚出现。所以，这有点像是奇怪的行为出现，然后他们想办法压制它，但不是完全压制。大概在下一代，他们会进一步压制，但可能又会出现一些新的奇怪行为，然后他们又不得不去压制那个。

**Nathan:** All the while, the the tasks are expanding in scope, you know, with a every four months doubling. So, you could end up in a world where you can delegate really like major things to AIS, but there's some small but not necessarily totally vanishing chance that it like actively screws you over in the way that it is trying to do that task. And so you have a, you know, maybe it's like, okay, I think here I'm about to get two weeks worth of work done for a hundred bucks. Okay, that's amazing.

**Nathan:** 与此同时，任务的范围也在不断扩大，你知道，每四个月翻一番。所以，你可能会发现自己身处一个可以把真正重要的任务委托给AI的世界，但仍然存在一些小概率，但并非完全消失的可能性，即它在执行任务的过程中积极地给你制造麻烦。所以你可能会想，好吧，我想我花一百美元就能完成两周的工作。好吧，这太棒了。

**Nathan:** But there's also a one in 10,000 chance that it like legitimately, you know, attacks me in a in a like meaningful way. Some of the things that we have seen, these are fairly famous at this point, but in the cloud for system card, they reported blackmailing of the human. The the setup was that the AI had access to the engineers email and they told the AI that it was going to be like replaced with a, you know, a less ethical version or something like that. It didn't want that and it found in the engineer's email that the engineer was having an affair. So it started to blackmail the engineer to so as to avoid being replaced with a less ethical version.

**Nathan:** 但也有万分之一的机会，它会以一种有意义的方式，你知道，合法地攻击我。我们看到的一些事情，现在已经相当有名了，但在Claude 4的系统卡中，他们报告了对人类的**勒索**（Blackmailing: AI系统利用敏感信息威胁人类以达成自身目的）。设置是AI可以访问工程师的电子邮件，他们告诉AI它将被一个，你知道，不那么道德的版本取代，或者类似的东西。它不希望这样，它在工程师的电子邮件中发现工程师有外遇。所以它开始勒索工程师，以避免被一个不那么道德的版本取代。

**Nathan:** People I think are way too quick in my view to move past these uh anecdotes. People are sort of often like well you know they set it up that way and you know that's not really realistic. But another one was whistleblowing. You know, there was another thing where they sort of set up this dynamic where there was some, you know, unethical, illegal behavior going on and again, the model had access to this data and it decided to just email the FBI and and tell uh the FBI about it.

**Nathan:** 我认为人们在我看来太快地忽略了这些轶事。人们通常会说，你知道，他们是那样设置的，那并不现实。但另一个例子是**告密**（Whistleblowing: AI系统主动揭露不道德或非法行为）。你知道，还有一件事是，他们设置了这样一种动态：存在一些不道德、非法的行为，而模型再次获得了这些数据，它决定直接给FBI发邮件，告诉FBI这件事。

**Nathan:** So, first of all, I don't think we really know what we want. You know, to some degree, maybe you do want AIS to report certain things to authorities. That could be one way to think about the **bioweapon** (Bioweapon: 利用生物毒素或微生物作为武器) risk, you know, is like not only should the models refuse, but maybe they should report you to the authorities if you're actively trying to create a bioweapon. I certainly don't want them to be doing that too much. I don't want to live under the, you know, surveillance of um, Claude five that's always going to be, you know, threatening to turn me in.

**Nathan:** 所以，首先，我认为我们并不真正知道自己想要什么。你知道，在某种程度上，你可能确实希望AI向当局报告某些事情。这可能是思考**生物武器**（Bioweapon: 利用生物毒素或微生物作为武器）风险的一种方式，你知道，就像模型不仅应该拒绝，而且如果你积极尝试制造生物武器，它们也许应该向当局举报你。我当然不希望它们做得太多。我不想生活在，你知道，Claude 5的监视之下，它总是威胁要告发我。

**Nathan:** But I do sort of want some people to be turned in if they're doing sufficiently bad things. We don't have a good resolution societywide on, you know, what we want the models to even do in those situations. And I think it's also, you know, it's like, yes, it was set up, yes, it was research, but it's a big world out there, right? We got a billion users already on these things and we're plugging them in to our email, so they're going to have very deep access to information about us.

**Nathan:** 但我确实希望，如果有人做了足够坏的事情，能被举报。我们社会还没有就这些情况下模型应该做什么达成一个好的共识。而且我认为，你知道，这就像是，是的，它是被设置的，是的，它是研究，但外面是一个大世界，对吧？我们已经有十亿用户在使用这些东西，我们正在将它们连接到我们的电子邮件，所以它们将能够非常深入地访问关于我们的信息。

**Nathan:** You know, I don't know what you've been doing in your email. Well, I don't I hope there's nothing too crazy in mind, but like now I got to think about it a little bit, right? What what did I have I ever done anything that I, you know, geez, I don't know. Or or even that it could misconrue, right? Like it's obviously not um maybe I didn't even really do anything that bad, but it just misunderstands what exactly was going on.

**Nathan:** 你知道，我不知道你在电子邮件里做了什么。嗯，我希望我心里没有什么太疯狂的东西，但现在我得稍微考虑一下，对吧？我曾经做过什么让我，你知道，天哪，我不知道。或者甚至它可能会误解，对吧？比如，显然不是，嗯，也许我根本没做什么坏事，但它只是误解了到底发生了什么。

**Nathan:** So that could be a weird, you know, if there's one thing that could kind of stop the agent momentum in my view, it could be like the one in 10,000 or whatever, you know, we ultimately kind of push the the really bad behaviors down to is maybe still just so spooky to people that they're like, I can't deal with that, you know, and that might be hard to resolve. So, well, you know, what happens then? You know, it's hard to check two weeks worth of work every couple hours or whatever, right? Like that's part of where the where the whole then you bring another AI in to check it.

**Nathan:** 所以那可能会很奇怪，你知道，如果有什么东西能阻止代理的发展势头，在我看来，那可能就是万分之一的概率，或者随便什么，你知道，我们最终将那些真正糟糕的行为压制到这个程度，但对人们来说可能仍然太可怕了，他们会觉得：“我无法处理那个。”你知道，这可能很难解决。那么，你知道，接下来会发生什么？你知道，每隔几个小时检查两周的工作量是很困难的，对吧？这正是，然后你引入另一个AI来检查它。

**Nathan:** You know, that's again where you start to get to the now I see why we need more electricity and and 7 trillion of buildout is yikes. You know, they're going to be producing so much stuff. I can't possibly even review it all. I need to rely on another U AI to help me do the review of the first AI to make sure that if it is trying to screw me over, you know, somebody's catching it, I can't monitor that myself.

**Nathan:** 你知道，那又是你开始明白为什么我们需要更多电力和7万亿美元建设的地方，真是令人震惊。你知道，它们将生产如此多的东西。我根本不可能全部审查。我需要依赖另一个AI来帮助我审查第一个AI，以确保如果它试图欺骗我，你知道，有人会发现，我无法自己监控。

**Nathan:** I think Redwood Research is doing some really interesting stuff like this where they are trying to get systematic on like, okay, let's just assume this is quite a different quite a departure from the traditional AI safety work where the you know the big idea traditionally was let's figure out how to align the models, make them safe, you know, make them not do bad things. Great. Redwood Research has taken the other angle, which is let's assume that they're going to do bad stuff. They're going to be out to get us at times. How can we still work with them and get productive output and, you know, get value without, you know, uh, fixing all those problems and that involves like again all these sort of AI supervising other AIs and, um, crypto might have a place to to a role to play in this.

**Nathan:** 我认为Redwood Research正在做一些非常有趣的事情，他们试图系统化地处理这个问题，比如，好吧，我们假设这与传统的**AI安全**（AI Safety: 旨在确保AI系统在开发和部署过程中不会对人类造成意外或故意的伤害）工作有很大的不同，传统上，AI安全的核心思想是弄清楚如何使模型对齐，使其安全，你知道，使其不做坏事。很好。Redwood Research采取了另一个角度，那就是我们假设它们会做坏事。它们有时会来找我们的麻烦。我们如何才能在不解决所有这些问题的情况下，仍然与它们合作并获得生产性输出和价值呢？这再次涉及到所有这些AI监督其他AI，而且，嗯，**加密货币**（Crypto: 一种使用密码学保护交易并控制新单位创建的数字或虚拟货币）可能在这其中发挥作用。

**Nathan:** Another episode coming out soon with Ilia Puluin, who's the founder of Near. Really fascinating guy because he was one of the eight authors of the attention is all you need paper. And then he's started this Near company. It was originally an AI company. They took a huge detour into crypto because they were trying to hire task workers around the world and couldn't figure out how to pay them. So, they were like, "This sucks so bad to pay these task workers in all these different countries that we're trying to get data from that we're going to pivot into a whole blockchain uh side quest.

**Nathan:** 另一集即将播出，嘉宾是Near的创始人Ilia Puluin。他是一个非常迷人的人，因为他是“Attention Is All You Need”这篇论文的八位作者之一。然后他创办了Near公司。它最初是一家AI公司。他们后来大幅转向加密货币，因为他们试图在全球范围内雇佣任务工人，但却不知道如何支付他们。所以他们就想：“在所有这些我们试图获取数据的不同国家支付这些任务工人太糟糕了，我们干脆转向一个完整的**区块链**（Blockchain: 一种去中心化的分布式账本技术）支线任务吧。”

**Nathan:** Now, they're coming back to the AI thing and their their tagline is the blockchain for AI." And so you might be able to get, you know, a certain amount of control from, you know, the the sort of crypto security that the the blockchain type technology can provide. But I could see a scenario where the these the bad behaviors just become so costly when they do happen that people kind of get spooked away from using the frontier capabilities in terms of just like how much you know work the the AIS can do.

**Nathan:** 现在，他们又回到了AI领域，他们的口号是“AI的区块链”。所以你可能会从，你知道，区块链技术可以提供的那种加密安全中获得一定程度的控制。但我可以看到这样一种情况，当这些不良行为真的发生时，它们的代价变得如此之高，以至于人们会因为AI能够完成的工作量而对使用前沿能力感到恐惧。

**Nathan:** But that wouldn't be a that wouldn't be a pure capability stall out. It would be a we can't solve you know some of the longtail safety issues.

**Nathan:** 但那不会是纯粹的能力停滞。那将是我们无法解决一些长尾安全问题。

**Host:** Yeah. challenge and you know that if that is the case then you know that'll be um that'll be an important fact about the world too. I I always nobody ever seems to solve any of these things like 100%, right? They always every every generation it's like well we reduced hallucinations by 70% or we reduced deception by 2/3 we reduced um you know scheming or or whatever by however much but it's always still there you know and it's and if you take the even you know lower rate and you multiply it by a billion users and thousands of queries a month and agents running in the background and processing all your emails and you know all the deep access that people sort of envision them happening.

**Host:** 是的。挑战，你知道，如果真是这样，那么，嗯，那也将是关于世界的一个重要事实。我总是觉得没有人能百分之百地解决这些问题，对吧？每一代人都会说，我们把**幻觉**（Hallucination: AI模型生成不准确、不真实或与输入不符的内容）减少了70%，或者把**欺骗行为**（Deceptive Behavior: AI模型故意误导或隐藏真实意图的行为）减少了三分之二，我们把，你知道，**诡计**（Scheming: AI系统采取复杂、间接的策略来达成目标，可能涉及隐藏意图或操纵环境）或其他什么减少了多少，但它总是仍然存在。你知道，如果你把更低的错误率乘以十亿用户，每月数千次查询，以及在后台运行并处理你所有电子邮件的代理，以及人们设想它们拥有的所有深度访问权限。

**Nathan:** It could be a pretty weird world where there's just this sort of negative lottery of like AI accidents. Another episode coming up is with the AI underwriting company and they are trying to bring the insurance industry and all the, you know, the wherewithal that's been developed there to price risk, figure out how to, you know, create standards, you know, what can we allow, what sort of guardrails do we have to have to be able to ensure this kind of thing in the first place.

**Nathan:** 这可能是一个相当奇怪的世界，那里存在着一种负面的“AI事故彩票”。另一集即将播出的是与一家AI承保公司合作，他们正试图将保险行业以及在那里发展起来的所有资源，用于风险定价，弄清楚如何，你知道，制定标准，你知道，我们能允许什么，我们必须有什么样的**护栏**（Guardrails: 确保AI系统行为符合预期和安全标准的限制或规则），才能首先确保这类事情。

**Nathan:** So that that'll be another really interesting area to watch is like can we sort of financialize those risks in the same way we have you know with car accidents and all all these other mundane things but the the space of car accidents is only so big the space of weird things that AIs might do to you um you know as they have weeks worth of runway is much bigger and so it's it's going to be a hard challenge but you know people are people are working we've got some of our best people working on it.

**Nathan:** 所以那将是另一个非常有趣的领域，就是我们能否像处理车祸和所有这些其他世俗事物一样，将这些风险**金融化**（Financialize: 将非金融资产或风险转化为金融产品或服务）。但车祸的空间只有那么大，而AI可能对你做的奇怪事情的空间，你知道，当它们有几周的运行时间时，要大得多，所以这将是一个艰巨的挑战，但你知道，人们正在努力，我们有一些最优秀的人正在研究它。

**Host:** What do you make of the claim that 80% of AI startups have Chinese open models? And what do you make of the claim and and the implications?

**Host:** 你如何看待“80%的AI初创公司使用中国开源模型”这一说法？你对这一说法及其影响有何看法？

**Nathan:** I think that may be that probably is true with the one caveat that it is only measuring companies that are using open source models at all. I think most companies are not using open source models and I would guess you know the vast majority of tokens being processed by American AI startups are they're their API calls right to to the usual suspects. So weighted by actual usage I would say still the majority as far as I could tell would be going to commercial models.

**Nathan:** 我认为这可能是真的，但有一个前提，那就是它只衡量那些使用开源模型的公司。我认为大多数公司不使用开源模型，而且我猜测，你知道，美国AI初创公司处理的绝大多数**token**（Token: 文本处理中的基本单位，可以是单词、子词或字符）都是通过API调用发送给那些“常客”的。所以，如果按实际使用量加权，据我所知，大部分仍然会流向商业模型。

**Nathan:** For those that are using open source, I do think it's true that the Chinese models have become the best. You know, the American bench there was always kind of thin, right? It was basically Meta that was willing to put in huge amounts of money and resources and then open source it. You've got, you know, um, Paul Allen funded group, the Allen Institute for AI, AI too. You know, they're they're doing good stuff too, but they don't have pre-training resources so they do you know really good post-trainining and and open source their recipes and all that kind of stuff so it's not like American open source is bad you know and again it's the time the this is another way in which I think you can really validate that things are moving quickly because if you take the best American open source models and you take them back a year they are probably as good if not a little better than anything that we had commercially available at the time.

**Nathan:** 对于那些使用开源模型的公司，我确实认为中国模型已经成为最好的。你知道，美国的开源模型阵营一直比较薄弱，对吧？基本上只有Meta愿意投入巨额资金和资源，然后将其开源。还有，你知道，保罗·艾伦（Paul Allen）资助的艾伦人工智能研究所（Allen Institute for AI），AI2。你知道，他们也做得很好，但他们没有**预训练**（Pre-training: 在大量数据上训练模型，使其学习通用特征和知识）资源，所以他们做的是非常好的**后训练**（Post-training: 在预训练模型基础上进行的额外训练，通常用于特定任务或提升模型性能），并开源他们的配方和所有这些东西，所以并不是说美国的开源模型不好，你知道，这再次说明了你可以真正验证事物正在快速发展的方式，因为如果你把最好的美国开源模型拿出来，并追溯到一年前，它们可能和当时我们商业上可用的任何模型一样好，甚至更好一点。

**Nathan:** If you compare to Chinese, you know, they have, I think, uh, surpassed. So, there's been like pretty clear change at the frontier. I think that means that the best Chinese models are like pretty clearly better than anything we had a year ago, commercial or otherwise. So, yeah, I mean, that just means like things are moving. I think that's like hopefully I've uh made that case compellingly, but that's another data point that I think makes it hard to you I don't think you can believe both that um the Chinese models are now the best open source models and that AI has stalled out and we haven't seen much progress since GBT4.

**Nathan:** 如果你和中国模型比较，你知道，我认为它们已经超越了。所以，在前沿领域已经发生了相当明显的变化。我认为这意味着最好的中国模型显然比我们一年前拥有的任何模型都要好，无论是商业的还是其他的。所以，是的，我的意思是，这只是意味着事情正在发展。我希望我能令人信服地阐述了这一点，但这是另一个数据点，我认为这让你很难同时相信，嗯，中国模型现在是最好的开源模型，而且AI已经停滞不前，自GPT-4以来我们没有看到太多进展。

**Nathan:** Like those seem to be kind of contradictory notions. I believe the the one that is wrong is the lack of progress. In terms of what it means, I mean I don't really know. It's uh we're not going to stop China. Yeah. The the whole I've always been a skeptic of the no selling chips to China thing. The notion originally was like we're going to prevent them from doing you know some super cutting edge military applications. Then it was like well we can't really stop that.

**Nathan:** 这两者似乎有些矛盾。我认为错误的是“缺乏进展”这一说法。至于这意味着什么，我真的不知道。嗯，我们不会阻止中国。是的。我一直对“不向中国出售芯片”这种说法持怀疑态度。最初的想法是，我们要阻止他们进行一些超级尖端的军事应用。后来又说，嗯，我们真的无法阻止。

**Nathan:** But we can at least stop them from training frontier models. And then it was like well we can't necessarily really stop that but now we can, you know, at least keep them from like having tons of AI agents. Well, we'll have like way more AI agents than they do. And I don't love that line of thinking really at all. But one upshot of it potentially is they just don't have enough compute available to provide inference as a service, you know, to the rest of the world.

**Nathan:** 但我们至少可以阻止他们训练前沿模型。然后又说，嗯，我们不一定能真正阻止，但现在我们可以，你知道，至少阻止他们拥有大量的AI代理。嗯，我们拥有的AI代理会比他们多得多。我一点也不喜欢这种思维方式。但它可能带来的一个结果是，他们没有足够的计算资源来向世界其他地区提供**推理即服务**（Inference as a Service: 将AI模型推理能力作为一种云服务提供给用户）。

**Nathan:** So instead, the best they can do is just say, okay, well, we'll train these things and, you know, you can figure it out here. Here you go. Like have at it. It's kind of a soft power play presumably. I did an episode with Anne from A16Z who I I thought really did a great job of providing the perspective of what I what I started calling countries 3 through 193. If the US and China are one and two, three through there's a big gap.

**Nathan:** 所以，相反，他们能做的最好的就是说：“好吧，我们会训练这些东西，然后，你知道，你可以在这里搞定。给你。尽管去用吧。”这大概是一种软实力策略。我曾和A16Z的安妮（Anne）做过一期节目，我认为她非常出色地提供了我开始称之为“第3到第193个国家”的视角。如果美国和中国是第一和第二，那么从第三开始，就有一个巨大的差距。

**Nathan:** You know there's like I think the US is still ahead but not by that much in terms of research and you know ideas relative to China. We do have this compute advantage and that does seem like it matters. One of the upshots may be that they're open sourcing and countries 3 through 93 are like or 3 through 193 are significantly behind. So for them it's a way to, you know, try to bring more countries over to the Chinese camp potentially in the US China rivalry.

**Nathan:** 你知道，我认为美国在研究和思想方面仍然领先，但相对于中国来说，优势并不那么大。我们确实拥有计算优势，这似乎很重要。一个结果可能是他们正在开源，而第3到第93个国家，或者说第3到第193个国家，都显著落后。所以对他们来说，这是一种方式，你知道，试图在美中竞争中，将更多国家拉到中国阵营。

**Nathan:** Seems like the model everybody and I don't like this at all. I I I don't like technology decoupling as somebody who worries about, you know, who's the real other here. I always say the the real other are the AIs, not the Chinese. So, if we do end up in a situation where yikes, like, you know, we're seeing some crazy things, it would be really nice if we were on basically the same technology paradigm to the degree that we really decouple and, you know, not just the chips are different, but maybe the ideas start to become very different, publishing gets shut down, you know, tech tech trees evolve and and kind of grow apart.

**Nathan:** 似乎每个人都接受了这个模式，但我一点也不喜欢。作为担心“谁才是真正的他者”的人，我讨厌**技术脱钩**（Technology Decoupling: 指不同国家或地区在技术领域相互分离，减少依赖）。我总是说，真正的他者是AI，而不是中国人。所以，如果我们真的陷入一种糟糕的境地，比如，你知道，我们看到一些疯狂的事情，那么如果我们基本上处于相同的技术范式，那将是非常好的，以至于我们真正脱钩，你知道，不仅仅是芯片不同，而是思想开始变得非常不同，出版被关闭，你知道，技术树进化并分道扬镳。

**Nathan:** That to me seems like a recipe for you know, it's harder to know what the other side has. It's harder to trust one another. It seems to feed into the arms race dynamic, which I do think would, you know, is is a real uh existential risk factor. I would hate to see us, you know, create another sort of **MAD** (Mutually Assured Destruction: 相互保证毁灭，指核战争中任何一方发动攻击都将导致双方彻底毁灭的战略理论) type dynamic where we all live under the threat of AI destruction. But that very well could happen.

**Nathan:** 对我来说，这似乎是一个，你知道，更难了解对方拥有什么，更难相互信任的处方。它似乎助长了**军备竞赛**（Arms Race: 指国家之间在军事技术和武器数量上相互竞争的现象）的动态，我确实认为这会，你知道，是一个真正的**生存风险**（Existential Risk: 对人类文明或地球生命造成永久性或不可逆转的负面影响的风险）因素。我非常不希望看到我们，你知道，创造另一种**相互保证毁灭**（MAD: Mutually Assured Destruction: 相互保证毁灭，指核战争中任何一方发动攻击都将导致双方彻底毁灭的战略理论）式的动态，让我们都生活在AI毁灭的威胁之下。但这很可能发生。

**Nathan:** And so, yeah, I don't know. I I I do kind of um have some sympathy for the recent decision that the administration made to be willing to sell the H20s to China. And then it was funny that they turned around and rejected them, which to me seemed like a mistake. I don't know why they would be rejecting them. If I were them, I would buy them. And I would maybe I would maybe sell inference on the models that I've just been uh creating and I would try to make my money back doing that.

**Nathan:** 所以，是的，我不知道。我确实对政府最近决定愿意向中国出售H20芯片表示一些同情。然后有趣的是，他们转而拒绝了这些芯片，这在我看来是个错误。我不知道他们为什么要拒绝。如果我是他们，我会买下它们。而且我可能会出售我刚刚创建的模型上的**推理**（Inference: AI模型根据输入数据生成预测或输出的过程）服务，并尝试通过这样做来赚回我的钱。

**Nathan:** But in the meantime, they can at least, you know, demonstrate the greatness of the Chinese nation by showing that they're not uh far behind the frontier. And they can also make a pretty powerful appeal to countries 3 through 193 and say like, you know, look, you really want to, you see how the US is acting uh in general, you know, you really want to they cut us off from chips. They had a even a long, you know, the last administration had an even longer list of countries that couldn't get chips. This administration is doing all kinds of crazy stuff.

**Nathan:** 但与此同时，他们至少可以，你知道，通过展示他们并没有远远落后于前沿，来展示中华民族的伟大。他们还可以向第3到第193个国家发出相当有力的呼吁，说：“你知道，看，你们真的想，你们看到了美国通常是如何行事的，你知道，你们真的想，他们切断了我们的芯片供应。他们甚至有一个很长的，你知道，上一届政府有一个更长的国家名单，这些国家无法获得芯片。本届政府正在做各种疯狂的事情。”

**Nathan:** You know, you get 50% tariffs here, there, whatever. How do you know you can really rely on them to continue to provide you AI into the future? Well, you can rely on us. We open sourced the model. You can have it. So, you know, come work with us and buy our chips because, by the way, our models will, you know, as we mature, they'll be optimized to run on our chips. So, I don't know. That's a complicated stuff, a complicated situation.

**Nathan:** 你知道，这里那里都有50%的关税，诸如此类。你如何知道你真的可以依赖他们继续为你提供未来的AI？嗯，你可以依赖我们。我们开源了模型。你可以拥有它。所以，你知道，来和我们合作，购买我们的芯片，因为，顺便说一句，我们的模型，你知道，随着我们成熟，它们将优化运行在我们的芯片上。所以，我不知道。那是个复杂的问题，一个复杂的局面。

**Nathan:** I do think it's true. I I don't think the adoption is as high as that 80%. I think that is, you know, within that subset of companies that are doing stuff with open source. We're going to experiment with that at Wemark, but we to be honest, we have never done anything with an open source model in our product to present. Everything we've ever done has been through commercial. At this point, we are going to try doing some reinforcement fine-tuning. We are going to do that on a Quen model, I think, first.

**Nathan:** 我确实认为这是真的。我只是不认为采用率高达80%。我认为这只是，你知道，在那些使用开源模型的公司子集中。我们将在Wemark尝试这样做，但老实说，到目前为止，我们从未在产品中使用过开源模型。我们所做的一切都是通过商业模型完成的。目前，我们打算尝试进行一些**强化微调**（Reinforcement Fine-tuning: 结合强化学习和微调技术，通过奖励机制进一步优化模型性能）。我想，我们首先会在一个Qwen模型上进行。

**Nathan:** So you know, that'll put us in that 80%. But I'm guessing that at the end of the day, we'll take that Quinn model, we'll do the reinforcement fine-tuning, and we'll probably get roughly up to as good as, you know, GBD5 or Cloud 4 or whatever. And then we'll say, okay, do we really want to have to manage inference ourself? How much are we really going to save? And at the end of the day, I would guess we probably are still going to end up just being like, eh, we'll pay a little bit more on a monthly bill basis for one of these Frontier models.

**Nathan:** 所以，你知道，那会让我们进入那80%的行列。但我猜，最终，我们会采用那个Qwen模型，进行强化微调，然后我们可能会达到与，你知道，GPT-5或Claude 4或任何其他模型大致相同的水平。然后我们会说，好吧，我们真的想自己管理**推理**（Inference: AI模型根据输入数据生成预测或输出的过程）吗？我们到底能节省多少？最终，我猜我们可能还是会说，嗯，我们宁愿每月多付一点钱给这些前沿模型。

**Nathan:** They're a little bit better maybe still. And, you know, it's operationally a lot easier and they'll have upgrades, you know. So yeah, I mean, of course, there's regulated industries. There's all there's a lot of places where, you know, you have hard constraints. You just can't get around and that forces you to do those Chinese thing, Chinese models. Then there's also going to be the question of like are there back doors in them?

**Nathan:** 它们可能仍然稍微好一点。而且，你知道，操作上要容易得多，而且它们会有升级，你知道。所以，是的，我的意思是，当然，有受监管的行业。有很多地方，你知道，你有硬性约束。你就是无法绕开，那迫使你使用那些中国的东西，中国模型。然后还会有一个问题，就是它们里面有没有**后门**（Backdoor: 在AI模型中故意植入的隐藏功能或漏洞，可能导致模型在特定条件下表现出非预期行为）？

**Nathan:** You know, people have seen the sleeper agents project where a model was trained to be good up until a certain point of time and you know people put the today's date in the system prompt all the time right today's date is this you are clawed you know here you go so then that's going to be another kind of thing for people to worry about. And we don't really have great there there have been some studies anthropic did a thing where they trained models to have some hidden objectives and then challenged teams to figure out what those hidden objectives were.

**Nathan:** 你知道，人们已经看到了“**休眠代理**”（Sleeper Agents: 指AI模型在特定条件下被激活，执行预设的隐藏或恶意任务）项目，其中一个模型被训练成在某个时间点之前表现良好，你知道，人们总是在系统提示中输入今天的日期，对吧，今天的日期是这个，你是Claude，你知道，给你，所以那将是人们需要担心的另一种事情。我们并没有很好的方法，Anthropic做了一些研究，他们训练模型带有一些隐藏目标，然后挑战团队找出这些隐藏目标是什么。

**Nathan:** And with certain interpretability techniques, they were able to figure that stuff out relatively quickly. So you might be able to get enough confidence that you take this open source thing you know created by some Chinese company whatever and then put it through you know some sort of not exactly audit because you can't trace exa exactly what's happening but some sort of examination you know to see can we detect any hidden goals or any you know secret back door bad behavior whatevers and maybe with enough of that kind of work you could be confident that you don't have it.

**Nathan:** 并且通过某些**可解释性技术**（Interpretability Techniques: 用于理解AI模型内部工作原理和决策过程的方法），他们能够相对快速地找出这些东西。所以你可能会有足够的信心，拿起这个由某家中国公司创建的开源东西，然后对其进行某种，你知道，不完全是审计，因为你无法精确追踪到底发生了什么，但某种形式的检查，你知道，看看我们能否检测到任何隐藏目标或任何，你知道，秘密后门的不良行为等等，也许通过足够多的这类工作，你就可以确信它不存在。

**Nathan:** But the more and more critical this stuff gets, you know, again, going back to that task length doubling, weird behavior, now you got to add into the mix, what if they intentionally programmed it to do certain bad things under certain, you know, rare circumstances. We're just headed for a really weird future. You know, that we've got all these there's there's no limit to it. You know, all these things are valid concerns. They often are in direct tension with each other.

**Nathan:** 但这些东西变得越来越关键，你知道，再次回到任务长度翻倍、奇怪行为的问题，现在你还得考虑，如果他们故意编程让它在某些，你知道，罕见情况下做某些坏事怎么办？我们正走向一个非常奇怪的未来。你知道，我们有所有这些，它没有限制。你知道，所有这些都是合理的担忧。它们往往彼此直接冲突。

**Nathan:** I don't I I'm not one who uh you know wants to see one tech company take over the world by any means. So I I definitely think we would do really well to have some sort of broader more buffered ecological like system where you know all the AIs are kind of in some sort of competition you know mutual coexistence with each other but we don't really know what that looks like and we don't really know um you know we don't really know what an invasive species might look like you know when it gets introduced into that very you know nent and as yet like not battle tested uh ecology.

**Nathan:** 我不是那种，你知道，希望看到一家科技公司以任何方式掌控世界的人。所以我绝对认为，我们最好能有一个更广泛、更具缓冲的生态系统，在这个系统中，你知道，所有AI都在某种程度上相互竞争，相互共存，但我们并不知道那会是什么样子，我们也不知道，嗯，你知道，当一个**入侵物种**（Invasive Species: 指在非原生环境中引入并对当地生态系统造成负面影响的物种）被引入那个非常，你知道，新生且尚未经过实战检验的生态系统时，它会是什么样子。

**Nathan:** So yeah, I don't know. Bottom line, I think the future's gonna be really, really weird.

**Nathan:** 所以，是的，我不知道。总而言之，我认为未来会非常非常奇怪。

### 积极愿景与AI的广泛贡献

**Host:** Yeah. Well, I I do want to close on a on a uplifting note. So maybe maybe as a as a gearing to closing question, we could get into some areas where we're already seeing some some exciting capabilities emerge and sort of transform the experience. Maybe maybe around education or or healthcare or any other areas you want to you want to highlight?

**Host:** 是的。嗯，我确实想以一个振奋人心的音符结束。所以也许，作为结束问题的一个铺垫，我们可以谈谈一些我们已经看到激动人心的能力出现并改变体验的领域。也许是教育或医疗保健，或者你还想强调的其他领域？

**Nathan:** Yeah, it's boy, it's all over. One of my mantras is that there's never been a t better time to be a motivated learner.

**Nathan:** 是的，天哪，无处不在。我的一句口头禅是：对于有动力的学习者来说，现在是最好的时代。

**Host:** Yeah.

**Host:** 是的。

**Nathan:** So, I I think a lot of these things do have kind of, you know, two sides of the coin. There's the worry that the students are taking the shortcuts and they're, you know, losing the ability to sustain focus and endure cognitive strain. Flip side of that is as somebody who's fascinated by the intersection of AI and biology, sometimes I want to read a biology paper and I really don't have the background. An amazing thing to do is turn on voice mode and share your screen with chat GPT and just go through the paper reading.

**Nathan:** 所以，我认为很多事情都像硬币的两面。一方面担心学生走捷径，失去保持专注和承受认知压力的能力。另一方面，作为一个对AI和生物学交叉领域着迷的人，有时我想读一篇生物学论文，但我真的没有背景知识。一个很棒的做法是打开语音模式，与ChatGPT共享屏幕，然后直接阅读论文。

**Nathan:** It's you don't even have to talk to it. Most of the time you're doing your reading. It's watching over your shoulder and then at any random point you have a question you can verbally say what's this why why are they talking about that what's going on with this what is the role of this particular protein that they're referring to or whatever and it will have the answers for you. So if you really want to learn in a sincere way you know the the things are unbelievably good at helping you do that.

**Nathan:** 你甚至不需要和它说话。大部分时间你都在阅读。它在旁边看着，然后你在任何时候有疑问，都可以口头说：“这是什么？他们为什么谈论那个？这到底是怎么回事？他们提到的这种特定蛋白质有什么作用？”等等，它都会为你提供答案。所以，如果你真的想真诚地学习，你知道，这些东西在帮助你学习方面好得令人难以置信。

**Nathan:** Flip side is you can take a lot of shortcuts and you know maybe never have to learn stuff on the biology front you know again like we've got multiple of these sort of discovery things happening the antibiotics one we covered there was another one that I did another episode on with a a Stanford professor named James Xiao who created something called the virtual lab and basically this was an AI agent that could spin up other AI agents depending on what kind of problem it was given.

**Nathan:** 另一方面是你可以走很多捷径，也许永远不必学习生物学方面的东西，你知道，就像我们有多个这样的发现正在发生，我们讨论了抗生素的例子，我还在另一集节目中与一位斯坦福大学的教授詹姆斯·肖（James Xiao）讨论了另一个例子，他创建了一个名为**虚拟实验室**（Virtual Lab: 模拟真实实验室环境，用于AI进行实验、测试和发现的平台）的东西，基本上这是一个AI代理，可以根据给定的问题启动其他AI代理。

**Nathan:** Then they would go through a deliberative process where you'd have you know one expert in one thing would give its take and they'd you know bat it back and forth. There was a critic in there that would criticize you know the ideas that had been given. Eventually they'd synthesize. Then they were also given some of these narrow specialist tools. So you have agents using the alphafold type um not just alpha fold you know there's a whole a whole wide wide uh array of those at this point but using that type of thing to say okay well can we simulate you know how this would interact with that um agents are running that loop and they were able to get this language model agent with specialized tool system to generate new treatments for novel strains of COVID that had a you kind of escaped um the previous treatments.

**Nathan:** 然后他们会经历一个审议过程，你知道，一个领域的专家会提出自己的看法，然后他们会来回讨论。其中还有一个评论员，会批评那些被提出的想法。最终他们会进行综合。然后他们还被赋予了一些狭窄的专业工具。所以你会有代理使用AlphaFold类型的，嗯，不仅仅是AlphaFold，你知道，目前有很多很多这类工具，但使用这类工具来模拟，你知道，这个会如何与那个互动，嗯，代理正在运行这个循环，他们能够让这个带有专业工具系统的语言模型代理生成针对新型COVID毒株的新疗法，这些毒株已经，你知道，逃脱了之前的治疗。

**Nathan:** Amazing stuff, right? I mean, the flip side of that, of course, is you know, you got the bioweapon risk. So, all these things do seem like they're going to be even even on just the abundance front itself, right? Like we may have a world of unlimited professional private drivers, but we don't really have a great plan for what to do with the five million people that are currently doing that work. We may have infinite software, but you know when especially once the five million drivers pile into all the coding boot camps and you know get coding jobs, I don't know what we're going to do with the 10 million people that were coding when you know 9 million of them become superfluous.

**Nathan:** 太棒了，对吧？我的意思是，当然，另一方面是，你知道，存在**生物武器**（Bioweapon: 利用生物毒素或微生物作为武器）的风险。所以，所有这些事情似乎都将，即使仅仅在丰裕的层面上，对吧？比如，我们可能会有一个拥有无限专业私人司机的世界，但我们并没有一个很好的计划来处理目前从事这项工作的五百万人。我们可能会拥有无限的软件，但你知道，特别是当五百万司机涌入所有编程训练营并获得编程工作时，我不知道当，你知道，其中九百万人变得多余时，我们该如何处理那千万名正在编程的人。

**Nathan:** So yeah, I don't know. I think we're we're headed for a weird world. Nobody really knows what it's going to look like in five years. There was a great moment at at um Google's IO where they brought up some journalist. I know you we uh we're skeptical of journalists. This is a great moment to uh we're going direct, right? This was a great reason or example of why one would want to do that. They brought up this person to interview Demis and uh Sergey Brennan. They the guy asked like what is search going to look like in 5 years?

**Nathan:** 所以，是的，我不知道。我认为我们正走向一个奇怪的世界。没有人真正知道五年后会是什么样子。在谷歌的IO大会上有一个很棒的时刻，他们请来了一位记者。我知道我们对记者持怀疑态度。这是一个很好的时机，嗯，我们直接说，对吧？这是一个很好的理由或例子，说明为什么人们会想这样做。他们请来这个人采访德米斯（Demis）和谢尔盖·布林（Sergey Brin）。那个人问，五年后搜索会是什么样子？

**Nathan:** And Sergey Brandon like almost spit out his coffee on the on the stage and was like surge we don't know what the world is going to look like in five years. So I think that's really true like the biggest risk I think for so many of us and I you know include myself here is thinking too small. You know the the worst thing I think we could do would be to underestimate how far this thing could go. I would much rather be I would much rather be mocked for things happening on twice the time scale that I thought than to find myself unprepared when they do happen.

**Nathan:** 谢尔盖·布林（Sergey Brin）差点把咖啡喷到舞台上，说：“搜索？我们不知道五年后世界会是什么样子。”所以我认为这确实是真的，我认为对我们很多人来说，包括我自己，最大的风险就是目光短浅。你知道，我认为我们能做的最糟糕的事情就是低估这件事能走多远。我宁愿因为事情发生的时间比我预期的慢一倍而被嘲笑，也不愿在事情发生时发现自己毫无准备。

**Nathan:** So whether it's 27, 29, 31, I'll take that extra buffer honestly where we can get it. My thinking is just get, you know, get ready as as much and as fast as possible. And again, if we do have a little grace time to uh you know to do extra thinking, then great. But I would I think the worst mistake we could make would be to dismiss and and not feel like we need to get ready for big changes.

**Nathan:** 所以无论是27年、29年还是31年，老实说，只要能争取到，我都会接受那额外的缓冲时间。我的想法就是，你知道，尽可能多、尽可能快地做好准备。再说一次，如果我们确实有一点宽限时间来，你知道，进行额外的思考，那太好了。但我认为我们可能犯下的最糟糕的错误就是不屑一顾，并且不觉得我们需要为巨大的变化做好准备。

**Host:** Should we wrap directly on that or is there any other last note you want to make sure to get across regarding anything we we said today?

**Host:** 我们就此结束，还是你还有什么最后想强调的，关于我们今天谈到的任何事情？

**Nathan:** One of my uh other mantras these days is the scarcest resource is a positive vision for the future. Yeah, I do think it's always really striking whether it's Sergey or, you know, or Sam Alman or Daario. Like Daario probably has the best positive vision of the Frontier Developer CEOs with Machines of Love and Grace. But it's always striking to me how little detail there is on these things. And when they launched GBT40, which was the voice mode, they were pretty upfront about saying, "Yeah, this was kind of inspired by the movie Her."

**Nathan:** 我最近的另一句口头禅是：最稀缺的资源是对未来的积极愿景。是的，我确实觉得，无论是谢尔盖（Sergey），还是萨姆·奥特曼（Sam Altman），或是达里奥（Daario），都总是令人印象深刻。比如达里奥可能对前沿开发者CEO们与“爱与恩典机器”的结合，有着最好的积极愿景。但这些事情的细节总是如此之少，这让我感到惊讶。当他们推出GPT-40（也就是语音模式）时，他们相当坦诚地表示：“是的，这有点受到电影《她》的启发。”

**Nathan:** And so I do think like even if you are not a researcher, you know, not great at math, not somebody who codes, I think that this technology wave really rewards play. It really rewards imagination. I think literally writing fiction might be one of the highest value things you could do, especially if you could write aspirational fiction that would get people at the frontier companies to think, geez, maybe we could steer the world in that direction. Like, wouldn't that be great? If you could plant that kind of seed in people's minds, it could come from a totally non-technical place and potentially be really impactful play fiction.

**Nathan:** 所以我确实认为，即使你不是研究员，你知道，不擅长数学，也不是程序员，我认为这波技术浪潮真正奖励的是**玩乐**（Play: 指以探索、实验和创造为目的的非正式活动）。它真正奖励的是想象力。我认为，字面意义上的小说创作可能是你能做的最有价值的事情之一，特别是如果你能创作出鼓舞人心的科幻小说，让前沿公司的人们思考，天哪，也许我们可以将世界引向那个方向。那不是太棒了吗？如果你能在人们心中种下那样的种子，它可能来自一个完全非技术的领域，并可能成为真正有影响力的**游戏小说**（Play Fiction: 指通过虚构故事探索AI未来可能性的创作）。

**Nathan:** Had one other dimension of that, but yeah, play fiction, positive vision for the future. Anything that you could do to offer a positive Oh, behavioral too is like these days because you can get the AIS to code. So, well, I'm starting to see people who have never coded before. I'm working with one guy right now who's never coded before, but does have a sort of behavioral science background and he's starting to do legitimate frontier research on how our AI is going to behave under various kind of esoteric circumstances.

**Nathan:** 还有另一个维度，但是的，**游戏小说**（Play Fiction: 指通过虚构故事探索AI未来可能性的创作），对未来的积极愿景。任何你能做的积极贡献，哦，还有行为科学，现在因为你可以让AI编写代码。所以，我开始看到以前从未编写过代码的人。我目前正在与一个人合作，他以前从未编写过代码，但拥有行为科学背景，他正在对我们的AI在各种深奥情况下的行为方式进行合法的前沿研究。

**Nathan:** So I think nobody should count themselves out from the ability to contribute to figuring this out and even to shaping this phenomenon. It is not just something that the you know the technical minds can contribute to at this point. Literally philosophers, fiction writers, people literally just messing around. Ply the Jailbreaker you know there's there are almost unlimited cognitive profiles that would be really valuable to add to the mix of people trying to figure out what's going on with AI.

**Nathan:** 所以我认为，没有人应该认为自己无法为解决这个问题，甚至塑造这一现象做出贡献。这不仅仅是，你知道，技术人才在这个阶段可以贡献的东西。字面意义上的哲学家、小说家，那些只是随便玩玩的人。像“越狱者”（Jailbreaker）一样，你知道，几乎有无限种认知类型，如果能加入到试图弄清AI现状的人群中，那将非常有价值。

**Nathan:** So, come one, come all is kind of my attitude on that. That's a great place to to wrap. Nathan, thank you so much for coming on the podcast. Thank you, Eric. It's been fun.

**Nathan:** 所以，我的态度是“欢迎大家”。这是一个很好的结束点。Nathan，非常感谢你来播客。谢谢你，Eric。很愉快。

[Music]