---
author: Lei
channel: null
date: 2025-07-25
guest: null
insight: null
layout: post.njk
series: null
source: https://www.youtube.com/watch?v=LeFobtxKgQU&t
speaker: 徒步的骑手
summary: 当前“智能驾驶”技术，特别是国产车的宣传名不符实，存在巨大安全隐患。即便是行业领先的特斯拉，其安全性也备受质疑，数据存在误导性。车主应保持警惕，不能盲信宣传。
tags:
- 视频文稿
- 自动驾驶
- 智能驾驶
- 特斯拉
- 汽车安全
title: 智能驾驶的真相：从董车帝评测到特斯拉的“数据炼金术”
file_name: smart_driving_truth_tesla_safety_risks.md
draft: true
---

## 国内自动驾驶的炒作与乱象

各位好。这两年国内车企疯狂炒作自动驾驶，炒作热度让发明自动驾驶的美国市场都望尘莫及。一些车主相信车厂的虚假广告，把**辅助驾驶**当成**全自动驾驶**来用，导致车毁人亡。发生事故以后车企大多是撇清关系，指责车主操作不当。他们说驾驶手册和购车合同都写的清清楚楚，除了事故，责任全在车主，跟车厂无关。

目前市场上家用汽车自动驾驶的性能和安全性，到底如何呢？

## 董车帝的全面评测：真相令人“脊背发凉”

昨天早晨，国内车评博主董车D在油管上传了一个多小时的智能驾驶测评视频。董车D是我看到的国内最靠谱的汽车测评频道，他跟抖音同是一个母公司，就是字节跳动，财大气粗。因为他不缺钱，所以他做测试，都是自己花钱买车，自己报高速公路，制作模拟场景。

董车D这场测试，总共用了36款车，模拟了6种事故场景，可以说是目前为止，对国内市场上各种智能驾驶汽车品牌和车型，做出的最全面的测评。

董车D的测评，模拟了高速行车中最容易导致事故的6种场景：
第一种场景，是高速车道上突然出现事故车。
第二种场景，是施工路段遭遇大卡车。
第三种场景，是高速公路上遇到临时施工。
第四种场景，是前车突然消失。
第五种场景，是高速路口遇到野蛮驾驶。
第六种场景，是遇到一头横穿公路的野猪。

测试结果可以说让人鸡背发凉。表现最好的是特斯拉的Model 3和Model X，这两款车在6项测试中通过了5项。在国产品牌中，少数表现最好的是6项中只通过了3项，大部分是6项中只通过了1项和0项。

## 评测结果解读：营销炒作下的安全隐患

这意味着什么呢？这意味着大部分国产品牌的汽车，他们所谓的智能驾驶性能名不符实，属于营销炒作。用懂车帝的话说，就是“只存在于PPT中”。

了解了国产品牌智能驾驶性能的真相，人们就不奇怪为什么国内经常传出智能驾驶车毁人亡的惨剧。车企不负责任，车主也不负责任，不但对自己的生命安全不负责任，而且对车里坐的家人、坐的朋友的生命安全也不负责任。

怕死是人的本能，所以一般情况下，人们不会拿自己的命开玩笑。但作死也是人的本能，很多人作死就是因为相信了不该相信的东西。智能驾驶或者说自动驾驶，就是这样一种东西。它还处在实验阶段，但是跟其他大部分实验不同的是，它不是在实验室做实验，而是直接到公路上去做实验，而且拿来做实验的小白鼠车主，是自己花钱让车企拿它们做实验。

董车帝的测试结果告诉我们一个冰冷的事实：你花钱买来的智能驾驶，在真正遇到危险场景的时候，很可能是一个弱智的睁眼瞎。中国车企高调吹嘘的“高阶智驾”，在决定生死的关键时刻，多数都是形同虚设，还没有普通司机的正常反应快。

## 特斯拉在美国：专业评测揭示的“不可预测性”

在这个测试中，只有特斯拉的Model 3和Model X表现较好，在6个场景中通过了5个。这个结果被一些特斯拉粉丝解读为“遥遥领先”。但是即便是“遥遥领先”的特斯拉智能驾驶，在美国的专业测评中，能达到的最好成绩也无非是“勉强及格”。

勉强及格我们假定是60分，如果满分是100分。一个学生考60分，其他学生都不及格，这意味着考题实在太难。但特斯拉这个在美国考60分的学生，一到中国就可以考到90分，其他的学生都不及格。但是中国的企业文化和中国的市场特色是：越不及格越吹嘘自己“遥遥领先”。

我们打这个60分的比方，是为了说明中国智能驾驶在市场上的真正位置。任何比喻都是片面的，都是为了说明一个道理。但是呢，凡事都不可能只包含一个道理，所以大家在听比喻的时候呢，头脑当中一定要有根弦儿，就是不能把比喻泛化，不能推而广之，尤其是在涉及生命安全的时候。如果满分100分，哪怕考了90分，仍然可以是很危险的。

具体到智能驾驶测试，最关键的一道题就是：如何避免车毁人亡。人都撞死了，你车再智能也白瞎。所以呢，安全性在智能驾驶中的权重，跟其他指标是不一样的。即使是其他所有题都答对了，得了90分，但是最关键的这道题，就是如何避免车毁人亡，这道题答错了，或者漏答了，你还会觉得这个车很智能吗？

我们来看一下美国专业测评对特斯拉自动驾驶的测试结果。在美国市场上呢，特斯拉把它功能比较少的辅助驾驶，叫做**Autopilot**（自动驾驶），把它功能比较多的辅助驾驶，叫做**Full Self-Driving**（全自动驾驶）。但在中国市场上呢，特斯拉是老老实实把Autopilot叫做**自动辅助驾驶**，又老老实实把Full Self-Driving叫做**智能辅助驾驶**。

美国有个汽车测评媒体，叫Motor Trend，比较有权威性，我经常看它的测评，有时候我买车也参考它的测评。Motor Trend的试车员呢，开了一辆特斯拉Model Y，测试它的全自动驾驶功能，测试了整整一年，写了一个报告，题目叫《我为什么不得不放弃使用特斯拉的全自动驾驶》(Why I had to quit using Tesla for self-driving)。

行车安全和事故规避，可以说是智能驾驶系统的下限。如果说董车帝在封闭的高速公路上测试了智能驾驶性能的这个下限，那么Motor Trend对特斯拉自动驾驶长达一年的深度体验，则是揭示了这个系统在日常使用中的混乱和潜在的危险。

Motor Trend的试车员不是在试车场或者封闭的高速公路上测试，而是在每天上下班、接送孩子的真实道路上测试。他的一句话让人不寒而栗，他说：“使用特斯拉的全自动驾驶，唯一能预测的就是它的不可预测性。”启动全自动驾驶以后，他感觉自己不是一个司机，也不是一个乘客，而是一个时刻准备着为自动驾驶擦屁股的安全员。

试驾员记录了一次险情：在一段路况并不复杂的乡村公路上，特斯拉全自动驾驶突然左打方向盘，越过双黄线开到对面车道上去了。幸运的是对面的车道上没有车。这种致命错误，在错误的时间、错误的地点，犯一次就会车毁人亡，不会再有第二次机会。最后，Motor Trend的试车员决定不拿自己的性命开玩笑，停止了使用特斯拉的自动驾驶功能。

### “幻影刹车”与“自杀式转向”：日常使用中的风险

其他一些专业试车员，还有不少车主，也去网上吐槽特斯拉自动驾驶的各种危险行为。

最常见的是**幻影刹车**。就是在高速车道上正常行驶着，因为桥梁投射在路面上的阴影，或者旁边有什么障碍物投射在路面上的阴影，或者旁边经过一辆大卡车，自动驾驶突然大力度刹车，仿佛前面有一堵墙一样。这很容易造成后车追尾事故。

另一个常见的危险行为，就是**自杀式的转向**。自动驾驶毫无征兆突然转动方向盘，冲向路边，有时候是路边的水泥墩子，有时候是护栏，有时候可能是一棵树。如果司机不及时干预，后果不堪设想。Motor Trend的试车员记录的自动驾驶突然左转方向盘开到对面车道上逆行，并不是个孤立的个案。

还有一个常见的危险行为，就是红绿灯前面表现得像精神错乱。它有时候会冲过停止线，停在路口中央；有时候会犹豫不决，在可以安全通过的时候拒绝启动；最可怕的是，它有时候还会闯红灯。

不少车主反映了，特斯拉的自动驾驶经常表现的逻辑混乱。在需要开快的时候，它专门选择最慢的车道；有时候它又犹豫不决，有时候又莽撞冲动，在高速出口的最后一秒强行并线。这种危险操作，很容易激怒受到影响的司机，引发路怒。试车员经过专业训练，可以处理这些危险的状况，但是一般车主遇到同样的状况，可能就会发生车祸。

一位试车员说，特斯拉实际上是让车主自己花钱，在未经训练的情况下，成了他测试辅助驾驶软件的免费测试员。

## 权威机构的差评：二级辅助驾驶的真相

在美国市场上，只有特斯拉敢这么干。特斯拉全自动驾驶的竞争对手，谷歌旗下的Waymo，是自己出钱测试，采用循序渐进的策略。

美国有个独立的公路安全非盈利组织，叫**IIHS (公路安全保险协会：The Insurance Institute for Highway Safety)**。他去年根据七项指标，测试了14个汽车品牌的辅助驾驶系统，结果有11个品牌综合评测是“差”。特斯拉的**自动驾驶**和**全自动驾驶**几乎垫底，在安全功能、司机监控、司机提醒、紧急措施、人机协调、方向盘操控等单项测评中全是“差”，综合评分也是“差”。只有Lexus的辅助驾驶被评为“可以接受”，通用和尼桑的辅助驾驶被评为“勉强过关”，没有一个系统的综合测评能够达到“好”的程度。

美国的《消费者报告》(Consumer Report)也对特斯拉自动驾驶的安全性做出了类似的差评。

美国的**SAE (美国汽车工程师协会：Society of Automotive Engineers)**把自动驾驶系统分为六级。目前为止美国汽车消费市场上，包括特斯拉在内的自动驾驶系统、全自动驾驶系统都属于二级，也就是部分驾驶功能自动化，但必须人工干预。这离完全不需要人工干预的五级全自动驾驶还相当遥远。

但是在美国市场上，只有特斯拉敢把二级辅助驾驶系统，叫做**自动驾驶 (Autopilot)**，甚至直接叫做**全自动驾驶 (Full Self-Driving)**。特斯拉从市场营销到产品命名，都是在放纵车主做不负责任的小白鼠，希望通过收集这些小白鼠的驾驶数据，包括车祸数据来优化它的自动驾驶系统。《消费者报告》和一些专业车评媒体都批评特斯拉这种做法。

一个负责任的辅助驾驶系统，首先不能误导车主，把辅助驾驶叫成自动驾驶，甚至全自动驾驶。相反呢，一个负责任的辅助驾驶系统，必须有效地监督车主，不能让一些不负责任的车主在方向盘后面为所欲为。而误导车主、放纵车主为所欲为，正是特斯拉的做法。其他美国车厂，没有一家敢这么做。

这种做法呢，在美国不是没有后果。一些使用特斯拉自动驾驶的车主在事故中死亡或者伤残，死者家属和伤残车主发起法律诉讼。特斯拉虽然声称，驾驶手册和卖车合同都规定，使用自动驾驶出了事故，一切责任在司机，但是仍然跟一些车主达成协议，支付一笔数额不对外公布的赔偿金。有些诉讼仍然在讨价还价阶段，估计最后也是以赔偿告终。如果进入审判阶段，原告将会迫使特斯拉公布关键事故率数据，并传唤特斯拉自动驾驶开发人员作证，那对特斯拉来说，将会是场公关灾难。

特斯拉的做法也招致了政府部门的调查。美国政府的国家公路交通安全局，正在调查特斯拉的自动驾驶和全自动驾驶的安全问题。加州政府也启动了对特斯拉自动驾驶虚假宣传的调查。

## 华尔街日报的重磅调查：特斯拉的“数据炼金术”

辅助驾驶是迈向自动驾驶的重要一步，这几年这种技术取得了日新月异的进展。驾车上路安全第一，如果正确使用辅助驾驶，可以降低司机的驾驶疲劳，减少车祸，让公路更安全。但是用虚假广告误导车主，放纵不负责任的司机滥用，不但不会减少车祸，而且会导致更多车祸，让公路更不安全。

在《懂车帝》那期节目当中，有位中国车主振振有词，他说：“车是我的，我想怎么开就怎么开。”正是这种气壮如牛的小白鼠，构成了当今公路上最大的车祸隐患。车是私人的，但公路是公共场所，不是私人场所。如果他自己花钱买地，建一条自己专用的私人道路，他当然可以想怎么开就怎么开。但在公路上，除了他以外还有别的车，还有别的司机，一出车祸谁也跑不了。他可以自己做自费小白鼠主动送死，但其他的司机不能让他拉着陪葬。

特斯拉的老板马斯克说，数据表明，他的自动驾驶事故率远低于活人司机。一些国产品牌的车企，炒作智能驾驶，也是用这个调调。这听起来无懈可击，但无非是另一种误导。特斯拉根本就没有公布过完整的自动驾驶事故率数据。到目前为止，公众连多少车主购买了特斯拉的自动驾驶，多少车主购买了特斯拉的全自动驾驶，多少车祸在发生的时候开启了这些功能，一概不知道。市场连数据都不知道，哪里谈得上什么数据比较，都是他自说自话。

即便不考虑马斯克数据的真实性，他的说法，还有一层更隐秘的误导性。几个月前，《华尔街日报》刊发了一篇重磅调查文章，曝光特斯拉如何操纵数据。记者像淘金一样，挖掘了美国国家公路交通安全局的事故数据，揭开了一场精心策划的“数据炼金术”。

记者发现，特斯拉的安全数据至少存在两大问题。

### 误导性比较：完美条件 vs. 现实路况

第一大问题，就是误导性的比较。这有点像田忌赛马。特斯拉只计算自动驾驶系统在天气良好、路况清晰的条件下开启时的行驶里程和事故率，然后去对比包含了酒驾、毒驾、恶劣天气、恶劣路况、深夜飙车等等所有这些极端情况下，活人司机驾驶的平均事故率。这种拿司机在完美条件下得到的结果，跟别人在任何条件下得到的结果对比，自己的结果当然看上去很美了。但是这种比较本身，就是耍流氓。

### 致命的数据清洗：碰撞前甩锅

第二大问题是致命的数据清洗，就是在车祸发生前的最后一刻甩锅，把责任推给司机。在大量事故报告中，调查人员发现一个规律：特斯拉的自动驾驶系统，经常是在碰撞发生前的最后一刻，自动脱离自动驾驶状态。这意味着，自动驾驶系统在碰撞的瞬间已经处于关闭状态。于是这起事故，在法律上，在统计数据上，就变成了一起由司机人为错误导致的事故，而不会被记录在自动驾驶的数据中。这显然也是在耍流氓。当然了，这不是一个简单的技术问题，这是一种系统性的、可能涉嫌欺诈的数据操纵。

## 结论：在智能时代，保持人间清醒

就是这样一个在美国被认为是充满安全隐患的辅助驾驶系统，到了中国汽车市场上，已经是鹤立鸡群。在所有国产车企的智能驾驶不及格的情况下，它已经能考到80分、90分。

《华尔街日报》的调查、Motor Trend的实地测评、董车D在封闭高速公路上的模拟测试，都让我们看到当今市面上炒得热火朝天的智能驾驶、自动驾驶、全自动驾驶等等等等各种噱头，可能都是皇帝的新装。它们虽然功能上有多有少，性能上有优有劣，但实质上都是二级辅助驾驶，离五级全自动驾驶还有相当遥远的距离。

人们之所以会对辅助驾驶抱有不切实际的幻想，主要原因是一些不良车企的误导和虚假宣传。他们不仅自己上台误导消费者，而且串通一些不良媒体、不良自媒体，甚至打爱国的旗号，糊弄消费者，把一些轻信的车主变成自费小白鼠，供他们在公路上做实验。普通消费者能接触到的公开信息，本身就是被筛选过的、被美化过的、被操纵过的。出于自我保护的安全本能，很多人的直觉会告诉他们不能全信，但是他们又用数据来说服自己“很安全，没问题”。数据都说了，数据还能有假的？数据还能不科学？毕竟大部分人不会去想，任何数据都可以被挑选、被裁剪、被操纵、被拿来误导他们。数据只有在知道怎么利用数据的头脑那里才有意义，大部分没有受过解读数据训练的人，没有这种头脑。

说到这里，我们可以把懂车地和Motor Trend的专业测评，还有一些媒体的调查和报道，拼成一幅大致完整的智能驾驶，或者说自动驾驶的图景。作为行业领头羊，特斯拉发起了这场自动驾驶革命。它在技术进步、提供便利的同时，为了争夺商业先机，把一种不成熟的、充满安全隐患的技术推向大众消费市场。进入中国以后，新兴车企为了抢占市场，利用取之不尽、用之不竭的零成本小白鼠，把这种不负责任的商业模式玩到了极端，已经导致严重的公路安全后果，可能到了政府不得不调查、不得不限制、不得不规范的地步。

智能驾驶或者说自动驾驶，经过几年的野蛮生长以后，有几点已经越来越清楚：
在技术上，各种测试表明，它在关键的救命场景下是不可靠的。
在设计上，它缺乏有效的安全监督，纵容不负责任的司机为所欲为。
在体验上，它不可预测的风险，给负责任的司机带来了另一种压力。
在数据上，它通过精心筛选和系统操纵，编织远离事实的安全故事。

在这里，我们跟董车帝、Motor Trend、华尔街日报一样，不是否定技术进步，更不是否定驾驶自动化的发展方向，而是提醒车主们：驾车上路安全第一，而安全与否，最终是取决于你。**辅助驾驶**不但不能提供安全，而且构成巨大的安全隐患。目前市场上自称的**智能驾驶**、**自动驾驶**、**全自动驾驶**，都是二级辅助驾驶，不是名副其实的自动驾驶，它需要司机随时干预。

自动驾驶是未来发展的方向，这本身没有问题，但这是条漫长的道路。这条通往未来的道路，不应该用虚假宣传和车主的生命来铺就。车企在技术创新的同时，为了抢占市场，会在营销上玩各种猫腻，甚至操纵数据、操纵舆论。在这种大环境下，车主要有保护自己、保护家人生命安全的意识。

务必记住，无论你的车号称有多智能，屏幕有多大，宣传片有多酷，在你握住方向盘的那一刻，这个世界上唯一能为你生命负责的，只有你自己。在智能驾驶时代，最智能的选择，是坚持人间常识，保持清醒，保持警惕，保持对机器性能的合理怀疑。

## 董车帝的最终忠告：安全驾驶的唯一法则

最后，让我们听一听董车帝的忠告，这条忠告说不定可以挽救不少车主和家人的生命：

“而目前，最安全的使用方式是人机共驾，让驾驶辅助帮助人降低碰撞风险，而在驾驶辅助超越自己极限的时候，人类要随时准备接手。而且以他们现在的能力，完全没有办法做到任何的脱手脱脚，无论他们的营销部门怎么宣传，大家都只能把它作为一个安全的辅助，以人驾为主。高阶驾驶辅助只能帮你降低一些疲劳程度，那1%的风险一旦发生了，它就可能会酿成100%的伤亡。”
