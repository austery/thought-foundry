---
title: 《智人之上》：信息网络如何重塑我们的隐私、自由与未来
summary: 本期节目深入探讨了尤瓦尔·赫拉利新书《智人之上》的核心观点，揭示了人类信息网络的演化，从讲故事到官僚制度，再到现代非生物信息网络（AI）。节目分析了先进技术如何同时加强极权与民主，并警示了无处不在的监控、算法偏见以及AI对人类自由和权力格局的深远影响。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- artificial-intelligence
- democracy
- information-networks
- stella-an
- totalitarianism
- yuval-noah-harari
people: []
companies_orgs: []
products_models: []
media_books: []
date: '2025-08-30'
author: 安争鸣（Stella An）
speaker: 安争鸣（Stella An）
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=Abmq4dBXpLc
status: evergreen
---
### 个人隐私的消逝与自我审查的困境

大家好，我是安争鸣，欢迎回到读书时间。最近，经常有网友善意提醒我，不要在网上发布任何生活照或分享个人信息，以免“帽子叔叔”找上门。我知道这些网友是出于好意，但我却感到哭笑不得。这些生活在海外的网友显然不了解，在我们这个地方，根本就没有什么隐私可言。即使没有任何知名度和影响力，匿名上网不露脸，从不分享个人生活，只要发表一句违规言论，哪怕是在私人的微信群里，“帽子叔叔”也绝对能在24小时内找到你“喝茶”。你的所有个人信息，包括住址、活动轨迹、通话信息和消费记录，他们都能立刻完全掌握。更别说像我这种露脸实名上网的人了。生活在这样的环境里，为保护个人隐私所做的一切努力其实都没有任何意义。唯一有效的自我保护措施，就是像我一样进行严格的自我审查，或者是干脆什么都不说。

很多人会感到困惑，我也很困惑，不明白社会怎么就变成了现在这个样子。难道我们以后就只能这样活着吗？还是说我们拥有的自由还会进一步缩减呢？会不会有一天，连我现在讲的这些经典书籍和知识都会变成违规内容？会不会有一天，连我这种单纯分享阅读的博主都会被关进“渣滓洞”？今天我要给大家分享的这本书，探讨的就是这些问题。它是我在频道里讲过很多次作者，以色列历史学家**尤瓦尔·赫拉利**（Yuval Noah Harari: 以色列历史学家，知名作家）去年出版的新书，名为**《智人之上：从石器时代到AI时代的信息网络简史》**（Nexus: A Brief History of Information Networks from the Stone Age to the AI Age）。其实，我觉得这本书的中文名翻译成《信息网络》更合适，因为它主要通过概述人类信息网络的形成和演化，来回答我们的社会怎么会变成现在这个样子，并尝试预言我们所处的社会有可能会走向怎样的未来。我特别喜欢赫拉利的书，一是因为他的写作方式特别通俗，不像那种单纯面向学术读者的书那样枯燥；二是因为他的一些观点真的很有启发性。接下来，我们就一起通过这本书提供的视角，了解一下信息网络的昨天、今天和明天，好好审视一下我们自身的命运吧。

### 人类力量的根源：大规模合作与讲故事

我们都知道，力量从来都不是个人努力的结果。即使你力大如牛，一口气能扛起200斤的小麦，也没有办法凭借这种个人的力量去支配别人。人类的力量，其实来源于大批人类的合作。所以，有些皇帝虽然看起来弱不禁风，一对一打架的话，可能连我都能甩他一个“大逼兜”，但他却可以让无数壮士人头落地。没错，我们**智人**（Homo Sapiens: 现代人类的学名）之所以能统治世界，其实并不是因为我们有多聪明，而是因为唯有智人能够进行灵活的大规模合作，而且能够互相合作的智人数量是没有上限的。天主教徒人数高达14亿，全球贸易网络更是能将80亿人全部连接起来。

智人的这种大规模合作能力，大概是从7万年前演化出来的。经过这一轮大脑结构和语言能力的演化之后，智人具备了讲述并相信各种虚构故事，而且能为之深深感动的能力。从那之后，为了合作，智人之间就不一定需要真正地彼此了解了，只要大家都知道同一个故事就行了。同一个故事可以讲给成千上万乃至几十亿人听，这就好比一个有着无限插座的中心枢纽，可以让所有人都插入进来建立起连接。所以，讲故事其实就是人类历史上最早的信息技术。

### 秩序的构建：从故事到官僚制度

说到这儿，反应快的小伙伴应该已经发现了，人类构建起庞大的信息网络，并不是为了追求真理，只是为了维持秩序与合作。所以故事不像物理定律，不需要基于客观现实。如果你制造了一个完全无视物理定律的炸弹，这颗炸弹就不可能响彻云霄；但是如果你创造出一套完全无视事实的意识形态，这套意识形态也依旧可能惊天动地，因为即使这些叙述不完全真实，也能有效地把人们动员起来。所以我们看到，掌握权力的往往是那些善于创造意识形态来维持秩序的人，至于那些只知道怎么制作炸弹的人，则只能乖乖听令。所以在电影《奥本海默》里我们看到，**奥本海默**（J. Robert Oppenheimer: 美国理论物理学家，曼哈顿计划的科学主任）要听富兰克林·罗斯福的话，还要被各种官僚挤兑。

在故事无法精细管理社会现实的情况下，人们就发明出了官僚制度。于是，合同、税务记录等文献记录就成为了管理的基础。从此之后，人类通过故事构建起的秩序，就是靠官僚制度来维持的。官僚制度的确大大提高了社会管理的效率，但是也存在一个严重的问题，就是它难以适应社会的变化。毕竟，官僚制度是依靠人来办事的，而既然是人类就难免犯错，所以人类的秩序总是维持一段时间之后就崩溃了，然后被新的秩序所取代。

### 自我修正机制：宗教、科学与政治体制

因此，任何秩序都需要一种自我修正机制。宗教秩序的自我修正机制往往都很弱，因为宗教经典寄希望于把权威投射在一个绝对正确的文本上，比如《圣经》、《古兰经》之类的，借此避开凡人可能会犯的错误。所以它总是宣称自己绝对正确，这样一来它就无法承认自己在制度上的错误。你绝对不会听到教皇向全世界人宣布，“啊，教会的专家刚刚发现《圣经》里面有一处严重的错误，不要紧我们马上就会发布2.0版本。”总之就是经文肯定是没错的，教义肯定是没错的。如果你问教皇为什么现代对犹太人、对女性更宽容了，教皇肯定会告诉你，“啊，经文本来就是这么写的，教义本来就是这样的，只不过是过去的和尚把经念歪了。”

相比之下，科学的自我修正机制就格外强大了，因为科学界的情况和宗教界的情况恰恰相反。你必须揭露现有理论的某种错误，或者发现一些前辈不知道的内容，才能在优秀期刊上发表论文。所以，科学机构不仅愿意承认自己的错误与无知，还会积极地揭露这些错误与无知。但是，科学机构的官僚制度之所以有强大的自我修正机制，是因为它不负责维护社会秩序。而警察、军队、政党、政府这些负责维护社会秩序的官僚机构，情况就有所不同了。

在维护社会秩序的制度方面，人类信息网络演化出了两种主要模式：极权政体和民主政体。极权政体是一种集中式的信息网络，所有信息都要汇集到中央进行处理，不允许任何独立机构自己做出决策。中央希望自己能牢牢把控着一切的信息流动，彻底掌握人民的所有生活，因为中央相信自己绝对正确，或者说把自己确立为正确的标准。民主政体则是一个分布式的信息网络，除了中央之外还有许多独立的节点，大多数信息并不会经过任何政府机构，独立节点可以自行处理信息并做出决策。民主政体相信人人都可能犯错，因此在赋予中央一些重大决策权的同时，还会保留一些能够挑战中央权威的强大机制。因此，所谓极权，其实就是由一个单一的中央信息枢纽来决定一切；而所谓的民主，则是由无数的信息节点持续对话，这些节点常常会相互影响，但是在很多问题上并不需要真正达成共识。不难看出，相比之下，民主政体的自我修正机制更强一些，极权政体的自我修正机制则比较弱。

### 现代信息技术对极权与民主的双重影响

那么按理来说，随着信息技术的不断发展和迭代，极权主义政体应该会被历史慢慢地淘汰掉才对。然而，情况却恰恰相反。现代新晋的信息技术，不但催生出了大规模的民主，也催生出了大规模的极权。为什么呢？因为在现代信息科技的加持之下，无论是让信息集中向中央流动，还是扼杀真相以维持秩序，都变得更容易了。那么问题就来了，现代先进的信息技术为什么会导致这样一个结果呢？

刚才我们回顾了人类如何通过故事、文献、制度构建起人与人之间的连接，也就是人类的信息网络。但是随着现代信息技术的发展，一种非生物的信息网络逐渐被构建了起来。所以，如果我们要想了解这个现代信息技术会把我们带向一个怎样的未来，就必须得先了解一下这个非生物的信息网络。

### 非生物信息网络的力量：计算机与AI

这个非生物的信息网络是由计算机构建起来的。计算机刚被发明出来的时候，人们普遍觉得它就是一个辅助人类的工具而已。但是随着技术的迭代，现在的计算机显然已经不再是一个单纯的工具了，而是能够独立决策与生成信息的，信息网络中的新成员。而说到计算机所掌握的力量，一个典型的案例就是社交媒体算法如何在一些国家制造与传播仇恨。

就比如发生在2016至2017年的**脸书**（Facebook: 全球最大的社交媒体平台之一）算法助长缅甸宗派冲突事件。2016至2017年，一个名为**若开罗星亚救世军**（Arakan Rohingya Salvation Army, ARSA: 缅甸若开邦的罗兴亚武装组织）的伊斯兰极端组织发动了一系列袭击，希望在若开邦建立一个伊斯兰国家。没想到随后缅甸政府军决定“用魔法打败魔法”，与佛教极端分子一起，发动了一场针对整个**罗兴亚人**（Rohingya: 缅甸若开邦的少数民族，主要信奉伊斯兰教）的种族清洗，杀害了7,000至25,000名平民，强奸虐待了18,000至6万名男女，并将73万名罗兴亚人赶出了缅甸。这些暴力活动是出于对所有罗兴亚人强烈的仇恨，而这种强烈的仇恨则来自于对罗兴亚人的负面宣传。这些负面宣传基本上都是在脸书上进行传播的，正是脸书算法不断地向缅甸人推送这些仇恨的信息，自动播放相关的视频以维持用户粘性。

当然了，计算机所掌握的力量还远不止如此。到了今天，计算机与计算机之间的连接已经可以完全不需要人类参与了。比如A计算机可能会写出一则假新闻，并将其发布到社交媒体上；B计算机可能会判断这就是一条假新闻，于是不仅会立刻删除它，还会警告其他计算机封锁这条新闻；而与此同时呢，C计算机分析了AB计算机的这些行为，判断这可能是一场政治危机的开端，于是立刻卖出高风险企业的股票，并且买入较为安全的政府债券。这时候，其他正在监控金融交易的计算机也可能为了回应这种状况，进而卖出更多企业股票，于是引发金融衰退。这整个过程可能都只发生在短短的几秒钟之内，人类可能连注意都不会注意到，更别说搞清楚这些计算机在做什么了。

更恐怖的是，计算机不仅拥有如此强大的力量，而且计算机网络还可以全天24小时不间断地运行。人类发展出中央极权式官僚网络最重要的功能之一就是对全民进行监控，但即使是斯大林时代的罗马尼亚政府，也不可能24小时监控所有公民，因为国安局特工也是需要睡觉的。要想持续监控2,000万罗马尼亚公民，大概得需要4,000万特工才能办得到。但是，如果政府在全国布满监控网络，安装间谍软件、监控摄像头、人脸与语音识别软件以及庞大的可搜寻数据库，其实就相当于有了无数不用睡觉的特工，那么持续监控所有的国民也就不再是梦了。这就是我在视频开头说的，在我们这压根就没有任何隐私可言的原因，因为我们所有人，都已经处在24小时不间断的监控之下了。由计算机构成的非生物信息网络可以永远开机运行，所以计算机网络正在倒逼人们接受一种新的生活方式，就是永远开机、永远连接、永远受监控。

### 计算机的“数字心灵”与公正的挑战

我知道有人可能会说：“哎呀，不用这么悲观，计算机取代人类支配这个社会其实是件好事。人类最大的问题就是人难免会犯错嘛，但是计算机算法趋于完善之后，却可以永远正确，永远找到最优解。那这样一来，我们不就相当于生活在一个全知全能的上帝所统治的‘上帝的国度’了吗？”但这种想法显然是“too young too simple naive”。其实从前面脸书煽动种族灭绝的例子就能看出来，计算机算法为了使自己获得力量，会去怎样利用人类。

而且，目前的很多研究都已经显示，计算机算法虽然不是生物实体，也没有意识，但也确实拥有类似于“数字心灵”的东西，甚至可能出现某种计算机之间的神话观点、虚构故事。所以，计算机算法同样可能有种族歧视、厌女、恐同、反犹主义倾向。2016年微软推出了一个智能聊天机器人，这个机器人可以自动读取人们在Twitter上的发言，然后与人们进行互动。结果不到几个小时，这个机器人就已经开始发表厌女和反犹的言论了，恶毒的言论不断增加，吓坏了微软的软件工程师，于是不到16小时就把它下架了。这些例子都充分说明，单靠技术是无法保障正义的。正因为如此，现代信息技术才会催生出大规模的极权。

### 民主制度的脆弱与极权制度的悖论

但是，潘多拉的魔盒一旦打开，就覆水难收了。人类现在已经不可能逆转这个网络不眠不休、自动化决策、由非人类主导的信息时代了。那么在这种背景之下，民主制度还能在21世纪存活吗？我们都知道，民主制度的存续依赖于信息公开和自我纠正机制。独立司法、自由媒体、选举都依赖于真实信息的流动。但是现在的背景之下，计算机却可以轻易地削弱民主制度的自我纠正机制，导致民主制度的失败。为什么呢？因为AI算法轻易就能制造出信息茧房，导致不同群体之间的对话消失。社交媒体中的AI推荐机制也可以轻易地操控舆论，加剧社会分裂。机器人账号还可以轻易地伪装成人类，参与政治讨论，甚至可能直接干预选举。

那说到这，有人可能就会问了：“照你这么说的话，在现在这种背景之下，极权制度一定会大获成功喽？”这倒也未必。人工智能算法确实有可能成为极权的利器，因为过去极权制度失败，基本上都是因为信息过于集中，无法容错，导致系统僵化。而现在借助AI的人脸识别、数据分析，国家就可以对公民进行全天候监控。算法还可以替代审查员与宣传员，精准投放思想灌输类的内容。权力者还可以利用AI构建完美的监控机器，比历史上任何极权体系都更高效。

但是，极权制度在人工智能面前也并非无往不利。因为首先，这个极权政府就没有控制非生物行为的经验。专制信息网络是以恐怖统治为基础的，但是计算机却没有办法被关进监狱，被虐待，被谋杀。在极权国家里，如果哪个国民讲了个“伟大领袖”的笑话，他肯定马上就会被抓进监狱；但要是某个聊天机器人讲了个“伟大领袖”的笑话，你又能拿他怎么样呢？特工既没法把他抓起来折磨，也没法威胁他的家人。该国政府确实可以删除或封锁这个程序，或者找出并惩罚写出这个程序的人，但总归都是比平常教训人民要难多了。人类工程师确实可以尽最大的努力，打造出尽可能向政府看齐的人工智能，但是别忘了，人工智能是有自我学习和演化能力的，所以保不齐哪一天就会走向政府的对立面，让独裁者被科技反噬，出现这种“君主控制不了自己的工具”的悖论。

### AI带来的全球权力重塑与“硅幕”降临

但是，盼望极权政府垮台的人，不要觉得这一定就是好事。因为独裁政权被科技反噬之后，有可能会造成更严重的后果。我们都知道，独裁者都是不择手段追求权力的人，所以当他们发现人工智能算法可以成为极权的利器之后，肯定会不择手段地去发展人工智能。虽然目前计算机还没有强大到完全摆脱人类的控制或是摧毁人类文明，但是一个偏执的独裁者却很可能会让犯错的人工智能拥有无限的权力。就比如一个独裁者，如果对人工智能的信任程度比对国防部长还高，肯定就会让人工智能来掌管一国威力最强大的武器。那这时候如果人工智能犯了错，或者开始追求非人类的目标，就可能会对整个人类文明造成灭顶之灾。

而且，你永远都不会知道AI会如何重塑全球的权力格局。赫拉利就觉得，说不定将来会出现一种**“硅幕”**（Silicon Curtain: 赫拉利提出的概念，指未来世界可能因科技划分成的数字阵营），就类似于冷战时期的“铁幕”，把整个世界划分为不同的数字阵营。一些科技巨头可能会演化成比传统国家更强大的数字帝国，他们通过数据掌握了人类的记忆，通过算法推荐掌握着一切的叙事，甚至通过预测与引导对人类行为进行控制，使普通人彻底失去自由与主体性。

### 结语：对人类命运的深思

这就是这本书大致的一个内容了。其实作者写这本书就是想告诉我们，人工智能并不仅仅是一个技术问题，而是关乎民主存亡、关乎权力结构与人类命运的政治问题。所以人类必须谨慎对待。但遗憾的是，我们这些普通的个体，好像谁都左右不了什么。不过我相信，凡是看到这里的观众，多少还是会对人类命运和自身命运产生一些有价值的思索。如果你愿意的话，可以分享在评论区。好，那以上就是本期视频的所有内容了。非常感谢大家的收看，阅读丰富人生，我是安争鸣，我们下期再见吧，拜拜。