---
author: Hung-yi Lee
date: '2025-10-26'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=Taj1eHmZyWw
speaker: Hung-yi Lee
tags:
  - machine-learning-fundamentals
  - gradient-descent
  - model-training-workflow
  - overfitting
  - neural-networks
title: 一堂课搞懂机器学习与深度学习：从三大步骤到模型训练实战
summary: 本文详细拆解了机器学习的核心三步骤：定义目标（损失函数）、划定范围（模型选择）与寻找最优解（优化算法）。通过“预测课程时长”的生动案例，从线性回归讲到深度神经网络，并深入探讨了梯度下降、过拟合、验证与超参数调优等关键概念，最后通过代码实战展示了完整的模型训练与验证流程。
insight: ''
draft: true
series: ''
category: technology
area: tech-insights
project:
  - systems-thinking
  - ai-impact-analysis
people:
  - Hung-yi Lee
companies_orgs:
  - PyTorch
  - TensorFlow
  - ChatGPT
products_models:
  - BERT
  - Adam
  - SQuAD
media_books:
  - 《鬼灭之刃》
  - 《一拳超人》
status: evergreen
---
### 机器学习的核心：从数据中寻找函数

到目前为止，我们已经探讨了生成式人工智能的基本原理：存在一个函数 F，它接收未完成的句子（输入 X）并输出下一个 Token（F(X)）。我们剖析了 F 的内部结构，但始终没有解答一个核心问题：这个函数 F 是如何被找出来的？

今天，我们将深入探讨这个核心问题。寻找一个能够根据未完成句子预测下一个 Token 的函数 F 的技术，统称为**机器学习**（Machine Learning: 一种通过数据和算法来模仿人类学习方式，并不断提高其性能的计算机科学领域）。本课程将分为原理和实作两部分，帮助大家彻底理解机器学习与深度学习的基本概念。

### 案例引入：如何预测老师何时下课？

虽然在生成式 AI 中，我们要找的是一个语言模型，但机器学习技术的应用范围远不止于此。为了更好地理解其通用性，我们将使用一个与语言模型无关的例子：创建一个函数，输入是李宏毅老师的课程投影片（X），输出则是老师讲授这堂课所需的时间（Y）。

这个函数的输出是一个具体的数值，这类任务在机器学习中被称为**回归**（Regression: 一种预测连续值输出的监督学习技术）。这个函数能回答一个所有学生都关心的问题：“老师什么时候下课？”只要将当前的投影片输入这个函数，它就能预测出课程的大致时长。

### 机器学习第一步：定义目标 (计算损失)

寻找一个函数的过程，我们称之为学习（Learning）或训练（Training），可以概括为“3+1”个步骤。前三个核心步骤分别是：
1.  定义目标：我要找什么样的函数？
2.  划定范围：我有哪些函数可以选择？
3.  寻找最优：如何从选择中找出最好的函数？

第一步是设定评判标准。假设有人给了我们一个函数 F，我们必须有能力评估它的好坏。这与我们之前讨论的“生成式人工智能能力检定”非常相似。评估一个模型通常需要准备一些输入，让模型产生输出，然后将输出与标准答案进行比较，计算它们之间的某种距离或相似度。所有这些差异的平均值，我们称之为评估指标（Evaluation Metric）。

在训练的第一个步骤中，我们做的事情与评估几乎完全相同。以预测课程时长为例，我们拥有老师过去上课的投影片和对应的实际授课时长。我们将这些投影片输入函数 F，得到预测时长，然后计算预测值与真实值之间的差距。

例如，我们将差距取平方后求平均值。这个平均值代表了函数的好坏：数值越小，预测越精准。当评判标准是数值越小越好时，这个数值被称为**损失**（Loss: 在机器学习中，用于衡量模型预测值与真实值之间差异的函数），或成本（Cost）。如果标准是越大越好，则称为目标（Objective）。

在这个案例中，我们计算预测时长与真实时长差距的平方和的平均值，这个特定的损失函数叫做**均方误差**（Mean Squared Error, 简称 **MSE**）。计算损失所用到的数据，即过去的投影片和对应的真实时长，被称为**训练数据**（Training Data: 用于训练机器学习模型的数据集）。

### 机器学习第二步：划定范围 (选择模型)

确定了评判标准后，我们需要划定一个候选函数的集合，也就是我们有哪些选择。

首先，函数无法直接处理“投影片”这种非数字输入。我们需要将其转化为数字，例如：投影片的页数（x1）、总字数（x2）、标题长度（x3）、是否包含“learning”一词（x4，用 0 或 1 表示）等。这些用于表示输入的数值被称为**特征**（Feature: 在机器学习中，指用于模型输入的单个可测量属性或特性）。

接下来，我们需要假设函数 F 的基本形态。一个直观的假设是，课程时长（y）与投影片页数（x1）成正比，可能还有一个固定的开场时间。因此，我们可以设定函数的形式为 `y = w1 * x1 + b`。

在这个函数中，w1 和 b 的具体数值是未知的，它们被称为**参数**（Parameter: 模型内部的变量，其值可以通过训练数据学习得到）。当我们把函数写成这种形式时，由于参数未知，它实际上代表了一个函数的集合。这个集合中的每一个函数都对应着一组特定的 w1 和 b 的值。这种形式的回归任务被称为**线性回归**（Linear Regression: 一种基本的回归分析，用于模拟自变量和因变量之间的线性关系）。

这个函数集合的范围是由人类根据对问题的理解，即**领域知识**（Domain Knowledge: 特定领域的专业知识）来划定的。我们相信页数与时长存在线性关系，所以选择了这个形式。这个由人类设定的函数范围，就是所谓的**模型**（Model: 对现实世界过程的数学表示，包含一系列参数，通过训练来学习）。如果你对问题有不同的理解，完全可以设计更复杂的模型，比如加入更多特征或非线性关系。

### 机器学习第三步：寻找最优函数 (优化问题)

有了目标（损失函数）和范围（模型）之后，第三步就是在我们划定的范围内，找到一个能让损失最低的函数。

损失 L 是参数 w1 和 b 的函数：选择不同的 w1 和 b，就会得到不同的函数，从而计算出不同的损失值。我们的目标是找到一组最优的 w1* 和 b*，使得 `L(w1, b)` 的值最小。这个问题被称为**优化**（Optimization: 在给定约束条件下，寻找一组参数以最大化或最小化某个目标函数的过程）。

对于只有两个参数的简单问题，我们可以使用最暴力的方法：穷举。在一个预设的范围内，遍历所有可能的 w1 和 b 的组合，计算每个组合对应的损失值，然后找出损失最小的那一个。我们可以将不同参数组合对应的损失值绘制成一个三维图形，这个图形被称为**损失地表**（Loss Surface）。通过观察这个地表，我们可以找到最低点，即最优的参数组合。

然而，在真实场景中，模型参数可能成千上万甚至数十亿，穷举法完全不可行。因此，我们需要一个更通用的优化算法。

### 梯度下降法：沿着最陡峭的路径下山

一个几乎适用于所有模型和损失函数的通用优化方法叫做**梯度下降法**（Gradient Descent: 一种迭代优化算法，用于寻找函数（通常是损失函数）的局部最小值）。

为了简化说明，我们先假设只有一个参数 w1。梯度下降法的思想是：
1.  **随机初始化**：从一个随机的 w1 值（w0）开始。
2.  **计算梯度**：计算当前位置的“坡度”，即损失函数对参数 w1 的偏微分（切线斜率）。这个斜率指明了让损失增大的方向。
3.  **更新参数**：朝着斜率相反的方向（即下坡方向）迈出一步。步长的大小由**学习率**（Learning Rate: 一个超参数，用于控制每次参数更新的步长）和斜率的大小共同决定。斜率越陡，步子迈得越大。
4.  **迭代**：重复步骤 2 和 3，直到走到一个斜率接近于零的地方（山谷的底部），此时就停止更新。

梯度下降法的一个明显缺点是它可能会陷入**局部最小值**（Local Minimum），而错过了全局最低点（Global Minimum）。

当有多个参数（如 w1 和 b）时，过程是类似的。我们会计算损失函数对每个参数的偏微分，这些偏微分共同组成一个向量，称为**梯度**（Gradient）。然后，我们沿着梯度的反方向更新所有参数。幸运的是，现代深度学习框架（如 PyTorch、TensorFlow）能够自动计算梯度，我们无需手动进行复杂的微积分运算。

### 训练实用技巧：批量处理与随机打乱

在实际应用中，训练数据量可能非常庞大。如果每次计算梯度都遍历所有数据，会非常耗时。因此，我们通常采用一种更高效的方法：

我们将整个训练数据分成若干个小份，每一份称为一个**批次**（Batch）。每次我们只用一个批次的数据来计算梯度并更新参数，而不是用全部数据。这种方法被称为**随机梯度下降**（Stochastic Gradient Descent, **SGD**）或小批量梯度下降。

当模型看完了所有批次的数据一次，这个过程被称为一个**周期**（Epoch: 在模型训练中，指整个训练数据集被模型完整地过了一遍）。在一个周期内，参数会被更新多次（次数 = 总数据量 / 批量大小）。

使用批次的好处是更新速度快，但缺点是每次更新的方向可能不太稳定，因为只基于一小部分数据。批量大小（Batch Size）是一个需要手动调整的**超参数**（Hyperparameter: 在开始学习过程之前设置值的参数，而不是通过训练得到的）。

此外，为了增加随机性，避免模型反复看到内容相同的批次，我们通常会在每个周期开始前对训练数据进行**随机打乱**（Shuffle）。

### “3+1”的关键一步：验证模型

完成了上述三个步骤，找到了一个在训练数据上损失很低的函数，我们能直接拿来用了吗？还不行。我们需要进行第四个，也是至关重要的一步：**验证**（Validation）。

验证就像是模拟考试，而最终的应用则是真正的大考（测试）。我们需要准备一份模型在训练过程中从未见过的数据，称为**验证集**（Validation Set）。我们用在训练集上找到的最优模型来对验证集进行预测，并计算其损失。

### 迭代与反思：当验证失败时该怎么办？

如果在验证集上，模型的表现很差（损失很高），那就意味着前面的三个步骤中可能存在问题。我们需要回头检查：

1.  **检查步骤一（目标定义）**：训练数据和验证数据的分布是否一致？如果用“2021年机器学习”课程的数据训练出的模型，去预测“2025年生成式AI导论”课程的时长，可能会因为两门课程性质不同（如导论课每页PPT讲解时间更短）而导致预测不准。这说明我们的训练目标（由训练数据定义）与实际应用场景不匹配。解决方法是更换更具代表性的训练数据。

2.  **检查步骤二（模型选择）**：我们选择的函数范围是否太小？线性模型 `y = w1*x1 + b` 只能表示直线关系。如果数据背后的真实关系是曲线，线性模型永远也无法拟合好。我们需要一个能表示更复杂函数的模型范围。

### 扩展模型边界：从线性回归到深度学习

如何构建一个能逼近任意函数的模型呢？理论上，任何复杂的曲线都可以通过足够多的短直线段（**分段线性曲线**，Piecewise Linear Curve）来近似。而任何分段线性曲线又可以由一个常数和多个“山坡形状”的函数叠加而成。

进一步拆解，这些“山坡形状”的函数可以由两个更基础的函数组合而成。这个基础函数的形式是 `max(0, wx + b)`，它有一个非常著名的名字：**修正线性单元**（Rectified Linear Unit, **ReLU**）。

通过将多个 ReLU 函数的输出进行加权求和，我们就可以构建出能够逼近任意复杂函数的模型。这个过程可以被图像化：
*   输入特征（如 x1, x2）分别乘以不同的权重（W），加上一个偏置（b），然后通过 ReLU 函数得到一组输出（a）。
*   这个“乘以权重、加上偏置、通过激活函数”的单元，我们称之为一个**神经元**（Neuron）。
*   多个神经元并行排列，组成一个**层**（Layer）。
*   将多个层堆叠起来，前一层的输出作为后一层的输入，就构成了**神经网络**（Neural Network）。
*   当神经网络包含很多个隐藏层（Hidden Layer）时，它就被称为**深度学习**（Deep Learning）。

在神经网络中，计算梯度的有效算法被称为**反向传播**（Backpropagation），它本质上是梯度下降法的一种高效实现方式。

### 深度学习的挑战：优化困境与过拟合

虽然深度学习模型拥有强大的表达能力，但训练过程也面临新的挑战：
1.  **优化失败**：由于损失地表极其复杂，梯度下降很容易陷入局部最小值或**鞍点**（Saddle Point），或者在梯度极其平缓的区域停滞不前，导致找不到足够低的损失。这需要我们仔细调整超参数（如学习率、批次大小、初始化方式）或使用更高级的优化器（如 Adam）。
2.  **过拟合**（Overfitting）：当模型过于复杂（函数范围过大）时，它可能会“记住”训练数据中的所有细节，包括噪声，而不是学习到底层的规律。这会导致模型在训练集上表现完美（损失极低），但在未见过的验证集上表现极差（损失极高）。这就像驾校学员只学会了根据特定标记（如后视镜里的贴纸）打方向盘，换一个没有标记的场地就完全不会倒车入库了。

### 应对过拟合：早停法与测试集的智慧

应对过拟合有多种策略，其中一种常用且有效的方法是**早停法**（Early Stopping）。在训练过程中，我们不仅监控训练损失，还同时监控验证损失。我们会发现，训练损失会持续下降，但验证损失在下降到某个点后会开始回升。我们就在验证损失最低的那个点停止训练，并保存当时的模型。

在机器学习竞赛或现实应用中，为了更公平地评估模型，测试数据通常会被分为**公开集**（Public Set）和**私有集**（Private Set）。参赛者可以多次提交模型并在公开集上看到分数，但这有对公开集过拟合的风险。最终的排名则由模型在仅有一次机会的私有集上的表现决定，这能更真实地反映模型的泛化能力。

### 代码实战：一步步实现课程时长预测模型

接下来，我们将通过一个完整的代码示例，将上述所有理论概念付诸实践。我们将：
1.  加载和准备数据（不同年份课程的投影片页数、字数和时长）。
2.  从一个简单的线性模型开始，通过暴力穷举和梯度下降法进行训练。
3.  进行模型验证，发现问题并迭代改进，例如更换训练数据、增加新特征（从总字数到平均每页字数）。
4.  构建并训练一个神经网络模型，体验优化过程的挑战与乐趣。
5.  观察并利用早停法来应对过拟合，找到在验证集上表现最佳的模型。
6.  最后，用我们训练出的最优模型，来预测今天这堂课的实际时长，完成最终的“测试”。

通过这一系列动手操作，你将对机器学习从理论到实践的整个流程有一个更深刻、更直观的理解。