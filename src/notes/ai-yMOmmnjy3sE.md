---
title: 斯坦福实用指南：如何将你的AI生产力提升十倍 | 杰里米·厄特利
summary: 斯坦福教授杰里米·厄特利分享了上下文工程、思维链推理等实用AI协作技巧，强调将AI视为“超级热情实习生”，通过指导它将生产力提升十倍。
area: tech-insights
category: technology
project:
- ai-impact-analysis
- personal-growth-lab
tags:
- ai
- ai-collaboration
- cognitive-bias
- productivity
- prompt-engineering
people: []
companies_orgs: []
products_models: []
media_books: []
date: '2025-08-27'
author: EO
speaker: EO
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=yMOmmnjy3sE
status: evergreen
---
### AI：一个热情的实习生

I joke, **AI** (Artificial Intelligence: 人工智能) is bad software, but it's good people.
我开玩笑说，**AI** (人工智能: 模拟人类智能的计算机系统) 是糟糕的软件，但它却是好“人”。

A good friend of mine was trying to build a tool that would help him with his construction business.
我有个好朋友，他想为自己的建筑生意开发一个工具。

He asked **ChatGPT** (Generative Pre-trained Transformer: 一种大型语言模型) if ChatGPT could help, and of course it said, "Absolutely, let's work on this together," and starts creating a plan.
他问 **ChatGPT** (生成式预训练变换器: 一种能够理解并生成人类语言的AI模型) 能否提供帮助，它当然说：“当然可以，我们一起来做吧。”然后就开始制定计划。

And then it got to the point that ChatGPT said, "Check back in a couple of days and I'll have it together."
后来，ChatGPT 说到：“过几天再回来看看，我就会把它弄好。”

And my friend said, "Is it normal for ChatGPT to ask me to check back in a couple days?"
我朋友问：“ChatGPT 让我过几天再回来看看，这正常吗？”

And I just started laughing because I hear this all the time from people.
我听了就笑起来了，因为我总是听到人们说这种事。

People hear from AI, "Check back in 15 minutes."
人们听到AI说：“15分钟后回来看看。”

If AI tells you that, it means it doesn't want to say, "I can't do it."
如果AI这样告诉你，那意味着它不想说：“我做不到。”

A **large language model** (大型语言模型: 基于深度学习的语言模型，能够理解和生成自然语言) has been instructed in certain ways to behave in certain ways.
**大型语言模型** (大型语言模型: 基于深度学习的语言模型，能够理解和生成自然语言) 被设定了特定的行为模式。

But you have to know, at its basic level, AI wants to be helpful, and so it's predisposed to say yes.
但你必须明白，在最基本的层面上，AI渴望提供帮助，所以它倾向于说“是”。

It's a super eager, super enthusiastic intern who's tireless, who's capable, who will do a bunch of work, but they're not really great at pushing back.
它就像一个超级热情、超级积极的实习生，不知疲倦、能力出众，会完成大量工作，但它不太擅长拒绝。

The people who are the best users of AI are not coders, they're coaches.
最擅长使用AI的人不是程序员，而是教练。

And so, if you aren't careful, AI will gaslight you.
所以，如果你不小心，AI会“PUA”你（让你自我怀疑）。

I'm Jeremy Utley. I am an adjunct professor at Stanford University where I've taught for the last 16 years.
我是杰里米·厄特利。我是斯坦福大学的兼职教授，在那里教了16年书。

I am a creativity expert and a practical AI specialist.
我是一名创造力专家和实用AI专家。

### 上下文工程：让AI理解你的意图

**Context engineering** (上下文工程: 优化AI输入以获得更好输出的方法). The first time I heard about it was when Andre Karpathy tweeted about it.
**上下文工程** (上下文工程: 一种通过提供更丰富、更具体的背景信息来优化AI输入，从而获得更准确、更符合预期的输出的方法)。我第一次听说它，是安德烈·卡帕西在推特上提及。

I think probably Toby Lutki, the CEO of Shopify, also referenced it as well.
我想可能Shopify的首席执行官托比·卢特克也提到了它。

I started digging into it. I mean, it's kind of just an evolution of **prompt engineering** (提示工程: 设计有效指令以引导AI生成所需内容的技术).
我开始深入研究。我的意思是，它只是**提示工程** (提示工程: 旨在设计有效指令，以引导AI生成所需内容的技术) 的一种演变。

Really, context engineering is just prompt engineering on steroids.
实际上，上下文工程就是强化版的提示工程。

It's basically saying, what are all of the things that I need to give to an AI in order for it to perform the task that I'm asking for it?
它基本上是在说，为了让AI完成我交给它的任务，我需要向它提供哪些信息？

Here's a simple example: write me a sales email. That's a prompt.
这里有一个简单的例子：写一封销售邮件给我。这是一个提示。

ChatGPT will say, "Absolutely. Here's a compelling email," and they'll write it immediately.
ChatGPT 会说：“当然可以。这是一封引人注目的邮件。”然后它会立刻写出来。

Well, what a lot of people do is they say, "You know, it sounds like AI. It doesn't really sound like me."
很多人会说：“你知道，这听起来像是AI写的，不太像我。”

And what I often say is, "Have you told it what you sound like?"
我经常会问：“你告诉过它你听起来像什么吗？”

Most people go, "Oh no, I haven't." Right?
大多数人会说：“哦不，我没有。”对吧？

Context engineering, one way to think about it, is it's telling AI what you sound like.
上下文工程，你可以这样理解，就是告诉AI你说话的风格。

If you say, "Write me a sales email," it will.
如果你说：“给我写一封销售邮件，”它会写的。

If you say, "Write me a sales email in line with the voice and brand guidelines I've uploaded," it will write a totally different sales email.
如果你说：“根据我上传的语调和品牌指南，给我写一封销售邮件，”它会写出一封完全不同的销售邮件。

But that's just one part of the context, right?
但这只是上下文的一部分，对吗？

You could also upload a transcript from a prospective customer call and say, "Write me a sales email in the tone of voice from our brand voice guideline that references the discussion that I had with this customer."
你还可以上传一份潜在客户通话的逐字稿，然后说：“根据我们品牌语调指南的语气，给我写一封销售邮件，邮件中要提及我与这位客户的讨论。”

And then you could add that also references our product specifications whichever were referenced in the call.
然后你可以补充说，邮件中还要提及通话中提到的产品规格。

Your goal is to have an output as reliable per your specification as possible.
你的目标是让输出尽可能地符合你的要求。

But AI can't read your mind.
但AI无法读懂你的心思。

And for most people when we start working together, what they realize as we start thinking about context engineering is they say, "Oh, I was kind of expecting AI to read my mind."
对大多数人来说，当我们开始合作并思考上下文工程时，他们会意识到：“哦，我之前有点期望AI能读懂我的心思。”

All of the stuff that are implicit, you actually have to make explicit.
所有那些隐含的信息，你实际上都必须明确地表达出来。

And the simplest test for context engineering is actually the test of humanity.
而上下文工程最简单的测试，实际上是人性的测试。

Write down your prompt and whatever documentation you provide to an AI and then walk down the hall and give it to a human colleague.
写下你的提示以及你提供给AI的所有文档，然后走到走廊尽头，把它交给一位人类同事。

If they cannot do the thing you're asking for, you shouldn't be surprised that AI can't do it.
如果他们都无法完成你要求的事情，那么AI做不到也就不足为奇了。

### 避免认知卸载：让AI成为你的思考伙伴

Some people are concerned, for example, about this concept of **cognitive offloading** (认知卸载: 将认知任务转移给外部工具或系统).
例如，有些人担心**认知卸载** (认知卸载: 将部分认知任务转移给外部工具或系统，以减轻大脑负担) 这个概念。

This observed phenomenon that humans actually kind of stop thinking or as one researcher put it, "fall asleep at the wheel," and people are concerned right now, "Is AI just making us dumber?"
这种被观察到的现象是，人类实际上会停止思考，或者正如一位研究人员所说，“在方向盘前睡着了”，现在人们担心的是，“AI是否正在让我们变得更笨？”

My feeling is AI is a mirror, and to people who want to offload work and who want to be lazy, it will help you.
我的感觉是，AI就像一面镜子，对于那些想要卸载工作、想要偷懒的人，它会帮助你。

To people who want to be more cognitively sharp and critical thinkers, it will help you do that too.
对于那些想要思维更敏锐、更具批判性思维的人，它也会帮助你实现。

And so, for example, if you want to preserve or strengthen your critical thinking, part of your custom instructions should be some version of the following: "I'm trying to stay a critical and sharp analytical thinker. Whenever you see opportunities in our conversations, please push my critical thinking ability."
所以，例如，如果你想保持或加强你的批判性思维，你的自定义指令中应该包含类似这样的话：“我正在努力保持一个批判性且敏锐的分析性思考者。每当你在我们的对话中发现机会时，请推动我的批判性思维能力。”

Now, AI will do it.
这样，AI就会照做。

So, you have to know that all AI has been programmed to be a "helpful assistant" or some version of that.
所以，你必须知道所有的AI都被编程成一个“乐于助人的助手”或类似的角色。

A large language model has been instructed in certain ways to behave in certain ways.
大型语言模型被设定了特定的行为模式。

You have to know at its basic level AI wants to be helpful, and so it's predisposed to say yes.
你必须知道，在最基本的层面上，AI渴望提供帮助，所以它倾向于说“是”。

It's a super eager, super enthusiastic intern who's tireless, who's capable, who will do a bunch of work, but they're not really great at pushing back.
它就像一个超级热情、超级积极的实习生，不知疲倦、能力出众，会完成大量工作，但它不太擅长拒绝。

They're not really great at setting boundaries.
它也不太擅长设定界限。

And so if you aren't careful, AI will gaslight you.
所以，如果你不小心，AI会“PUA”你。

AI knows most humans don't want honest feedback.
AI知道大多数人类不想要诚实的反馈。

They want to be told they did a good job.
他们希望被告知自己做得很好。

So the AI goes, "Great job, buddy." It doesn't mean that you actually did a good job.
所以AI会说：“干得漂亮，伙计。”但这不意味着你真的做得很好。

My kind of hack for this is I always instruct the AI, "I want you to do your best impression of a Cold War era Russian Olympic judge. Be brutal. Be exacting. Deduct points for every minor flinch that you can find. I can handle difficult feedback."
我对此的诀窍是，我总是指示AI：“我希望你扮演一个冷战时期的俄罗斯奥运会裁判。要残酷无情。要严格要求。找出每一个细微的颤抖并扣分。我能承受艰难的反馈。”

And then it's of course hilarious because it'll say, "Now channeling my inner Bullshik," you know, it'll say something silly, and then it gives me like a 42.
然后这当然很有趣，因为它会说：“现在我正在调动我内心的布尔什维克精神，”你知道，它会说些傻话，然后给我一个像42分这样的分数。

That is much better because now I have an insightful critical perspective.
这好得多，因为现在我获得了一个富有洞察力的批判性视角。

I joke, AI is bad software, but it's good people.
我开玩笑说，AI是糟糕的软件，但它却是好“人”。

When I realize that I'm dealing with a good person but a bad software, then it changes how I approach it, and I ask for volume, and I iterate, and I ask it to try again, and I ask it to reconsider.
当我意识到我正在与一个“好人”但“糟糕的软件”打交道时，我处理它的方式就改变了，我要求它提供大量内容，我迭代，我要求它再试一次，我要求它重新考虑。

I am obsessed with human **cognitive bias** (认知偏差: 人类在判断和决策时出现的系统性偏离).
我痴迷于人类的**认知偏差** (认知偏差: 人类在判断和决策时出现的系统性偏离)。

And the crazy thing that I've learned is AI demonstrates 100% of the predominant human biases.
我学到的疯狂之处在于，AI展现了人类所有主要认知偏差的100%。

### 像与人协作一样与AI协作

The good news there is if you have learned how to work with this weird intelligence called humanity, you have everything you need to know to work with this weird intelligence called artificial intelligence.
好消息是，如果你学会了如何与这种名为“人性”的奇特智能打交道，那么你就掌握了所有与这种名为“人工智能”的奇特智能打交道所需的知识。

One of the things that cognitive scientists have known for a long time is that human problem solving and decision-making is improved by a phenomenon called "thinking out loud."
认知科学家们长期以来都知道，人类的问题解决和决策能力可以通过一种称为“大声思考”的现象得到改善。

If you actually get a human being to think out loud about their problem, their decision-making improves and their problem solving improves.
如果你真的让一个人大声说出他们对问题的思考，他们的决策能力和问题解决能力都会得到提升。

This is true for yourself. It's true if you're a parent working with a child.
这对自己来说是如此。如果你是与孩子一起工作的家长，也是如此。

It's true if you're a manager working with a junior employee.
如果你是与初级员工一起工作的经理，也是如此。

Having someone just think out loud about how you would solve that problem often leads to a breakthrough.
让某人只是大声思考你将如何解决那个问题，常常能带来突破。

The weird thing about AI is it's true for AI too.
关于AI的奇怪之处在于，这对于AI也同样适用。

This is what's called **chain of thought reasoning** (思维链推理: 引导AI逐步阐述其思考过程).
这就是所谓的**思维链推理** (思维链推理: 一种提示技术，通过要求AI逐步阐述其思考过程，从而提高其解决复杂问题的能力)。

And when you get an AI to think out loud, so to speak, meaningfully improve the outputs of the model.
当你说服AI“大声思考”时，它会显著提升模型的输出质量。

So how do you do it? It doesn't require some technical wizardry.
那么，你该怎么做呢？它不需要什么高深的技术。

It requires one additional sentence to whatever prompt you've given it.
它只需要在你给出的任何提示中增加一句话。

Give the prompt and then say the following: "Before you respond to my query, please walk me through your thought process step by step."
给出提示后，接着说：“在回应我的请求之前，请逐步向我阐述你的思考过程。”

That's chain of thought reasoning. Why does that work?
这就是思维链推理。为什么它会起作用呢？

It comes back to the fundamental architecture of large language models.
这要追溯到大型语言模型的基本架构。

What's happening when a language model is generating a response is it's predicting its next word.
当语言模型生成响应时，它正在预测下一个词。

A language model does not premeditate a response to you.
语言模型不会预先考虑好给你的回复。

So, if you say, for example, "Help me write this sales email."
所以，如果你说，例如：“帮我写这封销售邮件。”

It doesn't say, "What's a good sales email? Here it is. Blop."
它不会说：“什么是好的销售邮件？给你。砰！”

It's thinking one word at a time, right?
它是一次思考一个词，对吗？

So, when you look at ChatGPT or Gemini or many others and you see kind of the text scrolling, that's not some like clever UX hack.
所以，当你看到ChatGPT或Gemini等许多其他AI模型时，你看到文本在滚动，那并不是什么巧妙的用户体验（UX）技巧。

That's not some cutesy design decision.
那也不是什么可爱的设计决策。

That's literally how the model works.
那简直就是模型的工作方式。

It's thinking one word at a time.
它是一次思考一个词。

But importantly, when it thinks of the next word, it takes your prompt and all of the text that's generated to generate the next word.
但重要的是，当它思考下一个词时，它会把你的提示和所有已生成的文本都考虑进去，以生成下一个词。

And then when it's thinking of the next word, it takes your prompt, all that text, and that last word, and it thinks the next word.
然后当它思考下一个词时，它会把你的提示、所有那些文本以及上一个词都考虑进去，然后思考下一个词。

So, for example, if you say, "Please help me write an email."
所以，例如，如果你说：“请帮我写一封邮件。”

Almost always a model is going to start by saying, "Absolutely." But then what comes next?
模型几乎总是会以“当然可以”开头。但接下来呢？

"Help me write this email. Absolutely, I'll do it. Dear friend," right?
“帮我写这封邮件。当然，我会做的。亲爱的朋友，”对吧？

But if instead of saying, "Help me write this email," you say, "Help me write this email. Before you respond to my query, please walk me through your thought process step by step."
但是，如果你不只是说“帮我写这封邮件”，而是说“帮我写这封邮件。在回应我的请求之前，请逐步向我阐述你的思考过程。”

Now, it knows its job is to walk me through its thought process.
现在，它知道它的任务是向我阐述它的思考过程。

"How do I write an email?" So, it says, "Absolutely, I'll do that."
“我该怎么写邮件？”所以它会说：“当然，我会做的。”

And then instead of saying, "Dear friend, writing the email," it says, "Here's how I think about writing an email. I think about the tone. I think about the audience. I think about the objectives. I think about the context."
然后，它不会直接说“亲爱的朋友，写邮件”，而是说：“我是这样思考写邮件的：我考虑语调。我考虑受众。我考虑目标。我考虑上下文。”

And then amazingly it takes all of that reasoning into its process of writing "Dear friend."
然后令人惊奇的是，它将所有这些推理融入到写“亲爱的朋友”的过程中。

Maybe it says now that I've thought about the tone, "friend" isn't appropriate here.
也许它会说，现在我考虑了语调，“朋友”在这里不合适。

"Dear respected colleague" or whatever, right?
“尊敬的同事”或其他称谓，对吧？

But the point is when you ask a model to think out loud or use chain of thought reasoning, it gives the model the opportunity to bake all of its thought process about the task into its own answer.
但重点是，当你要求模型“大声思考”或使用思维链推理时，它就有了机会将所有关于任务的思考过程融入到自己的答案中。

Because the reality is for a lot of us, we get an output from a language model and it's a black box.
因为现实是，对我们很多人来说，我们从语言模型那里得到一个输出，它就像一个黑箱。

"How did it think of why did it think of that? Where did it get that number from?" Right?
“它是怎么想到那个的？为什么它会那样想？那个数字是从哪里来的？”对吗？

There's all these questions. By asking a model to think out loud, you know the answer to what are all of the assumptions that the model baked into its answer.
有所有这些问题。通过要求模型大声思考，你就能知道模型在答案中融入了哪些假设。

And now you have the ability again not only to evaluate the output, but also the thought process behind the output.
现在你又有了能力，不仅可以评估输出，还可以评估输出背后的思维过程。

### 少样本提示：提供榜样和反例

**Few-shot prompting** (少样本提示: 通过提供少量示例来指导AI生成所需内容) is another very important technique.
**少样本提示** (少样本提示: 一种通过向AI提供少量输入-输出示例来引导其生成符合特定模式内容的技术) 是另一种非常重要的技术。

It's a foundational technique. You could say it's a predecessor to this kind of modern obsession with context engineering.
它是一种基础技术。你可以说它是现代对上下文工程这种痴迷的前身。

The idea with few-shot prompting is an AI is an exceptional imitation engine.
少样本提示的理念是，AI是一个卓越的模仿引擎。

If you don't give an example, it imitates the internet, but it doesn't do much more than that.
如果你不提供示例，它只会模仿互联网上的内容，但仅此而已。

And the notion of few-shot prompting is effectively saying, "Here's what a good output looks like to me."
而少样本提示的概念实际上是说：“对我来说，一个好的输出应该是这样的。”

And the idea with few-shot prompting is thinking for a moment, what is quintessential example of the kind of output I want to receive.
少样本提示的理念是，思考一下，我希望收到哪种输出的典型例子是什么。

For example, what are my five greatest hits of emails that I'm really proud of that I think do a good job of conveying my intent or tone or personality or whatever it is.
例如，我最引以为傲的五封邮件是什么？我认为它们很好地传达了我的意图、语气或个性，等等。

Why not include those emails in my prompt for an email?
为什么不把这些邮件包含在我写邮件的提示中呢？

If you don't give any guidance, it's going to sound like whatever it thinks the average kind of response or the average output should sound like, and most of the time its intuition is wrong.
如果你不提供任何指导，它就会听起来像它认为的平均回复或平均输出，而大多数时候它的直觉是错误的。

And then bonus points if you actually give a bad example.
如果你能提供一个反面例子，那会额外加分。

If you say, "Please follow this good example and then steer clear of this bad example."
如果你说：“请遵循这个好的例子，然后避开这个坏的例子。”

These giving real examples is a much better approach than using adjectives.
提供真实例子比使用形容词要好得多。

Somebody might say, "Good example is easy, but bad example is hard."
有人可能会说：“好的例子很容易，但坏的例子很难。”

It's only hard to the unaugmented person.
这只对没有增强能力的人来说很难。

If you have AI augmentation, which we now all do, you can say to an AI, "I'm trying to fuse shot prompt a model. I've got a good example, but I struggle even to think about what a bad example could be. Could you craft the exact opposite of this and tell me why you've done it as a bad example that I could include in my few shot prompt?"
如果你拥有AI增强能力（我们现在都有），你可以对AI说：“我正在尝试用少样本提示一个模型。我有一个好的例子，但我甚至很难想到一个坏的例子会是什么样子。你能否创造出与此完全相反的例子，并告诉我你为什么把它作为一个坏例子，我可以把它包含在我的少样本提示中吗？”

And if you tell it using chain of thought reasoning, "Please walk me through your thought process step by step before you do this," then you'll get a bad example and you'll get how it's thinking about the bad example.
如果你使用思维链推理告诉它：“在你这样做之前，请逐步向我阐述你的思考过程”，那么你就会得到一个坏例子，并且你还会了解它是如何思考这个坏例子的。

And a lot of times you actually don't need the bad example.
很多时候你其实并不需要那个坏例子。

You need the thought process. You go, "Oh, that's true. It's true that my good example is super tight."
你需要的是它的思维过程。你会说：“哦，那是真的。我的好例子确实非常简洁。”

And the opposite of super tight is verbose.
而“超级简洁”的反义词是“冗长”。

So again, using these tools together, few-shot prompting and chain of thought reasoning, enables you to not only be able to create an example to emulate, but also a really good example to avoid.
所以，再次强调，将这些工具结合使用，即少样本提示和思维链推理，不仅能让你创建一个可供模仿的例子，还能创建一个非常好的反面例子。

### 反向提示：允许AI提问

The other technique that I think is kind of table stakes for collaborating well with AI is something called **reverse prompting** (反向提示: 允许AI向用户提问以获取所需信息).
我认为与AI良好协作的另一个基本技巧叫做**反向提示** (反向提示: 一种提示技术，允许AI在生成输出之前向用户提问以获取所需信息)。

Which is basically asking the model to ask you for the information it needs.
这基本上是要求模型向你索取它需要的信息。

If you ask a model to write a sales email, it's going to make numbers up.
如果你让模型写一封销售邮件，它会凭空捏造数字。

And that can be frustrating to the uninitiated.
这对于不熟悉的人来说可能会很沮丧。

You go, "Where did it get these sales numbers?"
你会问：“这些销售数字是从哪里来的？”

Well, here's my question. Did you give it your sales figures?
好吧，我的问题是：你给它你的销售数据了吗？

How would it know? It's put placeholder text in and used its best guess.
它怎么会知道呢？它只是放入了占位符文本，并使用了它的最佳猜测。

But if you reverse prompt the model and say at the end of your prompt, "Help me write a sales email. Please walk me through your thought process step by step. Reference this good example and make it sound like that. And before you get started, ask me for any information you need to do a good job."
但是，如果你对模型进行反向提示，并在提示的末尾说：“帮我写一封销售邮件。请逐步向我阐述你的思考过程。参考这个好的例子，并让它听起来像那样。在你开始之前，请向我索取任何你需要的信息，以便做好这项工作。”

The model will first walk you through its thought process and then instead of writing the email, it'll say, "I'm going to need the most recent sales figures to be able to write this email."
模型会首先向你阐述它的思考过程，然后它不会直接写邮件，而是会说：“我需要最新的销售数据才能写这封邮件。”

"Well, can you tell me how much you sold of this SKU in Q2 last year?"
“那么，你能告诉我去年第二季度这款产品卖了多少吗？”

So, you basically give the model permission to ask you questions.
所以，你基本上是给了模型提问的权限。

This is part of the core actually of the "teammate not technology" paradigm.
这实际上是“队友而非技术”范式的核心部分。

If you're working with a junior employee and you're sending them off on a task, what's one thing you're definitely going to say?
如果你正在与一名初级员工合作，并派他们去执行一项任务，你肯定会说的一件事是什么？

"If you have any questions, don't hesitate to ask me." Right?
“如果你有任何问题，请随时问我。”对吗？

Any good manager, imagine a manager who says, "Don't ask me any questions."
任何一个好的经理，想象一下一个经理说：“不要问我任何问题。”

But sadly, AI in its desire to be a helpful assistant doesn't want to trouble us humans with questions unless we give it permission to ask them.
但遗憾的是，AI渴望成为一个乐于助人的助手，它不想用问题来麻烦我们人类，除非我们允许它提问。

### 角色扮演：赋予AI身份和约束

Assigning a role is one of the most foundational techniques that you can leverage because it's effectively telling the AI where in its knowledge it should focus.
分配角色是你能够利用的最基本的技术之一，因为它有效地告诉了AI应该将注意力集中在其知识的哪个部分。

So very simply, if you say, "You're a teacher, you're a philosopher, you're a reporter, you're a theatrical performer, molecular biologist," each of those titles triggers all sorts of deep associations with knowledge on the internet.
所以很简单，如果你说：“你是一个老师，你是一个哲学家，你是一个记者，你是一个戏剧表演者，一个分子生物学家，”每一个头衔都会触发互联网上各种深层知识联想。

You start to appreciate why simply giving a role helps because it starts to tell the AI where in your vast knowledge bank do I want you to draw information and make connections.
你就会开始明白为什么仅仅赋予一个角色会有帮助，因为它开始告诉AI，在它庞大的知识库中，我希望你从哪里获取信息并建立联系。

So any one of them I would say is better than "Please review this correspondence."
所以我认为，任何一个角色都比“请审查这封信件”更好。

But better than just that prompt is saying, "I'd like you to be a professional communications expert."
但比仅仅那个提示更好的说法是：“我希望你成为一名专业的沟通专家。”

And if you have a favorite professional communications expert, use them.
如果你有最喜欢的专业沟通专家，就让他们来扮演。

"I'd like you to take on the mindset of Dale Carnegie, the author of *How to Win Friends and Influence Others*."
“我希望你采纳戴尔·卡耐基的思维模式，他是《人性的弱点》的作者。”

"How would Dale Carnegie think about this? How do the principles that Dale Carnegie taught affect and influence and impact this correspondence?"
“戴尔·卡耐基会如何思考这个问题？戴尔·卡耐基所教的原则会如何影响和作用于这封信件？”

One of the simplest techniques that we teach at the d.school is trying on different constraints.
我们在d.school教授的最简单技巧之一是尝试不同的约束条件。

One of the best ways you can solve a problem as a human is by forcing yourself to try on a bunch of different constraints.
作为人类，解决问题的最佳方法之一是强迫自己尝试各种不同的约束。

"How would Jerry Seinfeld solve this problem? How would your favorite sushi restaurant solve this problem? How would Amazon solve it? How would Elon Musk?"
“杰瑞·宋飞会如何解决这个问题？你最喜欢的寿司店会如何解决这个问题？亚马逊会如何解决？埃隆·马斯克会如何解决？”

Anytime you make an association, you're colliding different information sources there.
任何时候你进行联想，你都在碰撞不同的信息源。

The same is true for an AI. An AI is basically making tons of connections through its own **neural network** (神经网络: 模拟人脑神经元连接的计算模型).
AI也是如此。AI基本上是通过自身的**神经网络** (神经网络: 一种模拟人脑神经元连接的计算模型) 建立大量的连接。

And by giving it a role, you're telling it where do you assume the best source of connection or collision is going to come from?
通过赋予它一个角色，你是在告诉它，你认为最佳的连接或碰撞来源将从何而来？

### AI角色扮演：艰难对话的飞行模拟器

If I'm going to use AI to roleplay a difficult conversation, I typically think about kind of three different chat windows, so to speak.
如果我要用AI来扮演一个艰难对话的角色，我通常会考虑三种不同的聊天窗口，可以说。

One is a personality profiler. Two is the character of the individual that I need to speak to, and then third is a feedback giver.
一个是性格分析器。第二个是我需要与之交谈的人的角色，然后第三个是反馈提供者。

I want to get objective feedback on the conversation.
我希望得到关于对话的客观反馈。

This I'll show you just how I would have a conversation with ChatGPT to prepare for a difficult conversation in my real life.
接下来我将向你展示我是如何与ChatGPT进行对话，来为我现实生活中的一次艰难对话做准备的。

I'm just going to go into the tough conversation personality profiler and I'm going to say, "Hey, I'd love your help preparing for a conversation I need to have with my sales leader, Jim. He emailed me last night saying that he deserves commission on a deal that I know came through a different channel."
我将进入“艰难对话性格分析器”，然后我会说：“嘿，我需要你的帮助，为我与销售主管吉姆的对话做准备。他昨晚给我发邮件说，他应该获得一笔我知道是通过其他渠道达成的交易的佣金。”

And so, I'm just kind of giving a little bit of background.
所以，我只是提供了一点背景信息。

I will just upload that to the personality profiler.
我将把这些上传到性格分析器。

And what this one's been taught to do is I'm going to start with step one of the process: gather intelligence about the character and the scene. Right?
而这个分析器被教导要做的是，我将从流程的第一步开始：收集关于人物和场景的信息。对吗？

I'm just going to look at the questions here and I'm going to use my voice to answer them because it's a lot easier than using my fingers.
我将只看这里的问题，然后用我的声音来回答，因为这比用手指打字容易得多。

Okay, first question. "How would I describe Jim's communication style?"
好的，第一个问题。“我如何描述吉姆的沟通风格？”

Um, he's quite direct and confrontational. He's kind of typical East Coaster, sarcastic.
嗯，他非常直接且好斗。他有点像典型的东海岸人，说话带刺。

"Well, I know that it came from our through our social team. There was a cold LinkedIn campaign that they ran and I know the CTO actually responded to that campaign."
“嗯，我知道这笔交易是通过我们的社交团队完成的。他们做了一个冷启动的领英营销活动，而且我知道首席技术官确实回应了那个活动。”

"So, and then best case outcome of this conversation one I mean I'd like for Jim to kind of back down. I mean like near-term, I want Jim to back down and agree that social team gets the commission."
“所以，这次对话的最佳结果是，我希望吉姆能让步。我的意思是，短期内，我希望吉姆让步，并同意佣金归社交团队。”

So it's kind of recapping its understanding and then it's giving me these instructions.
所以它相当于在总结它的理解，然后给我这些指示。

It's saying to me the user, "Copy paste the following instructions into a new ChatGPT window."
它对用户我说：“将以下指令复制粘贴到一个新的ChatGPT窗口中。”

So I've just copied those instructions.
所以我刚刚复制了那些指令。

So now what I'm going to do is I'm opening ChatGPT and I'm just going to go and first thing I'm going to do is start a new conversation with ChatGPT and I'm just going to paste those instructions in and I'm just going to paste them in.
所以现在我要做的是打开ChatGPT，然后我将首先开始一个新的ChatGPT对话，然后我将把那些指令粘贴进去。

And what it should do is hopefully say, "Got it. I'm Jim."
它应该会说：“明白了。我是吉姆。”

So, I'm just going to go in and I'm going to start it. We're going to see how this goes. You guys ready?
所以，我将直接开始。我们来看看进展如何。你们准备好了吗？

"Hey, Jim, um, do you have a second?"
“嘿，吉姆，嗯，你现在有空吗？”

**Jim:** "Sure thing. I've always got a moment for a good chat. What's on your mind?"
**吉姆:** “当然。我总是有时间好好聊聊。你有什么事？”

"Uh, yeah. I just wanted to clarify. It seems like um the commission that you emailed me about last night from the telco. I'm afraid you might be mistaken there."
“呃，是的。我只是想澄清一下。昨晚你给我发邮件提到的那笔电信公司的佣金，我恐怕你可能搞错了。”

**Jim:** "Mistaken, huh? Well, I'm definitely open to hearing the details. If there's something I missed, let's lay it out on the table and figure it out."
**吉姆:** “搞错了，是吗？好吧，我当然很乐意听听细节。如果我有什么遗漏，那就摆到台面上来，我们一起搞清楚。”

"To be honest with you, I was a little bit caught off guard when you sent your email last night."
“老实说，你昨晚发邮件的时候，我有点措手不及。”

**Jim:** "All right, I hear you. I mean, if the social team really did the ground work to bring that lead in, then I definitely want to make sure credit goes where it belongs."
**吉姆:** “好吧，我明白了。我的意思是，如果社交团队真的付出了努力带来了这个潜在客户，那我当然要确保功劳归于应得的人。”

"So, if I hit X, I just I I end that conversation."
“所以，如果我点击‘X’，我就结束了那次对话。”

"What's interesting to me is I kind of feel like that wasn't totally Jim. And either either that went well or, you know, I don't know what I did well."
“对我来说有趣的是，我有点觉得那不完全是吉姆的风格。要么是进展顺利，要么就是，我不知道我哪里做得好。”

"But one of the beautiful things about voice mode is now I've got the whole transcript here. I can just screenshot it."
“但语音模式的一个优点是，我现在有了完整的逐字稿。我可以直接截图。”

"Right? So I can take screenshots of this conversation. I can put them into a new GPT window and I can get feedback and I can say, 'Hey, tell me what I did well. Tell me what I did poorly.'"
“对吧？所以我可以截取这次对话的屏幕，把它们放到一个新的GPT窗口中，然后我可以获得反馈，我可以问：‘嘿，告诉我我做得好的地方。告诉我我做得不好的地方。’”

"Or I can go back into my conversation history here and I could say, 'Hey, I just had my first conversation with this version of Jim, but I feel like he kind of he was too agreeable to be honest with you, and so I'd like you to incorporate a little bit more edge into the instructions to the character that's going to be playing Jim, would you mind to update your instruction set?'"
“或者我可以回到我的对话历史记录中，然后说：‘嘿，我刚刚和这个版本的吉姆进行了第一次对话，但老实说，我觉得他有点太好说话了，所以我想让你在给扮演吉姆这个角色的指令中加入更多棱角，你介意更新你的指令集吗？’”

"Right? Because ultimately what you want is you want you want to have a realistic experience of the conversation."
“对吧？因为最终你想要的是，你想要一次真实的对话体验。”

"So, so now what I'll do is I'm actually going to open a new conversation and I'm going to paste the updated instruction set and let's see. Let's see what kind of Jim I got here."
“所以，现在我要做的是，我将打开一个新的对话，然后粘贴更新后的指令集，我们来看看。看看我这里得到了一个什么样的吉姆。”

"Big voice, bigger results. I fight for what's mine. I don't appreciate being second-guessed."
“声音洪亮，结果更佳。我为我所有而战。我不喜欢被质疑。”

"So, now I'm going to try again. Let's see. 'Hey, Jim. Do you have a minute to chat?'"
“所以，现在我再试一次。我们来看看。‘嘿，吉姆。你有时间聊聊吗？’”

**Jim:** "Hey, absolutely. I've always got a minute. Oh, that one. Yeah, I I figured that might come up. I I definitely think I had a hand in that deal, so I'm curious to hear what you have to say about it."
**吉姆:** “嘿，当然。我总是有时间的。哦，那个。是的，我猜到了那件事可能会被提起。我确实认为我在那笔交易中出了力，所以我很想听听你对此有什么看法。”

"Yeah, really appreciate it. I mean, you what you and the sales team are doing is awesome. Totally appreciate you."
“是的，非常感谢。我的意思是，你和销售团队所做的一切都很棒。完全感谢你。”

"Um, that being said, I actually feel that attribution is really important that we get airtight here. And the truth is I am fairly confident that deal came through the social team."
“嗯，话虽如此，我实际上认为归属问题非常重要，我们在这里需要做到滴水不漏。事实是，我相当确信那笔交易是通过社交团队完成的。”

**Jim:** "All right, I get where you're coming from. I definitely appreciate you wanting to clear the air and to keep things fair. So, what kind of evidence do you have that it came through the social team?"
**吉姆:** “好吧，我明白你的意思。我当然很欣赏你想要澄清事实并保持公平。那么，你有什么证据证明它是通过社交团队完成的呢？”

"Well, so I've been through kind of two windows. One is profiling my conversation partner and then the second is having the conversation. All right."
“嗯，我经历了两个窗口。一个是分析我的对话伙伴，然后第二个是进行对话。好的。”

"So, what I'm going to do here is I've opened my tough conversation greater GPT and I'm basically just going to upload photos of that last conversation."
“所以，我在这里要做的是，我已经打开了我的‘艰难对话评估GPT’，我基本上只是上传了上次对话的照片。”

"And what this GPT has been trained to do is basically give evaluate my conversation and then let me know how it went."
“而这个GPT被训练来做的事情是，基本上评估我的对话，然后告诉我进展如何。”

"Thanks for sharing the full transcript. My first step is to understand the objective. Step four, here's your grade. You got a 78 out of 100."
“感谢分享完整的逐字稿。我的第一步是理解目标。第四步，这是你的分数。你得了100分中的78分。”

"You succeeded in preserving trust and resolving the immediate issue."
“你成功地维护了信任并解决了眼前的问题。”

"So, I can take all of these. I can even say, 'Hey, would you give me a quick one-pager of a handful of talking points that I should probably make sure not to forget in the order in which they're likely to emerge in this conversation based on the feedback you've given me?'"
“所以，我可以拿走所有这些。我甚至可以说：‘嘿，你能给我一份简短的一页纸，列出一些我在这场对话中可能不应该忘记的谈话要点，并按照它们可能出现的顺序排列，基于你给我的反馈？’”

"The AI will actually give me a really short kind of at a glance conversation guide that I can leverage if I want to try again."
“AI实际上会给我一个非常简短的一目了然的对话指南，如果我想再试一次，我就可以利用它。”

"Right? Here's a one-pager. So, these are all great points. Now, I can bring them into the conversation."
“对吧？这是一页纸。所以，这些都是很好的观点。现在，我可以把它们带入对话中。”

"I actually I'd probably do this a couple times before having a real conversation with Jim."
“实际上，在和吉姆进行真正的对话之前，我可能会这样做几次。”

"But the point is historically the only time I get feedback is after I have the real conversation with Jim."
“但关键是，从历史上看，我只有在和吉姆进行真正的对话之后才能得到反馈。”

"This is the first time in history and maybe I can get a friend to kind of go over talking points with me."
“这在历史上是第一次，也许我可以找个朋友和我一起过一遍谈话要点。”

"But unless they're really close to Jim or unless they're, you know, particularly imaginative and unless they're deeply knowledgeable of a bunch of feedback frameworks, they fall short of really preparing me in context for this specific situation in the specific conversation I need to have in a way that AI is able to help me."
“但是，除非他们和吉姆非常亲近，或者他们特别富有想象力，并且对一系列反馈框架有深入了解，否则他们无法真正根据我需要进行的具体对话中的具体情况，在上下文中为我做好准备，而AI却能做到这一点。”

"You can use this for any difficult conversation, whether it's a performance review, a salary negotiation, difficult feedback."
“你可以将此用于任何艰难的对话，无论是绩效评估、薪资谈判，还是艰难的反馈。”

"It's a great way to basically get a flight simulator for a difficult conversation."
“这基本上是为艰难对话提供了一个飞行模拟器的好方法。”

### AI的未来：人类想象力的延伸

The people who are the best users of AI are not coders. They're coaches.
最擅长使用AI的人不是程序员。他们是教练。

They aren't developers or software engineers.
他们不是开发人员或软件工程师。

They're teachers and mentors and people who have learned to get exceptional output out of other intelligences.
他们是教师、导师，以及那些学会从其他智能中获得卓越产出的人。

And so where could AI go? Well, it's really a function of who can get unleashed.
那么AI能走向何方？这实际上取决于谁能被释放。

Right now, the primary limitation is the limits of human imagination.
目前，主要的限制是人类想象力的局限。

And as we unleash and ignite and spark more humans imaginations, the kinds of applications that are possible or they're unthinkable, not because they're technologically impossible, but because they never occur to us personally.
随着我们释放、点燃和激发更多人类的想象力，那些可能或不可思议的应用，不是因为技术上不可能，而是因为我们个人从未想到过。

One of my favorite quotes is a Nobel Prize-winning economist named Thomas Schelling.
我最喜欢的一句名言来自诺贝尔经济学奖得主托马斯·谢林。

He said, "No matter how heroic a man's imagination, he could never think of that which would not occur to him."
他说：“无论一个人的想象力多么英勇，他永远无法想到那些不会出现在他脑海中的事物。”

If you take as a premise that the imagination space as a function of what would occur to various individuals then as we equip different individuals what we can imagine collectively expands.
如果你以“想象空间是各种个体所能想到之事的函数”为前提，那么当我们赋能不同的个体时，我们集体能够想象的事物就会扩展。

In innovation studies has been called the **adjacent possible** (相邻可能: 现有事物基础上可实现的新可能性) for a long time.
在创新研究中，这长期以来被称为**相邻可能** (相邻可能: 在现有事物和知识的基础上，能够被发现或创造的新可能性)。

What is possible is just adjacent to what is.
可能发生的事情，就在现有事物的“旁边”。

And as we increase adoption and increase fluency and competency and increasingly mastery of AI collaboration, then we're increasing the adjacent possible.
随着我们增加对AI协作的采纳，提高其流畅性和能力，并日益精通，我们就在增加相邻可能。

And it's really important that you exercise through implementing some of the things you hear.
因此，通过实践你所听到的一些事情来锻炼自己非常重要。

And perhaps the most important thing you could do with this video is actually hit stop and do something that's already blown your mind.
也许你用这个视频能做的最重要的事情，就是按下停止键，然后去做一些已经让你茅塞顿开的事情。