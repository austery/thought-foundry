---
author: 最佳拍档
date: '2025-10-23'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=Bma6tHQYaD4
speaker: 最佳拍档
tags:
  - intelligence-commodification
  - verifier-law
  - jagged-frontier
  - adaptive-compute
  - ai-development-trends
title: Jason Wei斯坦福演讲：智能商品化、验证者法则与AI锯齿状前沿
summary: Meta研究科学家Jason Wei在斯坦福大学的演讲中，提出了理解和驾驭AI发展的三个核心思想：智能正在成为一种商品，其获取成本趋近于零；验证者法则，即AI将优先攻克易于验证的任务；以及智能的锯齿状前沿，指出AI能力发展不均衡且快速起飞不太可能。他深入探讨了自适应计算、信息获取成本下降、领域民主化等趋势，并提供了预测AI攻克任务速度的启发式法则，为理解AI的未来提供了全面框架。
insight: ''
draft: true
series: ''
category: technology
area: tech-insights
project:
  - ai-impact-analysis
  - systems-thinking
people:
  - Jason Wei
companies_orgs:
  - Meta Superintelligence labs
  - OpenAI
  - Google Brain
  - Stanford University AI Club
  - KOSIS
  - DeepMind
  - iRobot
products_models:
  - o1 模型
  - Deep Research
  - 思维链
  - 指令微调
  - ChatGPT
  - GPT-3
  - Operator
  - AlphaDev
  - AlphaZero
  - AlphaEvolve
media_books: []
status: evergreen
---
### Jason Wei斯坦福演讲：AI发展的三大核心思想

上周，斯坦福大学AI俱乐部邀请了Jason Wei作为嘉宾，进行了一场精彩的演讲。如果你关注我们频道或者AI领域一段时间，那么应该对他并不陌生。Jason Wei目前在Meta Superintelligence labs担任研究科学家。在此之前，他在OpenAI参与了**o1 模型**（OpenAI One Model: OpenAI 内部研究项目，首次大规模展示自适应计算概念）和Deep Research产品的创建。更早之前，他在Google Brain工作期间，推动了**思维链**（Chain of Thought: 一种通过逐步推理来解决复杂问题的AI提示技术）和**指令微调**（Instruction Tuning: 通过在多样化任务指令上训练模型，使其能更好地遵循指令）等关键技术的发展。他的论文引用次数超过9万次，是当今AI领域最具影响力的研究者之一。

在这次演讲中，Jason提出了他认为在2025年理解和驾驭AI发展的三个核心思想，分别是：第一、智能正在成为一种商品；第二、验证者法则；第三、智能的锯齿状前沿。今天，我们就来回顾一下这场演讲的内容，看看该如何理解这三个AI的核心思想。

### 核心思想一：智能正在成为一种商品

演讲从一个问题开始：AI的发展会怎么改变我们的世界？对于这个问题，不同的人给出的答案可能会天差地别。Jason的一位量化交易员朋友认为，ChatGPT虽然很酷，但在他的实际工作中却几乎派不上用场。而另一位顶级AI实验室的研究员则悲观地表示，他们可能只剩下两三年的工作时间，之后就会被AI取代。这种巨大的分歧，根源在于对AI能力发展速度和成本变化的理解不同。

所以Jason的第一个观点是，智能，或者说获取知识和进行推理的能力，正在迅速被商品化，它的成本和获取门槛正趋向于零。Jason认为，AI的发展可以分为两个阶段。第一个阶段，前沿突破。在这个阶段，AI还无法很好地完成某项任务，研究人员的目标是解锁新的能力。比如，我们可以看到过去五年，各大模型在**MMLU**（Massive Multitask Language Understanding: 一种衡量语言模型在多任务和多领域知识方面能力的基准测试）通用基准测试上的性能都是逐步提升的。第二个阶段是能力商品化。一旦某项能力被解锁，它的成本就会开始急剧下降。Jason展示了一张图表，纵坐标是时间，横坐标是达到特定MMLU分数所需要的计算成本。趋势非常明显，每过一年，获得同等智能水平的模型的成本都在大幅降低。

那这个趋势会持续下去吗？Jason的答案是肯定的，而背后的核心驱动力，是一种在深度学习历史上第一次真正奏效的技术——**自适应计算**（Adaptive Compute: 模型根据任务难度动态调整计算资源使用量的技术）。Jason提到，在去年之前，深度学习领域的主流范式都是固定计算，也就是说，无论问题是简单的还是复杂的，模型在推理时消耗的计算资源基本上都是固定的。但是现在，我们已经进入了自适应计算的时代，模型可以根据任务的难度，动态地调整计算资源的使用量。而这个概念的首次大规模展示，正是OpenAI一年多前发布的o1模型。研究表明，在解决数学问题的时候，如果在测试阶段投入更多的计算量，模型的性能就会相应提高。

自适应计算的意义在于，它打破了模型规模决定智能上限的僵局。对于简单的任务，我们可以用极小的计算资源来完成，从而将成本推向极限。我们不必再为了回答一个简单的问题，而去运行一个万亿参数的庞然大物。这使得智能的单位成本可以持续下降。

智能商品化的另一个体现，是获取公共信息的时间成本急剧下降。Jason用一个例子说明了这一点。假设我们想知道1983年韩国釜山的人口是多少。在前互联网时代，我们可能需要开车去图书馆，翻阅大量的百科全书或年鉴，花费几个小时的时间。而在互联网时代，我们可以用搜索引擎，浏览几个网页，找到答案，可能需要几分钟。如今在聊天机器人时代，我们可以直接提问，答案几乎是瞬时的。

那如果我们把问题变得更难一些呢？比如想知道1983年在釜山有多少对新人结婚呢？应该说，这个问题的信息更加隐蔽。在前互联网时代，你可能需要飞到韩国，去政府档案馆查阅几十本卷宗，这可能需要几天甚至几周的时间。在互联网时代，你可能需要懂韩语，在特定的政府数据库网站上进行复杂的查询。但是在今天的**AI Agents**（AI智能体: 能够自主感知环境、规划行动并执行任务的人工智能系统）时代，这个问题可以在几分钟内解决。Jason提到，GPT-3无法回答这个问题，但是OpenAI的内部研究工具**Operator**（OpenAI内部研究工具: 能够自动访问外部数据库并构建查询语句）可以。它能够自动访问**KOSIS**（Korean Statistical Information Service: 韩国统计信息服务数据库）数据库，通过多次点击和尝试，构建正确的查询语句，最终找到答案。

为了衡量这种能力，OpenAI内部创建了一个名为**BrowseComp**（OpenAI内部基准测试: 衡量AI在信息搜索和验证方面的能力）的基准测试，其中的问题通常是答案一旦找到就很容易验证，但是寻找的过程却非常耗时。测试结果显示，人类解决这些问题平均需要两个小时以上，而且很多问题人类在两小时内根本无法完成。而OpenAI的Deep Research模型已经能够解决其中将近一半的问题了。

那么，智能商品化会给我们带来哪些影响呢？Jason也总结了三点。第一、领域的民主化。过去因为知识壁垒而门槛很高的领域，将被大大拉平。编程就是一个典型例子，现在人人都可以借助AI成为开发者。个人健康也是如此，你可以通过AI获取专业医生水平的建议，进行个性化的健康实验。第二、私有信息价值的提升。当所有公共信息的获取成本都降为零的时候，那些未公开的、内部的、私有的信息的相对价值将会急剧上升。第三、个性化的信息流。未来我们访问的，可能不再是千人一面的公共互联网，而是为每个人量身定制的个性化互联网。我们所关心的一切信息，都会以最适合自己的方式所呈现出来。

### 核心思想二：验证者法则

Jason提出的第二个核心思想，是一个他称之为**验证者法则**（Verifier’s Law: 预测任务被AI攻克速度的规律，与任务的可验证性成正比）的规律。这个法则可以帮助我们预测哪些任务会最先被AI攻克。比如在计算机科学中，有一个著名的概念叫做**验证与求解的不对称性**（Asymmetry of Verification and Solving: 验证一个解的正确性通常比找到它更容易），也就是验证一个解是否正确，通常比找到这个解要容易得多。

Jason列举了一些例子来帮助我们理解这种不对称性在现实世界中的体现。第一类情况，易于验证，但是难于求解。比如数独，求解一个复杂的数独可能需要很长时间，但是验证一个填好的数独是否正确只需要几秒钟。还有就是编写或者测试代码，构建并且运行整个Twitter的后端系统需要数千名工程师，但是验证这个网站是否正常工作只需要打开浏览器点几下就行了。第二类情况，验证与求解难度相当。比如数学竞赛题，对于某些证明题，验证答案的过程几乎等同于重新推演一遍解题过程。第三类情况，难以验证，但是易于求解。比如编写一段数据处理脚本，你自己写一个脚本可能很快，但是要去验证别人写的垃圾脚本是否完全正确，可能比自己重写一遍还要花时间。或者是撰写一篇事实性的文章，AI可以轻易地生成一篇看起来很有道理、充满事实陈述的文章，但是要逐一核实其中每一个信息的准确性，却是一项极其繁琐和耗时的工作。

那理解了这个概念之后，我们可以将不同的任务放置在一个坐标系中，X轴是生成的难度，Y轴是验证的难度。其中一个有趣的点是，我们可以通过提供特权信息来改变一个任务的验证难度。比如，对于数学题来说，如果提供了答案和解题步骤，验证就变得非常容易。

基于以上这些观察，Jason提出了他的核心论断，也就是验证者法则，指的是训练AI解决某个任务的能力与该任务的可验证性成正比。因此，任何可解的、而且易于验证的任务，最终都将被AI攻克。具体来说，一个任务的可验证性高低取决于以下五个因素：一、客观性（Objective Truth），是否存在一个明确的、客观的正确答案？二、速度（Fast），验证一个答案需要多长时间？三、可扩展性（Scalable），能否同时快速验证数百万个不同的提议解呢？四、低噪音（Low Noise），每次验证得到的结果是否一致呢？五、连续奖励（Continuous Reward），评价体系是二元的，还是能够提供一个连续的分数来衡量解的优劣呢？我们日常见到的大多数的AI基准测试，它们的本质其实就是高度可验证的任务，这也就解释了为什么AI在这些基准测试上的表现突飞猛进。

利用这种不对称验证性的最经典的例子，应该属DeepMind的**AlphaDev**（DeepMind项目: 利用进化式搜索算法发现比人类专家更优的算法）项目。他们选择了一些极难解决、但是解法很容易被验证的计算问题，比如找到一种算法可以对某些序列进行更快的排序，或者用最少的指令实现某个功能。这种做法非常巧妙，可以概括为一种进化式的搜索算法。第一步，生成（Sample），先让大语言模型生成大量候选的解决方案。第二步、评估（Grade），因为任务是高度可验证的，所以可以自动、快速地给每个方案打分。第三步、迭代（Iterate），将得分最高的方案作为灵感，反馈给大语言模型，让它在下一轮生成更高质量的方案。通过投入海量的计算资源进行这种循环，AlphaDev能够发现比人类专家设计的算法更优的解。

Jason举了一个例子，找到11个六边形的最佳摆放方式，让它能够被一个最小的外部六边形包围。这个问题完美符合了高可验证性的所有标准：结果客观、计算验证快、可扩展、无噪音，并且外部六边形的大小提供了一个连续的奖励信号。因此，验证者法则告诉我们的是：第一、最先被自动化的领域，将是那些工作成果极易验证的领域，比如某些类型的软件测试、代码优化、金融市场的套利策略发现等等。第二、测量即优化，创造衡量和验证标准本身将变得极具价值。如果你能够为某个原本难以衡量的领域，设计出一套快速、客观、可扩展的评估体系，那么接下来就可以利用AI来大规模地优化它。

### 核心思想三：智能的锯齿状前沿

Jason的第三个观点是关于AI能力发展的形态。很多人对AI的未来有一种二元对立的看法，要么觉得它无所不能，要么觉得它漏洞百出。比如在AI安全领域，有一个流传已久的假说，叫做**快速起飞**（Fast Takeoff: AI智能达到临界点后能力在极短时间内爆炸性增长的假说）。这个假说认为，一旦AI的智能达到某个临界点，比如能够自主进行AI研究，它的能力将在极短的时间内发生爆炸性增长，远超人类，形成所谓的超级智能。

但是Jason认为，这种情况大概率不会发生。他的理由是，AI的自我提升能力更可能是一个渐进的、连续式的过程，而不是一个像0或1一样的二进制开关。与其想象某一天AI突然就能训练下一代AI了，更现实的场景可能是这样的：第一年，AI连研究的代码库都跑不起来；第二年，AI可以勉强训练一个模型，但是效果很差；第三年，AI可以自主训练了，但是效果不如顶尖的人类研究团队；第四年，AI训练得很好，但是偶尔还需要人类介入，来解决一些疑难杂症。

此外，AI的能力发展并不是一个平滑的、齐头并进的战线，而是一个**锯齿状的前沿**（Jagged Frontier: AI能力发展不均衡，在不同任务上表现出高峰和深谷的特性）。我们可以想象一下AI的能力图谱，它不是一条平滑的上升曲线，而是一条布满了高峰和深谷的崎岖山脉线。高峰处是AI目前表现出超人能力的领域，比如解决复杂的数学问题、编写某些类型的竞赛代码。而深谷处则是AI表现得非常糟糕的领域，比如，很长一段时间里，ChatGPT会认为9.11比9.9大。另一个例子是**特林吉特语**（Tlingit: 一种只有几百名北美原住民会说的语言，因数据稀缺而难以被AI学习），这是一种只有几百名北美原住民会说的语言，由于数据极度的稀缺，AI几乎不可能学会。

更重要的是，不同任务的提升速度也是不同的。那些位于高峰的任务，可能会因为高度的可验证性而得到算法的快速优化，变得越来越强。而那些位于深谷的任务，它们的瓶颈可能在于物理世界的交互或数据采集，提升速度会非常缓慢。就好像AI不会因为在数学上取得了突破，就突然学会了如何说一口流利的特林吉特语。

那么，我们该如何预测一个特定的任务被AI攻克的速度呢？Jason提供了三个简单、但是非常有效的启发式法则。第一、数字任务对物理任务。AI在纯数字领域的进展速度远快于物理世界。原因很简单，那就是迭代速度。在数字世界里，你可以用海量的计算资源进行百万次的模拟和实验。但是在物理世界，一个机器人做一个动作，收集一次数据，速度是受物理定律限制的。Jason引用了一幅1981年的漫画，画的是一个能帮你做作业的家庭作业机，这在今天几乎已经成为现实。但是像iRobot那样的家用机器人，离我们还很遥远。

第二是对人类的难度。总的来说，对人类越容易的任务，对AI也越容易。当然也有例外，比如AI可以在海量数据中发现人类无法察觉的模式，比如从数百万张医学影像中预测乳腺癌。第三、数据的丰富度。数据量是决定AI性能的关键因素。一个清晰的例子是，模型的数学表现与该语言在训练语料库中出现的频率呈现出非常强的正相关关系。不过这个规则同样有一个例外，那就是如果一个任务有明确、单一的评价指标，我们就可以像**AlphaZero**（DeepMind项目: 通过自我对弈强化学习掌握围棋、国际象棋等游戏）或**AlphaEvolve**（DeepMind项目: 利用进化算法优化蛋白质结构等复杂问题）那样，通过**强化学习**（Reinforcement Learning: 一种机器学习方法，通过与环境互动、试错来学习最优行为策略）生成几乎无限的合成数据来训练模型。

基于这三个启发式规则，Jason给出了一个关于AI能力发展时间线的预测表格，其中不乏一些有趣的思考。首先是非对称的行业冲击。AI的影响将极不均衡，像软件开发这些领域，可能将被AI彻底改变和加速。而另一些领域，比如理发、传统手工艺，短期内可能几乎不受影响。其次是理性的预期管理。理解AI能力的锯齿状特性，可以帮助我们避免陷入AI无所不能或者AI一无是处的极端思维，从而对AI的发展有一个更加理性和现实的预期。

### 总结

最后，我们大概总结一下Jason Wei分享的三个核心思想，它们共同构成了一个理解和思考AI未来的框架。首先是智能的商品化，计算和知识的成本正在趋近于零，这是一个不可逆转的宏观趋势，它将重塑知识型工作的价值。其次是验证者法则，一个任务的可验证性决定了它被AI征服的速度，我们应该重点关注那些易于衡量和评估的领域，它们将是AI最先突破的地方。最后是锯齿状的前沿，AI的发展是不均衡的，在能力图谱上既有高峰也有深谷，我们需要具体问题具体分析，而不是笼统地谈论AI能做什么。基于这个框架，我们就可以思考哪些工作会被自动化呢？哪些新机会正在涌现？我们又应该学习什么样的新技能呢？如果能够找到这些问题的答案，也许就能找到我们自己在这个新时代中的位置了。