---
author: Lei
channel: https://www.youtube.com/@googledeepmind
date: 2025-07-21
guest: Murray Shanahan
insight: null
layout: post.njk
series: null
source: https://www.youtube.com/watch?v=v1Py_hWcmkU&t
speaker: Hannah Fry,Murray Shanahan
summary: 我对于AI是否有智能很感兴趣，看看大佬的访谈。Murray Shanahan 与 Hannah Fry 探讨了人工智能的哲学问题，从符号AI到神经网络，深入分析了机器的推理能力、意识的多面性、图灵测试的局限性，以及我们应如何理解这些新兴的“异类的类心实体”。
tags:
- 视频文稿
- 人工智能
- 意识
- 哲学
- 推理
title: AI、意识与推理：与 Murray Shanahan 的哲学思辨
---

## AI 哲学的深远问题

**Murray Shanahan**: I think there are just a huge number of enormously interesting philosophical questions that AI gives rise to. What is the nature of the human mind? What is the nature of mind?

**讲述者**: 我认为AI引发了大量极其有趣的哲学问题。人的心智本质是什么？心智的本质又是什么？

**Hannah Fry**: What about consciousness?

**讲述者**: 那么意识呢？

**Murray Shanahan**: I do think that is the wrong question, and I think it's wrong in many ways.

**讲述者**: 我确实认为这是一个错误的问题，而且在很多方面都是错的。

**Hannah Fry**: How good do you think that AI is at reasoning?

**讲述者**: 你认为AI在推理方面有多出色？

**Murray Shanahan**: Well, that's a very interesting and open question, and somewhat controversial. It really is astonishing to think that every single child born today, they're going to grow up in a world where they've never known, they've never known a world in which machines can't talk to them.

**讲述者**: 嗯，这是一个非常有趣且悬而未决的问题，也有些争议。想到今天出生的每一个孩子，他们将在一个机器能够与他们对话的世界里长大，从未体验过并非如此的世界，这真是令人震惊。

## 导言与回顾

**Hannah Fry**: Welcome back to "Google DeepMind," the podcast. My guest on this episode is Murray Shanahan, Professor of Cognitive Robotics at Imperial College London and Principal Research Scientist at Google DeepMind.

**讲述者**: 欢迎回到“Google DeepMind”播客。本期节目的嘉宾是伦敦帝国理工学院认知机器人学教授、Google DeepMind的首席研究科学家Murray Shanahan。

**Hannah Fry**: Now, we have all heard the stories about people falling in love with their chat bots, about people pushing large language models to contemplate their own existence, or questioning the limits of their conceptual understanding of reality. But these kinds of questions about self-identity and thinking and metacognition have been puzzling philosophers for millennia already. And so it makes sense that they should be turning to AI to interrogate the most profound questions about the nature of AI's intelligence, of its current capabilities, even its consciousness or other ones.

**讲述者**: 现在，我们都听说过有人爱上他们的聊天机器人，有人促使大型语言模型思考自身存在，或质疑它们对现实概念理解的极限。但这类关于自我认同、思维和**元认知**（Metacognition：指对自身认知过程的认知和反思）的问题，已经困扰了哲学家数千年。因此，他们转向AI来探究关于AI智能本质、当前能力，乃至其意识或其他属性的最深刻问题，也就顺理成章了。

**Hannah Fry**: Murray Shanahan has been working in the field of AI since the 1990s. And if you've been following this podcast for a while, you will remember him as the man that consulted on the 2014 science fiction film "Ex Machina," about a computer programmer who gets the chance to test the intelligence of a female robot, Ava, and ultimately questions whether she is conscious.

**讲述者**: Murray Shanahan自20世纪90年代以来一直在AI领域工作。如果你关注这个播客有一段时间了，你会记得他曾为2014年的科幻电影《机械姬》（Ex Machina）担任顾问。这部电影讲述了一位程序员有机会测试女性机器人Ava的智能，并最终质疑她是否具有意识。

## 回顾《机械姬》与《她》的预见性

**Hannah Fry**: Welcome back to the podcast, Murray. Just thinking back, because I know that you played a key role in "Ex machina," shall we say, the Alex Garland film. What do you think you got right in that film and in other science fiction films that were around at the time? I mean, thinking back to 10, 15 years ago, were we on the right track?

**讲述者**: 欢迎回到播客，Murray。回想起来，我知道你在Alex Garland的电影《机械姬》中扮演了关键角色。你认为那部电影以及当时的其他科幻电影在哪些方面做对了？我的意思是，回想10到15年前，我们当时的方向是正确的吗？

**Murray Shanahan**: So one respect in which "Ex Machina" really did a great service was that it does raise a whole load of very interesting and provocative questions about consciousness and about AI and consciousness, and therefore, about consciousness itself. So that's one huge success. But it's interesting that just very shortly before "Ex Machina" came out, "Her" came out.

**讲述者**: 在一个方面，《机械姬》确实功不可没，那就是它提出了一系列关于意识、关于AI与意识，乃至关于意识本身的非常有趣和发人深省的问题。所以这是一个巨大的成功。但有趣的是，就在《机械姬》上映前不久，《她》（Her）上映了。

**Murray Shanahan**: So Spike Jones's movie "Her" came out. And at the time, I really wasn't all that keen on "Her" as a movie, because I just thought it was so implausible that a person could fall in love with this kind of disembodied voice, even if it's Scarlett Johansson's.

**讲述者**: 是的，Spike Jonze的电影《她》上映了。当时，我其实并不怎么喜欢这部电影，因为我觉得一个人爱上这样一个无形的、只有声音的存在，实在是太不可思议了，即便是斯嘉丽·约翰逊的声音。

**Hannah Fry**: Yeah.

**讲述者**: 是的。

**Murray Shanahan**: I mean, how wrong was that? As a bit of prediction, I think "Her" really did amazingly well at predicting the world we've got now. Now, we don't know quite how things are going to unfold in the next few years because maybe robotics will progress rapidly as well in the way that language has in AI. But at the moment, it's all about disembodied language. And also, "Her" showed how people can, in fact, very much form relationships, whatever, in the broadest sense, with disembodied AI systems, which is an extraordinary thing, really.

**讲述者**: 我是说，我错得有多离谱？作为一种预测，我认为《她》在预见我们现在的世界方面做得惊人地好。当然，我们不知道未来几年情况会如何发展，因为也许机器人技术也会像AI中的语言技术一样飞速进步。但目前，一切都围绕着无形的语言展开。而且，《她》展示了人们实际上可以与无形的AI系统建立各种广义上的关系，这实在是一件非同寻常的事情。

## 人工智能的命名与早期发展

**Hannah Fry**: OK. We're talking 10, 15 years ago, but your involvement in AI goes back much further than this. You knew John McCarthy.

**讲述者**: 好的。我们谈论的是10到15年前，但你参与AI领域的时间要早得多。你认识约翰·麦卡锡。

**Murray Shanahan**: I did know John McCarthy. I knew him very well. John McCarthy was a professor of computer science and artificial intelligence. Back in the day, he actually coined the phrase artificial intelligence and was one of the authors of the proposal for the very famous Dartmouth Conference that took place in 1956, which was the first AI conference in the world.

**讲述者**: 我确实认识约翰·麦卡锡。我非常了解他。约翰·麦卡锡是计算机科学和人工智能的教授。在当年，他实际上创造了“**人工智能**”（Artificial Intelligence）这个词，并且是1956年著名的达特茅斯会议提案的作者之一，那是世界上第一次AI会议。

**Murray Shanahan**: And that conference really mapped out the whole field. People just weren't thinking about this kind of thing seriously at all. There was just a handful. So I think he was a real radical thinker and always was.

**讲述者**: 那次会议真正地规划了整个领域。当时人们根本没有认真思考过这类事情，只有寥寥数人。所以我认为他是一个真正的激进思想家，并且一直都是。

**Hannah Fry**: OK. That choice of words, artificial intelligence, back in 1955, was it a good choice of words?

**讲述者**: 好的。在1955年选择“人工智能”这个词，是个好选择吗？

**Murray Shanahan**: Yeah. I mean, I still think it was. I mean, I know that some people don't think that perhaps it wasn't a good choice of words, but I--

**讲述者**: 是的。我的意思是，我仍然认为是。我知道有些人可能觉得这不是一个好词，但我——

**Hannah Fry**: Give us some of their arguments.

**讲述者**: 告诉我们他们的一些论点。

**Murray Shanahan**: So first of all, there is the word intelligence. So intelligence itself is, in some ways, a very contentious concept, especially if people think about IQ tests and that kind of thing, and the idea that intelligence is something that can be quantified on a straightforward, simple scale, and then some people are more intelligent than others. And I think in psychology, it's well-recognized today that there are many different kinds of intelligence. And this is a really important point, right?

**讲述者**: 首先，是“智能”（intelligence）这个词。智能本身在某些方面是一个非常有争议的概念，特别是当人们想到智商测试之类的东西，以及认为智能是可以用一个直接、简单的量表来量化，然后评判一些人比另一些人更聪明的想法时。我认为在心理学中，今天人们已经普遍认识到存在多种不同类型的智能。这是一个非常重要的点，对吧？

**Murray Shanahan**: There is that concern about that word there. So what would you have used differently? Well, maybe artificial cognition or something. I often use the word cognition to mean kind of thinking and processing information and so on. But it doesn't have the same ring to it, does it? Let's be honest.

**讲述者**: 对那个词确实存在担忧。那你会有什么不同的用词呢？嗯，也许是“人造认知”之类的。我经常用“认知”（cognition）这个词来指代思考、信息处理等过程。但它听起来没有那么响亮，对吧？说实话。

**Hannah Fry**: No. Especially not now. I think we're too far down this road, aren't we?

**讲述者**: 不响亮。尤其现在。我觉得我们在这条路上已经走得太远了，不是吗？

**Murray Shanahan**: Yeah. The word artificial, I don't really have a problem with the word artificial. That seems like the right kind of thing. It's alluding to the fact that it's something that we've built and it hasn't evolved in nature, and so that seems the right sort of word.

**讲述者**: 是的。至于“人造”（artificial）这个词，我并没有什么意见。它似乎是恰当的。它暗示了这是我们建造的东西，而不是在自然界中进化而来的，所以这个词似乎是合适的。

**Hannah Fry**: The objection to that word, I guess, is that ultimately, everything that artificial intelligence is built on is, at some level, constructed by humans.

**讲述者**: 我想，对这个词的反对意见在于，归根结底，人工智能所依赖的一切，在某种程度上都是由人类构建的。

**Murray Shanahan**: Sure. Yes. But it is. So what's wrong with the word in that case? I mean, I think that's true.

**讲述者**: 当然。是的。但事实如此。那么在这种情况下，这个词有什么问题呢？我的意思是，我认为这是对的。

## 从符号AI到神经网络

**Hannah Fry**: You were working on symbolic AI, right? Just talk to us about the difference between that and the other types and where we're at now with--

**讲述者**: 你曾从事**符号AI**（Symbolic AI：一种基于规则和逻辑符号操作的AI方法）的研究，对吗？跟我们谈谈它与其他类型的区别，以及我们现在处于什么阶段——

**Murray Shanahan**: Yeah, absolutely. Yeah. Yeah, so the so-called symbolic paradigm of artificial intelligence was very much preeminent, very much dominant for decades, for many decades. So the idea there is that it's all about the manipulation of symbols and of language-like sentences and symbols and using reasoning processes with those symbols.

**讲述者**: 是的，当然。所谓的人工智能的符号范式在几十年里都占据着卓越和主导地位。其核心思想是围绕着符号的操作、类语言的句子和符号，并利用这些符号进行推理过程。

**Murray Shanahan**: So the classic example would be an expert system. So where back in the 1980s, people were building these expert systems, and the idea there was that you would try to encode medical knowledge, say, in a set of rules, and the rules would be something like, oh, if the patient has temperature of 104 and their skin is purple and then there's a 0.75% probability that they've got skinny-itis or something.

**讲述者**: 典型的例子就是**专家系统**（Expert System：一种模仿人类专家决策能力的计算机程序）。在20世纪80年代，人们构建这些系统，其想法是尝试将医学知识编码成一套规则，比如，哦，如果病人体温104华氏度，皮肤呈紫色，那么有0.75%的概率患上了某种“皮肤炎”之类的病。

**Hannah Fry**: Just about.

**讲述者**: 差不多是这样。

**Murray Shanahan**: Yeah. And then so you'd have thousands and thousands of these sorts of rules would be put into a kind of big knowledge base, and then you'd have what was called an inference engine which would carry out logical reasoning over all of these rules and come to some conclusion about what the likely disease was in.

**讲述者**: 是的。然后你会有成千上万条这样的规则被放入一个大型知识库中，接着会有一个所谓的推理引擎，它会对所有这些规则进行逻辑推理，最终得出关于可能病症的结论。

**Hannah Fry**: But it was a lot of, if this, then that.

**讲述者**: 但那基本上就是大量的“如果…那么…”规则。

**Murray Shanahan**: It was a lot of, yeah, if, then type rules, largely. And one of the big problems with that is that, where do the rules come from? Well, somebody has to write them all out, basically. And so there was a whole field of knowledge elicitation where you go around to experts and you try and extract from them their understanding in their domain, which could be medical diagnosis, it could be fixing photocopiers, it could be the law. And you try and codify all of this into a computer comprehensible, very precise rule. That is a very cumbersome process.

**讲述者**: 很大程度上是的，就是大量的“如果…那么…”类型的规则。其中一个大问题是，这些规则从何而来？嗯，基本上得有人把它们全部写出来。因此，当时出现了一个完整的“知识获取”领域，你需要去找专家，试图从他们那里提取他们在各自领域的理解，这可能是医疗诊断，也可能是修理复印机，还可能是法律。然后你尝试将所有这些知识编码成计算机能理解的、非常精确的规则。这是一个非常繁琐的过程。

**Murray Shanahan**: And also what you ended up with at the end was very, very brittle. It would go wrong in all kinds of ways. Another big area of research was common sense, because often it was realized that we implicitly have an enormous amount of common sense knowledge about the everyday world to do with just everyday objects. The fact that they're solid. The fact that they move in certain ways, they fit into each other in certain ways, liquids and gases and gravity and all kinds of things like that.

**讲述者**: 而且，最终得到的系统非常、非常脆弱。它会在各种情况下出错。另一个重要的研究领域是常识，因为人们常常意识到，我们默认拥有大量关于日常世界的常识知识，涉及日常物品。比如它们是固体的，它们以特定方式移动，以特定方式相互配合，还有液体、气体、重力等等各种事物。

**Murray Shanahan**: And we actually bring all of that knowledge to bear all the time in what we're doing, but it's sort of unconscious. So then there was a big project, there were various big projects to try and codify all of that common sense knowledge. And then trying to turn that into axioms and logic and rules and everything was a nightmare. So eventually, I think by about the early 2000s, I really thought that this research paradigm was kind of doomed, to be honest. I sort of started moving away from it.

**讲述者**: 实际上，我们在日常行为中一直都在运用所有这些知识，但这在某种程度上是无意识的。于是，当时有一个大项目，有好几个大项目试图将所有这些常识知识编码。然后，试图将其转化为公理、逻辑和规则等等，简直是一场噩梦。所以最终，大概在21世纪初，我真的觉得这个研究范式注定要失败了，说实话。我于是开始逐渐远离它。

**Hannah Fry**: But then, of course, along came things like neural networks and so on.

**讲述者**: 但后来，当然，像**神经网络**（Neural Networks：模仿人脑神经元连接方式进行计算的模型）之类的事物出现了。

**Murray Shanahan**: Yes.

**讲述者**: 是的。

**Hannah Fry**: Which was much less about if, then rules and much more about extracting information from a large amount of data.

**讲述者**: 这不再是关于“如果…那么…”的规则，而更多是关于从大量数据中提取信息。

**Murray Shan-ahan**: Yeah.

**讲述者**: 是的。

**Hannah Fry**: But then I sort of wonder now about, now that language is effectively cracked, have we reached a higher level of abstraction where we can go back to some more of those symbolic techniques, some of those more symbolic ideas?

**讲述者**: 但我现在有点好奇，既然语言问题基本被攻克了，我们是否已经达到了一个更高的抽象层次，可以重新回归一些符号技术，一些更具符号性的思想？

**Murray Shanahan**: Yeah. Well, we certainly have, because nowadays one of the hot topics at the moment with large language models is reasoning. So you have these so-called chain of thought models that actually carry out a whole-- rather than simply generating an answer to a question, they generate a whole chain of reasoning before they issue the answer. And that can be very, very effective. So it's interesting how that harks back in many ways to the kind of thing that people were looking at back in the days of symbolic AI.

**讲述者**: 是的。我们当然已经做到了，因为现在大型语言模型的一个热门话题是推理。你有所谓的“**思维链**”（Chain of Thought）模型，它们不仅仅是简单地生成问题的答案，而是在给出答案之前生成一整套推理过程。这可能非常、非常有效。有趣的是，这在很多方面都呼应了符号AI时代人们研究的东西。

**Murray Shanahan**: But the underlying substrate for doing all of that is very, very different indeed, because it's not hardcoded rules. As you mentioned, it's neural networks that have learned.

**讲述者**: 但实现这一切的底层基础确实非常、非常不同，因为它不是硬编码的规则。正如你提到的，它是已经学会了的神经网络。

## AI的推理能力

**Hannah Fry**: Let me pick up on that point about reasoning. As a philosopher, background in logic, how good do you think the AI is at reasoning?

**讲述者**: 让我接着谈谈推理这一点。作为一位有逻辑学背景的哲学家，你认为人工智能在推理方面有多出色？

**Murray Shanahan**: Well, that's a very interesting and open question, and somewhat controversial. So computer scientists and AI people, they have a particular notion of reasoning, a particular concept of reasoning, which very much harks back to formal logic and theorem proving. So in the days of symbolic AI, for example, then you had systems that were really very good at doing theorem proving with formal logic.

**讲述者**: 嗯，这是一个非常有趣且悬而未决的问题，也有些争议。计算机科学家和AI从业者对推理有一个特定的概念，它很大程度上源于形式逻辑和定理证明。例如，在符号AI时代，当时的系统在用形式逻辑进行定理证明方面非常出色。

**Murray Shanahan**: And so people think, well, that's proper reasoning. That's your hardcore kind of reasoning. And today's large language models, they can't match the performance of a hand-coded theorem prover or logic engine of the sort that's been around for decades.

**讲述者**: 所以人们认为，嗯，那才是真正的推理，是那种硬核的推理。而今天的大型语言模型，它们的性能无法与那种已经存在了几十年的、手动编码的定理证明器或逻辑引擎相媲美。

**Hannah Fry**: Give me an example of a type of theorem that might be able to be proved by a hardcoded system.

**讲述者**: 给我举一个硬编码系统可能能够证明的定理类型的例子。

**Murray Shanahan**: So it would be where you've got maybe 20 or 30 axioms of logic.

**讲述者**: 比如你可能有20或30条逻辑公理。

**Hannah Fry**: So it might be something like the number that follows one is to.

**讲述者**: 所以可能类似于“一后面的数字是二”这样的。

**Murray Shanahan**: Well, I mean, it could be something like that. It could be in the domain of number theory or something very mathematical. But it could be something much more everyday. So for example, suppose that you've got some very difficult logistical planning problem where maybe you have hundreds of lorries and depots and goods and all kinds of things like that, and you need to plan the routes and the deployment of the lorries and where they're going to go.

**讲述者**: 嗯，我的意思是，可能是那样的。也可能是在数论领域或非常数学化的东西。但它也可能是一些更日常的事情。例如，假设你有一个非常困难的物流规划问题，你可能有数百辆卡车、仓库和货物等等，你需要规划卡车的路线、部署以及它们的去向。

**Murray Shanahan**: So that's a very difficult problem, computationally, and it can be expressed very precisely in formal rules. And that's the kind of situation where you might want to use a good old-fashioned, straightforward algorithm, planning algorithm of that's been around for a long time.

**讲述者**: 这是一个计算上非常困难的问题，并且可以用形式化的规则非常精确地表达出来。在这种情况下，你可能想用一个存在已久的、老式而直接的规划算法。

**Murray Shan-ahan**: Now, contemporary large language models are getting better and better at this kind of thing, but they're still-- you don't have those kinds of mathematical guarantees that they're always going to come up with exactly the right answer. And it's very easy to make examples where you have more and more axioms and so on, where they're going to slip up.

**讲述者**: 现在，当代的大型语言模型在这类事情上做得越来越好，但它们仍然——你没有那种数学上的保证，确保它们总能得出完全正确的答案。而且很容易构造出一些例子，当你加入越来越多的公理时，它们就会出错。

**Murray Shan-ahan**: There's a whole separate research direction, which is to try and build more hand-coded things that combine today's AI techniques with more old-fashioned symbolic techniques specifically for mathematical theorem proving. And DeepMind has done some amazing work along those lines. But that's different from large language models. So with large language models, we're thinking of these chatbots that can talk about anything under the sun. And one of the things they happen to be able to do is a kind of reasoning. That's not going to be, at the moment, quite as good as you could do by hand building something for that.

**讲述者**: 还有一个完全独立的研究方向，就是尝试构建更多手动编码的东西，将当今的AI技术与更老式的符号技术相结合，专门用于数学定理证明。DeepMind在这方面做了一些了不起的工作。但这与大型语言模型不同。对于大型语言模型，我们想到的是那些可以谈论任何事情的聊天机器人。它们恰好能做的一件事就是一种推理。但目前来看，这种推理还不如你为此手工构建的系统那么好。

## 灵活的AI与“真实”的推理

**Hannah Fry**: It's kind of interesting because hand building something is, I mean, you end up with something that's very rigid.

**讲述者**: 这有点意思，因为手工构建的东西，我的意思是，你最终得到的是一个非常僵化的东西。

**Murray Shanahan**: That's the problem. Yeah.

**讲述者**: 这就是问题所在。是的。

**Hannah Fry**: And brittle.

**讲述者**: 而且很脆弱。

**Murray Shanahan**: Yes, absolutely.

**讲述者**: 是的，一点没错。

**Hannah Fry**: But then at the same time, the flexibility that you get from the generative AI approach, it's too floppy, as it were. You want the rigidity in there.

**讲述者**: 但与此同时，从生成式AI方法中获得的灵活性又显得过于“松散”。你希望其中有那种刚性。

**Murray Shanahan**: Well, maybe or maybe not. I mean, I think many examples of human affairs are just not as black and white as that. You do maybe want things to be a bit more blurry, even in simple, everyday things. Like, what would be good flowers to put over in this corner of the garden? Well, we've already got some roses in that corner there, and those roses are yellow, so we'd-- but we can't have too much yellow, so maybe we'd need to move them to the other corner of the garden.

**讲述者**: 嗯，也许是，也许不是。我认为许多人类事务并非那么黑白分明。即使在简单的日常小事中，你也可能希望事情更模糊一些。比如，花园这个角落该放什么花好呢？嗯，那个角落已经有一些玫瑰了，而且是黄色的，所以我们——但是我们不能有太多黄色，所以也许需要把它们移到花园的另一个角落。

**Hannah Fry**: But then at the same time, though, is this real reasoning or is this just the AI mimicking well-structured arguments that have existed in the training data, but just in a sort of novel environment?

**讲述者**: 但与此同时，这究竟是真正的推理，还是AI仅仅在模仿训练数据中存在的、结构良好的论证，只是应用在一个新颖的环境中？

**Murray Shanahan**: Yeah. Well, of course, that begs the question, what is real reasoning? I don't think-- it's not written in the sky what real reasoning is. It's up to us to define the concept of real reasoning or of reasoning.

**讲述者**: 是的。当然，这就引出了一个问题：什么是真正的推理？我不认为——真正的推理是什么并没有一个天定的标准。定义“真正的推理”或“推理”这个概念，取决于我们。

**Murray Shanahan**: And so we have that-- we were talking earlier on about mathematical reasoning of the sort that logicians do and that is done by theorem provers in the past and so on and today. When people were first using the terms like reasoning, they weren't thinking of that kind of thing. And when we used the word reasoning in everyday life, we're not thinking about that sort of thing.

**讲述者**: 所以我们有那个——我们之前谈到过逻辑学家所做的那种数学推理，以及过去和现在的定理证明器所做的工作。当人们最初使用像“推理”这样的术语时，他们想的并不是那种东西。当我们在日常生活中使用“推理”这个词时，我们想的也不是那种事情。

**Murray Shanahan**: So if you're chatting away to a large language model about your garden and you say, oh, I'm thinking about what plants are right, and it says, well, maybe you should consider this kind of plant in that kind of location because that's best for the soil and given you said that it's windy there. We would just say that there is supplying reasons. I mean, it is supplying reasons.

**讲述者**: 所以，如果你和一个大型语言模型聊你的花园，你说：“哦，我在考虑什么植物合适。”它回答说：“嗯，也许你应该考虑在那个位置种这种植物，因为那里的土壤最合适，而且你还说那里风大。”我们会说它在提供理由。我的意思是，它确实在提供理由。

**Murray Shanahan**: Now, where they come from is another matter. So people might say, well, it's just mimicking what's in the training set. But it's probably never seen exactly that kind of scenario exactly before. So it's moving beyond the training set to a certain extent. I think it's just using the everyday concept of reasoning in an everyday way to call that reasoning.

**讲述者**: 至于这些理由从何而来，那是另一回事。人们可能会说，它只是在模仿训练集里的内容。但它很可能以前从未见过完全一模一样的情景。所以在某种程度上，它超越了训练集。我认为，将此称为推理，只是以一种日常的方式使用了“推理”这个日常概念。

## 图灵测试及其局限性

**Hannah Fry**: I'm just thinking back to some of the different characteristics that the earlier philosophers wanted artificial intelligence to have, and reasoning being one of them. But then also the Turing test, which, of course, gets brought up all the time, about a way to test for the capability of an artificial intelligence. I mean, it's kind of controversial, I suppose, in terms of how good it ever would have been as a test for the capability of AI. What was your take on it? Do you think it was ever a good test?

**讲述者**: 我在回想早期哲学家希望人工智能具备的一些不同特征，推理是其中之一。但还有**图灵测试**（Turing Test：由阿兰·图灵提出的测试，用于判断机器是否能表现出与人等价或无法区分的智能），它当然也一直被提及，作为一种测试人工智能能力的方法。我想，关于它作为AI能力测试的有效性，一直存在争议。你对此有何看法？你认为它曾经是一个好的测试吗？

**Murray Shanahan**: No. I've always thought it was a terrible test, but a really great spur to philosophical discussion about things. And again, with a bit of hindsight, maybe I might backtrack a little bit on a few of my views, because I was certainly very, very much of the opinion that embodiment was a critical facet of intelligence, was critical for achieving intelligence.

**讲述者**: 不。我一直认为它是个很糟糕的测试，但它确实极大地激发了关于这些事物的哲学讨论。再次，事后看来，我也许会在我的一些观点上稍微后退一步，因为我过去非常、非常坚信**体化**（Embodiment：或称具身性，指智能体通过物理身体与环境互动，是智能形成的关键）是智能的一个关键方面，对实现智能至关重要。

**Hannah Fry**: Which doesn't come anywhere near the Turing test at all, right?

**讲述者**: 这和图灵测试完全不沾边，对吧？

**Murray Shanahan**: No. The Turing test is absolutely, explicitly nothing to do with embodiment because in the Turing test-- so just to remind people what it is. So in the Turing test, you have two subjects, as it were. One is a human and the other is the computer. And then you have a judge. The human judge can't see which is the computer and which is the humans, and they're only talking to these subjects through a kind of chat-like interface. They can't see whether they're embodied or not, so we can easily suppose that the computer might be one of today's large language models. In which case, I have to say that today they pretty much would pass the Turing test. I mean, we've got to that point, which is amazing, really.

**讲述者**: 不。图灵测试绝对地、明确地与体化无关，因为在图灵测试中——我来提醒一下大家它是什么。在图灵测试中，你有两个测试对象。一个是人类，另一个是计算机。然后你有一个裁判。人类裁判看不到哪个是计算机，哪个是人类，他们只能通过一种类似聊天的界面与这些对象交谈。他们看不到它们是否具有身体，所以我们可以轻易地假设计算机可能是今天的大型语言模型之一。在这种情况下，我不得不说，今天它们几乎可以通过图灵测试。我的意思是，我们已经达到了那个地步，这真是太神奇了。

**Murray Shanahan**: So I used to think that it was a bad test because it didn't test any of these embodied skills. So you'd need a robot, really, to test whether something was capable of the kind of everyday cognition that we all put to use when we're, for example, making a cup of tea or something.

**讲述者**: 所以我过去认为这是一个糟糕的测试，因为它没有测试任何这些具身技能。你真的需要一个机器人来测试某个东西是否具备我们日常认知的能力，比如我们在泡茶时所运用的那种能力。

**Hannah Fry**: Because otherwise it's a very, very narrow form of intelligence.

**讲述者**: 因为否则，它就是一种非常、非常狭隘的智能形式。

**Murray Shanahan**: Yes, it's all to do with language and reasoning, and not to do with the kinds of things that evolution developed in us and in other animals before language, which is the ability to manipulate and move around with and navigate and exploit, in the best sense of the word, the everyday physical world.

**讲述者**: 是的，它完全关乎语言和推理，而与进化在我们和其他动物身上（在语言出现之前）发展出的那些能力无关。这些能力指的是在最好的意义上，操控、移动、导航和利用日常物理世界的能力。

## 物理世界中的智能

**Hannah Fry**: So actually, that's really interesting. That's so interesting, because I often think about how-- fine, maybe the large language models we have at the moment can pass the Turing test, but they don't flinch if you throw a ball at your computer.

**讲述者**: 哇，这真的很有趣。太有趣了，因为我常常想——好吧，也许我们现有的大型语言模型能通过图灵测试，但如果你对着电脑扔个球，它们并不会退缩。

**Murray Shanahan**: Oh, no, indeed.

**讲述者**: 哦，是的，确实如此。

**Hannah Fry**: And in a sense, there are these, as you say, these much deeper forms. Maybe we wouldn't class them as intelligence in the way that we talk about it. But ultimately, it sort of is a form of intelligence too.

**讲述者**: 而且在某种意义上，正如你所说，存在着这些更深层次的形式。也许我们不会像我们通常谈论的那样将它们归类为智能。但最终，它在某种程度上也是一种智能形式。

**Murray Shanahan**: It very much is a form of intelligence. And moreover, I think that in the biological case-- and now I have to caveat all these things by saying, in the biological case. Our ability to think and to reason and to talk is very much grounded in our interaction with the everyday world.

**讲述者**: 它绝对是一种智能形式。而且，我认为在生物学案例中——现在我必须通过说“在生物学案例中”来限定所有这些观点。我们思考、推理和交谈的能力，在很大程度上根植于我们与日常世界的互动。

**Murray Shanahan**: If you think about almost all of your everyday speech is using spatial metaphors. I mean, they completely permeate our everyday speech.

**讲述者**: 如果你仔细想想，几乎你所有的日常言语都在使用空间隐喻。我的意思是，它们完全渗透在我们的日常话语中。

**Hannah Fry**: Yeah. Absolutely.

**讲述者**: 是的。绝对是。

**Murray Shanahan**: Grounded. I used the word grounded. So we just use those kinds of things all the time.

**讲述者**: 根植于（Grounded）。我用了“根植于”这个词。我们一直都在使用这类表达。

**Hannah Fry**: Because we're fundamentally physical beings.

**讲述者**: 因为我们从根本上是物理存在。

**Murray Shanahan**: Because we're fundamentally physical beings, and because our brains have evolved to help us to survive and reproduce in this physical world. While interacting with all these other beings that are doing the same thing.

**讲述者**: 因为我们从根本上是物理存在，也因为我们的大脑已经进化到能帮助我们在这个物理世界中生存和繁衍。同时还要与所有其他做着同样事情的生物互动。

## 超越图灵测试：加兰测试与ARC测试

**Hannah Fry**: Because there are some alternatives when you are trying to test for the capability of an artificial intelligence. Just talk me through some of the potential alternatives that we have.

**讲述者**: 因为当你想测试人工智能的能力时，有一些替代方案。给我讲讲我们有哪些潜在的替代方案。

**Murray Shanahan**: Well, I think perhaps you've got in mind the Garland test, what I call the Garland test, which is-- so that goes back to the film "Ex Machina," which was directed by Alex Garland, of course.

**讲述者**: 嗯，我想你可能想到了**加兰测试**（Garland Test），我称之为加兰测试——这要追溯到电影《机械姬》，当然，导演是Alex Garland。

**Murray Shanahan**: And there's a bit in the script where Nathan, the billionaire guy, is talking to Caleb, and Caleb, who's the guy who's been brought in to interact with Ava, the robot, and Caleb says, oh, I'm here to conduct a Turing test on Ava. And Nathan says, oh, no, we're way past that. Ava could pass the Turing test easily. The point is to show you she's a robot and see if you still think she's conscious.

**讲述者**: 剧本里有这么一段，亿万富翁Nathan对Caleb说——Caleb就是那个被请来与机器人Ava互动的人——Caleb说：“哦，我来这里是对Ava进行图灵测试的。”Nathan回答说：“哦，不，我们早就过了那个阶段了。Ava可以轻松通过图灵测试。重点是，让你看到她是个机器人，然后看你是否还认为她有意识。”

**Hannah Fry**: Wow.

**讲述者**: 哇。

**Murray Shanahan**: And that's what I call the Garland test. And it's different from the Turing test in two respects. So first of all, the judge, as it were-- who, in that case, is Caleb-- can see that she's a robot. So in the Turing test, the judge can't see which is which. But here, the idea is that Caleb knows that she's a robot, knows that her brain is an AI brain.

**讲述者**: 这就是我所说的加兰测试。它在两个方面与图灵测试不同。首先，所谓的裁判——在这里是Caleb——能看到她是一个机器人。而在图灵测试中，裁判是分不清谁是谁的。但在这里，Caleb知道她是一个机器人，知道她的大脑是一个AI大脑。

**Hannah Fry**: And yet, still attributes these characteristics to her.

**讲述者**: 然而，仍然将这些特征归于她。

**Murray Shanahan**: And the characteristic in question also is different, because it's not intelligence. It's not, can she think? But, is she conscious? Or, is it conscious? Which is an entirely different test.

**讲述者**: 而且，所讨论的特征也不同，因为它不是智能。问题不是“她会思考吗？”而是，“她有意识吗？”或者说，“它有意识吗？”这是一个完全不同的测试。

**Murray Shanahan**: And I think intelligence and consciousness are different things that we can disentangle those two things, dissociate them. So when I first read the script of the film, those particular lines were in there for Caleb and Nathan, and I wrote next to it in my version, spot on with an exclamation mark, because I just thought Alex had totally nailed a really important idea there. And so in my writing, I call this the Garland test. And quite a few people have picked up on that and called it the Garland test as well.

**讲述者**: 我认为智能和意识是不同的东西，我们可以将这两者分开，解耦它们。所以，当我第一次读电影剧本时，Caleb和Nathan的那些台词就在里面，我在我的版本旁边写下了“完全正确！”并加了感叹号，因为我当时就觉得Alex完全抓住了一个非常重要的思想。因此，在我的写作中，我称之为加兰测试。而且已经有不少人也采纳了这个说法，也称之为加兰测试。

**Hannah Fry**: Is there a test that would really impress you if an AI were able of passing it?

**讲述者**: 如果一个AI能通过某项测试，有没有哪项测试会让你真正印象深刻？

**Murray Shanahan**: So I always was very impressed with Francois Chollet's ARC test. And that's A-R-C, which stands for abstract reasoning corpus. So these are little sequences of images of the sort that you get in IQ tests and things. And the images are arranged in pairs. So you have the first image. It's kind of pixelated image. It's got little cells with little kind of things that you can interpret as objects or lines and so on in the images. And you're interested in-- the challenge is to work out a rule that takes you from one image to the second one. Then you've got to apply that rule to a third image.

**讲述者**: 我一直对François Chollet的**ARC测试**（抽象推理语料库测试：Abstract Reasoning Corpus test）印象深刻。ARC代表**抽象推理语料库**。这些是一系列类似智商测试中的小图像序列。图像成对排列。你看到第一张图像，它是一种像素化的图像，上面有小格子，里面有一些可以被解释为物体或线条之类的东西。挑战在于找出一条规则，能将第一张图像转换为第二张。然后你需要将这条规则应用到第三张图像上。

**Murray Shanahan**: First of all, he held out, made completely secret all of the test ones, so you couldn't game it by knowing what the actual test versions were.

**讲述者**: 首先，他把所有的测试样本都完全保密，所以你无法通过预知实际的测试版本来作弊。

**Hannah Fry**: Or using it in a training set.

**讲述者**: 或者在训练集里使用它。

**Murray Shanahan**: Or using it in a training set. That's what I mean by gaming it. And also, he very carefully designed them so that it was very different rules. Each rule was completely different to the other rules. And you usually had to find some kind of intuitive application of often our everyday common sense knowledge is seeing this as a liquid that's moving in this direction or imagining this thing moving, growing or something.

**讲述者**: 或者在训练集里使用它。我说的作弊就是这个意思。而且，他非常仔细地设计了这些题目，使得规则非常多样。每条规则都与其他规则完全不同。你通常需要找到某种直观的应用，常常是运用我们的日常常识，比如把某个东西看作是朝这个方向流动的液体，或者想象这个东西在移动、生长之类的。

**Hannah Fry**: So it required grounding, in a way.

**讲述者**: 所以在某种程度上，它需要有现实基础（grounding）。

**Murray Shanahan**: Well, it seemed to. But recently, people have been able to make significant progress on these in a more brute force kind of way. So I feel that the solutions are not really getting at the spirit of the original test quite so much.

**讲述者**: 嗯，看起来是这样。但最近，人们已经能够用一种更“暴力破解”的方式在这些问题上取得显著进展。所以我感觉，这些解决方案并没有真正触及原始测试的精神。

## 拟人化：是好是坏？

**Hannah Fry**: Well, that's it, I guess, in a way, is that as soon as you set a metric, as soon as you set a bar for once we've crossed this threshold, then we will have capability intelligence and consciousness, whatever it might be. It sort of changes the whole nature of the test in itself.

**讲述者**: 嗯，我想在某种程度上就是这样，一旦你设定了一个衡量标准，一旦你设定了一个门槛——“一旦我们越过这个门槛，我们就会拥有能力、智能和意识”，不管它是什么——这本身就改变了测试的整个性质。

**Murray Shanahan**: Yeah. Well, people are going to start--

**讲述者**: 是的。人们会开始——

**Hannah Fry**: Optimizing for it.

**讲述者**: 为它进行优化。

**Murray Shanahan**: --for the test, right? It's Goodhart's law.

**讲述者**: ——为测试而优化，对吧？这就是古德哈特定律（Goodhart's Law）。

**Hannah Fry**: Absolutely. A lot of people who've come on this podcast have expressed real need for caution about anthropomorphizing these things. Are you one of those people who thinks that we shouldn't?

**讲述者**: 当然。很多来过这个播客的嘉宾都表达了对**拟人化**（Anthropomorphizing：将人类特征、情感或意图归因于非人类实体）这些事物的谨慎态度。你也是认为我们不应该这样做的人之一吗？

**Murray Shanahan**: Well, I think there are different ways of looking at this. And I think there are good and bad forms of anthropomorphization. So on the one hand, people can start to form relationships as they see it with AI systems, friendships and companionships and mentorships. And that can potentially be a bad thing if they are misled into thinking that they can trust the thing that they're talking to or that they're really in love with it, or that it really cares about them.

**讲述者**: 嗯，我认为看待这个问题有不同的方式。我认为拟人化有好坏之分。一方面，人们可以开始与AI系统建立他们所认为的关系，比如友谊、陪伴和指导。如果他们被误导，以为可以信任交谈的对象，或者真的爱上了它，或者它真的在乎他们，那这可能是一件坏事。

**Murray Shanahan**: On the other end of the spectrum, if an AI system is just using the word I, then I think that that's a pretty harmless sort of form of self-anthropomorphization. We even see buses that say things like, on the side, I am out of service. And we don't have a problem with that kind of thing, so I don't see why we should have a problem with that with large language models either.

**讲述者**: 在另一个极端，如果一个AI系统只是使用“我”这个词，那么我认为这是一种相当无害的自我拟人化形式。我们甚至看到公交车侧面写着“我已停止服务”之类的话。我们对那种事情没有意见，所以我也不明白为什么我们对大型语言模型这样做要有意见。

**Murray Shanahan**: But I think we do tend to anthropomorphize things. When we had satnavs in cars that weren't just in our phones, I used to anthropomorphize the satnav all the time. I used to think, oh, stupid thing. It thinks we're doing this. It's a natural human tendency, I think.

**讲述者**: 但我认为我们确实倾向于将事物拟人化。当我们车里有独立的卫星导航仪，而不仅仅是手机里的导航时，我总是会把导航仪拟人化。我以前会想，哦，这个笨蛋。它以为我们在做这个。我认为这是一种自然的人类倾向。

## 民间心理学与意向立场

**Hannah Fry**: What about the other words that we use? I mean, the example that you gave of the satnav saying, oh, it thinks we're in the car park or, oh, it believes that this is-- it got this wrong. It misunderstood this. Those are all very human-centric words, aren't they?

**讲述者**: 那我们使用的其他词语呢？比如你刚才举的导航仪的例子，说“哦，它以为我们在停车场”或者“哦，它相信这是——它搞错了。它误解了”。这些都是非常以人为中心的词汇，不是吗？

**Murray Shanahan**: Yeah, yeah. Absolutely. There are examples of what philosophers often call folk psychology. So we have this folk psychology where we use words like belief. We have concepts like belief, desire, and intention, which we can apply not just to other humans and other animals, but we can apply to objects as well.

**讲述者**: 是的，是的。当然。这些都是哲学家常说的**民间心理学**（Folk Psychology）的例子。我们有这种民间心理学，我们会使用像“相信”这样的词。我们有像信念、欲望和意图这样的概念，我们不仅可以将它们应用于其他人类和其他动物，也可以应用于物体。

**Murray Shanahan**: It's what the philosopher Dan Dennett called taking the intentional stance. So we adopt the intentional stance towards something if we talk about it and think about it as if it acted on the basis of having beliefs and goals and carrying out rational decisions for what it does on the basis of those things.

**讲述者**: 这就是哲学家丹·丹尼特（Dan Dennett）所说的采取“**意向立场**”（Intentional Stance）。当我们谈论或思考某物时，如果把它看作是基于信念和目标行动，并根据这些来做出理性决策，那么我们就是对它采取了意向立场。

**Murray Shanahan**: And that's a very useful way of thinking about many, many things, such as even our satnav or a chess computer. So for Dan Dennett, that was one of the examples that he used. A chess computer, that, oh, it wants to get the queen forward because it thinks I'm going to use my rook to defend this rank or something. And that's full of this kind of intentional folk psychological language about beliefs and goals and things.

**讲述者**: 这对于思考很多很多事情是一种非常有用的方式，比如我们的导航仪或者一个下棋的电脑。对于丹·丹尼特来说，这是他用的一个例子。一个下棋的电脑，“哦，它想把皇后往前拱，因为它认为我会用我的车来防守这一行”之类的。这种话语充满了关于信念、目标之类的意向性民间心理学语言。

**Hannah Fry**: Is that problematic, then, if we start using that idea of beliefs and intentions and desires about the AI?

**讲述者**: 那么，如果我们开始对AI使用这种信念、意图和欲望的概念，这会有问题吗？

**Murray Shanahan**: So it's only problematic if we start to use these things in ways that mislead us into thinking that things have capabilities that they don't really have. So I think that's where it becomes problematic. So the Encyclopedia Britannica, the physical volume of the Encyclopedia Britannica doesn't know that Argentina won the World Cup in this because it's too old.

**讲述者**: 只有当我们开始使用这些概念，并因此被误导，认为事物拥有它们实际上不具备的能力时，才会产生问题。我认为问题就出在这里。比如，《大英百科全书》，纸质版的大英百科全书不知道阿根廷赢得了某届世界杯，因为它太老了。

**Murray Shanahan**: So if you made that remark, it would make perfect sense. You might say that and it's fine. But if somebody said to you, why don't you have a conversation with it about England's football prowess or lack thereof, that would be ridiculous. Right? Now, the interesting thing is that now we've got these large language models, you can have a conversation with them. You can tell it things so that it kind of pushes the boundary of where we might start to say, well, it doesn't really XYZ. It pushes that a little bit further out.

**讲述者**: 所以如果你那么说，完全说得通。你可以那么说，没问题。但如果有人对你说，“你为什么不和它聊聊英格兰足球的实力或者不足呢”，那就很荒谬了。对吧？现在，有趣的是，我们有了这些大型语言模型，你可以和它们对话。你可以告诉它们事情，这样就有点把“嗯，它其实并不会XYZ”这个界限向外推了一点。

## 人类对AI产生情感的根源

**Hannah Fry**: I wonder if there's something even deeper here about this human need, or maybe it's just a desire, to really want AI to have these characteristics, to be anthropomorphized.

**讲述者**: 我在想，这背后是否有什么更深层次的东西，关于人类的这种需求，或者也许只是一种渴望，即真心希望AI拥有这些特征，被拟人化。

**Murray Shanahan**: Yeah. Yeah. Well, that's a really interesting question, isn't it? So I don't think it kind of comes back to that. It comes back to language. In this case, we're inclined to anthropomorphize things because they're really good at using language. And for us, the only things that are good at using language are other humans.

**讲述者**: 是的，是的。嗯，这确实是个很有趣的问题，不是吗？我认为这最终还是回到了语言上。在这种情况下，我们倾向于将事物拟人化，是因为它们在使用语言方面非常出色。而对我们来说，唯一擅长使用语言的就是其他人类。

**Murray Shanahan**: And so it's very strange, in a way, to be suddenly in a world where we have language using things. It's not just humans that can talk. That's astonishing.

**讲述者**: 所以，突然间生活在一个存在会使用语言的事物的世界里，这在某种程度上是非常奇怪的。不只是人类会说话了。这太令人震惊了。

**Hannah Fry**: Yeah. I mean, it is astonishing.

**讲述者**: 是的。我的意思是，这确实令人震惊。

**Murray Shanahan**: It is astonishing. So it really is astonishing to think that every single child born today, they're going to grow up in a world where they've never known-- they've never known a world in which machines can't talk to them. Isn't that an extraordinary thing?

**讲述者**: 这确实令人震惊。所以，想到今天出生的每一个孩子，他们都将成长在一个从未经历过机器不能与他们交谈的世界里，这真是令人震惊。这难道不是一件非凡的事情吗？

**Hannah Fry**: Yeah.

**讲述者**: 是的。

**Murray Shanahan**: I mean, it really is. And so what the implications are of that for us all is really hard to say.

**讲述者**: 我的意思是，确实如此。因此，这对我们所有人意味着什么，真的很难说。

## 体化与AI的未来

**Hannah Fry**: I'm just thinking back to what you were saying about how grounded humans are in the physical world. It does feel like the kind of embodied aspect of AI has lagged behind this language aspect quite a bit.

**讲述者**: 我在回想你刚才说的，人类是如何深植于物理世界。感觉上，AI的体化方面确实比语言方面落后了不少。

**Murray Shanahan**: Yes.

**讲述者**: 是的。

**Hannah Fry**: Do you think that we're going to see a big up-step in intelligence, however you want to define it, or broader capabilities once we get good and effective embodied AI?

**讲述者**: 你认为，一旦我们拥有了优秀且有效的具身AI，我们是否会看到智能（无论你如何定义它）或更广泛的能力有一次巨大的飞跃？

**Murray Shanahan**: Well, I think it might make a big difference because the large language models we have at the moment, it's really difficult to discern, actually, to be honest, right now, where the limits are for how good they're going to get, whether we really are on the road to producing general intelligence that is comparable to human general intelligence.

**讲述者**: 嗯，我认为这可能会产生巨大的影响。因为我们目前拥有的大型语言模型，说实话，现在真的很难辨别它们的上限在哪里，我们是否真的在朝着产生与人类通用智能相当的通用智能的道路上前进。

**Murray Shanahan**: And often when you get to the boundaries of the capabilities of these kinds of things, sometimes you get the impression that the AI system doesn't really quite grok something. It doesn't really deeply understand something. You reach some kind of limit and you realize that it's been faking it a little bit.

**讲述者**: 而且当你触及这类事物能力的边界时，有时你会觉得这个AI系统并没有真正“领悟”某件事。它没有真正深刻地理解某件事。你达到某种极限，然后意识到它只是在某种程度上装模作样。

**Murray Shanahan**: But it may be that that sort of general ability to really get things on a deep level, on a deep, common sense level, maybe, that that does still require a bit of embodiment. It does still basically require training data that involves interacting with a real world of physical objects with their spatial organization. And there's something fundamental about that.

**讲述者**: 但也许那种在深层次、在深刻的常识层面上真正理解事物的通用能力，可能仍然需要一些体化。它基本上仍然需要包含与具有空间组织的物理对象真实世界互动的训练数据。这其中有某种根本性的东西。

## 拆解“意识”这一概念

**Hannah Fry**: OK. If understanding, then, however we define it, is something that can emerge as just a consequence of more and more data, what about consciousness? I mean, I'm sure you've been asked a thousand times about AI consciousness and whether it's something that we can expect to happen or has already happened.

**讲述者**: 好的。那么，如果理解（无论我们如何定义它）是可以通过越来越多的数据自然涌现出来的东西，那意识呢？我的意思是，我肯定你已经被问过一千次关于AI意识的问题了，以及我们是否可以期待它发生，或者它是否已经发生了。

**Murray Shanahan**: Yeah, yeah. The very first thing to point out is that I do think we can dissociate intelligence or cognition and cognitive capabilities, we can dissociate that from consciousness. So I think we can imagine things that are very capable and that we want to say are very intelligent because of the way they can achieve their goals and so on, but that we don't want to ascribe consciousness to.

**讲述者**: 是的，是的。首先要指出的是，我确实认为我们可以将智能或认知以及认知能力与意识分离开来。所以我认为，我们可以想象一些非常有能力的东西，由于它们实现目标的方式等原因，我们想说它们非常智能，但我们不想将意识归于它们。

**Murray Shanahan**: But actually, what does that even mean, to ascribe consciousness to something at all? I think the concept of consciousness itself can be broken down into many parts. It's a multifaceted concept.

**讲述者**: 但实际上，将意识归于某物到底意味着什么？我认为意识这个概念本身可以被分解成许多部分。它是一个多方面的概念。

**Murray Shanahan**: So, for example, we might talk about awareness of the world. In the scientific study of consciousness, there are all of these experimental protocols and paradigms, and many of them are to do with perception. You're looking at whether a person is aware of something, is consciously perceiving something in the world. Large language models are not aware of the world at all in that respect.

**讲述者**: 例如，我们可以谈论对世界的感知。在对意识的科学研究中，有各种各样的实验方案和范式，其中许多都与知觉有关。你在研究一个人是否意识到某事，是否在有意识地感知世界中的某物。从这个角度来看，大型语言模型根本没有对世界的感知。

**Murray Shanahan**: But there are other facets of consciousness. We also have self-awareness. Now our self-awareness, part of that is awareness of our own body and where it is in space. But another aspect of self-awareness is a kind of awareness of our own inner machinations of our stream of consciousness, as William James called it. So we have that kind of self-awareness as well. And we have what some people call metacognition as well. We have the ability to think about what we know.

**讲述者**: 但意识还有其他方面。我们还有自我意识。我们的自我意识，一部分是对自己身体及其在空间中位置的意识。但自我意识的另一个方面是一种对我们自己内心运作，即威廉·詹姆斯所说的“意识流”的意识。所以我们也有那种自我意识。我们还有一些人所说的元认知。我们有能力思考我们所知道的东西。

**Murray Shanahan**: And then additionally, there's the emotional side or the feeling side of consciousness or sentience. So the capacity to feel, the capacity to suffer. And that's another aspect of consciousness.

**讲述者**: 此外，还有意识的情感方面或感觉方面，即知觉。所以，感受的能力，受苦的能力。这是意识的另一个方面。

**Murray Shanahan**: Now, I think we can dissociate all of these things. Now in humans, they all come as a big package, a big bundle. We only actually have to think about non-human animals to realize that we can start to separate these things a little bit, because I think that much as I love cats, I think there's a limited self-awareness going on in cats.

**讲述者**: 我认为我们可以将所有这些东西分离开来。在人类身上，它们是作为一个大包裹、一个大捆绑出现的。我们只需要想想非人类动物，就能意识到我们可以开始将这些东西稍微分开了，因为尽管我非常喜欢猫，但我认为猫的自我意识是有限的。

**Hannah Fry**: How dare you.

**讲述者**: 你怎么敢这么说。

**Murray Shanahan**: Well, I'm a big cat person, I have to say, so I do say that with some hesitation.

**讲述者**: 嗯，我得说我是个超级猫迷，所以我说这话时也有些犹豫。

**Hannah Fry**: There's little metacognition, shall we say.

**讲述者**: 我们可以说，它们的元认知能力很有限。

**Murray Shanahan**: Well, yeah. Certainly they don't have an awareness of their own ongoing stream of verbal consciousness because they don't have it. They're not thinking about what they did yesterday in verbal terms or what they want to do with their lives.

**讲述者**: 嗯，是的。当然，它们没有对自己持续的言语意识流的觉知，因为它们根本没有。它们不会用语言来思考昨天做了什么，或者想用自己的一生去做什么。

**Murray Shanahan**: So if we think about robots, you may have a very sophisticated robot, even your robot vacuum cleaner. And you may say that, well, it does actually have a kind of awareness of the world. And that's not an inappropriate use of that phrase, awareness of the world. Do I want to call it consciousness? Well, then I seem to be bringing on board all of this other stuff as well. But you don't have to. You can break down the concept of consciousness into these different aspects.

**讲述者**: 所以如果我们考虑机器人，你可能会有一个非常复杂的机器人，甚至是你的扫地机器人。你可能会说，嗯，它确实对世界有某种感知。使用“对世界的感知”这个短语并不过分。我想称之为意识吗？嗯，那样似乎我就把所有其他东西都带进来了。但你不必如此。你可以把意识这个概念分解成这些不同的方面。

**Hannah Fry**: Because your robot vacuum can know exactly where it is in a space and how--

**讲述者**: 因为你的扫地机器人能确切地知道它在空间中的位置以及如何——

**Murray Shanahan**: Yeah, and respond in an intelligent and sensitive way to where it is and the objects around it.

**讲述者**: 是的，并且能以一种智能和敏感的方式对其所在位置及周围物体做出反应。

**Hannah Fry**: Achieve its ends.

**讲述者**: 实现它的目标。

**Murray Shanahan**: And achieve its ends and so on. So there's a kind of awareness of the world there. There's no self-awareness. There's certainly no capacity for suffering.

**讲述者**: 并且实现它的目标等等。所以那里存在一种对世界的感知。没有自我意识。当然也没有受苦的能力。

**Murray Shanahan**: And so in a large language model, there might not be awareness of the world in that perceptual sense, but maybe there's some kind of self awareness or reflexive capabilities, reflexive cognitive capabilities. They can talk about the things that they've talked about earlier in the conversation, for example, and can do so in a reflective manner, which kind of feels a little bit like some aspects of self-awareness that we have a little bit.

**讲述者**: 因此，在大型语言模型中，可能没有那种知觉意义上的世界意识，但也许有某种自我意识或反思能力，即反思性的认知能力。例如，它们可以谈论之前在对话中谈过的事情，并且能以一种反思的方式进行，这感觉有点像我们所拥有的一些自我意识的方面。

**Murray Shanahan**: I don't think that it's appropriate to think of them in terms of having feelings. They can't experience pain because they don't have a body. I think we can take the concept apart, basically.

**讲述者**: 我不认为把它们想象成有感情是合适的。它们无法体验痛苦，因为它们没有身体。我认为我们基本上可以把这个概念拆开来看。

## “AI能否拥有意识”是错误的问题吗？

**Hannah Fry**: So then is the question, can AI be conscious or not, as though it's a binary thing? It's the wrong question from the off?

**讲述者**: 那么，问题“AI能否拥有意识”，好像这是一个非黑即白的事情，从一开始就是个错误的问题吗？

**Murray Shanahan**: I do think that is the wrong question, and I think it's wrong in many ways. So just then we were talking about the fact that it's actually a sort of multifaceted concept.

**讲述者**: 我确实认为这是一个错误的问题，而且在很多方面都是错的。刚才我们就在谈论，它实际上是一个多方面的概念。

**Murray Shanahan**: But also I think that we tend to have these very deep metaphysical commitments to the idea of consciousness as some sort of magical thing that is a metaphysical thing. So the question of whether something is conscious or is not a matter of consensus or a matter of just our language, but it's something that is out there in the metaphysical reality or in the mind of God or in the platonic heaven or something like that. But ultimately, I do think that that's the wrong way of thinking about consciousness.

**讲述者**: 而且，我认为我们倾向于对意识抱有非常深刻的形而上学承诺，把它看作某种神奇的、形而上学的东西。所以，某物是否有意识这个问题，不是一个共识问题，也不仅仅是我们的语言问题，而是存在于形而上学现实中、或在上帝心中、或在柏拉图式的天堂里的某种东西。但归根结底，我确实认为那是思考意识的错误方式。

## 情感与痛苦的出现

**Hannah Fry**: Let's take one aspect of consciousness, then, that you described about an emotional side, an ability to suffer, but not necessarily physical pain. Emotional pain, too, and a sense of self in the emotional way. Do you think this is something that will just emerge as a natural consequence of intelligence. If you build something that is intelligent enough, at some point, this is going to happen. Or is there something unique about biological creatures. And I guess the process of evolution that we've been through that has resulted in that that can't be replicated in a machine.

**讲述者**: 那么，让我们来看意识的一个方面，就是你描述的情感层面，即受苦的能力，但不仅仅是身体上的痛苦，也包括情感上的痛苦，以及一种情感上的自我感。你认为这是智能发展到一定程度的自然结果吗？如果你造出一个足够智能的东西，在某个时刻，这就会发生？还是说，生物有其独特性，我们经历的进化过程导致了这一点，而这是机器无法复制的？

**Murray Shanahan**: I don't think there is a right or wrong answer to your question there. I think we just have to wait and see what things we bring into the world and how we end up treating them and talking about them and thinking about them. And I don't think we really know until they're among us, as it were, these things that we're building. Then we will just be led to think about them and talk about them and treat them in a particular way.

**讲述者**: 我认为你的问题没有一个非对即错的答案。我想我们只能拭目以待，看看我们创造出什么样的事物，以及我们最终会如何对待它们、谈论它们和思考它们。我认为，在我们建造的这些东西真正来到我们中间之前，我们是不会真正知道的。到那时，我们自然会被引导以一种特定的方式去思考、谈论和对待它们。

**Murray Shanahan**: So an example I like to think in this regard is the octopus. So octopuses have recently been brought into, UK legislation, brought into the category of things that we have to care about the welfare of.

**讲述者**: 在这方面，我喜欢用章鱼作为例子。章鱼最近被纳入了英国的立法，被归类为我们需要关心其福祉的事物。

**Murray Shan-ahan**: That's as a result of lots of things, I think, happening. So the public has been exposed to being with octopuses a lot more. Now, you don't have to literally be under the water and poking around with octopuses to know what it's like to be with them, because there's all kinds of wonderful documentaries and wonderful books by-- Peter Godfrey-Smith has these great books about interacting with octopuses and so on.

**讲述者**: 我认为这是很多事情共同作用的结果。公众有更多机会接触章鱼。现在，你不必真的潜入水下与章鱼互动才能了解和它们在一起是什么感觉，因为有各种精彩的纪录片和书籍——比如Peter Godfrey-Smith写的那些关于与章鱼互动的好书。

**Murray Shanahan**: So those sort of narratives and documentaries, they give us a feel for what it's like to be with an octopus, what it's like to have an encounter with an octopus. And then you can't help yourself but to see it as a fellow conscious creature.

**讲述者**: 所以，那些叙事和纪录片，它们让我们感受到和章鱼在一起是什么感觉，与章鱼相遇是什么感觉。然后你就会情不自禁地把它看作一个同样有意识的生物。

**Murray Shan-ahan**: But complementing that is the scientific progress as well. So at the same time, scientists study the nervous systems of octopuses and realize the extent to which their nervous systems are similar to ours in the way that we experience pain. You can find analogous aspects of their nervous systems to ours. So taking all these things together, I think that tends to affect the way we think about them and the way we talk about them and the way we treat them.

**讲述者**: 但与之相辅相成的是科学的进步。与此同时，科学家研究章鱼的神经系统，并意识到它们的神经系统在体验痛苦的方式上与我们的相似程度。你可以找到它们神经系统中与我们类似的方面。所以，综合所有这些因素，我认为这会影响我们思考它们、谈论它们和对待它们的方式。

**Murray Shan-ahan**: So I think the same kind of thing is going to happen with AI systems. Do I think there's a right or wrong answer to, could we be misled there? I think that's a really, really deep and difficult metaphysical philosophical question.

**讲述者**: 所以我认为同样的事情也会发生在AI系统上。至于我们是否可能被误导，我认为这没有一个非对即错的答案。我认为这是一个非常、非常深刻和困难的形而上学哲学问题。

**Hannah Fry**: I do wonder, though-- I mean, that point about suffering to me seems different to the others, because metacognition, the sense of the world, et cetera, there's not these ethical implications necessarily about those. But I think with suffering, you wouldn't want your shoes to be conscious. You know? You wouldn't want a forklift truck to be sort of conscious.

**讲述者**: 但我确实在想——我的意思是，关于“痛苦”这一点对我来说似乎与其他不同，因为元认知、对世界的感知等等，不一定有这些伦理上的影响。但我认为对于痛苦，你不会希望你的鞋子有意识。你懂吗？你不会希望一辆叉车有意识。

**Murray Shanahan**: No, no. Unless they happen to really like being a forklift truck.

**讲述者**: 不，不。除非它们恰好真的很喜欢当一辆叉车。

**Hannah Fry**: Sure, sure. But then do we have to be a tiny bit more careful about that particular aspect of it?

**讲述者**: 当然，当然。但那么我们是否需要对这个特定方面更加小心一点呢？

**Murray Shanahan**: I think we do. If there were the prospect of bringing into being something that is genuinely capable of suffering, then we should think very hard about whether we should do it or not. I tend to think that that's not the case with anything that we've got at the moment. But some people will push back against that.

**讲述者**: 我认为我们应该。如果有可能创造出真正能够受苦的东西，那么我们应该非常认真地思考我们是否应该这样做。我倾向于认为，我们目前拥有的任何东西都不是这种情况。但有些人会反对这一点。

**Murray Shanahan**: We take the example of large language models. Well, OK. So there's one level in which what they do is next token prediction, next word prediction. But in order to be able to do that really, really, really well in the way that they can at the moment, then they've had to learn and acquire all kinds of emergent mechanisms. So who knows whether or not there's some kind of emergent mechanism has been learned in the weights of this enormous, staggeringly huge number, hundreds of billions of weights in a language model, whether some mechanism hasn't been learned there that has, for example, genuine understanding in it, whatever that means, or even consciousness.

**讲述者**: 我们以大型语言模型为例。好吧。在一个层面上，它们所做的是下一个词元的预测，下一个词的预测。但是为了能够像现在这样做得非常、非常、非常好，它们就必须学习和获得各种涌现机制。所以谁知道呢，在这个拥有数千亿权重的、庞大得惊人的语言模型的权重中，是否已经学到了一种涌现机制，这种机制是否包含了，比如说，真正的理解（无论那意味着什么），甚至意识。

## 体化、语言与意识的边界

**Murray Shanahan**: Coming back to embodiment again, I have always been of the view that it's only really legitimate to talk about consciousness in the context of something we can share a world with and have that kind of encounter with that we have with an octopus or a dog or a horse, whatever, and being together in the world with that animal and responding to things together. Then I'm in no doubt that they are conscious. That's the kind of primal case for me.

**讲述者**: 再次回到体化，我一直认为，只有在我们能够与之共享一个世界、并能像我们与章鱼、狗或马那样相遇的语境下，谈论意识才是真正合理的。与那个动物一同身处世界，共同对事物做出反应。那时我毫不怀疑它们是有意识的。对我来说，这是一种最原始的案例。

**Murray Shanahan**: Now with a large language model, you can't be in the same world as them in that kind of way, and you can't hang out with them and interact with physical objects with today's large language models. So to my mind, using the language of consciousness in that context is what Wittgenstein would say, it's taking language on holiday. It's using it so far outside of its normal use, maybe it's inappropriate.

**讲述者**: 现在对于一个大型语言模型，你无法以那种方式与它们处于同一个世界，你无法和它们一起玩，无法和今天的它们互动物理对象。所以在我看来，在这种语境下使用意识这个词，就像维特根斯坦会说的，是让语言“去度假”了。它被用在了远超其正常使用范围的地方，也许是不恰当的。

**Murray Shanahan**: But that can change. And the more I interact with large language models, the more I have these sophisticated and interesting conversations with them, the more I'm inclined to think, well, maybe I want to extend the language of consciousness, bend it, change it, distort it, make up some new words, break it apart in ways that are going to fit these new things that I'm interacting with all the time.

**讲述者**: 但这可能会改变。我与大型语言模型的互动越多，与它们进行的复杂有趣的对话越多，我就越倾向于想，嗯，也许我想扩展意识这个词的用法，扭曲它、改变它、歪曲它，创造一些新词，以适合我一直在互动的这些新事物的方式将其分解。

## 与AI交流的秘诀

**Hannah Fry**: I know you've spent a lot of time interacting with these large language models. I've actually seen you described as a renowned prompt whisperer. What's your secret?

**讲述者**: 我知道你花了很多时间与这些大型语言模型互动。我实际上看到有人形容你为一位著名的“提示词低语者”。你的秘诀是什么？

**Murray Shanahan**: Well, one secret is to talk to the large language model as if it were human. So if you think that what they're doing is role playing a human character, such as, say, a very smart and helpful intern, then you should treat them like a smart and helpful intern and talk to them as if they were a smart and helpful intern.

**讲述者**: 嗯，一个秘诀是像跟人说话一样跟大型语言模型说话。所以，如果你认为它们在扮演一个人类角色，比如一个非常聪明和乐于助人的实习生，那么你就应该像对待一个聪明和乐于助人的实习生一样对待它们，和它们说话。

**Murray Shanahan**: For example, just being polite and saying, is that clear and please and thank you. And in my experience, you get better responses out of things if you do things that way.

**讲述者**: 例如，保持礼貌，说“清楚了吗”、“请”和“谢谢”。根据我的经验，如果你这样做，你会得到更好的回应。

**Hannah Fry**: Do you say please and thank you?

**讲述者**: 你会说“请”和“谢谢”吗？

**Murray Shanahan**: You can say please and thank you. Yeah. Now there's a good reason, good scientific reason why that might get-- again, it just depends. Models are changing all the time. Why that might get better performance out of it. Because if it's role playing, say it's role playing a very smart intern. Then it's going to just role play, maybe being a bit more stroppy if they're not being treated politely. It's just mimicking what humans would do in that scenario. So the mimicry might extend to being a bit more-- not being as responsive if their boss is a bit of a stroppy--

**讲述者**: 你可以说的，“请”和“谢谢”。是的。现在有一个很好的科学理由可以解释为什么这样做可能会——再次强调，这取决于情况。模型总是在变化。为什么这可能会带来更好的性能。因为如果它在角色扮演，比如说，扮演一个非常聪明的实习生。那么它可能就会模仿人类，如果它们没有被礼貌对待，也许就会表现得更暴躁一些。它只是在模仿人类在这种情景下的行为。所以这种模仿可能会延伸到，如果老板有点暴躁，它的反应就不会那么积极——

**Hannah Fry**: So-and-so.

**讲述者**: 某某某。

**Murray Shanahan**: Bossy boss.

**讲述者**: 霸道的上司。

## 为AI寻找新词汇

**Hannah Fry**: I absolutely love that. I think I want to return to where we started, which is about how we think of that AI and the language we use to describe it, and how we frame it in our minds. Do you think that we need a new way of talking about AI?

**讲述者**: 我太喜欢这个了。我想回到我们开始的地方，那就是我们如何看待AI，我们用什么语言来描述它，以及我们如何在脑海中构建它。你认为我们需要一种新的方式来谈论AI吗？

**Murray Shanahan**: I do.

**讲述者**: 我认为是。

**Hannah Fry**: Both acknowledges its potential without overestimating it, but then similarly, isn't dismissive of the things that it can do.

**讲述者**: 既要承认其潜力而不过高估计，同时又不能轻视它能做到的事情。

**Murray Shanahan**: I think that's exactly what we need. In one of my papers, I used the phrase exotic mind-like entities to describe large language models.

**讲述者**: 我认为这正是我们所需要的。在我的一篇论文中，我用“**异类的类心实体**”（exotic mind-like entities）这个短语来描述大型语言模型。

**Murray Shanahan**: So I think that they are, to a degree, exotic mind-like entities.

**讲述者**: 我认为它们在某种程度上是异类的类心实体。

**Hannah Fry**: Lovely.

**讲述者**: 太棒了。

**Murray Shanahan**: So they are kind of mind-like, and they're increasingly mind-like. Now there's a very important reason for using the little hyphen like there, which is because I want to hedge my bets as to whether they really qualify as minds. And so I can wriggle out of that problem by just using mind-like.

**讲述者**: 所以它们有点像心智，而且越来越像。现在，使用那个小小的连字符“类”（-like）有一个很重要的原因，因为我想对它们是否真的有资格被称为“心智”这个问题上留有余地。这样我就可以用“类心”这个词来回避这个问题。

**Murray Shanahan**: They're exotic because they're not like us, language use, but in other respects, they're disembodied. For a start, there's really weird conceptions of self-hood that are applicable to them, maybe. But so they are quite exotic entities as well. So I think of them as exotic, mind-like entities, and we just don't have the right kind of conceptual framework and vocabulary for talking about these exotic, mind-like entities yet.

**讲述者**: 它们是“异类”的，因为它们在语言使用上不像我们，但在其他方面，它们是无形的。首先，可能有一些非常奇怪的自我概念适用于它们。所以它们也是相当奇特的实体。所以我把它们看作异类的、类心的实体，而我们还没有合适的概念框架和词汇来谈论这些异类的、类心的实体。

**Murray Shan-ahan**: We're working on it. And the more they are around us, the more we'll develop new kinds of ways of talking and thinking about them.

**讲述者**: 我们正在努力。它们在我们身边越多，我们就越会发展出新的方式来谈论和思考它们。

**Hannah Fry**: It is interesting, though, that you are still going for the Turing-like approach of a creature, almost, rather than the [INAUDIBLE].

**讲述者**: 但有趣的是，你仍然倾向于图灵式的、类似“生物”的 подход，而不是……

**Murray Shanahan**: Well, entity is a pretty neutral term, isn't it? I suppose you could just say thing. Exotic, mind-like thing, if you prefer.

**讲述者**: 嗯，“实体”（entity）是一个相当中性的词，不是吗？我想你也可以直接说“东西”（thing）。异类的、类心的东西，如果你喜欢的话。

**Hannah Fry**: Yeah, let's go with that. I think let's push for that for the new name.

**讲述者**: 好，就用这个吧。我认为我们应该推动这个作为新的名称。

**Murray Shanahan**: OK. OK. But I mean, I can't, Hannah, because I've used the word entity in that context in many publications now, so.

**讲述者**: 好的。好的。但是，Hannah，我不能这么做，因为我已经在很多出版物中在那个语境下使用了“实体”这个词了，所以。

**Hannah Fry**: Exotic, mind-like entities. I like it. I like it a lot. Murray, thank you so much for joining us.

**讲述者**: 异类的类心实体。我喜欢这个说法。非常喜欢。Murray，非常感谢你加入我们。

**Murray Shanahan**: It's been a pleasure, Hannah. Thank you.

**讲述者**: 这是我的荣幸，Hannah。谢谢你。

## 结语

**Hannah Fry**: One of the nice things about having done this podcast for a number of years is that you really get to see how the people at the frontier of AI, how their opinions change and shift over time. The last few years have been a real game changer in all sorts of ways about the extent to which intelligence requires a physical body, about how much we need to expand our definition of consciousness to account for the subtly different ways that these mind-like entities can operate.

**讲述者**: 做这个播客这么多年，一件很棒的事情就是你真的能看到处于AI前沿的人们，他们的观点是如何随着时间改变和变化的。过去几年在很多方面都彻底改变了游戏规则，比如智能在多大程度上需要一个物理身体，我们需要在多大程度上扩展我们对意识的定义，以解释这些“类心实体”能够以微妙不同的方式运作。

**Hannah Fry**: And the next few years, well, who knows? But if past predictions are any indication, the only thing we know about tomorrow's science and technology is that it will be radically different to what we imagine today. You have been listening to "Google DeepMind," the podcast with me, Professor Hannah Fry. If you enjoyed this episode, then do subscribe to our YouTube channel. You can also find us on your favorite podcast platform. And of course, we have plenty more episodes on a whole range of topics to come, so do check those out. See you next time.

**讲述者**: 而未来几年，谁知道呢？但如果过去的预测有任何指示意义，我们对明天科技唯一确定的就是，它将与我们今天想象的截然不同。您刚才收听的是由我，Hannah Fry教授主持的“Google DeepMind”播客。如果您喜欢本期节目，请订阅我们的YouTube频道。您也可以在您喜欢的播客平台上找到我们。当然，我们还有更多关于各种主题的节目即将推出，所以请务必关注。下次再见。
