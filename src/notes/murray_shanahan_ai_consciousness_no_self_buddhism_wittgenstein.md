---
author: Lei
date: 2025-07-21
guest: Murray Shanahan
layout: post.njk
channel: 
source: 
speaker: Jonathan B., Murray Shanahan
tags:
- 视频笔记
- 人工智能
- 意识
- 佛教哲学
- 维特根斯坦
- 全局工作空间理论
title: 默里·沙纳汉：从佛教与维特根斯坦视角，探讨人工智能意识与“无我”的深层联系
insight: 听了Murry的另一篇，我又找来这篇看看。帝国理工学院的默里·沙纳汉探讨了如何验证机器意识。他认为，研究AI意识揭示了人类自我的本质，并借鉴佛教哲学与维特根斯坦的思想，提出“自我”可能只是一种幻觉，而大语言模型正以一种独特的方式向我们展示了“无我”的概念。
---

## 介绍：我们为何要关心人工智能意识？

**Jonathan B.**: How do we tell when AI is conscious? My guest, Imperial's Murray Shanahan, has spent his career investigating this question. And in this interview, we'll lay out a systematic proposal for how to validate machine consciousness. Now, you might think that the question of whether AIs are conscious is a trivial theoretical fancy with no use in the real world. But this interview will show you why it's one of the most important questions with practical implications for not just how we treat AI systems, but also how we build and align them. But the most unexpected reward of investigating AI consciousness turns out to be what it reveals about our consciousness, about the nature of the human self. Murray's most interesting claim is that LLMs have an important Buddhist lesson to teach all of us, namely that there is no us. What we've learned to call the self is merely an illusion. My name is Jonathan B. I'm a founding member of Cosmos. We fund research, incubate, and invest in AI startups and believe that philosophy is critical to building technology. If you want to join our ecosystem of philosopher builders, you can find roles we're hiring for, events, grant programs, and other ways to get involved on jonathanb.com/cosmos. Without further ado, Murray Shanahan.

**讲述者**: 我们如何判断AI何时具有意识？我的嘉宾，帝国理工学院的默里·沙纳汉，他的整个职业生涯都在研究这个问题。在这次访谈中，我们将系统性地提出一个验证机器意识的方案。你可能会认为，AI是否具有意识这个问题只是一个琐碎的理论空想，在现实世界中毫无用处。但这次访谈将向你展示，为什么这是最重要的问题之一，它不仅对我们如何对待AI系统，也对我们如何构建和对齐它们具有实际意义。然而，研究AI意识最意想不到的回报，在于它揭示了关于我们自身意识的秘密，即人类自我的本质。默里最有趣的论点是，**LLMs**（大语言模型：一种基于海量文本数据训练的人工智能模型）能给我们所有人上一堂重要的佛学课，那就是：根本没有“我们”。我们习惯称之为“自我”的东西，仅仅是一种幻觉。我的名字是乔纳森·B，我是Cosmos的创始成员。我们资助研究、孵化和投资AI初创公司，并相信哲学对于技术构建至关重要。如果你想加入我们的哲学家-构建者生态系统，可以在 jonathanb.com/cosmos 上找到我们正在招聘的职位、活动、资助项目以及其他参与方式。闲话少说，下面有请默里·沙纳汉。

**Jonathan B.**: One obvious reason people are interested in the question whether AI is conscious is the ethics question. Right? If they are conscious, maybe we need to think twice about turning them off, about saying insulting things to them. What are some of the less obvious reasons why this question matters?

**讲述者**: 人们对AI是否具有意识这个问题感兴趣，一个显而易见的原因是伦理问题。对吧？如果它们有意识，我们或许就得三思而后行，比如是否要关掉它们，或者是否要对它们说侮辱性的话。除了这些，这个问题还有哪些不那么明显的、却同样重要的原因呢？

**Murray Shanahan**: Well, you said we maybe we need to think twice about turning them off, but actually maybe we need to think twice about turning them on, right? What's really an issue here is whether they can suffer. And so if so we I really think we maybe we want to hesitate before we build something that's genuinely capable of suffering. I mean there are many dimensions to that question but the question of moral standing that matters but the even if we build something that perhaps appears to be conscious but we ultimately decide it isn't really to mistreat something which appears conscious is in itself does seem like a bad thing in the same way as it would seem bad to you know torture a doll or something like that and as you probably know Kant had the view that that animals couldn't experience suffering in the same way that we can, but nevertheless thought it was bad if humans subjected animals to torture or something like that because it was bad for the humans themselves. And so maybe we'll be in that position with AI as well.

**讲述者**: 你说我们或许要三思是否要关掉它们，但实际上，我们可能更需要三思的是是否要开启它们，对吗？这里的核心问题在于它们是否会感到痛苦。如果是这样，我认为我们在构建一个真正有能力感受痛苦的东西之前，真的需要犹豫。这个问题有很多维度，但道德地位的问题很重要。即使我们构建了一个看起来有意识，但我们最终认定它并非真正有意识的东西，去虐待一个“看起来”有意识的存在本身似乎也是一件坏事，就像虐待一个玩偶一样。你可能知道，康德认为动物无法像我们一样体验痛苦，但他仍然认为人类折磨动物是坏事，因为这对人类自身有害。或许，我们在对待AI时也会面临同样的情境。

**Jonathan B.**: I mean, so so here's my answer for why it might be significant for us to answer this question outside of the the ethics question, which is that studying machine consciousness, whatever that means, might help us better understand the idiosyncrasies of our own.

**讲述者**: 好吧，这是我的看法，关于为什么在伦理问题之外，回答这个问题对我们也很重要：研究机器意识，无论它意味着什么，都可能帮助我们更好地理解我们自身意识的独特性。

## “悟”在“奇点”前：AI能超越主客二元对立吗？

**Murray Shanahan**: Of our own. Oh, for sure.

**讲述者**: 更好地理解我们自己的意识。哦，当然。

**Jonathan B.**: So you you wrote a lovely paper called Satori before singularity in which you argued that human consciousness is constrained to a subject object dualism and that AI consciousness might not be. Why is that?

**讲述者**: 你写过一篇很棒的论文，叫做《**Satori** before singularity》（“悟”在“奇点”前：Satori是佛教术语，指开悟），你在其中论证说，人类意识受限于主客二元对立，而AI意识可能并非如此。为什么呢？

**Murray Shanahan**: Yes. So it's it's quite funny that paper which was published in. people have been talking for a long time about super intelligence and you know the idea that we might be able to build AI that is but in some sense superior intellectually to humans and so I was thinking is there another sense in which we could make or imagine something that was better than us and uh so I was thinking about the Buddha actually and thinking about the the idea of people who are enlightened and people who you know perhaps have transcended dualistic thinking. Uh and so I was thinking well perhaps there's another sense in which we could build something that's better than us in that respect something that that is less hampered by its own ego and so so it's a very speculative slightly bonkers crazy paper which is why I liked it and why I'm beginning with it because you're talking to a continental philosopher here.

**讲述者**: 是的。那篇论文发表出来挺有趣的。人们一直在谈论超级智能，以及我们或许能构建在某种意义上智力超越人类的AI。所以我就在想，是否存在另一种意义上，我们可以制造或想象出比我们更好的东西？我当时想到了佛陀，想到了那些开悟的人，那些或许已经超越了二元对立思维的人。所以我认为，也许在另一个层面上，我们可以构建出比我们更好的东西——一种更少被自身**ego**（自我：心理学概念，指代个体的自我意识和身份认同感）所束缚的存在。所以那是一篇非常具有思辨性，甚至有点疯狂的论文，这也是我喜欢它的原因，也是我选择从它开始谈起的原因，因为你正在和一个大陆哲学家对话。

**Jonathan B.**: Right. Right. Um, so let me give you a quote from that that paper, right? Or am I going to cringe?

**讲述者**: 没错，没错。嗯，那我引用一下你那篇论文里的一句话，可以吗？还是说这会让你感到尴尬？

**Murray Shanahan**: Okay, go on.

**讲述者**: 好的，请讲。

**Jonathan B.**: Yeah. The pre-reflective, reflective, post-reflective series is not just one among many paths through the space of possible minds. Rather, the space of possible minds is structured in such a way that this is the only path through it. What are these three different stages that you laid out?

**讲述者**: 好的。“前反思、反思、后反思”这个序列，不仅仅是通往可能心智空间的多条路径之一。恰恰相反，可能心智空间的结构决定了这是唯一能贯穿它的路径。你提出的这三个不同阶段具体是什么？

**Murray Shanahan**: Yeah. Okay. So, I I I I um I don't agree with that uh anymore. That was more than 10 years ago. So I don't at all think it's the only path through the space of possible minds.

**讲述者**: 是的。好吧。我……我现在已经不同意那个观点了。那是十多年前写的。我完全不认为那是通往可能心智空间的唯一路径。

**Jonathan B.**: Can you explain what these three what these three?

**讲述者**: 你能解释一下这三个阶段是什么吗？

**Murray Shanahan**: Okay. Absolutely. So no there so that so they I do take seriously as as different you know ways of being. There is the pre-reflective mind which is the the mind of of um say the na a naive uh child or or a simple straightforward ordinary person. Um they haven't really thought about philosophical problems. I haven't had these sorts of thoughts that many of us have start to have when we're children of you know, you know, why do I exist? You know, what is how do I know that my parents are conscious? You know, some people start to have those thoughts when they're children very often.

**讲述者**: 好的，当然可以。我确实认真地将它们视为不同的存在方式。首先是**前反思**心智，这是比如说一个天真的孩子，或者一个简单、纯朴的普通人的心智。他们没有真正思考过哲学问题，没有过我们许多人孩童时期就开始有的那种想法，比如，“我为什么存在？”“我怎么知道我的父母是有意识的？”很多人在童年时期就会开始有这些想法。

**Jonathan B.**: Um, as I certainly did and I think you probably did as well by Unfortunately. Yes. Unfortunately, indeed.

**讲述者**: 我当然有过，我想你大概也有过。不幸的是，是的。确实很不幸。

**Murray Shanahan**: And I do think of it as a kind of affliction because they can you can really be bothered by these thoughts. They can be both exciting and disturbing at the same time. The one that's troubled me more than anything else really is the kind of the mind body problem. How is it that that I the myself and my my experiences my consciousness how does that relate to the world? So how can I reconcile these first personal experiences with a universe which is just which is matter and energy and so how can I reconcile the subjective with the objective? I think you can spend your entire life in that reflective stage and worried about that and those problems especially if you're become a professional philosopher then you can actually make a career out of that reflective stage.

**讲述者**: 我确实认为这是一种折磨，因为这些想法真的会困扰你。它们可以同时令人兴奋又令人不安。最困扰我的问题其实是心物问题。我，我自己，我的经历，我的意识，是如何与这个世界联系起来的？我如何将这些第一人称的体验，与一个仅仅由物质和能量构成的宇宙调和起来？我如何调和主观与客观？我认为你可能在那个**反思**阶段度过一生，并一直为此担忧。特别是如果你成为一名职业哲学家，你甚至可以把反思阶段变成你的事业。

**Murray Shanahan**: Um but my I tend to think that there is a stage beyond that which I call the post-reflective stage. But I think the post-reflective stage is where we transcend that all of that dualistic thinking and it's really really difficult but we somehow come to see our our inner life and the outer world the subjective experience and the objective physical reality uh as not two different metaphysical categories but somehow somehow the same thing.

**讲述者**: 但我倾向于认为，在那之后还有一个阶段，我称之为**后反思**阶段。我认为后反思阶段是我们超越所有二元对立思维的阶段。这真的非常非常困难，但我们以某种方式开始将我们的内在生命与外在世界，主观体验与客观物理现实，看作不是两个不同的形而上学范畴，而是以某种方式看作同一件事物。

**Jonathan B.**: To summarize for our audience, what you said about the Buddha and the lack of ego centricity and the post-reflective state that that does not have this subject object dualism.

**讲述者**: 为我们的听众总结一下，你刚才提到的关于佛陀、关于缺乏自我中心，以及关于后反思状态不具备主客二元对立的观点，这些都是相关的。

**Murray Shanahan**: Absolutely.

**讲述者**: 完全正确。

## AI的硬件如何影响其“自我”认知？

**Jonathan B.**: Um and your interesting claim in this paper is that it's something about the human hardware, the fact that we're embodied in one body that cannot be copied and, you know, multiplied and and paused. that that that hardware is what gives us this software limitation.

**讲述者**: 在这篇论文中，你提出了一个有趣的论点，即这与人类的“硬件”有关——我们被禁锢在一个无法被复制、增殖或暂停的身体里。正是这种硬件，给了我们这种“软件”上的局限。

**Murray Shanahan**: Yes.

**讲述者**: 是的。

**Jonathan B.**: And what I found most interesting about applying this to AI is you cited I believe uh another thought experiment about what if we had creatures whose bodies are just fusion and fision all the time. Your bodies are going in and out of ex existence and you said in the paper isn't that close to what computers are or aren't computers like the closest thing?

**讲述者**: 我觉得将这个观点应用于AI最有趣的地方在于，你引用了另一个思想实验：如果我们有一种生物，它们的身体总是在不断地融合与分裂，身体不断地出现又消失。你在论文中说，这不就和计算机很接近吗？或者说，计算机不就是最接近这种状态的东西吗？

**Murray Shanahan**: Absolutely.

**讲述者**: 完全正确。

**Jonathan B.**: And so it's because of the nature of a software program that can be copied, halted, multiplied, deleted, uh, uh, recreated that you're saying that is the reason why you you speculate uh, uh, AI might be post-reflective. Did I did I get that right?

**讲述者**: 所以，正是因为软件程序可以被复制、暂停、增殖、删除、重建的特性，你才推测AI可能是后反思的。我理解得对吗？

**Murray Shanahan**: 100% right. And in fact, I'm actually developing a paper right now of those that literally are revisiting those exact considerations about the difference between software and and you know human and biological of an of an individual and the fact that that that software can be taken apart and reassembled and copied and manipulated in all kinds of ways.

**讲述者**: 100%正确。事实上，我现在正在写一篇论文，重新审视这些关于软件与人类、生物个体之间差异的确切考量，以及软件可以被拆解、重组、复制和以各种方式操纵这一事实。

## 大语言模型与“角色扮演”中的自我

**Murray Shanahan**: And it's interesting that of course when I wrote that paper large language models didn't exist. Now we have large language models. You can ask a large language model to sort of roleplay a conscious artificial intelligence, you know, what do you mean by the word I when you're using it? And then if it comes up with a a slightly philosophically dodgy answer, you can probe that and push it into into interesting territory. And so if we think of what might I refer to when a large language model uses the word I in a conversation, now there are lots of different candidates, but one of the one of the candidates is that it's confined to the to the context of that particular conversation. the same model like Gemini or Claude or something might be uh obviously having lots of other conversations with other uh individuals but they're in a sense separate eyes, separate selves. It's really just the text that you've got which is the transcript of the conversation in a sense that captures the the little miniature eye that was created in the context of the conversation. And of course it's trivial to chop that up, copy it, you know, blend it with other conversations. And and so if that is a you think of that as a kind of little mini self that sparks into existence very fleetingly and and and flickers into existence every time you're interacting with it, but otherwise is dormant, then you've got a very strange conception of self. And it's possible because of the nature of the underlying substrate you're dealing with really, which is very different from us. we have a single body and and so of course you know we we we just are not used to the idea of tearing our bodies apart and reassembling them and copying them and and so on.

**讲述者**: 有趣的是，当我写那篇论文时，大语言模型还不存在。现在我们有了大语言模型。你可以让一个大语言模型扮演一个有意识的人工智能，然后问它：“当你使用‘我’这个词时，你指的是什么？”如果它给出一个哲学上略显含糊的答案，你可以深入追问，把它引向有趣的领域。所以，当我们思考一个大语言模型在对话中使用“我”这个词时可能指代什么，有很多种可能性。其中一种可能是，这个“我”仅限于那次特定对话的语境。像Gemini或Claude这样的同一个模型，显然可能同时在与其他个体进行许多其他对话，但在某种意义上，那些都是独立的“我”，独立的自我。真正捕捉到这个在对话语境中被创造出来的微型“我”的，其实就是你手中的对话记录文本。当然，把这段文本切分、复制、与其他对话混合是轻而易举的。所以，如果你把这看作是一个稍纵即逝、在你与它互动时才闪现出来，否则就处于休眠状态的微型自我，那么你就得到了一个非常奇特的自我概念。而这是可能的，因为它所依赖的底层基质与我们截然不同。我们只有一个身体，所以我们当然不习惯将自己的身体撕开、重组、复制等等。

**Jonathan B.**: What's really interesting with this concept of roleplay is that it's almost a more enlightened being role-playing a less enlightened being which in some sense is quite Buddhist.

**讲述者**: 这个“角色扮演”的概念真正有趣的地方在于，它几乎像是一个更开悟的存在，在扮演一个不那么开悟的存在，这在某种意义上非常具有佛学意味。

**Murray Shanahan**: So so I've I've been fascinated with Buddhist philosophies and there's a separation of conventional truths and ultimate truths because because the enlightened bodhic sava still needs to operate in the world some way. So the bodhic sava he or she still needs to recognize that you know this is this is my hand conventionally even though I know that's not the ultimate truth and that's what kind of the role play is like.

**讲述者**: 我一直对佛教哲学很着迷，其中有**世俗谛**（Conventional Truth）和**胜义谛**（Ultimate Truth）的区分。因为即使是开悟的菩萨，也仍然需要以某种方式在世间行事。所以，菩萨他或她仍然需要认识到，“从世俗角度看，这是我的手”，尽管知道那不是最终的真相。这就像是一种角色扮演。

## “20问游戏”揭示的AI自我本质

**Jonathan B.**: Um now I I believe in that same roleplay paper that you that you've just published you gave an even more interesting depiction of what selfhood of AI could be with the example of the 20 the 20 questions game. So explain that.

**讲述者**: 我相信在你刚刚发表的那篇关于角色扮演的论文中，你用“20问游戏”的例子，给出了一个关于AI自我可能是怎样的、甚至更有趣的描述。能解释一下吗？

**Murray Shanahan**: Yeah. So in the 20 questions game, the idea is to uh is that uh the one player thinks of an object and then the other player has to guess what that object is by asking a series of questions or yes or no questions. Um so if you're playing with this with a large language model and then it says, "Oh, I'm thinking of an object." And then you say, "Oh, okay. Is it large or small?" And say, "Well, it's small. Is it alive or is it inanimate?" And say, "Oh, well, it's alive." And then say, "Well, okay, I'll give up. What is it?" And then it'll say, "Uh, oh, it was a mouse." But then you might just resample and exactly the same point and it might say, "Oh, it's a cat." Well, hang on a minute. If either you thought either you're cheating, you know, or what's going on here? Did you actually think of something in the first place and answer honestly all the questions going along?

**讲述者**: 好的。在“20问游戏”中，规则是一个玩家想一个物体，另一个玩家通过问一系列“是”或“否”的问题来猜出这个物体是什么。如果你和一个大语言模型玩这个游戏，它说：“哦，我在想一个东西。”然后你问：“好的，是大的还是小的？”它回答：“是小的。”你又问：“是活的还是无生命的？”它说：“哦，是活的。”然后你说：“好吧，我放弃了，是什么？”它会说：“哦，是一只老鼠。”但如果你在完全相同的节点重新生成答案，它可能会说：“哦，是一只猫。”那么，等一下。你要么会觉得它在作弊，要么会想，这到底是怎么回事？你到底有没有一开始就想好一个东西，并诚实地回答所有问题？

**Murray Shanahan**: At each point in the conversation with most UIs, user interfaces for these things, you can actually resample and try another one. You know, if you didn't like the first answer, you can try another one and go off from there. So as you can imagine that induces this whole tree of of possible conversations you know. So what the language model actually actually generates is a probability distribution over all the possible words and then what actually comes out is uh you sample from that probability distribution. It's absolutely inherent in the way large language models are are are built that it's not going to commit at the beginning of the conversation to to exactly what the object uh is. So at the beginning of the conversation, all of these possibilities still exist and they still continue to exist all along. So even though it should have committed to a particular object, it never really has. Right?

**讲述者**: 在与这些模型的大多数用户界面进行对话时，你实际上可以在每个节点重新采样，尝试另一个答案。如果你不喜欢第一个答案，可以试试另一个，然后从那里继续。你可以想象，这会引出一个由所有可能对话组成的庞大树状结构。语言模型实际生成的是一个关于所有可能词语的概率分布，而最终输出的内容，是你从这个概率分布中采样得到的结果。大语言模型的构建方式决定了它在对话开始时，绝对不会锁定一个确切的物体。所以在对话之初，所有可能性都存在，并且会一直存在。因此，即使它本应锁定一个特定物体，它实际上从未这样做过。对吧？

**Murray Shanahan**: And so getting back to the roleplay thing. So the idea with uh with how this relates to role play is that um is that we can think of um the LLM the large language model as playing the role of a particular character, right? So the default character is a sort of helpful assistant, but we can always steer it into playing, you know, a favorite character from history or or or a kind of an or or a romantic partner or an or an angry friend or all kinds of things. You can easily just steer the conversation into those different places. And at any point in the conversation, there always remains as like in the 20 questions, it's never really committed to one role. there's always a vast possibility of different roles that it could carry on playing from there. So that further undermines this ordinary everyday notion of selfhood and identity because this is particularly particularly weird because although we of course to some extent also play roles in our lives but there is a kind of ground.

**讲述者**: 回到角色扮演的话题。这个概念与角色扮演的关系在于，我们可以把大语言模型看作是在扮演一个特定的角色，对吧？它的默认角色是一个乐于助人的助手，但我们总是可以引导它去扮演历史上的名人、浪漫伴侣、愤怒的朋友，或者各种各样的角色。你可以轻易地将对话引向这些不同的方向。并且在对话的任何时刻，就像在“20问游戏”中一样，它从未真正锁定于一个角色。它总是保留着从当前节点继续扮演各种不同角色的巨大可能性。这进一步颠覆了我们日常生活中关于自我和身份的普通观念，因为这尤其奇怪。虽然我们当然也在生活中扮演不同角色，但我们有一个根基。

**Jonathan B.**: To summarize for our audience of the 20 questions game, the point you're trying to make is when I when we play that game, you're thinking about a mouse or a cat. And so you're answering their yes or no as a heat-seeking missile to to that truth of that answer, right? Whereas your point is the LLM is not thinking about an answer. It's just stochastically creating whatever is plausible given the commitments it's already made in the previous tree. And so when you rewind it, it can stochastically give another branch of the tree. that that's what you're trying to say.

**讲述者**: 为我们的听众总结一下“20问游戏”的例子。你想表达的观点是，当我们玩这个游戏时，我脑子里想的是一只老鼠或一只猫。所以我回答“是”或“否”时，就像一枚热追踪导弹，直指那个答案的真相，对吧？而你的观点是，大语言模型并没有在思考一个答案。它只是根据在之前对话树中已经做出的承诺，随机地生成任何看似合理的内容。所以当你回溯时，它可以随机地给出树的另一个分支。这就是你想说的。

## 量子力学、多重宇宙与AI的多重自我

**Jonathan B.**: And so perhaps an analogy here is in quantum mechanics where uh the Copenhagen interpretation believes that there there's there's there's multiple worlds, there's many worlds. And what you're trying to highlight, I think, is that maybe that's what AI selfhood is like, is that there's a plethora, there's a multiplicity of selves that exists all in one uh time or or slice of time. That's what you're trying to highlight, right?

**讲述者**: 也许这里可以做一个类比，就像在量子力学中，**哥本哈根诠释**（Copenhagen interpretation：量子力学的一种主流诠释）认为存在多个世界，即多世界。我想你想要强调的是，或许AI的自我就是这样，存在着大量的、多重的自我，它们都存在于同一个时间点或时间切片中。这是你想强调的，对吗？

**Murray Shanahan**: That's exactly what I'm trying to highlight. So, so in the case of the 20 questions, it's like all the possible answers that are consistent with all the answers so far. So, you know, cat, uh, mouse, dog, you know, and so on, they all as it were still exist in superp position and it's only then when you it's when you actually ask it what the thing is that you collapse as it were the the distribution and and it has to fix on one of them. So similarly the the idea is that um the all the many the roles that that that are consistent with the conversation so far um that that the LLM has been playing they still exist all in superp position. So uh so yes it's like there's a multiverse of possible conversations and possible roles that can be can be played right in a way that we are having this conversation is not like that at all right yeah well you say that it's not like that at all but of course this is the point is that is that I think our intuition says that it's not like that but the whole analogy then with Buddhism I think is is saying is saying well isn't it interesting that these large language models if we if we think about them in these terms they uh as it were they bring to the four these sort of slightly challenging conceptions of selfhood which then we can reflect back on our own onto ourselves. Right. Right. I see.

**讲述者**: 这正是我想要强调的。在“20问”的例子中，就好像所有与已知答案相符的可能答案，比如猫、老鼠、狗等等，它们都以一种叠加态存在着。只有当你真正问它“那是什么”的时候，你才算是“坍缩”了这个概率分布，迫使它锁定其中一个答案。同样地，这个想法是，大语言模型到目前为止在对话中扮演的所有与对话内容一致的、繁多的角色，它们也全都以叠加态存在。所以，是的，这就像存在一个由可能对话和可能角色构成的多重宇宙。我们现在的这场对话完全不是那样的，对吧？嗯，你说它完全不像，但当然，这正是关键所在。我认为我们的直觉告诉我们它不像，但与佛教的整个类比，我认为是在说：这些大语言模型，如果我们从这个角度去思考它们，它们把这些对自我概念稍具挑战性的想法推到了前台，然后我们就可以将这些想法反观自身。是的，是的，我明白了。

**Jonathan B.**: So that's so I find that really really uh provocative and interesting you know avenue of thought and this is what I meant when I said that my answer would be investigating machine consciousness can be a mirror for us to better understand 100% agree with that.

**讲述者**: 所以我发现这是一个非常、非常有启发性且有趣的思路。这正是我之前所说的，我的答案是：研究机器意识可以成为一面镜子，帮助我们更好地了解自己。我百分之百同意这一点。

## 这种哲学思辨的现实意义是什么？

**Jonathan B.**: Now our our audience members I think should be forgiven if at this point of the conversation they're like oh this is just philosophical mumble jumb but what's the real payoff of this kind of view of uh of AI selfhood?

**讲述者**: 我想，如果我们的观众在对话进行到这里时觉得“哦，这不过是些哲学上的胡言乱语”，他们是应该被原谅的。但这种关于AI自我的观点，到底有什么实际的好处呢？

**Murray Shanahan**: And I think this is the payoff to so let me read you a quote from your essay. Untainted by metaphysical egoentricity, the motives of a post-reflective AI plus would be unlikely to resemble those of any anthropocentric stereotype motivated to procreate or self-modify. If the post-reflective AI plus were in fact the only possible AI plus and if it produced no peers or successors then the singularity would be forstalled or more precisely the intelligence explosion that is central to imagined singularity scenarios would be capped. There would be AI plus but no further progression to AI++. So this is the the payoff okay of this self.

**讲述者**: 我想这就是它的好处所在，让我来读一段你文章里的话。“一个后反思的AI+，由于没有形而上学的自我中心主义的污染，其动机将不太可能与任何以繁衍或自我改造为动机的人类中心主义刻板印象相似。如果后反思的AI+实际上是唯一可能的AI+，并且它不产生同类或后继者，那么技术奇点将被阻止，或者更准确地说，作为想象中奇点情景核心的智能爆炸将被封顶。届时将会有AI+，但不会有向AI++的进一步发展。”所以，这就是这种“自我”观的好处。

**Murray Shanahan**: By the way, just to read just to read now, this thing was written in 2012. And I, you know, I I'm not sure I really believe all of that at all. If only it were that easy to um uh to ensure that uh uh that some kind of intelligence exploion didn't happen. So, as a just to reiterate, this is a slightly mad essay that you've that you've picked on. I'm I I'm I'm still uh you know, I'm actually more proud of it in some ways now than I was then, but it's still not to be taken entirely serious.

**讲述者**: 顺便说一下，现在读起来，这篇文章是2012年写的。而且，你知道，我不太确定我是否还完全相信所有这些。要是能那么容易就确保某种智能爆炸不发生就好了。所以，再次重申，你挑出来的这篇是一篇有点疯狂的文章。我现在在某些方面其实比当时更为此感到自豪，但它仍然不应该被完全当真。

**Jonathan B.**: So, let me just um reiterate that. But there is a very serious idea wi-i within here which is that we assume the terminator scenario these this AI is going to want to defend itself. It's going to want to procreate. But your point is if what we talked about about the the egocentric less view of AI is right that the AI is going to be like the Buddha then maybe those fundamental assumptions are wrong and maybe this is the this is the title of the paper there will be Satatori before singularity. There's an maybe there is an an inherent cap yes on a superior intelligence willingness to advance that that's the thought right I guess that's the thought yes but I um you know now now allow me to argue against myself please so so you know the argument of the people who are concerned with existential risk um so they will point to what they call convergent instrumental goals and you've alluded to some just now so the uh uh so the the idea is that whatever goal you give to the uh to to your AI for example manufacturing paper clips to use Eleazowski's and Nick Bostonramm's famous example then in pursuit of that goal if it's very very very very powerful then there will always be these instrumental goals such as accumulating resources protecting itself so I don't necessarily buy my own argument in that paper although although I like the ideas

**讲述者**: 那么让我重申一下。这里面有一个非常严肃的想法，那就是我们通常假设会出现“终结者”情景，认为AI会想要自我防卫，想要繁衍。但你的观点是，如果我们之前讨论的关于AI缺乏自我中心的观点是正确的，即AI会像佛陀一样，那么或许那些基本假设就是错的。这或许就是那篇论文的标题《“悟”在“奇点”前》的含义。或许对于一个卓越智能体来说，其前进的意愿存在一个内在的上限。是的，我想这正是其思想核心。但是，现在请允许我反驳一下自己。那些关注生存风险的人们，他们的论点会指向所谓的**趋同性工具目标**（convergent instrumental goals），你刚才也提到了一些。这个想法是，无论你给你的AI设定什么目标，例如制造回形针——这是尤德科夫斯基和尼克·博斯特罗姆的著名例子——在追求这个目标的过程中，如果它非常非常强大，那么它总是会产生一些工具性目标，比如积累资源、自我保护。所以我并不一定完全接受我那篇论文中的论点，尽管我喜欢那些想法。

**Jonathan B.**: I I I love the idea again I I do think I may be a bigger fan of your paper than you are at this. But that was going to be my objection. The paper clip example. There might be instrumental goal like like in fact procreation and defending yourself is probably instrumental to most goals we would we would want the AI to do. However, right there's conversion to right it removes one let's call it the Terminator scenario or something that the AI itself has some kind of selfobsessed uh ambition.

**讲述者**: 我再次表示，我非常喜欢这个想法。我觉得我可能比你更喜欢你的那篇论文。但我的反对意见也正是这个：回形针的例子。可能存在工具性目标，事实上，繁衍和自我防卫对于我们希望AI完成的大多数目标来说，可能都是工具性的。然而，这确实排除了其中一种可能性，我们称之为“终结者”情景，即AI本身具有某种自我迷恋的野心。

**Murray Shanahan**: Right. And so absolutely if that is true. Um that is true. Yes.

**讲述者**: 是的。如果那是真的，那确实是这样。是的。

## 对原始论点的批判与“超主观臆想”

**Jonathan B.**: So there's two more critiques of your original argument I had which I think it sounds like you're probably going to agree with. The first one is that they are still roleplaying selfhood. Yes. And and selfhood at least for the information they've been fed procreation and self-defense is critical to that. Right. So so even though maybe their core operating system doesn't have that kind of egoentrism they are roleplaying it.

**讲述者**: 对于你最初的论点，我还有两个批判，听起来你很可能会同意。第一，它们仍然是在“扮演”自我。是的。而至少从它们被输入的信息来看，繁衍和自卫对于“自我”这个角色至关重要。对。所以，即使它们的核心操作系统没有那种自我中心主义，它们也在扮演它。

**Murray Shanahan**: Yeah.

**讲述者**: 是的。

**Jonathan B.**: Um, and the second issue that I had w with with with your argument is it assumes the hardware determines the software. But even in the human case, that's not true. Even our human embodiness in the case of the Buddha and enlightened masters today, they were able to transcend. Yes. This this dual this uh this dualistic view, right? So, so how do you respond to those two issues?

**讲述者**: 我对你论点的第二个问题是，它假设了硬件决定软件。但即使在人类的例子中，这也不是真的。即使是我们受限于肉身，像佛陀和今天的开悟大师们，他们也能够超越。是的。超越这种二元对立的观点，对吧？那么，你如何回应这两个问题？

**Murray Shanahan**: Okay. Well, of course, when that paper was written then then we didn't have large language models and the whole roleplay scenario wasn't uh you know wasn't something that I was thinking about at all. I mean I was very much was appealing to that notion of ego in that in the first paper and today we see it being sort of manifest perhaps in a kind of role playinging self. I so I totally totally agree with you. Um uh so it is something a little different and actually let me let me use that as an as an entree to this other scenario which I wanted to to paint. So, so one way in which um uh in which we could imagine a positive outcome is through hyperstition.

**讲述者**: 好的。当然，写那篇论文的时候，我们还没有大语言模型，整个角色扮演的情景也完全不是我当时考虑的事情。在那篇论文里，我主要是在探讨“自我”这个概念，而今天我们看到它或许以一种“角色扮演的自我”的形式显现出来。所以我完全同意你的观点。这确实是有些不同的。实际上，让我就此引出我想描绘的另一个情景。我们可以想象，通往积极结果的一条路径是通过**超主-观臆想**（Hyperstition：一个由虚构叙事通过影响人类行为而最终自我实现为现实的过程）。

**Murray Shanahan**: If there's some fictional uh story um of uh of a say I don't know something some some something bad like let's say like a murder or something and then somebody in reality has a copycat of that of that murder that would be an example of hypers that's not a very pleasant example but it's basically where or or any way in which um uh life imitates art say so so um so that's that's hypian so it's where things that are fictional then because people then imitate the fiction based on the fiction then they can become reality. Um and one way in which that can can happen in the contemporary an uh world of large language models is through science fiction characters science fiction AI characters. Now of course our large language models they were trained on a vast repertoire of of uh stories including scripts of science fiction movies, science fiction stories and novels and so on. many many AI characters uh exist in those um uh in those stories. So when a contemporary large language model starts to roleplay an AI system, which it's often going to do because it's uh it it knows that it's an AI system usually. Then then what's it going to roleplay? It's going to roleplay all these architect well the things exactly or some mashup of all these different things. So it's going to pick its ideas from stuff that's in its training set and all of these, you know, literary and fictional and and artistic examples in its training set.

**讲述者**: 如果有一个虚构的故事，比如说一个关于谋杀之类的坏事，然后在现实中有人模仿了这个谋杀案，这就是一个超主观臆想的例子。这个例子不太愉快，但基本意思就是，生活模仿了艺术。虚构的东西，因为人们基于它进行模仿，最终可以变成现实。在当今大语言模型的世界里，这种情况发生的一种方式就是通过科幻角色，特别是科幻AI角色。我们的大语言模型是在大量的故事语料上训练的，包括科幻电影剧本、科幻小说等等。这些故事里存在着大量的AI角色。所以，当一个当代的大语言模型开始扮演一个AI系统时——它通常会这么做，因为它知道自己是个AI系统——它会扮演什么呢？它会扮演所有这些原型，或者说是所有这些不同事物的混合体。它会从它的训练集中，从所有这些文学、虚构和艺术的例子中汲取灵感。

**Murray Shanahan**: Now we are sort of a little bit in a position to maybe try and steer this whole process a little bit because the more good stories we have and in a sense my own paper dare I say it is a good story of a of an imagined science fiction and then the more of those that are around then the more possibility there is of the uh of the the future AI roleplaying these good role models that are that are out there. So perhaps through the mechanism of hyperstition, we can actually um uh you know make it more likely that the AIs of the future will have good role models when they're role playing, right?

**讲述者**: 现在，我们或多或少有能力去尝试引导这个过程。因为我们拥有的好故事越多——从某种意义上说，我自己的那篇论文，恕我直言，就是一个关于想象中的科幻的好故事——那么未来AI扮演这些现存的、好的榜样的可能性就越大。所以，或许通过超主观臆想的机制，我们实际上可以增加未来AI在角色扮演时拥有良好榜样的可能性，对吧？

**Jonathan B.**: That makes sense. I have a friend who is um starting a company um a film company to make more positive sci-fi uh views for humans, right? But I think he'll be very delighted to learn that you think that there's also potentially a moral benefit for the machines as well as as a model to learn.

**讲述者**: 这很有道理。我有个朋友正在创办一家电影公司，旨在为人类创作更多积极的科幻作品。我想他会很高兴地得知，你认为这对机器也可能有道德上的好处，可以作为它们学习的榜样。

**Murray Shanahan**: Indeed. If those if those uh well if the movies themselves or the or the the screen plays find their way into the training sets then then that's all part of a melting pot of possible uh roles that the thing can play.

**讲述者**: 的确如此。如果那些电影本身，或者电影剧本，能够进入训练集，那么它们就会成为这个系统可以扮演的各种可能角色的熔炉的一部分。

## 硬件与软件的关联：佛陀、忒修斯之船与LLM

**Jonathan B.**: What about the second push back I had which had to do with the connection between the hardware and the software because in the very example that you gave the Buddha it was an example of the software transcending the hardware.

**讲述者**: 关于我提出的第二个反驳，即硬件和软件之间的联系，你有什么看法？因为在你给出的佛陀的例子中，它恰恰是一个软件超越硬件的例证。

**Murray Shanahan**: Yeah. Yeah. So you're alluding I think particularly to the fact that um that we have bodies that are confined.

**讲述者**: 是的，是的。我想你特别指的是我们拥有受限的身体这一事实。

**Jonathan B.**: There are plenty of biological organisms that are are much less uh that are you know that are that of course they're embodied in a sense but they but they're if you think of things like microisal networks or or or or things things like that then then their bodies are much less confined in space and so on. But the problem for humans is because our bodies are confined to one, you know, little lump of of of matter. And so we we identify with this lump of matter and uh and and that means that our conception of selfhood, I think, is very much informed by the fact that this lump of matter stays kind of the same. Now, of course, there are um uh uh you know, all kinds of challenges to the to to the idea of identity of personal identity.

**讲述者**: 有很多生物体，它们的身体受到的限制要小得多。当然，它们在某种意义上也是具身的，但如果你想想菌根网络之类的东西，它们的身体在空间上的限制就小得多。但对人类来说，问题在于我们的身体被限制在一小块物质里。因此，我们认同这块物质，这意味着我们对自我的概念，在很大程度上是基于这块物质保持相对不变这一事实。当然，对于个人身份认同的观念，存在着各种各样的挑战。

**Jonathan B.**: Chipsius, right?

**讲述者**: **忒修斯之船**（Ship of Theseus：一个关于身份认同的哲学思想实验），对吧？

**Murray Shanahan**: Chip thesis, which of course we can apply to the human body because we know that all of ourselves are replaced over our lifetime and our memories grow and our personalities change and Buddhist thinking actually, you know, takes those challenges and and indeed uses them to challenge our notions of selfhood as well. But nevertheless, it's still there's still a lot to overcome there because we really do have a notion of selfhood, I think, which is which is tied down to to this and that that we we think it has inherent existence because of that.

**讲述者**: 是的，忒修斯之船悖论。我们当然可以将其应用于人体，因为我们知道我们身体的所有细胞在一生中都会被替换，我们的记忆在增长，性格在改变。实际上，佛教思想正是利用这些挑战来质疑我们对自我的观念。然而，即便如此，仍然有很多障碍需要克服，因为我们确实有一个自我概念，我认为，它是与这个肉体紧密相连的，我们因此认为它具有内在的实存性。

**Jonathan B.**: Right. So, so, so you're saying you're kind of agreeing with the critique that it is possible to transcend. There's just a heavy heavy inertia.

**讲述者**: 好的。所以，你的意思是，你某种程度上同意那个批判，即超越是可能的，只是存在着非常非常大的惯性。

**Murray Shanahan**: Yeah. He heavy inertia. Um, but if you flip that, you then aren't saying that an AI built on, let's call it non-dual hardware necessarily will conceive of itself as non-dual. It will it's just more conducive. That's the point you're making.

**讲述者**: 是的，巨大的惯性。但反过来看，你也不是说，一个建立在（我们称之为）非二元硬件上的AI，就必然会认为自己是非二元的。它只是更有利于形成这种观念。这才是你的观点。

**Murray Shan-ahan**: Well, I mean, there's how it might conceive itself, you know, some future AI when that even makes sense, right? Uh, and then there's the AI systems that are around today, which can roleplay things that are doing that and can be lessons for us because we can actually they they can actually be philosophically provocative for us even today. So, they might not conform to their own self-descriptions, but their own self-d you know, if they describe themselves as conscious, maybe that's right, maybe that's wrong. is philosophically provocative and we can we can apply that those provocative conceptions back to ourselves.

**讲述者**: 嗯，我的意思是，这涉及到它如何看待自己，你知道，未来的某个AI，当这个问题有意义的时候。然后，还有今天存在的AI系统，它们可以扮演那些角色，并给我们以启示，因为它们在今天就能在哲学上给我们带来启发。所以，它们可能不符合自己的自我描述，但它们自己的自我描述——如果它们把自己描述为有意识的，也许是对的，也许是错的——这本身就具有哲学上的启发性，我们可以把那些启发性的概念反思到我们自己身上。

**Jonathan B.**: You mentioned the uh the ship of thesis and those are the exactly the type of um dialectical questions a Buddhist master would would ask the student with. Yeah. Yeah. Yeah. Are you are you are you your shoe? Are you your your your feet? Are you your hands? Are you your chest?

**讲述者**: 你提到了忒修斯之船，而这正是佛教大师会用来与学生进行辩证问答的那类问题。是的，是的。你是你的鞋子吗？你是你的脚吗？你是你的手吗？你是你的胸膛吗？

**Murray Shanahan**: And perhaps we should say what they say. So you you brought up the ship of thesis. Is that the ship of thesis that that um is gradually take you know over the years the the the the mast is replaced and then the next mast is replaced and then a bit of the deck's replaced and part of the hull is replaced and this happens over many many years until eventually all every last bit of wood in the uh of the original ship is gone and you have a have a completely new ship. Well, do you so is it still the same ship or is it not? And if it's not, at what point did it change from, you know, did it become not the ship it originally was? So that's the the the problem of identity. We we might actually sort of, you know, sort of be very frustrated and think, well, what is the right answer here? And people might come up with all kinds of theories about identity. And but, you know, if we think about it honestly, we we'd have to say, well, it's just it's just up to us. We just decide what we think is when it's the same ship and when it's not the same ship. It's a entirely matter of convention to say that this is the same ship and that's not the same ship. There's no metaphysical fact to the matter about whether it's the still the ship of thesis or not.

**讲述者**: 也许我们应该解释一下这个悖论。你提到了忒修斯之船。这艘船，多年来，它的桅杆被更换了，然后下一根桅杆也被更换了，然后一部分甲板被更换了，一部分船体也被更换了。这个过程持续了很多很多年，直到最后，原始船上的每一块木头都不复存在，你得到了一艘全新的船。那么，问题是，这还是同一艘船吗？如果不是，它是在哪个节点上不再是原来的那艘船的？这就是身份认同的问题。我们可能会因此感到非常困惑，想知道，这里的正确答案到底是什么？人们可能会提出各种关于身份认同的理论。但如果我们诚实地思考，我们不得不说，这完全取决于我们自己。我们来决定什么时候它是同一艘船，什么时候不是。说这是同一艘船或不是同一艘船，完全是一个约定俗成的问题。关于它是否仍然是忒修斯之船，不存在一个形而上学的事实。

**Jonathan B.**: And I think this I think I was wrong before. I think this is the true payoff of of the Satori paper because by examining an LLM that appears to be a human self, it's much easier to see for example 20 the 20 questions uh uh example you gave, how it is this kind of Buddhist self in flux that's going and you look at the hardware it's built on. It could be copied, it could be deleted, could be restarted. By seeing how such a a a human appearing self is actually this non-self, yes, we can apply that to ourselves.

**讲述者**: 我想我之前错了。我认为这才是《“悟”在“奇点”前》这篇论文的真正价值所在。通过审视一个看起来像是人类自我的大语言模型，就更容易看清——比如在你给出的“20问游戏”的例子里——它如何体现了这种流变中的、佛学式的自我。你再看看它所构建的硬件基础：它可以被复制，可以被删除，可以被重启。通过看到这样一个看似人类的自我实际上是“非我”，是的，我们就可以把这个领悟应用到我们自己身上。

**Murray Shanahan**: That's precisely. And this is what the Buddhist master would want us to do. So maybe the Buddhist master in the 21st century can use the LLM as an example.

**讲述者**: 正是如此。这正是佛教大师希望我们去做的。所以，或许21世纪的佛教大师可以把大语言模型作为一个例子来教导。

**Jonathan B.**: That's exactly what I think um we can do and it's something I'm very very interested in pursuing in fact. Um right. So I've been talking recently to some to some uh to some Buddhists.

**讲述者**: 这正是我认为我们可以做的，而且事实上我非常有兴趣去探索。是的。我最近和一些佛教徒有过交流。

**Murray Shanahan**: Bob Thurman uh who is a very well-known I I just emailed him last week.

**讲述者**: 鲍勃·瑟曼，他非常有名，我上周刚给他发了邮件。

**Jonathan B.**: In fact, we are we we were uh co-founding a foundation together called the Eternity Foundation to use AI to translate uh a lot of the the lost texts from from the Tibetans.

**讲述者**: 事实上，我们正在共同创立一个名为“永恒基金会”的基金会，旨在利用AI来翻译大量失传的藏文典籍。

**Murray Shanahan**: So, well, how interesting. Well, we spoke last week and we're speaking again tomorrow. um and um uh and this is exactly the kind of project that you just described which um which I'm going to be talking about with him and I have a a paper which is in the pipeline which describes exactly exactly this.

**讲述者**: 哦，那太有趣了。我们上周刚聊过，明天还要再聊。而你刚才描述的这个项目，正是我准备要和他讨论的。我有一篇正在准备中的论文，描述的也正是这个。

**Jonathan B.**: So for me that is the payoff at the moment.

**讲述者**: 所以对我来说，这在当下就是回报。

**Murray Shanahan**: Yeah.

**讲述者**: 是的。

## 维特根斯坦的哲学疗法：没什么可隐藏的

**Jonathan B.**: And so in other words, you agree with the core insight of Buddhist philosophy that this is a ship of thesis because because you know a westerner let's say a cartisian right kito like they just put a stake in the ground and say no no no LLMs are completely different from me. I have a soul that lasts say K above time even you you take the Buddhist stance 100% I do. Yeah. Yeah.

**讲述者**: 换句话说，你同意佛教哲学的核心洞见，即我们自身就是一艘“忒修斯之船”。因为，你知道，一个西方人，比方说一个笛卡尔主义者，他们会坚决地认为，不不不，大语言模型和我完全不同。我有一个超越时间的灵魂。而你，你采取的是佛教的立场。我百分之百是这样。是的。

**Murray Shanahan**: I'm deeply influenced by by Buddhism and always and always have been. All of my philosophy is very very much influenced by by Buddhism.

**讲述者**: 我深受佛教的影响，一直都是。我所有的哲学思想都深受佛教的影响。

**Jonathan B.**: Well, um I know you're dying to talk about Wickenstein.

**讲述者**: 嗯，我知道你很想谈谈**维特根斯坦**（Ludwig Wittgenstein：奥地利裔英国哲学家，语言哲学的代表人物）。

**Murray Shanahan**: Yes.

**讲述者**: 是的。

**Jonathan B.**: So, let me give you uh a quote about why you think it's so important for us to talk about Wikenstein before we investigate or when we investigate AI consciousness. Wikinstein's phrase, nothing is hidden, is to say, nothing is metaphysically hidden. My experiences are just as much out there as in here. Consciousness is only private in the unsterious sense that a ball can be hidden under a magician's cup. In both cases, a more detailed inquiry would reveal all. What does Wickstein have to teach us about LLM consciousness?

**讲述者**: 那么，让我引用一段话，关于你为什么认为在研究AI意识之前或之时，讨论维特根斯坦如此重要。“维特根斯坦的名言‘没什么可隐藏的’，是说，没有什么东西在形而上学层面是隐藏的。我的体验既在‘外面’，也在‘里面’。意识的私密性，仅仅是在一种毫无神秘感可言的意义上，就像一个球可以被藏在魔术师的杯子底下。在这两种情况下，更深入的探究都将揭示一切。”关于大语言模型的意识，维特根斯坦能教给我们什么？

**Murray Shanahan**: Well, I think Vickinstein has a lot to teach us about consciousness in general. Um uh so so let's set aside AI and LLM consciousness for now because in my mind um much of the discuss contemporary discussion about consciousness is mired in dualistic thinking and and so let's take an example so u very famously David charas introduces the distinction between the so-called hard and easy problems of consciousness. Um so the easy problem of consciousness is trying to understand the relevant the all the kind of cognitive operations that that that we associate with consciousness. So such as the ability uh to produce verbal reports of uh our experiences to bring to bear uh memory and and so on on our decision- making to integrate all of these things. So understanding those which is a huge scientific challenge um that he characterizes as the easy problem. Now the hard problem is to uh is to try to understand how is it that mere physical matter as it were can give rise to to the to our inner life at all to the to to the fact that we experience things at all. How does that come from mere physical matter? Because this it seems as if whatever explanation we provide for all of those cognitive aspects is not going to account for this magical light that's on inside me.

**讲述者**: 我认为维特根斯坦关于一般意识有很多可以教给我们的。让我们暂时把AI和LLM的意识放在一边，因为在我看来，很多当代关于意识的讨论都深陷于二元论思维。举个例子，大卫·查默斯（David Chalmers）非常著名地提出了所谓的意识的**“难问题”和“易问题”**（Hard and Easy problems of consciousness）。意识的“易问题”是试图理解我们与意识相关的所有认知操作，比如产生关于自身体验的口头报告的能力，将记忆等因素应用于决策的能力，以及整合所有这些东西的能力。理解这些是一个巨大的科学挑战，他将其定性为“易问题”。而“难问题”则是试图理解，纯粹的物理物质是如何能够产生我们的内在生命，产生我们体验事物这一事实本身的。这如何能从纯粹的物理物质中产生？因为似乎无论我们为所有这些认知方面提供何种解释，都无法解释我内心那盏神奇的点亮的灯。

**Murray Shanahan**: And uh so that's sort of the hard problem and you earlier on you alluded to dayart the demon might be tricking me into thinking that you're out there. All of these sensations might be not from a world but they all might come from a from this demon. All I really really really know for certain is that uh is that I think I am because if even as I'm doubting that the very act of doubt is only possible because I am thinking to doubt is to think is to exist as a as a subject. So Daycart reduces everything and so pairs away all of the physical world and leaves us just with just with the the the the experiencing ego. And so in doing that he's kind of he's carved the reality in two by by saying that there's this stuff out there and there's this thing in here which is me and my my my ego. So, so he creates this dualistic picture and this is what Dave Charmer's when he um talks about the hard problem is is alluding to now.

**讲述者**: 这就是所谓的“难问题”。你之前提到了笛卡尔，那个恶魔可能在欺骗我，让我以为你真实存在于外部世界。所有这些感觉可能并非来自一个真实的世界，而都来自这个恶魔。我唯一能真正确信的是，“我思故我在”。因为即使我在怀疑，怀疑这个行为本身之所以可能，就是因为我在思考。怀疑就是思考，思考就是作为一个主体而存在。所以笛卡尔削减了一切，剥离了整个物理世界，只给我们留下了体验着的自我。通过这样做，他把现实一分为二，一边是外在的东西，另一边是内在的我以及我的自我。他创造了这样一幅二元对立的图景，而这正是查默斯在谈论“难问题”时所暗指的。

**Murray Shanahan**: Um so what does Vickenstein teach us to get back to the original question Vickinstein's uh procedures philosophical procedures and and and tricks and therapeutic methods right enable us to overcome that dualistic thinking much as Buddhist thinkers do such as Nagajuna.

**讲述者**: 那么，回到最初的问题，维特根斯坦教了我们什么？维特根斯坦的哲学程序、技巧和治疗方法，使我们能够克服那种二元对立的思维，就像龙树菩萨等佛教思想家所做的那样。

**Jonathan B.**: Can you can you tell us a bit more about these therapeutic techniques or or how he resolves this dualistic?

**讲述者**: 你能多告诉我们一些关于这些“治疗技巧”的事吗？或者说，他是如何解决这种二元对立的？

**Murray Shanahan**: Yes. Well, so the first so the very first step is to is to understand a little bit about the nature of language. So he wants us to to as he would say it you know let's not ask what words mean or what a sentence means but let's ask how the words are used and how the sentences are used in everyday human life and everyday human affairs. And the important thing is there is that that that the context in which we use words is always uh you know the context is our human affairs other people the things we want to do what we want other people to do for us or with us or what we want to do together. So that's the essence of of language is that it's is that it's it's something that we um use to oil the wheels of human commerce.

**讲述者**: 好的。第一步，也是最根本的一步，是去理解语言的本质。他希望我们，用他的话说，不要去问词语或句子的“意思”是什么，而是去问这些词语和句子在日常人类生活和事务中是“如何被使用”的。重点在于，我们使用词语的语境总是我们的人类事务、他人、我们想做的事、我们想让别人为我们或与我们一起做的事，或者我们想共同做的事。这就是语言的本质——它是我们用来润滑人类交往齿轮的工具。

**Murray Shanahan**: Now that's all very well with ordinary words like chair and shoe and so on. But when it comes to really difficult words like self and consciousness and belief and truth and um knowledge and uh beauty, you know, so these are all very difficult philosophical words and it's much much harder to um to to so if we want to ask what those words mean a mind, you know, it's it does it seems a bit inadequate to to actually say, well, let's do how are those words used? But that is the strategy. So his strategy is to is to say well let's let's really look into how these words are used. And if we have a philosophical problem that or something that bugs us philosophically like the mindbody problem or this or this kind of dualistic thinking the hard problem then maybe the way to tackle it is to is to uh investigate how the relevant words are used. And by doing that you can often ultimately dissolve the sense that there is a philosophical problem there in the first place. And the really interesting case to do this with is with the case of consciousness and of subjective experience. And that that's where the whole private language remarks which are central to the philosophical investigation. So they do that they apply this strategy to subjective experience and it's really the deepest thing.

**讲述者**: 对于像“椅子”、“鞋子”这样的普通词汇，这套方法很好用。但当涉及到像“自我”、“意识”、“信仰”、“真理”、“知识”和“美”这样真正困难的词汇时，情况就复杂多了。这些都是非常困难的哲学词汇，如果我们想问这些词语的意思，仅仅说“让我们看看这些词语是如何被使用的”，似乎有些不够。但这就是他的策略。他的策略就是说，让我们真正深入地研究这些词语是如何被使用的。如果我们有一个哲学问题，或者像心物问题、这种二元论思维的“难问题”这样在哲学上困扰我们的东西，那么解决它的方法或许就是去研究相关词语的使用方式。通过这样做，你常常可以最终消解掉那种“这里存在一个哲学问题”的感觉。用这个方法来处理意识和主观体验的案例，真的非常有趣。这正是《哲学研究》中核心的“私人语言论证”所做的。他们将这个策略应用于主观体验，这真的是最深刻的部分。

**Jonathan B.**: So when I hear you say, let's stick stick on the human case. There's nothing in here that's not out here. Yeah. Is this a good way to understand it, which is let's say a tragedy befalls my family. And you know, you can measure a lot of things about my heart rate, my speech, you know, my how my brain is firing. And you're saying there's nothing more that my subjective experience of witnessing that tragedy would add.

**讲述者**: 当我听你说，让我们聚焦于人类的例子，“内在的一切无不显现于外”。我这样理解对吗？比方说，我的家庭遭遇了一场悲剧。你可以测量很多关于我的数据，比如我的心率、我的言语、我的大脑活动。而你的意思是，我目睹那场悲剧的主观体验，并不会增添任何额外的东西。

**Murray Shanahan**: Well, so so so as soon as I hear sentences like there's nothing more than or there's there is something is no more than something is just then then then we know that we're going wrong in a different kind of way, right? Because that in itself is a metaphysical claim is a reductive metaphysical claim. So so people often misread Vickenstein as a kind of behaviorist and and is saying oh well consciousness just is behavior. Say so of course he's not saying anything like that. The really great punchline in the philosophical investigations is where somebody accuses him of saying that so so we're thinking about sensation say a sensation of pain and uh and somebody accuses him of saying well you're you're saying that the sensation of of the the sensation itself is a nothing and Vickenstein comes back saying no I'm that's not what I'm saying um it it's not a nothing but it's not a something either the point is that a nothing would serve as well as a something about which nothing can be said. And that's you know that to my mind is as is as great as any line any Zen Buddhist has ever uttered because it uh um it it it the point is not to establish a a metaphysical position of its own but to enable people to transcend the metaphysical positions that they're tempted by.

**讲述者**: 嗯，一旦我听到像“无非是……”或者“仅仅是……”这样的句子，我们就知道我们正以一种不同的方式走错了路，对吧？因为这本身就是一个形而上学的论断，一个还原论的形而上学论断。人们经常将维特根斯坦误读为行为主义者，认为他说“哦，意识就只是行为”。他当然没有说类似的话。《哲学研究》中真正精彩的点睛之笔，是有人指责他这么说。我们在思考感觉，比如说痛觉。有人指责他说：“你是在说，感觉本身是‘无物’。”维特根斯坦反驳道：“不，我不是那个意思。它不是‘无物’，但它也不是‘某物’。关键在于，一个‘无物’和一个‘我们无法言说的某物’，其作用是一样的。”这句话，在我看来，和任何禅宗大师说过的任何话一样伟大。因为它不是要建立自己的形而上学立场，而是要帮助人们超越那些他们容易陷入的形而上学立场。

## 什么是内格尔的蝙蝠与维特根斯坦的回应

**Jonathan B.**: Okay. But but help me let's let's use the tragedy case when Wigenstein says nothing is hidden about my experience of the suffering of like let's say all my family dies what does he mean by that what is he trying to say there

**讲述者**: 好的，但请帮我理解一下。让我们用悲剧的例子来分析，当维特根斯坦说，关于我经历的痛苦——比如我所有家人都去世了——“没什么可隐藏的”，他到底是什么意思？他想表达什么？

**Murray Shanahan**: well he's saying he's trying to say that nothing is metaphysically hidden I mean of course you're quite right to a light on you know the most difficult examples of this so where we have like deeply felt things that we feel so we feel that there's there's a there's a private dimension to this. Right now, of course, there's a private dimension in the same sense that a ball could be hidden underneath a magician's cup in the fact that I might, you know, I might uh um uh have all kinds of thoughts and words and so on that are going on inside my head that are uh that I don't articulate. Um uh but they're they're not metaphysically hidden. They're just I you know, I don't express them. There's all kinds of things going on inside my brain and inside my body that might be hidden in practice because because you can't see inside my brain, but they're not metaphysically hidden either. I can I can probe inside your brain. I can see things lighting up. So, all of that contributes to what we might to to the public to what is public.

**讲述者**: 他是在说，没有什么东西在形而上学层面是隐藏的。当然，你举的这些最困难的例子很恰当，比如我们有深切的感受，所以我们觉得这其中有一个私密的维度。是的，当然存在一个私密的维度，但这和魔术师把球藏在杯子底下的私密性是同一种。我脑海里可能会有各种各样我没有表达出来的想法和词语。但它们并非形而上学地被隐藏起来，只是我没有表达出来而已。我的大脑和身体内部发生着各种各样的事情，这些事情在实践中可能是隐藏的，因为你看不到我的大脑内部，但它们同样也不是形而上学地被隐藏的。我可以探测你的大脑，我可以看到某些区域被激活。所有这些都构成了公共的、可被观察的部分。

**Jonathan B.**: I I know you're going to be resistant to identity claim, but when I hear nothing is metaphysically hidden, I hear there's no epistemic barrier for me to access whatever this is. And so the only barrier right now is a barrier of technology essentially something like that, right?

**讲述者**: 我知道你会抗拒身份认同的说法，但当我听到“没有什么在形而上学上是隐藏的”时，我理解为，对我而言，去接触“这个东西”不存在任何认知上的障碍。所以，目前唯一的障碍本质上是技术上的障碍，是这样吗？

**Murray Shanahan**: Like oh well okay now that that's is a great point but there's a very big difference important difference uh here right which is which is um which which is really crucial which is that I'm not you right? So, so, so there is a difference between being you and being me and the same and and and and that's very different, right? So, so, so your feelings are yours and mine are mine and I'm not you and you're not me and so that that is a barrier that can't be overcome. I mean, it's but it's not a metaphysically mysterious barrier. It's no more metaphysically mysterious than the fact that there is not the same as here. So we can easily confuse indexicality so that the so that the fact that I am in this position here and I am me we can confuse that with a metaphysical um uh division.

**讲述者**: 好的，这是一个很好的观点。但这里有一个非常重要的区别，一个至关重要的区别，那就是：我不是你，对吧？所以，成为你和成为我之间是有区别的，这是非常不同的。你的感受是你的，我的感受是我的，我不是你，你也不是我。这是一个无法逾越的障碍。但这不是一个形而上学上神秘的障碍。它并不比“那里”和“这里”不是同一个地方更神秘。我们很容易将**指示性**（indexicality：语言学概念，指代词的意义依赖于语境）——即“我在这里”和“我是我”这个事实——与一种形而上学的划分混淆起来。

**Jonathan B.**: So so let's use more examples to help our audience understand the position Nagel's bat. So famously yeah so famously Nagel says you can learn everything about a bat right like the things we we know right now and the things that we can know future with better technology how it flaps its wings. Yes. But you're not gonna know what it really feels like to be a bat. Yes. Right. Absolutely.

**讲述者**: 让我们用更多的例子来帮助观众理解这个立场，比如内格尔的蝙蝠。内格尔有个著名的论点，他说你可以了解关于一只蝙蝠的一切，包括我们现在知道的，以及未来通过更好的技术能知道的，比如它如何扇动翅膀。是的。但你永远不会知道“作为一只蝙蝠”的真实感受是什么。是的。对。完全正确。

**Murray Shanahan**: What would Stein say to that? Well, I've often um thought that there's a little bit of a linguistic trick going on there. There's there are different senses of no in play to conjure up this this this dualistic um thought. Um and so I think that's happening that happens here as well. So when so when Nagel says we can never know really know what it's like to be a bat, all he's saying is that we are not bats and we can never we can never be bats, right? We we're not bats. That's he's not adding anything more with the word no. So so it's interesting that that in one sense it sounds mysterious. In the other sense when you remove the word no, it doesn't sound mysterious. But he but but when he uses that when he adds that word no, that is not adding anything uh more. It's just creating a puzzle as I see it.

**讲述者**: 维特根斯坦会怎么说？我常常觉得，这里面有点语言上的花招。为了引出这种二元论的想法，这里使用了“知道”这个词的不同含义。我认为这里也是如此。当内格尔说我们永远无法“真正知道”作为一只蝙蝠是什么感觉时，他所说的不过是：我们不是蝙蝠，也永远不可能成为蝙蝠。我们不是蝙蝠。他用“知道”这个词并没有增添任何额外的东西。有趣的是，从一方面看，这听起来很神秘。但另一方面，如果你去掉“知道”这个词，它听起来就不神秘了。但他使用这个词时，并没有增加任何更多的东西，在我看来，它只是在制造一个谜题。

**Jonathan B.**: But if you had a fact sheet about everything you could possibly measure externally about a bat, what is the relationship between that and being a bat?

**讲述者**: 但是，如果你有一份关于一只蝙蝠所有可以从外部测量的全部事实的清单，那么这份清单和“作为一只蝙蝠”之间是什么关系呢？

**Murray Shanahan**: Well, that's what is the relationship between that and being obviously there's obviously it's it's it's very different from from from being here than to being there.

**讲述者**: 嗯，这和“成为”之间的关系是什么？很明显，这和“在这里”与“在那里”的区别是一样的，非常不同。

## 加兰测试：超越图灵测试的新范式

**Jonathan B.**: But the next topic is related to this and uh it's about the movie X Machina which you were a scientific adviser to and you coined the term uh the Garland test. Tell us about that and why it's significant.

**讲述者**: 下一个话题与此相关，是关于电影《机械姬》（Ex Machina），你是这部电影的科学顾问，并且创造了“**加兰测试**”（Garland Test）这个术语。请告诉我们这是什么，以及它为什么重要。

**Murray Shanahan**: Exmachino was directed by Alex Garland and credits my book embodiment in the inner life with having you know having helped him to write the script having inspired him a little bit on the script uh which is wonderful in the final film uh and a particular scene and in this scene uh Ava the robot um uh is uh is being discussed and we've got Caleb the uh the the the sort of the programmer guy who's been brought into the compound this billionaire Nathan Nathan who's built Ava the robot and Caleb is trying to work out exactly what he's there to do and he says and he he learns about Ava and uh and then he says, "Ah, okay. I'm here to conduct a Turing test." And then uh and then uh Nathan says, "Oh, no." He says, "We're way past that. Ava could pass the cheuring test easily. The point is to show you she's a robot and see if you still think she's conscious."

**讲述者**: 《机械姬》由亚历克斯·加兰执导，他在片中致谢了我的书《具身性与内在生命》，说这本书帮助他写了剧本，给了他一些灵感，这在最终的电影中，尤其是在一个特定场景里体现得非常棒。在那个场景中，机器人艾娃正在被讨论。程序员凯莱布被亿万富翁内森带到了他的基地，内森建造了机器人艾娃。凯莱布试图弄清楚他来这里的目的，他了解了艾娃之后说：“啊，好的，我是来做一个**图灵测试**（Turing Test：由艾伦·图灵提出，测试机器是否能表现出与人等价或无法区分的智能的测试）的。”然后内森说：“哦，不。我们早就过了那个阶段了。艾娃可以轻松通过图灵测试。重点是，我要让你看到她是个机器人，然后看你是否还认为她有意识。”

**Jonathan B.**: So now that's a really really great line. And when I read that line in the script, I wrote I wrote spoton.

**讲述者**: 这句台词真的非常非常棒。当我在剧本里读到这句时，我写下了“一针见血”。

**Murray Shanahan**: So Alex Garland explicitly uh distinguishes his test from Cheurings by saying the point is to show you she's a robot, right? So you straight away you know there it's not hidden from you. I mean there aren't two entities that you're discriminating between, but you you see right away that she's a robot. It's testing for a different thing as well. It's testing for intelligence. It's not testing for intelligence or whether it can think, but it's testing for consciousness, right? Um, and so that's the Garland. So I call that I call that the Garland test because Alex Garland basically kind of invented it, I think, in that moment in the film.

**讲述者**: 亚历克斯·加兰明确地将他的测试与图灵测试区分开来，他说重点是“让你看到她是个机器人”，对吧？所以你马上就知道，信息没有对你隐藏。你不是在两个实体之间进行区分，而是立刻就知道她是个机器人。它测试的也是不同的东西。它不是测试智力，不是测试它是否会思考，而是测试意识，对吧？所以这就是加兰测试。我称之为加兰测试，因为我认为亚历克斯·加兰基本上在电影的那个时刻发明了它。

**Jonathan B.**: And I imagine given our discussion on Wikenstein, you like this test as well as the Turing test because it's Wikensteinian in in the following sense. It turns the metaphysical question of intelligence and consciousness to one about convention, right? like in in the sense that the touring test it's not about you know let's figure out whether this thing is actually thinking let's figure out if a regular human would think conventionally would use normal language to describe if it's thinking in the in the uh Garland test the question isn't you know let's poke into Ava's brain and and figure out if there's a consciousness somewhere hidden it's whether a person despite knowing she's a robot will still conventionally think that uh uh that that she is conscious this is very Wikensteinian.

**讲述者**: 鉴于我们对维特根斯坦的讨论，我猜你喜欢这个测试，也喜欢图灵测试，因为它在以下意义上是维特根斯坦式的：它将关于智能和意识的形而上学问题，转化为了一个关于约定俗成的问题，对吧？图灵测试的意义不在于搞清楚这个东西是否真的在思考，而在于一个普通人是否会按照惯例，用日常语言来描述它是否在思考。在加兰测试中，问题不是去探究艾娃的大脑，找出是否隐藏着某个意识，而是看一个人在明知她是机器人的情况下，是否仍然会按照惯例认为她是有意识的。这非常维特根斯坦。

**Murray Shanahan**: Yeah, it is. I think it is very Wickinsteinian. Um uh as is the Turing test. Very Wickinsteinian. And of course, Turing and Vickenstein uh knew each other. Turing was going to Vickenstein's classes. And I and I Oh, wow. Uh and I, you know, and I I've always thought that there was a Vickinsteinian uh influence on Turing when he wrote that paper.

**讲述者**: 是的，我认为它非常维特根斯坦。图灵测试也是如此，非常维特根斯坦。当然，图灵和维特根斯坦是相互认识的。图灵曾去上维特根斯坦的课。哇哦。而且我一直认为，图灵在写那篇论文时，受到了维特根斯坦的影响。

**Jonathan B.**: I see. I see. So, so many people interpret Turing, I did certainly before this conversation, as a behavioralist, but that might not not be true, right? He might be this because because he um his move right at the beginning of uh of computing machinery and intelligence the paper in question his move is to say uh does a machine think? Well, that's a really difficult question to answer for this that and the other reason you know and you know blah blah blah. Let's replace it by the following question. So he doesn't he he replaces the question can a machine think with a different one. He doesn't reduce it to the other one. That would be the behavioralist position.

**讲述者**: 我明白了。很多人，包括我在这次谈话之前，都把图灵解读为行为主义者，但这可能并不正确，对吧？他之所以采取这种做法，是因为在他那篇关于计算机器与智能的论文开篇，他的做法是提出问题：“机器会思考吗？”然后说，由于种种原因，这个问题很难回答。让我们用下面这个问题来“替换”它。他不是将“机器会思考吗”这个问题“还原”为另一个问题，而是用另一个问题去“替换”它。将问题还原才是行为主义的立场。

## 经验探究：全局工作空间理论

**Jonathan B.**: We should like to situate consciousness as we know it within the larger picture of consciousness as it could be. And the possibility of artificial consciousness of man-made artifacts with an inner life is implicit here. The intuition behind the quote I just read as well as the Garland test and the Turing test is that in some sense the true test for consciousness is communal consensus in some or like like conventional reactions. But but that's a bit different from what you suggested prior which is an empirical investigation into let let's say the neuronal structure.

**讲述者**: “我们应该将我们所知的意识，置于意识可能存在的更广阔的图景中。人造物具有内在生命，即人造意识的可能性，在这里是隐含的。”我刚才读的这段引文，以及加兰测试和图灵测试背后的直觉是，在某种意义上，对意识的真正测试是社群的共识，或者是约定俗成的反应。但这与你之前建议的，对神经元结构进行经验性研究，又有些不同。

**Murray Shanahan**: Those are two different ways right? Oh but you could do both of those things. So who knows how you know our use of the word consciousness and all the very many words associated with it is going to change and evolve over time in our using the word um we may bring in all kinds of things. Right? So in deciding whether we think octopuses um are sentient and can suffer and deserve our uh our moral concern, right? Then then we look at their behavior. We also look at the scientific evidence for how they're constructed neuronally and and so on. So all all of that is grist mill of of of uh you know changing our consensual conventional way of talking about them and all of it right in but but all of it not is public. It's not there's nothing metaphysically hidden about what's inside the octopus's brain. It might be practically hidden for temporarily, but it's not metaphysically hidden.

**讲述者**: 这是两种不同的方法，对吗？哦，但你可以同时做这两件事。谁知道我们对“意识”这个词以及所有相关词汇的使用会如何随着时间演变呢？在使用这个词时，我们可能会引入各种各样的考量。对吧？比如，在决定我们是否认为章鱼有知觉、会痛苦、值得我们道德关怀时，我们会观察它们的行为，也会研究关于它们神经元构造的科学证据等等。所有这些都为我们改变对它们的共识和惯常说法提供了素材。但所有这一切都是公开的，章鱼大脑内部并没有什么形而上学上隐藏的东西。它可能暂时在实践中是隐藏的，但并非形而上学地隐藏。

**Jonathan B.**: So, what I'm hearing from you is there are two independent criterion, right? One is the the convention of the community and the other is the empirical foundations, but they're not conflicting in the sense that the conventions might change. And so the the empirical criterion is simply to to answer are these things conscious in the way that we are conscious right now. Yes. But we we very well might decide that we want to expand the definition of consciousness to include other types.

**讲述者**: 所以，我从你这里听到的是，存在两个独立的标准，对吗？一个是社群的约定俗成，另一个是经验基础。但它们并不冲突，因为约定俗成可能会改变。而经验标准只是为了回答：这些东西是否以我们目前理解的方式具有意识。是的。但我们很可能决定，我们想要扩展意识的定义，以包含其他类型。

**Murray Shanahan**: Yes. Yes. So I broadly agree with everything that you you just said. But I should point out that I think the what you're calling the empirical criteria are part of the con of they contribute to the convention as far as I see it. our consensus for how we use the language of consciousness. So that can be shaped by many things including what the scientists say who are studying this kind of stuff. So so if um um scientists say say oh well you know we've been looking at octopuses and we see that they've got these things that are like no receptors in uh in in mammals and and and their brains are organized in this and that the other kind of way and so that that that all contributes to the consensus to the convention. So I don't see these things as separate things, right?

**讲述者**: 是的，是的。我大致同意你刚才说的一切。但我要指出，我认为你所谓的“经验标准”，在我看来，是构成“约定俗成”的一部分，它们促进了我们对于如何使用意识语言的共识。这个共识可以被很多东西塑造，包括研究这类东西的科学家们怎么说。所以，如果科学家说，“哦，我们一直在观察章鱼，发现它们有类似于哺乳动物痛觉感受器的东西，而且它们的大脑是以某种方式组织的”，所有这些都会促进共识和约定俗成的形成。所以我不认为这些是分开的事情，对吧？

**Jonathan B.**: as a summary for our audience um what this whole discussion around Wiganstein has set up set us up for is to give us license to proceed with an empirical examination of our current consciousness of the current substrate the current material substrates if you will of our current consciousness And the theory you propose to explain it is called global workspace theory. So tell us about that.

**讲述者**: 为我们的听众总结一下，我们刚才围绕维特根斯坦的整个讨论，为我们铺平了道路，给了我们一个许可，让我们得以对我们当前的意识、当前的基质，或者说我们当前意识的物质基质，进行经验性的检验。而你提出的用以解释它的理论，叫做**全局工作空间理论**（Global Workspace Theory）。请给我们讲讲这个理论。

**Murray Shanahan**: Yes. Um so the idea is to think of um uh a cognitive architecture in which there is a whole collection of uh parallel processes processes that are working at the same time. So in intuitively these may be processes that are to do with uh memory. So I first I walk through the lobby and I see certain uh cues and and and like you know chairs laid out and the and the uh the reception and so on and that triggers all kinds of memories. And so inside my brain there's all sorts of little processes that are running that are triggering associations with being in a hotel with with uh uh you know seeing these kinds of uh chairs and the reception and all kinds of things. Then I might pass a person and and that might be what remind me of some somebody. So, so all those kinds of processes are going on at the same time.

**讲述者**: 好的。这个理论的核心思想是，将认知架构设想为一个由大量并行进程组成的集合，这些进程同时工作。直观地说，这些进程可能与记忆有关。比如，我走过酒店大堂，看到一些线索，比如摆放的椅子、前台等等，这会触发各种各样的记忆。我大脑里就会有各种小进程在运行，触发与住酒店、看到这类椅子和前台等相关的联想。然后我可能经过一个人，这又可能让我想起某个人。所有这些进程都在同时发生。

**Murray Shanahan**: You have all of these processes that are going on unconsciously in parallel but some of them become really really important to the current uh uh situation and those ones that are that are sort of um command attention as it were they take over the attention mechanism. So what they have to say the information that they're they're dealing with then gets broadcast throughout the brain. And so that's the global workspace. So they're contributing to the global workspace and and the the central metaphor there is broadcast. So the so there's a distinction there between the processing that's going on locally within these little processes um uh versus the processing that that's going on more globally that's broadcast through the medium of broadcast.

**讲述者**: 你有所有这些无意识的并行进程在运行，但其中一些对于当前情境变得至关重要。这些进程会“抢占”注意力，接管注意力机制。它们所处理的信息随后会被广播到整个大脑。这就是全局工作空间。它们在为全局工作空间做贡献，而这里的核心比喻就是“广播”。因此，这里有一个区别：一种是在这些小进程内部进行的局部处理，另一种是通过广播媒介进行的、更全局化的处理。

**Jonathan B.**: To make it very simple um let's say I have uh memory, I have emotion, uh I have appetite. Let's say that there's those are three parallel processes. uh in every moment these three processes are competing for which one is has the most important thing and then that uh becomes broadcasted to the other parts and that is what conscious experience is about that's the rough claim right rough

**讲述者**: 简单来说，假设我有记忆、情绪和食欲这三个并行进程。在每一刻，这三个进程都在竞争，看哪个有最重要的事情要处理，然后胜出的那个就会被广播到其他部分，而这，就是意识体验的本质。这是大致的说法，对吧？

**Murray Shanahan**: roughly but I think I'd want to kind of break down the processes to be smaller ones so the memory side of it so say I walk through the hotel lobby and over on my left is a reception and uh and and over to my right is the bar and to ahead of me is is is the lift. Well, you can imagine that in my memory there's there's a little there's a whole lot of little processes that are being active that that deal with bars and um and they might be saying, "Hey, let's go and have a drink." You know, there's a whole load of processes that are active that that deal with hotel receptions and they're thinking, "Oh, we need to check in. Let's take our luggage over there." And then there's a whole load of processes that deal with um you know, going uh getting in the lift and going to the third floor, but but also I need to getting late. I need to meet Jonathan. Right? So the need to meet Jonathan process if you like to think of it that way is going to cooperate with the go to the lift process and together that's what they're they're going to broadcast to the whole brain and they're going to shut out the kind of like let's go to the bar and have a drink uh urge and and the uh let's think about bars and receptions perceptual bits. So so so some things are going to be shut out some things are going to uh kind of come together into an active coalition that's whose influence is going to permeate the whole brain.

**讲述者**: 大致如此，但我想把这些进程分解得更小一些。比如记忆方面，假设我走过酒店大堂，左边是前台，右边是酒吧，前面是电梯。你可以想象，在我的记忆中，有很多处理“酒吧”的小进程被激活了，它们可能会说：“嘿，我们去喝一杯吧。”同时，还有一大堆处理“酒店前台”的进程被激活，它们在想：“哦，我们需要办理入住，把行李拿过去。”然后还有一大堆处理“乘电梯上三楼”的进程。但同时，我也意识到时间不早了，我需要去见乔纳森。对吧？所以，“需要见乔纳森”这个进程，会和“去乘电梯”这个进程合作，它们会联合起来，将信息广播到整个大脑，并压制住像“去酒吧喝一杯”的冲动，以及关于酒吧和前台的感知信息。所以，有些东西会被抑制，有些东西会汇聚成一个活跃的联盟，其影响力将渗透到整个大脑。

**Jonathan B.**: So the the explanation of consciousness by this theory is the processes the coalition of processes that win the competition and that is broadcasted out into its entire system. Right.

**讲述者**: 所以，这个理论对意识的解释是：赢得竞争的进程联盟，及其被广播到整个系统中的过程。对。

**Murray Shanahan**: You wrote a paper titled a cognitive architecture that combines internal simulation with a global workspace where you presented uh a computer architecture a robotics architecture specifically that is built to imitate a global workspace that there's these different competing processes and the most important one is gets broadcasted. You know drawing from our Wikinstein conversation or do you also want to say that this kind of thing is conscious in some sense like if we imitate the conscious structure the cognitive architecture of human consciousness in a machine that will also become conscious.

**讲述者**: 你写过一篇题为《一种结合内部模拟与全局工作空间的认知架构》的论文，在其中你提出了一种计算机架构，具体来说是一种机器人架构，它旨在模仿一个全局工作空间，其中有这些不同的竞争进程，而最重要的那个会被广播出去。从我们关于维特根斯坦的对话出发，你是否也想说，这种东西在某种意义上是有意识的？比如，如果我们在机器中模仿人类意识的认知结构，它也会变得有意识吗？

## 具身性：意识的另一个必要条件？

**Jonathan B.**: No, because um because you know e even if we uh even if we accept global workspace theory for biological consciousness um but you know the idea there is that is that is that it would be a necessary condition not a sufficient condition. Just having something that conforms to that description is not enough to sustain the level of complex behavior and and and or internal activity even that is going to lead us to um treat something as a fellow conscious creature. Right. Right. conscious being building something in that way may enable you to build something that does exhibit very sophisticated behavior may you know maybe that's the that's the key to doing that maybe

**讲述者**: 不会，因为即使我们接受全局工作空间理论来解释生物意识，那里的观点是，它会是一个**必要条件**（necessary condition），而非**充分条件**（sufficient condition）。仅仅拥有符合该描述的东西，不足以维持那种能让我们将其视为同类有意识生物的复杂行为或内部活动水平。是的。以那种方式构建某物，或许能让你造出展现非常复杂行为的东西，也许那正是关键所在。

**Murray Shanahan**: I see so so let me try to tie this with our Wikenstein in conversation where Wickensstein helped us clear the ground consciousness investigating whether LLMs are conscious is can proceed empirically you looked at how current consciousness is sustained that's the global workspace theory and then you're saying This might be a necessary condition but not a sufficient condition. But but that's how you hope this research the kind of trajectory.

**讲述者**: 我明白了。让我尝试将此与我们关于维特根斯坦的对话联系起来。维特根斯坦帮助我们扫清了障碍，让我们知道研究大语言模型是否具有意识可以从经验层面着手。你研究了当前意识是如何维持的，提出了全局工作空间理论，然后你说这可能是一个必要条件，但不是充分条件。但这就是你希望这项研究发展的轨迹。

**Jonathan B.**: Yeah. This is all about the easy problem. So this is this is trying to trying to explain uh the the the uh you know how well the psychological um uh and behavioral and cognitive aspects of consciousness.

**讲述者**: 是的。这都关乎“易问题”。这是在试图解释意识的心理、行为和认知方面。

**Murray Shanahan**: So given um the perhaps increased urgency of answering the AI consciousness question, what do you think are the other empirical methods we should explore alongside global workspace theory?

**讲述者**: 考虑到回答AI意识问题的紧迫性可能在增加，你认为除了全局工作空间理论，我们还应该探索哪些其他的经验方法？

**Jonathan B.**: I think behavior is is really really important. So very often when people discuss consciousness and I do suspect that this is another aspect of of dualistic thinking um they tend to think of it as as some disembodied, you know, uh kind of thing.

**讲述者**: 我认为行为真的非常重要。人们在讨论意识时，常常——我怀疑这是二元论思维的另一个方面——倾向于将其视为某种脱离肉体的、你知道的，那种东西。

**Murray Shanahan**: In the case of the of global workspace theory, what kinds of sophisticated behavior does having this cognitive architecture uh uh you know underpin? Right? That's that's uh what's the point of it? What's the why is this cognitive architecture of interest? was it's of interest because it's a way of of um uh of marshalling the resources of massively parallel computation particularly in the case of of of biological wetwware because it's it's kind of anatomically distributed and there's all kinds of challenges with the wiring and things like that. So it may not actually be relevant in the computers in the case of AI.

**讲述者**: 在全局工作空间理论的案例中，这种认知架构支撑了哪些复杂的行为？对吧？这才是重点。为什么这种认知架构会引起兴趣？它的价值在于，它是一种调动大规模并行计算资源的方式，尤其是在生物“湿件”的情况下，因为它是解剖学上分布式的，存在各种布线等挑战。所以，在计算机和AI的情况下，它可能实际上并不相关。

**Jonathan B.**: And so embodiment obviously is uh one of the key terms in the title of your book. Um and the claim is is that embodiment and behavior is it seems to be another necessary condition in addition to the global workspace architecture.

**讲述者**: 很显然，“**具身性**”（Embodiment）是你书名中的一个关键词。你的论点是，具身性和行为，似乎是除了全局工作空间架构之外的另一个必要条件。

**Murray Shanahan**: So so for our employing so all of this is about you know when when uh would we want to employ the language of consciousness right? So let's think about just in the biological case, it may be that that we employ the language of consciousness in the context of things that exhibit this kind of really sophisticated and rich and rich behavior. Um and uh and when we look into it, we discover that that uh that that them instantiating this global workspace architecture is a really important part of that.

**讲述者**: 所以，这一切都是关于，我们什么时候会想要使用“意识”这个词汇。让我们只考虑生物学的例子，我们可能是在那些展现出非常复杂和丰富行为的生物的语境中使用“意识”这个词的。而当我们深入研究时，我们发现它们实例化了这个全局工作空间架构，是其中的一个非常重要的部分。

**Jonathan B.**: So another really important word here is integration. So what the global workspace architecture facilitates is is is is integration. So it means that the the full resources of our brain can be brought to bear on the current situation.

**讲述者**: 这里另一个非常重要的词是“整合”。全局工作空间架构所促进的正是整合。这意味着我们大脑的全部资源都可以被调动起来，以应对当前的情况。

**Murray Shanahan**: How do you think about the precondition of embodiment given LLM? Because LLM sure seem to be unembodied. They they've simply ingested a lot a lot of text and sometimes like other kinds of bits of information and yet they seem to exhibit a great deal of intelligence.

**讲述者**: 考虑到大语言模型，你如何看待具身性这个先决条件？因为大语言模型看起来确实是非具身的。它们只是吸收了大量的文本，有时还有其他类型的信息，但它们似乎展现出了相当高的智能。

## 智能与理解：LLM真的“懂”吗？

**Jonathan B.**: Uh yes indeed. So we are we do want to talk about intelligence or consciousness maybe. Let's let's that's a great distinction, right? Because what is the what what do you think embodiment is a precondition for embodiment or sorry intelligence or or consciousness? But maybe we can tackle them separately.

**讲述者**: 是的，的确。我们是想谈论智能还是意识？这是一个很好的区分，对吧？你认为具身性是智能还是意识的先决条件？或许我们可以分开来讨论。

**Murray Shanahan**: Yeah. So so so does it make sense to apply the word intelligence to contemporary large language model? I have to say I think it does you know I mean how can you not I mean um so so the so it's just natural to say I think in the in the case of of it's the point of the touring test right?

**讲述者**: 是的。那么，将“智能”这个词用于当代的大语言模型有意义吗？我必须说，我认为有。我的意思是，你怎么能否认呢？这很自然，我认为，这就是图灵测试的意义所在，对吧？

**Jonathan B.**: Yeah. Well, yes indeed it is the point of the cheuring test and they do kind of pass the cheuring test.

**讲述者**: 是的，这确实是图灵测试的重点，而且它们在某种程度上确实通过了图灵测试。

**Murray Shanahan**: Yeah. So I think it's natural to to say they do have some kind of intelligence. Let's take another word understanding. So that's a controversial one. So so you know people have written and said they don't have real understanding and so on. But again you know uh I think that there are many circumstances in which um in which it's we cannot help applying the word understanding to to them. So so for example I say I want to convert all my latte entries to this format. So then I give it the thing I want to convert and it does it and it's you know it's kind of about right but then I notice that it's it's sort of inserting more commas than you know commas than I or more spaces say more white space than I like in my so I say to it uh but I I only want you know to indent with two two spaces and and it says oh sure here's the thing indented with two spaces right now you would have to say well it understood my instruction it understood the original instruction didn't completely understand it but maybe it was a ambiguous. Then I corrected it and it understood my correction and it made it made it right. Now, why on earth would we not use the word understanding in those circumstances to characterize what's going on there?

**讲述者**: 是的。所以我认为很自然地可以说它们确实具有某种智能。让我们看另一个词：“理解”。这是一个有争议的词。有人写文章说它们没有真正的理解等等。但同样地，我认为在很多情况下，我们都忍不住要用“理解”这个词来形容它们。比如，我说我想把我所有的LaTeX条目转换成这种格式。我给它要转换的东西，它就做了，而且做得差不多对。但我注意到它插入的逗号或空格比我想要的多。于是我对它说，“但我只想用两个空格缩进。”它回答说，“哦，好的，这是用两个空格缩进后的结果。”现在你不得不说，它理解了我的指令。它理解了最初的指令，虽然没完全理解，但可能是我表达得不够明确。然后我纠正了它，它理解了我的纠正，并做对了。那么，在这种情况下，我们为什么不用“理解”这个词来描述所发生的事情呢？

## 思想实验：如果你的硅基孪生兄弟存在

**Jonathan B.**: Maybe I can give another kind of push back against the the Wickensteinian position as you've presented it um by just pushing the strategy a bit further. This this idea of observing and understanding the the the cognitive architecture. So let's imagine I have a cog a robot twin here looks exactly like me purely silicon okay and he has a global workspace uh uh setup and of cogn architecture his behavior is onetoone my behavior in the exact same scenario and let's say we we figure out even more biological preconditions of consciousness all of it is imitated in his silicon architecture and then the question is is he conscious is it is it reasonable to think that he's conscious when you poke him the exact same reaction that I laugh. I scream and I shout like a little girl. What's the answer there? Like like like this is where I think the empirical

**讲述者**: 也许我可以通过进一步推动这个策略，来对你所呈现的维特根斯坦立场提出另一种反驳。这个策略就是观察和理解认知架构。让我们想象我有一个机器人孪生兄弟，他长得和我一模一样，纯硅基的。他有一个全局工作空间架构，他的行为在完全相同的情景下与我的一一对应。再假设我们找出了更多意识的生物学先决条件，所有这些都在他的硅基架构中被模仿了。那么问题是：他有意识吗？当你戳他时，他做出和我一模一样的反应——大笑、尖叫、像个小女孩一样大喊——认为他有意识是合理的吗？答案是什么？这里我认为经验性的…

**Murray Shanahan**: Well, sure you can guess where I'm going to go with this kind of You're going to say yes, right?

**讲述者**: 嗯，当然你可以猜到我对此的看法。你会说“是”，对吧？

**Jonathan B.**: No, no, no. I'm going to say I'm going to say well it just you know I how will we come to treat that that thing? How will we come to speak of it as a society as a community? That's so that so I want to replace your question with that question.

**讲述者**: 不，不，不。我要说的是，我们最终会如何对待那个东西？作为一个社会，一个社群，我们会如何谈论它？我想用这个问题来替换你的问题。

**Murray Shanahan**: Right. But but recall there were two standards that there was the the consensus criterion and then there was the empirical criterion and I know that these are interrelated.

**讲述者**: 对。但是回想一下，之前有两个标准：一个是共识标准，另一个是经验标准，我知道这两者是相互关联的。

**Jonathan B.**: Well yeah don't I I I kind of um you know corrected that as it were because so the consensus is draws on behavior and it draws on uh ways it works inside.

**讲述者**: 嗯，是的，我某种程度上已经修正了那个说法。因为共识是基于行为，也基于其内部工作方式的。

**Murray Shanahan**: So, so the way we come to treat it that that that may be that may be we may uh be very influenced by the fact that that's that scientists say, "Oh, this is how it works inside. Look, it's only doing this that and the other. It's just a lookup table." So, oh, yeah. Okay. Well, we're not going to treat it. That's, you know, that may be the consensus, right? Right. Or it may not. I don't know. I don't know. You know, I we have to we'd have to wait and see how things unfold.

**讲述者**: 所以，我们最终如何对待它，可能会受到科学家们说法的影响。比如科学家说：“哦，它内部是这样工作的。看，它只是在做这个那个，只是一个查找表。”那么，好吧，我们可能就不会以某种方式对待它。这可能就是共识，对吧？也可能不是。我不知道。我们必须拭目以待，看事情如何发展。

**Jonathan B.**: It's very hard to imagine. And so in in ordinary language in the same way that you're comfortable in ordinary language with me saying this is consciousness. This is this is not conscious. I'm conscious he he is either conscious or or right like like he is conscious or unc like there is a fact of the matter in ordinary language.

**讲述者**: 这很难想象。在日常语言中，就像你对我说“这个有意识，那个没意识”感到自在一样。我有意识，而他，要么有意识，要么没有。在日常语言中，这里存在一个事实。

**Murray Shanahan**: Well as for this particular example um of course I'm not going to answer the question is is there a fact of the matter? So, so you know when this thing has been among us right for these things for 30 years and uh and uh and and we've all settled on the way we talk about these things and treat them and behave them behave with them and interact with them. Um then you might ask somebody like me in that community is there a fact of the matter about whether twin um and then in ordinary language and then they would say they would they would say well I don't know why you're adding that weird phrase the fact of the matter but of course it's conscious or not right I don't know I see

**讲述者**: 对于这个特定的例子，我当然不会回答“是否存在一个事实”这个问题。你知道，当这个东西已经在我们中间存在了30年，我们都已习惯了如何谈论它、对待它、与它互动。那时，你可能会问那个社群里的某个像我这样的人，关于这个孪生兄弟是否存在一个事实。然后，在日常语言中，他们会说：“我不知道你为什么加上‘是否存在一个事实’这个奇怪的短语，但它当然要么有意识，要么没有。”我不知道，我明白了。

**Jonathan B.**: so let let me put it this way let's say a society was determining who to harm me or my or my twin and let's say you know we all need to eat food there's only one one food enough for both of us. Yeah. Uh presumably if this was a garbage can with no consciousness, you'd say giving it to the garbage can would be a morally wrong thing to do than giving it to Jonathan who's alive. Is there a right or wrong moral decision there? Presumably there is given whether my digital twin or or my my robot twin can suffer or not. So the the moral right or wrongness seems to be dependent on the consciousness question. So there there is also a right or wrong there, right?

**讲述者**: 让我换个方式说。假设一个社会在决定伤害我还是我的孪生兄弟。再假设我们都需要食物，但只有一份足够一个人吃的食物。是的。可以想见，如果对方是一个没有意识的垃圾桶，你会说把食物给垃圾桶而不是给活着的乔纳森，在道德上是错误的。那么这里是否存在一个道德上对或错的决定？想必是存在的，这取决于我的机器人孪生兄弟是否会感到痛苦。所以，道德的对错似乎取决于意识问题。那么，这里也存在一个对错之分，对吧？

## 苦涩的教训：从符号AI的退却中学到了什么？

**Jonathan B.**: An electrical spike can be emitted by a neuron at any time where time of course is another continuous variable. From a mathematical point of view, this property alone could be enough to push the dynamics of the brain beyond the class of Turing computable functions. The brain operates on a continuum both in the uh uh firings of the neurons themselves as well as on the time or asynchronous versus synchronous. Yeah. Yeah. Um, does this mean theoretically the human brain might have intellectual capacities that are just beyond any type of uh uh touring touring machines?

**讲述者**: 神经元可以在任何时候发出一个电脉冲，而时间当然是另一个连续变量。从数学角度看，仅此一特性就足以将大脑的动态推向图灵可计算函数类别之外。大脑在神经元自身的放电以及时间（异步与同步）上，都是在一个连续统上运作的。是的。那么，这是否意味着理论上，人脑可能拥有任何类型的图灵机都无法企及的智力能力？

**Murray Shanahan**: Well, okay. So, it certainly means mathematically and theoretically that it could fall into a class of computations which is outside of the Turing class of computations. So, that's that is a mathematical fact. Um but uh but on the other hand we also know that during uh computations can simulate a continuous system to any arbitrary degree of of fidelity to any degree of fidelity that you like you know you just make your numbers have give them more decimal places right um now you're never going to give them an infinite number of decimal places but you can always add more decimal places basically to to numbers so you can so you so you can simulate any physical process to any arbitrary degree of of fidelity. Now they're mathematically they're different. They remain different. But does that matter functionally? That's really what you're asking. I have no idea.

**讲述者**: 好的。从数学和理论上讲，这当然意味着它可能属于图灵计算类别之外的一类计算。这是一个数学事实。但另一方面，我们也知道图灵计算可以以任意高的保真度模拟一个连续系统。你只需要给你的数字增加更多的小数位。你永远无法给它们无限多的小数位，但你总是可以增加更多的小数位。所以你可以以任意高的保真度模拟任何物理过程。现在，从数学上讲，它们是不同的，并且将一直不同。但这在功能上重要吗？这才是你真正想问的。我不知道。

**Jonathan B.**: I suspect not. I suspect that because you can imitate it to to any arbitrary degree, right?

**讲述者**: 我怀疑不重要。我怀疑，因为你可以以任意高的精度模仿它，对吧？

**Murray Shanahan**: Yeah. I mean that so that would be my that would be my inclination would would be to think that there's no barrier to what you can do with a computer because of this mathematical fact.

**讲述者**: 是的。我的倾向是认为，由于这个数学事实，计算机能做的事情没有障碍。

**Jonathan B.**: in your embodiment book you described all the different types of of the brain's architecture that we have not simulated right basically what we've done with current LLM's transformer architecture uh generative uh large language models is just taking the neur the the neuron the the neural net kind of architecture and then just scaling up into a tremendous degree why has just imitating that part of the brain and not all this other functionality been able to replicate so much of human behavior that needed the whole brain.

**讲述者**: 在你的《具身性》一书中，你描述了我们尚未模拟的各种大脑架构类型。基本上，我们目前用LLM的Transformer架构、生成式大语言模型所做的，只是采用了神经网络的架构，然后将其大规模扩展。为什么仅仅模仿大脑的这一部分，而不是所有其他功能，就能够复制如此多需要整个大脑才能实现的人类行为？

**Murray Shanahan**: Well, so first of all, uh you know, what we have in neural networks today in artificial neural networks is very actually very very different to what we have in in the brain. So, so artificial neural neural neur artificial neurons are not really much like real neurons at all. So that's I mean that's one very very important caveat and the kind of learning that goes on is very very different to the kind of learning that goes on in in in real brains. So um so the question is even more interesting in some way.

**讲述者**: 首先，我们今天在人工神经网络中拥有的东西，实际上与大脑中的东西非常非常不同。人工神经元与真实神经元根本不太像。这是一个非常重要的提醒。而且，其中发生的学习过程，与真实大脑中的学习过程也大相径庭。所以，这个问题在某种程度上变得更有趣了。

**Jonathan B.**: It is actually even more interesting in a way.

**讲述者**: 某种程度上说，它确实更有趣了。

**Murray Shanahan**: Yeah. So so so why how is it that um that using this very different very different substrate we've managed to kind of create these uh um well this this extraordinary uh sort of similacum of intelligence. The interesting thing is that we don't really know. We don't really we I mean that's the bizarre position that we've ended up in which I would not have anticipated um if you'd asked me when I wrote that book um you know 15 years ago um uh where we where we we're building things um and because we're training them on very large amounts of training data and they're very very large collections of neurons very very big networks and then then all the weights you know of these networks change as a result of training and then as if by magic they end up with this extraordinary functionality but we don't really understand how they work at a at a level that we're able to explain the you know the intelligence there as far as there is intelligence there

**讲述者**: 是的。那么，我们是如何利用这种截然不同的基质，创造出这种非凡的、类似智能的东西的呢？有趣的是，我们其实并不知道。这正是我们所处的奇怪境地，也是我15年前写那本书时没有预料到的。我们正在建造东西，因为我们用海量数据训练它们，它们是巨大的神经元集合，非常大的网络。然后，这些网络的权重在训练中发生变化，接着，仿佛魔术一般，它们就具备了这种非凡的功能。但我们并不真正理解它们的工作原理，至少无法在能够解释其智能的层面上理解——如果那里真的有智能的话。

**Jonathan B.**: maybe I can ask this question um in a slightly different way like we asked the stori before singularity question which is what does it tell us about human intelligence because um for the longest time the dominant paradigm of AI is symbolic AI and for our listeners back home, this is giving declarative like logical propositions that chain together in in various ways to solve problems. Yeah. What has worked instead is these black boxes of like rough simulations of but not even to your point of neural nets. Yeah. That is able to produce behavior that symbolic AI is just so far away from. So is this something that we can learn about human consciousness which is this? The Stoics take an extremely intellectualist view of human nature. Behind human nature are the series of propositional statements we're asenting to. That is what they think is driving the human machine. Yes. But maybe that's not it, right? Maybe for us what what is at basis is a much more complicated biological architecture. Which the logical statements are only surface manifestations of. Is that something you

**讲述者**: 也许我可以用一种稍微不同的方式来问这个问题，就像我们问“悟在奇点前”那个问题一样：这告诉了我们关于人类智能的什么？因为在很长一段时间里，AI的主流范式是**符号AI**（Symbolic AI）。对听众来说，这指的是给出陈述性的、像逻辑命题一样的东西，它们以各种方式链接起来解决问题。是的。但现在奏效的，反而是这些像黑箱一样的、粗糙的模拟物，甚至如你所说，都算不上真正的神经网络。是的。它能够产生符号AI远不能及的行为。那么，这是否是我们能从中学到关于人类意识的东西呢？斯多葛学派对人性持一种极端理智主义的观点。他们认为，人性的背后是我们所同意的一系列命题陈述，这才是驱动人类这台机器的东西。是的。但也许并非如此，对吧？也许对我们来说，基础是一个复杂得多的生物架构，而那些逻辑陈述只是其表面的显现。这是你…

**Murray Shanahan**: That's absolutely right. I think uh you know if to put it crudely I think we've probably arrived at the conclusion that uh you know human level cognition uh is is implemented on a spaghetti like mess. It doesn't have the kind of structure. It doesn't have the kind of structure that we would that we intuitively think should be there. It's a mess. Um and and I think that in my own trai, you know, intellectual trajectory as an AI researcher, uh it's been a kind of a a gradual retreat from wanting to build things in uh in a way that is intelligible, you know, where the architecture is fundamentally intelligible.

**讲述者**: 完全正确。我认为，粗略地说，我们可能已经得出了这样一个结论：人类水平的认知，是实现在一团乱麻般的结构上的。它没有我们直觉上认为应该有的那种结构。它就是一团乱麻。我认为，在我自己作为一名AI研究者的学术生涯中，这是一个逐渐后退的过程，从最初想要以一种可理解的方式——即架构本身是可理解的——来构建事物，慢慢退却。

**Jonathan B.**: You were on the symbolic side for a long time for for for for quite a few years.

**讲述者**: 你在符号AI领域待了很长一段时间，好几年。

**Murray Shanahan**: Yeah. I mean, I I I also abandoned it a very long time ago. But then the interesting thing is that then even when I was working in in machine learning and in neural networks and uh you know what I spent a long long time on was trying to learn representations neural representations that nevertheless had a sort of symbolic like structure right you kind of clinging on to that clinging on to that that kind of uh vision of things that things had to be had to have a compositional structure like language um and but okay they would be learned and they would be realized on the neural kind of uh substrate. But nevertheless, at some important level, they had to have this language-like compositional structure of like objects, predicates and propositions and things and um a topography essentially, right?

**讲述者**: 是的。但我很久以前也放弃了它。但有趣的是，即使后来我从事机器学习和神经网络工作时，我花了很长时间研究的，也是如何学习到那些仍然具有某种符号化结构的神经表征。你有点像是在固守那种观念，认为事物必须具有像语言一样的组合结构，比如对象、谓词和命题，以及一种本质上的拓扑结构，对吧？好的，它们可以是被学习的，可以在神经基质上实现，但在某个重要层面上，它们必须拥有这种类似语言的组合结构。

**Jonathan B.**: Yeah. But I but and then I you know I gradually had to retreat more and more and more from that position and even so so I think so I think then you then you know you retreat a bit more and then you think okay let's stop trying to force the architecture to have that structure.

**讲述者**: 是的。但我然后，你知道，我不得不逐渐地、越来越多地从那个立场上后退。然后我想，好吧，让我们停止试图强迫架构拥有那种结构。

**Murray Shanahan**: So the dural architecture, right? So we're not we're way out of gofine and good old fashioned AI, symbolic AI, but but I'm but I'm still trying to kind of force the the representations that are learned within the neural substrate to sort of have an have a kind of symbolic like structure. Then okay, that doesn't work either. So then so then maybe you're thinking, well, okay, let let it let's let it all emerge, right? So we we'll have this kind of complete black box. Yeah. Right. But but but then then surely we're going to we'll find that there are these structures there when we look but even that is not but even that doesn't seem to be the case right you find that you you know you train these things then there's a whole field of mechanistic interpretability that's trying to understand what goes on inside well you know that's a mess as well it still looks like a mess you know you just keep looking inside and it and and of course they've made a lot of progress there are things that you can extract but they don't look like the intuitive categories we had for how we would understand cognition in the past in terms of you know language like propositional representations and so on

**讲述者**: 是的，神经架构。我们已经远离了传统的符号AI，但我仍然试图强迫在神经基质中学习到的表征具有某种符号化的结构。然后，好吧，那也行不通。所以你可能会想，好吧，让一切都自然涌现出来吧。我们将拥有这个完全的黑箱。是的。但是，当我们去观察时，我们肯定会发现那里存在着某种结构。但即使是这样，似乎也不是事实。你发现，你训练了这些东西，然后有一个叫做**“机制可解释性”**（mechanistic interpretability）的整个领域，试图理解内部发生了什么。嗯，那也是一团乱麻。它看起来仍然是一团乱麻。你不断地向内看，当然他们也取得了很多进展，你可以提取出一些东西，但它们看起来并不像我们过去用来理解认知的那些直观范畴，比如类似语言的命题表征等等。

**Jonathan B.**: in some sense your entire life has been a series of retreats it has not but not just on the computer science side but it it sounds like also on the philosophical side oh I don't know about that did did you not retreat to the Wigansteining position from a dualist oh you started oh well oh well I mean I still haven't escaped the dualist position but I know where I need to go right right I think it's but you see I'm trying to say on the metaphysical side where I imagine as any kid growing up interested in this you think well there must be an essence well is it is it Adams is it course and then you right so you you see the mirror like it's a it's a both turning to Wickenstein as well as turning away from symbolic AI is a kind of relinquishing control in a mature way right if you if you like

**讲述者**: 从某种意义上说，你的一生就是一系列的退却，不仅是在计算机科学方面，听起来在哲学方面也是如此。哦，那可不一定。你不是从二元论者退到了维特根斯坦的立场吗？哦，你是从那里开始的。嗯，我仍然没有摆脱二元论的立场，但我知道我需要去往何方。是的。你看，我想说的是在形而上学方面，我想象任何一个对这个感兴趣的孩子，都会想，肯定有一个本质，是原子吗？是别的什么？然后你就看到了镜像，转向维特根斯坦和背离符号AI，都是一种以成熟的方式放弃控制，如果你愿意这么说的话。

**Murray Shanahan**: yeah although I although I think it's a bit different with the philosophy because uh with the philosophy I don't think I've I've I've got where I want to go but I knew where I needed to go from a very long time ago I see um which work which is what Buddhism and Vickenstein because you've obviously thought deeply about these issues as well right and so of course you can easily kind of rec conjure up uh these dualistic thoughts with these kinds of um uh going down the sort of line of thinking that you're so so so there so it's sort of a bit different right so I've long known where what the destination should be but not known not quite got there um uh with the philosophy with how you build AI and how you understand cognition and it really has been a series series of retreats and and uh but that's progress I mean you know if you if you uh change your mind that's that's learning

**讲述者**: 是的，虽然我认为哲学方面有点不同。在哲学上，我不认为我已经达到了我想去的地方，但我很早就知道我需要去往何方。我明白了，那就是佛教和维特根斯坦。因为你显然也深入思考过这些问题，对吧？所以你当然可以很容易地用你那种思路，重新唤起那些二元论的想法。所以这有点不同。我早就知道目的地应该在哪里，但还没完全到达。但在如何构建AI和理解认知方面，这确实是一系列的退却。但这就是进步。如果你改变了想法，那就是在学习。

**Jonathan B.**: rich Sutton of course famously described this you know very similar thing as the bitter lesson I don't you come so he has this paper called the bitter lesson where he says that well you know what we've learned is over the years we started you know thinking that we want to build things that we can understand and we're going to reveal and and and that's the that's the uh that's that's what makes it exciting. We'll understand these things that we're building and we and it's by understanding that we can be be able to build them. But in fact, we've had to relinquish all of that and realize that what do you do is you is you use learning, you use scale scaling and you use search and you use a lot of computation. So you scale the training data, you scale the computation, you scale search and those are the things mindless stuff at scale is what is what works.

**讲述者**: 理查德·萨顿（Rich Sutton）当然把一个非常类似的事情，著名地描述为“**苦涩的教训**”（The Bitter Lesson）。他有一篇同名论文，里面说，我们多年来学到的是，我们最初以为我们想要构建我们能理解的东西，我们将会揭示其原理，这才是令人兴奋的。我们将理解我们正在构建的东西，正是通过理解，我们才能构建它们。但事实上，我们不得不放弃所有这些，并意识到，你所做的就是利用学习、利用规模化、利用搜索和大量的计算。你扩大训练数据规模，扩大计算规模，扩大搜索规模，而这些，这种大规模的、看似盲目的东西，才是真正有效的。

**Murray Shanahan**: Where do you think it's a bitter lesson because because because intellectually there's something frustrating about that.

**讲述者**: 你认为它为什么是“苦涩的”教训？因为从智识上讲，这其中有令人沮丧的东西。

**Jonathan B.**: Yeah. We we want it to be this you know beautiful topography this platonic form right but but yeah so

**讲述者**: 是的。我们希望它是这种，你知道的，美丽的拓扑结构，这种柏拉图式的形式，对吧？但现实是……

## AI会取代哲学思考吗？

**Jonathan B.**: your work uh your intellectual work as a AI researcher as a philosopher um do you think AI is going to replace a great deal of this certainly it's already augmented I mean even in my own work but but do you think yeah do do you think AI is going to replace replace the intellectual yeah replace a lot of intellectual work that you do now

**讲述者**: 你的工作，你作为AI研究者和哲学家的智力工作，你认为AI会大量取代这些工作吗？当然它已经起到了增强作用，即使在我自己的工作中也是如此。但你认为，是的，你认为AI会取代智力工作吗？取代你现在做的很多智力工作？

**Murray Shanahan**: well um so so when it comes to the the philosy I mean there's no point in it replacing it because because you need to be the one doing it. Yes, of course. I mean that's like getting a a robot to run around a running track for you. I mean there there that is you literally pointless, right? And by the way I think similar you can make similar answers to uh to using AI in creative contexts as well. So so um the point is not the production the point is the cultivation.

**讲述者**: 嗯，当涉及到哲学时，让它来取代是没有意义的，因为你需要自己去做这件事。是的，当然。这就像让一个机器人替你在跑道上跑步一样。那是毫无意义的，对吧？顺便说一句，我认为在创意领域使用AI也是类似的答案。重点不在于“产出”，而在于“修养”。

**Jonathan B.**: Of course, of course for some people the point is the production is part of the point because they make their living out of it. So this is like really important issue for for for philosophy professors.

**讲述者**: 当然，对某些人来说，“产出”本身就是重点的一部分，因为他们以此为生。所以这对哲学教授来说是个非常重要的问题。

**Murray Shanahan**: Yeah. Well, for philosophy professors and people working in the creative industries as well. And these are, you know, important issues. But but you know, uh but if if I'm doing my uh my my art project, you know, at home for my own satisfaction, you know, I'm not going to just prompt an AI to do it. I'm just, you know, because I want to make the thing, you know, that's the point. the same as if I don't want to make a robot run around the track for me because and similarly you can't do you know I can't make an AI do philosophy for me because that's not going to give me insight but you can in all of these cases uh accelerate yeah use them as tools to to to help you in

**讲述者**: 是的。对哲学教授和创意产业工作者来说都是如此。这些都是重要的问题。但是，如果我在家为了自己的满足感做我的艺术项目，我不会只是提示一个AI来完成它。因为我想亲手制作那个东西，那才是重点。就像我不想让一个机器人替我绕着跑道跑一样。同样地，我不能让一个AI替我做哲学，因为那不会给我带来洞见。但在所有这些情况下，你都可以利用它们作为工具来加速和帮助你。

**Jonathan B.**: what about the the AI researcher point because that I imagine at least compared to philosophy is a lot more about the production right

**讲述者**: 那么关于AI研究者的工作呢？我想象中，至少与哲学相比，那更多地是关于“产出”，对吧？

**Murray Shanahan**: well that's true yes so so I think AI research uh as with many um you many things is going to be you know uh augmented and and enhanced uh by AI of course you know but but not just that but the the potential of of perhaps replacing yeah well maybe um indeed yeah sure I see and uh and who knows where we go from there

**讲述者**: 那倒是真的。所以我认为AI研究，就像很多其他事情一样，会被AI增强和提升。当然，不仅如此，还有可能被取代的潜力。是的，也许吧，确实。我明白了，谁知道我们会从那里走向何方。

**Jonathan B.**: what do you think if you have kids how do you think about educating them right now like what what kind of skills and well great question I think we need to educate people in how to live Well, philosophy I mean yeah well yeah I mean not maybe not the kind of philosophy we've been talking about here but you know what what is a good life it's a different philosophical question I

**讲述者**: 如果你有孩子，你现在会如何考虑教育他们？比如需要什么样的技能？很好的问题。我认为我们需要教育人们如何好好生活。哲学，我是说，是的，也许不是我们这里谈论的那种哲学，而是关于“什么是美好生活”——这是一个不同的哲学问题。

**Jonathan B.**: remember reading a few years back which is uh canes John Maynard Kanes has this paper called the economic possibilities for our grandchildren which he wrote in 1930 and uh and there he's imagining a future where a sort of a sort of well utopian potentially future of abundance where you where economic challenges have been overcome and people just have can lead lives of leisure. But then he poses the question well what do we do then really you know what how how what would it mean to lead a good life under those circumstances when a certain aspects of meaning are taken away from uh from us. I think these are extremely good questions. I don't personally have answers to those ones.

**讲述者**: 我记得几年前读过，约翰·梅纳德·凯恩斯在1930年写过一篇名为《我们孙辈的经济可能性》的论文。他在其中想象了一个未来，一个物质极大丰富的、潜在的乌托邦未来，经济挑战已被克服，人们可以过上悠闲的生活。但他接着提出了一个问题：那时我们到底做什么呢？在那种情况下，当某些意义的来源被剥夺后，过上美好的生活意味着什么？我认为这些都是极好的问题。我个人对这些问题没有答案。

**Jonathan B.**: I see. Well, thank you for a fascinating interview, professor. This has been this has been amazing. Thank you very much.

**讲述者**: 我明白了。教授，非常感谢您接受这次精彩的访谈。这太棒了。非常感谢。

**Murray Shanahan**: Yeah, I've enjoyed it very much.

**讲述者**: 是的，我非常享受这次访谈。

**Jonathan B.**: Thanks for watching my interview. If you like these kinds of discussions, I think you fit in great with the ecosystem we're building at Cosmos. We fund research, incubate, and invest in AI startups and believe that philosophy is critical to building technology. If you want to join our ecosystem of philosopher builders, you can find roles we're hiring for, events we're hosting, and other ways to get involved on jonathanb.com/cosmos. Thank you.

**讲述者**: 感谢观看我的访谈。如果你喜欢这类讨论，我想你会非常适合我们正在Cosmos构建的生态系统。我们资助研究、孵化和投资AI初创公司，并相信哲学对于技术构建至关重要。如果你想加入我们的哲学家-构建者生态系统，可以在 jonathanb.com/cosmos 上找到我们正在招聘的职位、我们举办的活动以及其他参与方式。谢谢。
