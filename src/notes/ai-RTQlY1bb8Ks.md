---
author: 北美王路飞
date: '2025-10-04'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=RTQlY1bb8Ks
speaker: 北美王路飞
tags:
  - t-literature-note
  - causal-inference
  - artificial-intelligence
  - data-science
  - judea-pearl
  - statistical-bias
title: 揭秘AI的致命缺陷：因果革命与数据思维的转变
summary: 本文探讨大数据与人工智能的局限性，指出其仅能发现相关性而无法理解因果。通过介绍图灵奖得主朱迪亚·珀尔的因果关系之梯，强调因果推理对驾驭数据、提升AI智能及解决实际问题的关键作用。
insight: ''
draft: true
series: ''
category: ''
area: ''
project: ''
status: evergreen
---
### 大数据与AI的因果盲区

本期节目将探讨一个可能冒犯到许多将**大数据**（Big Data: 指数据量巨大、增长速度快、数据类型多样的数据资产）奉为神明的人的观点：你比你的数据更聪明。尽管日常讨论中数据、算法和人工智能似乎无所不能，但一个残酷的真相是：数据，特别是我们引以为傲的大数据，本质上是极其愚蠢的。它能以惊人的效率揭示事物之间的**相关性**（Correlation: 指两个或多个变量在数值上表现出某种程度的同步变化），例如购买A商品的用户也倾向于购买B商品，但它永远无法解释“为什么”会发生这种关联。

本文将深入探讨一场正在悄然发生、颠覆整个数据科学的**因果革命**（Causal Revolution: 指数据科学领域从关注相关性转向关注因果关系范式的转变）。这场革命将赋予人们全新的强大思维武器，使其能够真正驾驭数据，从被动的信息接收者转变为主动的现实洞察者，成为一个能够理直气壮地追问“为什么”的人。

**因果推理**（Causal Inference: 一门旨在识别和量化事物之间因果关系的科学）这门新科学听起来学术，但其缘起是为了纠正现代科学，特别是**统计学**（Statistics: 一门收集、分析、解释、呈现和组织数据的科学）长达半个世纪的一个“原罪”。在统计学教育中，老师们会反复强调“相关不是因果”（correlation is not causation）。例如，公鸡打鸣与太阳升起高度相关，但前者显然不是后者的原因。然而，教育往往止步于此，只告知我们什么不是因果，却从未教授到底什么是因果。翻阅经典统计学教材，几乎找不到“原因”（cause）一词。在很长一段时间内，在严肃的科学期刊中讨论因果关系几乎是一种禁忌。

这并非仅仅是学术界的象牙塔之争，它与普通人的生活息息相关。由于缺乏严谨讨论因果的工具，这个知识体系的巨大空白导致人类社会付出了极其惨痛的代价，甚至是以数百万人的生命来计算，这一点后续将详细阐述。有人可能会认为，这已是过时的观点，如今有了人工智能和深度学习，只要将海量数据输入机器，它就能自行学习事物背后的因果规律。但这其实是一个非常普遍且危险的误解。

今天的**人工智能**（Artificial Intelligence, AI: 模拟人类智能的机器系统），无论看起来多么智能，其底层逻辑绝大部分依然是基于相关性。它是一个登峰造极的关联大师，能从亿万张猫的图片中精准识别下一张图片中是否有猫。然而，它对猫的理解仅限于像素、纹理、轮廓等统计特征的组合，它并不知道是“猫”这个实体导致了这些像素的出现。因此，AI被困在了认知水平的底层。

### 因果之梯：从关联到反事实

为了更清晰地理解这一观点，本书作者、**图灵奖**（Turing Award: 计算机科学领域的最高荣誉）得主**朱迪亚·珀尔**（Judea Pearl: 以发展出因果推理理论而闻名的计算机科学家）提出了一个堪称思想核武器的工具——**因果关系之梯**（Causal Hierarchy/Ladder: 一种将认知能力分为关联、干预和反事实三个层次的框架）。

想象一下，我们认识世界的方式就像爬这座梯子。第一层是**关联**（Association: 观察事物之间共同变化的模式），其处理方式是观察，回答的问题是“是什么”或“如果我看到X，Y的可能性有多大”。例如，医生通过病历发现某个指标高，判断病人患某种病的概率也高。这便是关联，当前的大数据分析、商品推荐、人脸识别等技术几乎都停留在这一层，它们是观察大师。

第二层是**干预**（Intervention: 主动改变某个变量并观察结果），其处理方式是行动，回答的问题是“如果我做了某件事，会发生什么”。这与观察有着天壤之别。例如，医生思考的不是有某个指标的人会怎样，而是“如果我给病人用这个药，他的病会怎么样？”这里包含了一个主动改变世界的动作。

第三层是**反事实**（Counterfactual: 想象在不同于实际发生情况下的结果），其处理方式是想象与反思，回答的问题是“为什么”或“如果当初……结果会不会不一样？”例如，一个人吃了药但仍不幸去世，其家人可能会追问：“如果当初我没有用这个药，他是不是反而能够活下来？”这是对一个未曾发生的世界的追问，所有关于后悔、责任、功劳的思考都发生在这最高的一层。

### 因果图与混杂变量：揭示隐藏的真相

这听起来可能有些抽象，但通过一个生活中的例子，我们可以立即理解第一层和第二层之间的巨大鸿沟。例如，在生活经验或数据库中，我们发现气压计读数急剧下降与风暴来临之间存在强烈关联。这属于梯子的第一层观察，可以通过观察气压计来预测风暴。现在，当我们爬到第二层干预。如果不是看到气压计读数下降，而是主动使其下降，例如打开盒子强行拨动指针，外面会因此刮起一场风暴吗？显然不会。因为强行改变气压计读数的干预动作并不会对天气产生任何影响。这里的“do”正是因果推理中一个核心符号——**do算子**（do-operator: 代表一种来自外部的、强制性的干预），它区分了“看到”与“做到”，这是区分关联和因果的第一步。长期以来，统计学工具中缺乏“do”这个概念，导致了无数悖论和错误结论。

我们的大脑之所以能毫不费力地做出这种区分，是因为我们脑中有一张关于世界如何运作的“地图”。这门新科学正是将这张地图绘制了出来，其工具就是**因果图**（Causal Diagram: 由点和箭头组成，点代表变量，箭头代表因果关系的图形模型）。它非常简单，点代表变量，箭头代表因果关系，A指向B代表A是B的原因，或者说B会受A的影响。

关于气压计和风暴，我们脑中的因果图是：一个点标注“大气压力”，从该点分别画出两个箭头，一个指向“气压计读数”，另一个指向“风暴”。这张图一目了然：气压计读数和风暴之间没有任何箭头直接相连，它们之所以同步变化，仅仅是因为它们有一个共同的原因——大气压力。在因果推理的行话中，这个大气压力就是**混杂变量**（Confounder: 指同时影响自变量和因变量，并造成两者之间虚假关联的变量）。这张看似简单的图，正是我们进行因果推理的基石。

### 随机对照实验与因果推理引擎

考虑一个更严肃且常见的场景：一种新药上市一段时间后，通过收集数据进行统计分析，发现药物使用者与非使用者一年后的死亡率对比显示，用药组死亡率明显高于非用药组（用药组15%，非用药组8%）。数据显示，吃药者死亡率反而更高，这难道是一种毒药吗？如果仅停留在因果之梯的第一层，我们很可能会得出这样的结论。

然而，一个具备因果思维的科学家会首先绘制一张因果图来表达对事件的假设。图中有三个点：病情严重程度、是否用药和是否死亡。从“病情严重程度”画一个箭头指向“是否用药”，因为病情越重的人越可能尝试新药；再从“病情严重程度”画一个箭头指向“是否死亡”，因为病情越重，死亡风险越高；最后在“是否用药”和“是否死亡”之间画一个带问号的虚线箭头，因为这是我们真正想探究的——药物本身对死亡是否有影响。这张图清晰地阐述了数据背后的故事：观察到的吓人相关性很可能并非药物本身导致，而是病情严重程度这个共同原因（即混杂变量）在背后作祟。那些不幸去世的人，并非因为吃了药，而是因为他们本身病情就很严重。

那么，如何才能知道药物的真实效果呢？我们真正想知道的，并非自然观察到的服药后的死亡概率，而是通过干预后的死亡概率，即在“吃药”这一行为上施加一个do函数。在现实世界中，实现这个do函数，也就是实现强制干预的黄金准则，便是**随机对照实验**（Randomized Controlled Trial, RCT: 一种通过随机分配受试者到不同组别来评估干预效果的实验设计）。

RCT的具体实现方式是：将一群病人通过巨大的抽签机随机分成两组，一组发放真药，另一组发放安慰剂。在之前的因果图中，从“病情”指向“用药”的箭头被剪断了。通过随机分配，我们人为地切断了病情和用药之间的天然联系，使得两组病人的病情严重程度在统计上基本拉平。此时，他们最终死亡率的差异便可被认为是药物这一唯一变量所导致。这种做法的目的正是为了切断病情严重者更有可能用药的天然联系，从而得出更具信心的结论。

尽管RCT随机对照实验非常强大，但它昂贵、耗时，在许多情况下甚至是不道德或不可能实施的。最典型的例子是吸烟：我们不可能将一万人随机分成两组，强迫其中五千人连续抽二十年烟来观察他们是否会得肺癌。面对这种无法进行实验的场景，难道就永远无法确定因果关系吗？过去答案很可能是肯定的，但现在我们有了新的答案。这正是因果革命最神奇之处：它告诉我们，即使没有进行干预实验，只要拥有一个足够可靠的因果模型（即因果图），就有可能通过一系列数学算法，从观察到的数据（因果之梯的第一层）中反算出干预的效果（因果之梯的第二层）。

### 因果推理的实践：从吸烟致癌到AI的未来

这套算法被称为**因果推理引擎**（Causal Inference Engine: 一种结合因果图和观察数据，通过数学算法估算因果效应的系统）。其流程图显示，输入端是代表我们对世界知识与假设的因果图，另一个输入端是来自观察的数据。引擎内部会进行一系列因果运算法则的计算，输出端则是一个估算量——一个数学公式或“菜谱”，指导我们如何通过计算观察到的数据来获得想要的因果效应。这就像我们虽然无法亲自进行随机实验，但可以利用因果图作为向导，在充满迷惑性的观察数据中，通过数学计算模拟出一个虚拟的随机实验。

这套理论并非纸上谈兵，其威力在人类健康史上最著名的战役——吸烟致癌大辩论中得到了淋漓尽致的体现。几十年来，烟草公司雇佣大量数学家和统计学家，反复利用“相关不是因果”的论点混淆视听。他们最常用的说法是，可能存在一种未知基因，它既导致人类天生喜欢尼古丁，又导致人容易得肺癌——这又是一个经典的混杂变量假设。由于无法进行RCT，这个问题在科学界和公共卫生领域困扰了很久。最终，正是依靠以**休厄尔·赖特**（Sewall Wright: 美国遗传学家，因其在进化遗传学和路径分析方面的工作而闻名）等人为先驱发展的**因果路径分析**（Causal Path Analysis: 一种通过路径图分析变量间因果关系的统计方法），以及后来更完善的因果推理框架，科学家才得以排除其他各种可能的混杂因素后，从海量的流行病学观察数据中得出一个无可辩驳的结论：吸烟是导致肺癌的一个直接原因。

然而，这场胜利来得太晚。科学界在因果问题上的犹豫和工具的匮乏，导致数以百万计的生命本可被拯救却未能实现。因此，因果推理是一个关乎生死的问题。

### AI的因果盲点与强人工智能的未来

理解了这一切，我们再回过头来看人工智能，便会有一个全新的视角：为什么说现在的AI仍然很“笨”？因为它死死地被“焊”在了因果之梯的第一层。一个深度学习模型本质上是一个极其复杂的函数，它在海量数据中拟合了各种变量之间的相关性。它对这个世界没有因果模型的理解，这意味着它很脆弱。一旦数据分布发生微小变化，例如换个医院、病人的饮食习惯不同，它之前学到的模型可能就完全失效，必须从头再学。然而，一个拥有因果模型的人类医生却能很快适应。

其次，它无法解释其决策。当你询问AI为何做出某个诊断时，它只会回答“因为输入的像素是这样的”，而无法说出“因为我看到一个有因果意义的病灶”。第三，也是最重要的一点，它缺乏想象力，无法回答“如果怎么样”的问题。如果想要创造出真正通用、能够与人类自然交流、规划未来、进行道德判断并为自己行为负责的**强人工智能**（Strong AI/Artificial General Intelligence, AGI: 指具有与人类同等或超越人类智能水平的人工智能），我们就必须让机器学会因果推理，让他们有能力顺着因果之梯往上爬。当然，需要指出的是，当作者撰写这段文章时，某些新的推理模型尚未推出，其观点是否会因此而改变，我们不得而知。

### 科学探索的循环与反事实的量化

因果图可能看起来神奇，甚至像是“上帝视角”，但必须强调，因果推理并非魔法，它恰恰是对科学精神的极致体现。它从不宣称能够凭空发现真相，其逻辑起点是我们绘制的因果图，而这张图本质上是我们基于现有知识对世界提出的一个假设，这个假设完全可能是错误的。因此，一个完整的因果探索之旅是一个优雅的循环：首先提出一个因果模型并绘图；其次根据模型推导出可检验的结论，例如模型可能暗示变量A和变量B在控制C之后应该是独立的；第三，用数据去验证这些结论；第四，如果数据与结论有冲突，则返回修正模型。这才是科学的真正样貌，它不是简单地将数据扔进黑箱，而是人类的知识洞察力与想象力与冰冷数据之间一场持续不断、互相启发、互相诘问的优雅舞蹈。

这场舞蹈最华丽的篇章发生在因果之梯的最高层——反事实。例如，“如果我昨天没有熬夜，今天的精神状态会不会更好？”或“在这起事故中，如果司机当时没有超速，那个行人是不是就可以幸免于难？”这是对另一个平行宇宙的思考，是人类智慧的桂冠。过去，这被认为是哲学家的专利，无法用科学回答。但现在，因果革命告诉我们，在某些条件下，甚至可以利用数据和因果模型来量化计算这些反事实问题的概率。例如，我们可以估算出超速行为是导致行人死亡的必要原因的概率有多大。这些发现将对法律判决、事故责任认定、个人决策反思带来革命性影响，也是通往自主进行科学探索的“人工科学家”的必经之路。

### 总结与展望：因果思维的力量

总结今日要点：首先，数据是“瞎子”，它对因果一无所知。当有人说“让数据说话”时，我们需要追问：谁来解释数据？用什么样的框架来解释？其次，学会“爬梯子”。遇到任何问题，先问自己我们讨论的是哪个层面：是关联（“是什么”），还是干预（“怎么办”），抑或是反事实（“为什么”）？仅仅做出这种区分，就能让人立即比多数人更清醒。最后，因果图是探索世界的“地图”。这个工具将我们的知识和假设用清晰的语言表达出来，使我们能够站在巨人的肩膀上，提出更深刻的问题。

如果对该话题意犹未尽，想深入探索，强烈推荐朱迪亚·珀尔的原著《The Book of Why》。同时，也可以了解因果推理历史上的一位“悲情英雄”——遗传学家休厄尔·赖特。早在20世纪20年代，他就绘制出了最早的因果路径图，可说是因果推理的“吹哨人”，但其思想却被主流统计学界压制和忽视了半个多世纪。他的故事本身就是一部令人扼腕的科学史。

这场因果革命最终带来的，不仅是一套新的工具或方法论，更像是一场思想解放。它告诉人类，我们与生俱来对“为什么”的好奇心和直觉，并非需要被科学方法压抑的原始冲动，它恰恰是我们认知中最宝贵、最强大的部分。这门新科学旨在将每个普通人脑中模糊、定性的因果直觉，锻造成一把锋利、可量化、可探索世界真相的手术刀。它最终想要传递的信念是：在这个被数据淹没的时代，我们无需成为数据的奴隶随波逐流，而应该成为自己数据的主人。因为推动人类文明前进的，不是数据本身，而是我们一次又一次勇敢地向世界发出的那个最古老也最有力的问题——“为什么？”

### “蟹战对赌”：一个统计学实验的启示

谈及RCT实验，不得不提一位知名的网络博主“五岳散人”。他曾与网友郑褚进行了一场“蟹战对赌”。郑褚认为同品种螃蟹吃不出区别，而五岳散人作为有二十多年品蟹经验的专业人士，坚信即使同属中华绒螯蟹品种，阳澄湖、固城湖、太湖饲养的螃蟹也一定有区别，并坚持认为阳澄湖大闸蟹最好吃。对赌规则是，五岳散人需从10组不同螃蟹中正确分辨出7组及以上的阳澄湖大闸蟹，方可证明自己的观点。郑褚的赌注是输了吃一台电脑。

这场“蟹战对赌”是一个经典的统计学实验，涉及**二项分布**（Binomial Distribution: 在一系列独立的是/非试验中，成功次数的概率分布）和**检验假设**（Hypothesis Testing: 一种统计推断方法，用于判断样本数据是否支持对总体参数的假设）。实验共测试十次，若五岳散人随机抽取，瞎猜的猜对概率是1/3。实验设计细节在此不赘述，但最终结果颇为有趣：五岳散人前7次全部猜错，后面3次猜对了2次。这个实验实际上展示了五岳散人的一个**系统性偏差**（Systematic Bias: 指测量或估计中存在的、非随机的、导致结果偏离真实值的错误）。实验结果不仅表明他无法区分产地，更直接挑战了他“阳澄湖大闸蟹最好吃”的核心信念。因为在实验条件下，他的味蕾明显偏好太湖蟹。如果他抛开对阳澄湖的执念，单纯选出最好吃的螃蟹，那么太湖蟹才是他心中的冠军。因此，设置70%正确率的“蟹战”得出了一个非常清晰的结论：五岳散人没有分辨螃蟹产地的能力。