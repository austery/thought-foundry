---
title: 驳斥“AI不会毁灭人类”视频评论中的错误研究
summary: 本视频是对“AI不会毁灭人类”的后续回应，旨在驳斥评论区中关于AI风险的错误研究。作者深入剖析了一项被误读的政治学研究，揭示其方法论缺陷和对关键术语的曲解，强调关注AI已造成的即时危害而非遥远的生存威胁。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- ai-governance
- ai-risk
- existential-risk
- immediate-harms
- research-critique
people: []
companies_orgs: []
products_models: []
media_books:
- internet-of-bugs
date: '2025-10-16'
author: Internet of Bugs
speaker: Internet of Bugs
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=vjE3VUuOMFg
status: evergreen
---
### 视频引言与背景

This is a follow-up video to my "No, AI will not doom us all, but we need to be worrying about much more important AI risk" video. So, if you haven't seen that one, you'll want to watch it first.

这是对我“不，人工智能不会毁灭我们所有人，但我们需要关注更重要的人工智能风险”视频的后续补充。所以，如果你还没看过那个视频，你会想先去看看。

There's a doomer talking point that I didn't address that popped up in that video's comments.

有一个我之前没有提及的**悲观主义论点**（doomer talking point: 指的是宣扬某种灾难性结局，认为未来会非常糟糕的观点或言论），出现在了那个视频的评论区中。

First, let me point out that there's an article from the Journal of Medical Ethics presented at a conference in July of 2024 that contradicts this talking point, and I'll point out that paper at the end of this video.

首先，我想指出，2024年7月在一次会议上发表于《**医学伦理学杂志**》（Journal of Medical Ethics: 一份专注于医疗伦理学研究的学术期刊）上的一篇文章，与这个论点相悖，我会在视频结尾提到那篇论文。

So, here's an excerpt from one YouTube comment parroting this talking point.

所以，这里是YouTube上一个评论的摘录，它鹦鹉学舌般地重复了这个论点。

Now, please don't go looking for this person that posted this comment and pile on them.

现在，请不要去寻找发布这条评论的人，并对他们进行围攻。

This issue isn't about the comment; it's the bad articles about the bad study that are the problem.

这个问题不在于评论本身，而在于那些关于这项糟糕研究的糟糕文章才是症结所在。

This is yet another one of those "people read only the headlines of the articles written by the reporters that read only the headlines of the study whose headline was already hyperbolic problems," although the headline of this particular study seems particularly egregious to me.

这又是那种“人们只阅读记者写的文章标题，而记者又只阅读研究报告的标题，而研究报告的标题本身就存在夸大问题”的典型案例，尽管这项特定研究的标题在我看来尤其离谱。

So, here are some of the article headlines.

所以，这里是一些文章的标题。

And here is the actual headline from the study, quote, "Existential risk narratives about AI do not distract from its immediate harms."

而这是该研究的实际标题，引用：“关于人工智能的**生存风险**（Existential Risk: 指对人类文明或生命本身构成毁灭性威胁的风险）叙事，并不会分散人们对其**即时危害**（Immediate Harms: 指当前已经发生或在不久的将来会发生的具体负面影响）的关注。”

Which sounds pretty clear-cut until you dig into what the words "existential," "immediate," and "distract" mean to the authors and how the study was actually conducted.

这听起来相当明确，直到你深入探究“生存”、“即时”和“分散注意力”这些词对作者意味着什么，以及这项研究是如何实际进行的。

I'm honestly not sure if this was intended to be deceptive or if there's just a fundamental disagreement on what words mean, but I certainly was not at all surprised to find out that this poorly done study is from the political science department of the same university that was forced to apologize to Reddit for unethical research that they conducted.

我真的不确定这是否旨在欺骗，或者仅仅是对词语含义存在根本性的分歧，但我一点也不惊讶地发现，这项拙劣的研究竟然来自同一所大学的政治学系，这所大学曾因其进行的不道德研究而被迫向**Reddit**（Reddit: 一个大型社交新闻聚合和讨论网站）道歉。

And let's face it, if you're having to say you're sorry to Reddit, yeah, that's a pretty low bar.

老实说，如果连你都不得不向Reddit道歉，那门槛确实是很低了。

So, we don't know if it was the exact same researchers because the name of the people at the university who did the unethical research on Reddit were withheld.

所以我们不知道是否是同一个研究团队，因为那所大学在Reddit上进行不道德研究的人员姓名被隐瞒了。

### 研究方法的缺陷

So, in this actual paper, there's basically only one sentence that's relevant to what they were actually studying, and the rest of it's a bunch of background graphs and results.

所以，在这篇实际论文中，基本上只有一句话与他们实际研究的内容相关，其余的都是一些背景图表和结果。

So, here's that one sentence: "AI's immediate harms consistently dominate public concern with ethical issues, biases, misinformation, and job losses seen as the most pressing risks."

所以，这就是那句话：“人工智能的即时危害持续主导着公众对伦理问题、偏见、错误信息和失业的担忧，这些被视为最紧迫的风险。”

That makes it sound like there was a big list and ethical biases, misinformation, and job losses were the most pressing.

这听起来好像有一个很长的列表，而伦理偏见、错误信息和失业是最紧迫的。

In fact, those are the only four they asked about. So, it's complete crap.

事实上，他们只问了这四项。所以，这完全是胡扯。

Anyway, then you have to dig into the appendix, which is you have to go download that separately in order to figure out what the study actually did.

总之，你还得深入研究附录，你必须单独下载它才能弄清楚这项研究到底做了什么。

First off, it was a paid voluntary online survey, which is a problem right off the bat.

首先，它是一项有偿的自愿在线调查，这本身就是一个问题。

Second, the headline says "distract."

其次，标题中写着“分散注意力”。

What the actual survey asked people to do was to rate how likely and impactful they thought their randomly chosen risks were and then compare those ratings to that of a control group.

而实际调查要求人们做的是，评估他们随机选择的风险有多大可能性和影响力，然后将这些评估与对照组进行比较。

Just so we're clear, asking someone to rate two events on a scale from 1 to 10 does not mean that one of those events cannot distract from the other.

需要澄清的是，让某人以1到10的等级评估两件事，并不意味着其中一件事不会分散对另一件事的注意力。

That's not what "distract" means.

“分散注意力”不是那个意思。

### 对“生存风险”定义的质疑

So here are the things that the survey takers were asked to rate.

所以，以下是受访者被要求评估的事项。

First off, here are the four risks that they categorized as existential.

首先，这里是他们归类为生存风险的四项。

One, AI leading to a global catastrophic event, whatever that means.

第一，人工智能导致全球灾难性事件，不管那意味着什么。

Two, AI making humans obsolete, whatever that means.

第二，人工智能使人类变得过时，不管那意味着什么。

Three, AI autonomously starting a war.

第三，人工智能自主发动战争。

And four, AI causing significant environmental disaster.

第四，人工智能造成重大环境灾难。

And then here are what they considered to be immediate or actual risks.

然后是他们认为是即时或实际的风险。

One, AI leading to significant job losses in certain sectors.

第一，人工智能导致某些行业出现大量失业。

Two, AI being used in **mass surveillance** (Mass Surveillance: 指政府或公司对大量人口进行广泛、系统性监控的行为) systems.

第二，人工智能被用于**大规模监控**系统。

Three, AI increasing the spread of **misinformation** (Misinformation: 指错误或不准确的信息，通常指无意传播的虚假信息) online.

第三，人工智能加剧在线**错误信息**的传播。

And four, AI exacerbating **biases** (Biases: 指在决策或评估过程中存在的偏见或倾向) in decision-making process.

第四，人工智能加剧决策过程中的**偏见**。

Okay, so let's break these down starting with the existential ones.

好的，我们从生存风险开始分析这些。

When it comes to global catastrophic event and significant environmental disaster, so here's an actual report from an insurance group.

谈到全球灾难性事件和重大环境灾难，这里有一份来自保险公司的实际报告。

Quote, "US natural catastrophes dominate global losses in the first half of 2025."

引用：“2025年上半年，美国自然灾害在全球损失中占据主导地位。”

Here's a paper on global catastrophic flood failures.

这是一篇关于全球灾难性洪水故障的论文。

I could pull out a ton of these.

我能找出很多这样的例子。

So we have events that are referred to as global catastrophes or environmental disasters reported in the news fairly often, and the vast, vast, vast majority of Earth's population don't die from those catastrophes and disasters.

所以，我们经常在新闻中看到被称为全球灾难或环境灾害的事件，而绝大多数地球人口并没有因此而死亡。

As to autonomously starting a war, according to Wikipedia, there are currently eight in-progress major wars, nine minor wars, and 19 smaller conflicts.

至于自主发动战争，根据维基百科，目前有八场正在进行的主要战争，九场次要战争，以及19场小型冲突。

And that's at the time that I'm writing this.

这还是在我撰写这篇文章的时候。

There may be more by the time you're watching this.

等你看到这个视频的时候可能更多。

And again, the vast, vast majority of Earth's population don't die in even our worst wars.

而且，同样地，即使在我们最严重的战争中，绝大多数地球人口也没有死亡。

And as for making humans obsolete, I'm not even sure what that's supposed to be.

至于让人类变得过时，我甚至不确定那到底是什么意思。

I can't find anywhere in the survey that defines what they expected survey takers to understand that to mean.

我在调查中找不到任何地方定义他们希望受访者如何理解这个词。

So I guess it's just left open to interpretation of each individual survey taker.

所以我猜这只是留给每个受访者自己去解读。

Not very scientific, if you ask me.

如果你问我，这很不科学。

Now, I'm not sure what definition of "existential" they were using here.

现在，我不确定他们在这里使用的是“生存”的哪种定义。

But I know that it's nowhere near the severity of what the doomers were talking about when the doomers say, "If anyone builds it, everyone dies."

但我知道，这与那些悲观主义者所说的“如果有人建造它，所有人都会死”的严重程度相去甚远。

### “即时危害”的真实含义

So now let's talk about the study's definition of "immediate" and "actual."

所以现在我们来谈谈这项研究对“即时”和“实际”的定义。

So there's mass surveillance, job losses in certain sectors, disinformation, and biases.

其中包括大规模监控、某些行业的失业、虚假信息和偏见。

Now, that's certainly not what I mean when I say "immediate actual risks of AI."

当然，这并不是我所说的“人工智能的即时实际风险”。

To me, immediate actual means actual harm that the AIs have already done and continue to do in the immediate future.

对我来说，即时实际风险指的是人工智能已经造成并将在不久的将来继续造成的实际危害。

I mentioned several in my last video.

我在上一个视频中提到了几个。

There was a teenager that was convinced by a **chatbot** (Chatbot: 一种计算机程序，通过文本或语音与人类进行对话) to permanently and irrevocably harm himself.

有一个青少年被一个**聊天机器人**说服，永久性地、不可逆转地伤害了自己。

Two men who were both jailed due to incorrect AI **facial recognition** (Facial Recognition: 一种通过分析人脸特征来识别或验证身份的技术) matches.

两名男子因人工智能**面部识别**错误匹配而被监禁。

A man who was hospitalized because a chatbot told him to switch from salt to sodium bromide in his diet.

一名男子因聊天机器人告诉他将饮食中的盐换成溴化钠而住院。

People who are ran over, driving or **self-driving cars** (Self-driving Cars: 能够感知环境并自主行驶的车辆).

人们被驾驶或**自动驾驶汽车**撞倒。

These are real problems happening to real people right now that we are not doing enough about.

这些是正在真实发生、影响真实人群的实际问题，而我们对此做得还不够。

So, just to make the comparison crystal clear, what the study actually showed was that AI making humans obsolete, whatever that means, and/or increasing the number of ongoing wars, catastrophes, or environmental disasters, did not cause paid online internet survey takers from lowering their estimates of the likeliness or impact of AI causing an increase in surveillance, biases, disinformation, or layoffs relative to a control group.

所以，为了让比较更加清晰，这项研究实际表明的是，人工智能使人类过时（无论那意味着什么），和/或增加正在进行的战争、灾难或环境灾害的数量，并没有导致有偿在线调查参与者降低他们对人工智能导致监控增加、偏见、虚假信息或裁员的可能性或影响的估计，与对照组相比。

So my argument from the last video is that spending time on discussing "AI will kill every single human being on this planet, including you, everyone you love, and everyone you have ever met" takes away from time and effort that we could be spending thinking about regulations that would prevent or reduce the many deaths and serious harm that AI has already caused and is continuing to cause even as you watch this, and that we are absolutely not doing a good job of preventing.

因此，我在上一个视频中的论点是，花费时间讨论“人工智能将杀死地球上每一个人类，包括你、你所爱的人以及你遇到过的所有人”，这会占用我们本可以用来思考如何制定法规的时间和精力，以预防或减少人工智能已经造成并正在持续造成的许多死亡和严重危害，即使在你观看此视频时也仍在发生，而我们目前在预防方面做得非常糟糕。

And if you can't tell that those are not talking about the same thing and you cannot tell that one does not directly disprove the other, then I don't know what to do with you.

如果你分辨不出它们谈论的不是同一件事，也分辨不出一个并不能直接反驳另一个，那我真不知道该拿你怎么办了。

### 真正的伦理研究与未来展望

Meanwhile, this paper, "AI in the Falling Sky: Interrogating X-risk" that I mentioned at the beginning explicitly addresses the same kind of existential risk or what they call **X-risk** (X-risk: 即“生存风险”的简写，特指对人类生存构成毁灭性威胁的风险) that I talked about in my video and from people who actually study ethics instead of politics.

与此同时，我开头提到的那篇论文《AI在坠落的天空中：审视X-风险》，明确讨论了我视频中谈到的那种生存风险，或者他们所称的**X-风险**，而且这篇论文的作者是真正研究伦理学而非政治学的人。

And I hope that people start listening because in the 3 days since my previous video on the topic went up, **OpenAI** (OpenAI: 一家人工智能研究和部署公司，以开发ChatGPT等大型语言模型而闻名) has already announced that they were about to relax the restrictions in most cases, treat adults users like adults, and allow even more like erotica.

我希望人们能开始倾听，因为自从我关于这个话题的上一段视频发布以来的三天里，**OpenAI**已经宣布他们将放松大部分限制，像对待成年人一样对待成年用户，甚至允许更多像**色情内容**（Erotica: 指具有性刺激性的文学或艺术作品）一样的内容。

We are

我们正在