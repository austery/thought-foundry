---
author: 北美王路飞
date: '2025-10-07'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=napDQwJwjIU
speaker: 北美王路飞
tags:
  - t-literature-note
  - michael-jordan
  - agi-critique
  - collective-intelligence
  - ai-ethics
  - market-design
title: 迈克尔·乔丹教授：AI革命中“超级智能”的误区与真解
summary: 加州大学伯克利分校教授迈克尔·乔丹批判硅谷对AGI的盲目追求，认为AI是集体智慧的镜子，而非独立神灵，并强调构建超级市场而非超级大脑，警惕数据垄断的社会风险。
insight: ''
draft: true
series: ''
category: ''
area: ''
project: ''
status: evergreen
---
### AI狂潮下的“超级智能”神话

近年来，关于人工智能（AI）的话题几乎到了爆炸的程度。每天都有消息称，**超级智能**（Superintelligence: 指在几乎所有领域都大大超越人类智能的假想智能系统）离我们越来越近，**AGI**（通用人工智能: Artificial General Intelligence，指能够理解、学习或执行人类所能完成的任何智力任务的人工智能系统）即将无所不能，能写诗、画画、代写代码。许多人因此兴奋地认为**奇点**（Singularity: 指技术发展达到一个临界点，此后技术进步将变得不可预测和不可控的假想未来事件）将至，例如萨顿老爷子就认为AGI终将取代人类。但也有人感到焦虑，像辛顿一样，担心自己创造的人工智能会取代人类工作，甚至恐惧电影中**天网**（Skynet: 电影《终结者》中拥有自我意识并试图毁灭人类的人工智能系统）的出现。

然而，我们似乎都默认了一个前提：AI正朝着一个独立的、超越人类的、神一样的超级大脑飞速进化。但如果这个讨论的基础，这个最根本的前提，从一开始就错了呢？今天，我们将探讨一个泼冷水的观点，它来自于一位名叫迈克尔·乔丹的教授。

初次听到迈克尔·乔丹聊机器学习，可能会让人感到诧异，以为是那位篮球巨星跨界。但实际上，这位乔丹教授是一位白人，也是一位极具影响力的机器学习领域权威。他任职于加州大学伯克利分校的电子工程与计算机科学及统计学系，是一位杰出教授。他曾被《科学》杂志评为全球最具影响力的计算机科学家，并获得过世界顶尖科学家协会奖、IEEE约翰·冯·诺依曼奖章等诸多顶尖奖项。他被认为是机器学习领域的奠基人之一，是无数AI大牛的老师或师爷。

### 颠覆性的洞见：人类智能的本质是社会的、集体的

当整个硅谷都在为AGI的到来而狂欢时，这位教父级的人物却反复提醒人们，我们可能走偏了。这究竟是一种颠覆性的洞见，还是老顽固的傲慢？要理解这一点，需要跟随乔丹教授回到一个最基本的问题：当我们说一个东西“智能”时，脑海中浮现的画面是什么？

很多人可能会想到爱因斯坦，一个孤独的天才坐在书房里，面对复杂公式，凭借超凡智力洞察宇宙奥秘。这几乎是我们对智能最高的想象，因此我们理所当然地认为，制造AI就是要制造一个电子版的爱因斯坦，让它能独立思考、推理和创造。

然而，乔丹教授指出，这种“孤胆天才”的叙事本身就是一个巨大的神话，一个误导我们几十年的美丽误会。他强调，我们必须搞清楚人类智能到底是如何运作的。一个人若被扔到孤岛上，可能活不过三天；若被扔到一个陌生国家，没有语言、没有过去几十年所受的教育和文明熏陶，同样会一事无成。因此，任何一个人的智能都不是凭空产生的，它深深根植于一个巨大的社会网络，一个由知识、文化、经验以及他人所组成的社会网络。我们不知道什么，可以去问别人，可以去查资料，而这些资料是无数前人智慧的结晶。

所以，乔丹教授认为，人类真正的智能本质上是社会的、文化的、集体的。这个定义听起来有些颠覆，但它是我们理解整个AI浪潮的关键钥匙。

### AI的本质：集体智慧的“回音室”与“镜子”

带着“智能是集体”的新视角，我们再来看今天的大语言模型，例如GPT。我们通常认为，在聊天框背后坐着一个越来越聪明的“他”，一个独立的、正在学习思考的大脑，我们提问，它思考后给出答案。但乔丹教授给出了一个截然不同、甚至有点扫兴的解释。

乔丹教授的原话是：“事实上，大模型的输入来自于几十亿人类。当你与大语言模型互动时，你是在与一个集体互动，而不是在与一个飘在宇宙中的单一智能互动。”这句话信息量巨大。它的意思是，AI本身没有观点、没有思想、也没有真正的理解。它的所有能力都来自于一件事：它吞下了几乎无法想象体量的人类数据——互联网上几乎所有的公开文本、书籍、论文、代码、对话。这些数据是几十亿人在过去几十年里思考、创造、争论、协作的全部产物。有人解决了问题并写下答案，有人犯了错误并留下记录，有人提出了伟大理论，有人分享了日常琐事。

AI做的本质上是一种超大规模的暴力美学，它用强大的算力去学习这些数据里的模式、关联和结构，成为一个人类知识的模式识别大师。所以，当你问它一个问题，它能给出回答，并不是它的原创思维，而是在浩瀚的人类知识库里，通过极其复杂的计算，找到了概率上最可能、最像人话的那个答案。AI在套用这些知识模式和知识结构时非常高效，甚至比大多数普通人做得更好。

可以打个比方：想象你走进了一个世界上最大的图书馆，里面收集了人类有史以来所有的文字记录。它不是一个安静的图书馆，而是一个巨大的回音室。你对这个回音室喊了一句话（你的提问、你的**prompt**：指用户向AI模型输入的文本指令或问题），你的声音会在这个巨大的空间里传播，它会从牛顿的《自然哲学的数学原理》上反弹，穿过莎士比亚的剧本、无数程序员写的代码以及无数网友的评论，产生共鸣。最后，这个空间里的所有知识根据你的问题产生一场盛大的共振，回传到你耳朵边的，是最清晰、最响亮的回声，也就是大语言模型的回答。

所以，你听到的并不是整个图书馆这个建筑本身在思考，而是它内部所有内容的回响。你以为你在跟一个超级图书管理员对话，其实你是在跟整个人类文明的集体记忆对话。这个视角一下就把AI从神坛上拉下来了。它不再是一个独立的神，而是我们集体智慧的一面镜子，一个强大的放大器。

### 硅谷的盲点：忽视经济学与社会学视角

理解了AI是集体智慧的镜子之后，下一个问题是：为什么硅谷那些最聪明的大脑似乎对这个方向根本不感兴趣，反而一门心思想要构建一个超级智能呢？乔丹教授的诊断非常犀利，他认为这是因为这些计算机科学家，尤其是硅谷的工程师们，普遍缺少了一根弦——经济学的弦。

他们太习惯把世界看成一个工程问题，有输入、有输出，中间是一个需要优化的系统，目标就是让这个系统越来越强大、越来越厉害。但他们往往忽略了，任何一个强大的技术一旦被部署到真实世界，它就不再是一个单纯的技术问题了，它立刻变成了一个经济问题、一个社会问题。

乔丹举了一个特别生动的例子：交通系统。如果我们让每个司机都追求个人利益最大化，也就是以最快的速度从A点到B点，那结果会是什么呢？结果就是每个人都堵在最近的一条路上，整个城市的交通系统崩溃，最后每个人的时间都变长了。一个好的交通系统设计师，他思考的不是让某一辆车开得最快，他思考的是整个网络的总通行时间最短，也就是说，他追求**社会福利**（Social Welfare: 指社会中所有个体福利的总和或平均值）的最大化。为了这个目标，他可能会设计红绿灯、设置单行道，甚至让某些车绕远路，这有可能会让个别人慢一点，但整个系统会变得更高效。

所以，AI系统也是一样。如果它的设计目标只是为了创造一个最强大的个体，而完全不考虑这个个体接入社会后将对整个系统的资源分配、激励机制、公平性质造成什么样的影响，它就极有可能像一个不守规矩的超级司机，把我们整个社会系统搞得一团糟。这就是乔丹所说的硅谷工程师文化的致命缺陷：他们痴迷于打造一辆性能怪兽，却很少去想如何设计好一个好的交通系统。

### 信息不对称：超级智能无法解决的现实困境

在经济学里，有一个基石性概念叫做**信息不对称**（Information Asymmetry: 经济学中指交易双方掌握的信息不相等的情况）。它听起来很学术，但其实无处不在。例如，你想买一辆二手车，卖家比你更了解这辆车的真实情况，他可能知道发动机有点小毛病；而你呢，比卖家更了解你心里的价位和预算。你们双方掌握的信息是不对等的。这种信息不对称决定了你们之间所有的互动：讨价还价、试探，甚至一些小小的谎言。说谎在经济学视角下，不完全是一个道德问题，它是在信息不对称环境下的必然策略。

那么问题来了，一个无所不知的超级智能能够解决这个问题吗？答案是不能。因为只要互动发生在人类之间，信息不对称就会永远存在。我们不可能完全知道对方的想法，对方也不可能完全知道我们的底牌。一个AI系统，就算它能够读取所有的公开数据，它也没有办法读取我们每个人脑子里那些没有说出口的、私有的信息和动机。所以，任何一个妄想知道一切、安排一切的超级智能系统，在现实世界就注定会失灵。

一个更聪明的做法是什么呢？不是去消除信息不对称，而是去设计一个好的机制或者市场，让拥有不同信息的人依然能够有效互动，并且愿意参与进来。例如，航空公司是怎么做的？他们不知道每个乘客到底愿意付多少钱，所以他们不提供一个单一价格，而是设计出一套复杂的合同：头等舱、商务舱、经济舱，提前订票、随时改退签。你可以根据你的私有信息（比如你有多赶时间、公司给不给报销）自己去选择适合自己的那款产品。这才是真正高级的处理复杂社会系统的方式。它承认不确定性，尊重个体差异，通过设计精巧的机制来引导最好的结果。而这，恰恰是乔丹认为AI应该发力的方向，也是目前最被忽视的方向。

### AI的能力边界：从围棋到“菜市场”的启示

有人可能会反驳，AI不是在围棋上战胜了人类冠军吗？它在蛋白质折叠预测上也取得了惊人的成就，这难道不就是超级智能的体现吗？这其实是一个非常好的问题。乔丹教授的理论恰好能够完美解释这一点。

围棋是一个**完美信息博弈**（Perfect Information Game: 博弈论中指所有参与者都了解游戏所有相关信息的博弈），规则是确定的，棋盘上所有信息对双方都是公开的，目标是单一的——赢棋。在这样一个封闭的、确定性的世界里，计算能力成为了王道，AI可以通过海量计算暴力破解这个游戏。

但是真实世界更像一个巨大的、混乱的、信息不对称的菜市场，并不是一个井然有序的棋盘。在菜市场里，没有唯一的规则，每个人的目标都不同——有人想买到最新鲜的，有人想买到最便宜的——充满了讨价还价、人际互动和各种不确定性。你永远不知道那个卖菜大妈今天心情怎么样，这有可能会影响最终的价格。在棋盘里，AI是神；但在真实世界的市场里，AI还是一个需要学习的学生，因为它面对的不仅仅是计算问题，更是关于人类动机、信任和协作的复杂社会问题。

所以，我们必须明确AI的能力边界。在规则明确的封闭系统里，它很强大；但在开放、复杂、充满不确定性的人类系统里，认为它能够包办一切，是一种危险的傲慢。

### 相关不等于因果：AI是工具而非生命

这里还需要理清一个经典的逻辑误区：相关不等于因果。我们看到AI能够写出流畅的文本，就认为它拥有了智能，这就像我们看到天气预报很准，就认为天气预报本身在控制天气一样。AI的强大表现和它拥有内在智能是两回事。

乔丹教授的观点其实在追问一个因果问题：AI的能力的“因”到底是什么？是那些算法本身足够聪明所以产生了智能，还是因为它学习的数据足够聪明，因为数据本身就是人类智能的产物，所以它只是高效地复制和重组了这些智能模式？目前的证据压倒性地指向了后者。AI不是那个会写诗的灵魂，它是那面能够映射出所有传世诗歌并且组合出新诗句的魔镜。我们不能因为镜子里的影像栩栩如生，就认为镜子本身拥有了生命。

搞清楚这个因果关系至关重要，因为它决定了我们对于AI的定位：它是一个工具，一个强大、能够放大我们集体智慧的工具，而不是一个我们应该顶礼膜拜甚至感到恐惧的新物种。

### AI的真正用武之地：构建“超级市场”

既然追求AGI是一条歧路，那正确的路在哪里呢？乔丹教授给出的答案是：停止幻想造一台无所不能的超级大脑，并且动手构建一个更加高效、更加公平的**超级市场**（Supermarket: 在此泛指广义的，能够连接供应与需求，促进资源有效配置的系统）。这个市场是广义的，它指任何能够连接供应和需求、促进资源有效配置的系统。

他用音乐市场举了个例子：过去音乐人创作歌曲，听众消费歌曲，这是一个相对简单的链条。但现在有了数据，有了AI，我们可以构建一个更复杂也更高效的**多边市场**（Multi-sided Market: 指平台或组织为两组或更多组不同的客户群提供服务，并从中获取价值的市场）。在这个系统里，AI可以做什么呢？它可以分析每一个听众的品味，不光给他推荐歌曲，还能够分析出他可能的消费偏好，并将这些信息（当然是在有隐私保护的前提下）提供给感兴趣的品牌方。

AI可以帮助一个不知名的独立音乐人找到那种最可能欣赏他作品的最一小撮听众，实现最精准的连接。它还能够帮助一个需要广告配乐的品牌，快速在海量的曲库中找到风格、情绪、版权都最匹配的音乐。你看，在这个途径里，AI没有取代任何人。它没有取代音乐家去创作，也没有取代听众去欣赏。它扮演了一个经济促进者的角色，让信息流动变得更快，匹配更加精准。系统里的每一个人——音乐人、听众、品牌方——都能够更好地实现自己的价值，整个系统的社会福利提高了。这才是AI的真正用武之地：不是去模仿和取代单一的人类，而是去增强整个人类社会的连接和协作能力。从医疗保健到交通物流，再到科学研究，所有领域都可以用这种构建市场的思路去重新设计和优化。

### AI的真实风险：权力失控与数据垄断

聊到AI，就不能不聊风险。但按照乔丹教授的理论，我们担心的风险可能搞错了重点。我们最害怕的，是电影中那种天网，AI觉醒产生了自我意识，然后毁灭人类。这是关于一个机器失控的叙事。但是乔丹认为，更现实也更紧迫的风险是一种权力的失控。

回想一下核心论点：AI的力量源于它学习了所有人类的数据。那么问题来了，谁拥有这些数据？谁掌控这些模型呢？答案是极少数的几家科技巨头。这其实就构成了一个巨大的风险。当数十亿人的集体智慧被压缩提炼，最后被几家公司所掌握和利用时，一种前所未有的权力不对称就诞生了。这很像100多年前美国的**镀金时代**（Gilded Age: 指19世纪末美国经济快速增长但社会贫富差距巨大的时期），少数强盗大亨控制铁路、石油等国家经济命脉，掠夺了巨额财富，但也带来巨大的社会问题。历史总是在重复。

所以，AI的风险可能不是一个科幻故事，而是一个严肃的社会经济问题，它关于垄断、关于公平、关于我们集体创造的价值最终该如何被分配。我们应该担心的，可能不是一个有自我意识的机器人，而是一个利用信息不对称和数据垄断，来最大化自身利益，却不顾及社会福利的、不受约束的超级公司。像马斯克这样去影响整个社交平台，就会对政治体系和整个社会带来非常大的影响。这种担忧其实更加紧迫也更加实际。

### 面对AI：明智的选择与开放的问题

面对这样一个复杂而强大的技术，我们每个人，无论在什么位置，都可以做出更明智的选择。

*   **普通用户：** 请记住“回音室”的比喻，把AI当成一个极其强大、能与人类集体智慧对话的工具。用它来获取信息、激发灵感、提高效率，但永远保持一份批判性精神。不要把它当成一个不会犯错的神谕，更不要把你个人的决策权完全交给一个没有价值观、没有责任能力的算法。
*   **AI从业者或开发者：** 乔丹教授的建议是抬起头来，看看代码之外的世界。除了关心你的模型准确率提高了多少，更要去思考你正在构建的这个系统对整个社会生态产生了什么样的影响。它是在促进一个更加公平、更加高效的市场，还是在加剧信息不对称和权力垄断？把社会福利这个词放到你的设计原则里。
*   **政策制定者：** 监管的重点肯定要从担心AI太聪明，转移到如何设计好的规则来确保市场的公平竞争，保护用户的数据权利，以限制数据和权利的过度集中。这不是要给技术发展踩刹车，而是要给他铺设好能够通往繁荣而非混乱的轨道。

当然，迈克尔·乔丹教授的框架给我们提供了一个全新的、具有解释力的视角，但他并不是所有问题的终极答案。他留下了一系列更深刻也更具建设性的开放问题，例如：我们到底应该如何量化和优化社会福利？在AI驱动的新型市场里，谁来扮演那个公正的中间人或者经纪人的角色？当AI能够完成所有模式化的工作时，人类独有的创造力、同理心和智慧又应该如何被更好地激发和衡量？这些问题没有简单答案，它们需要跨越计算机科学、经济学、社会学、伦理学等多个领域的智慧共同来探索。

### 结语：重塑AI的定位与人类的未来

回顾迈克尔·乔丹教授的观点，我们看到了一个关于AI可能完全不同的故事。如果大家只记住三件事，它们是：

1.  AI不是一个独立的外来的神，它是我们人类集体智慧的一面镜子。你和它每一次互动，都是在与我们自己的人性、知识与偏见互动。
2.  我们发展AI的目标或许不应该是去复刻一个虚无缥缈的超级大脑，而是利用它的数据处理能力去构建一个连接你我、促进协作、提升整个社会效率的超级市场。
3.  AI最值得警惕的风险，可能不是科幻电影中那种机器人暴动，而是现实世界里由于数据垄断所导致的悄无声息的权力失衡。

所以，回到我们最初的问题：面对狂奔的AI，我们应该感到恐惧吗？听完乔丹教授的分析，你可能会感到一丝新的释然和安心。这种安心并不是因为AI变弱了——恰恰相反，它很强大——而是因为我们最终可以把它的定位，从一个不可预测、潜在的竞争对手，拉回到一个我们可以理解、可以驾驭、可以设计的强大工具上来。

AI的故事，最终可能不是一个关于硅基生命战胜碳基生命的科幻叙事，而是一个更加古老也更加深刻的人类故事：我们作为一个集体，如何利用我们发明的新工具，来更好地组织我们自己，更好地相互协作，共同去解决那些凭单个个体无法解决的复杂问题。未来不在那个神秘的黑箱算法里，未来在我们每一个人的选择、互动、连接之中，因为我们才是那个真正的驱动一切的集体智能。