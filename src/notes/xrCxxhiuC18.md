---
author: 北美王路飞
date: '2025-08-29'
guest: ''
layout: post.njk
source: https://www.youtube.com/watch?v=xrCxxhiuC18
speaker: 北美王路飞
tags:
  - ai-critique
  - agi-hype
  - neuro-symbolic-ai
  - ai-regulation
  - generalization-problem
title: 认知科学家加里·马库斯：为何硅谷的AGI“弥天大谎”需要被驯服？
summary: '知名认知科学家**加里·马库斯**（Gary Marcus: 著名认知科学家、心理学家、畅销书作家，以其对当前主流AI发展路线的批判而闻名），作为AI领域的头号批评家，长期以来坚持批判当前AI发展路线。本文深入探讨了他从研究人类大脑缺陷到质疑大语言模型“幻觉”的智识历程，揭示了AI在抽象推理和泛化能力上的根本性缺陷。马库斯认为，硅谷在贩卖**通用AI**（General AI, AGI: 能够像人类一样理解、学习和应用智能来解决任何问题的AI系统）的“弥天大谎”，呼吁引入**FDA**（美国食品药品监督管理局: 负责监管食品、药品、医疗器械等产品安全性的美国政府机构）式的监管，并倡导**神经符号混合AI**（Neuro-symbolic AI: 结合了神经网络和符号逻辑的混合人工智能方法）作为未来方向。他强调，在AI狂热中，批判性思维和对技术局限性的警惕至关重要。'
insight: ''
draft: true
series: ''
category: general
area: society-systems
project:
  - ai-impact-analysis
  - systems-thinking
  - historical-insights
people:
  - Gary Marcus
  - Elon Musk
  - Sam Altman
  - Daniel Kahneman
companies_orgs:
  - OpenAI
  - Google
  - Waymo
  - FDA
products_models:
  - GPT-5
  - ELIZA
  - AlphaFold
  - ChatGPT
media_books:
  - Kludge
  - Thinking Fast and Slow
  - Rebooting AI
  - Taming Silicon Valley
  - Washington Post
status: evergreen
---
### AI时代的“头号唱反调者”：加里·马库斯

大家好，欢迎来到我的频道。今天我们来聊一位名叫**加里·马库斯**（Gary Marcus: 著名认知科学家、心理学家、畅销书作家，以其对当前主流AI发展路线的批判而闻名）的学者。前段时间，**GPT-5**（Generative Pre-trained Transformer 5: OpenAI开发的大型语言模型，用于生成文本、回答问题等）发布后，他在Twitter上疯狂嘲讽，表现得非常兴奋。在AI圈内，马库斯其实是赫赫有名的“头号唱反调者”。无论是OpenAI还是谷歌发布新模型，他总是第一个跳出来说：“你这玩意儿不行，还是个‘磕了药的**自动补全**（Auto-complete: 一种软件功能，根据用户输入预测并提供可能的完成选项）’。”

这听起来像不像一个专门跟科技过不去的老顽固？但最有意思的是，他前半辈子专门研究心理学和神经科学，最出名的一本书叫做《**Kludge**（笨拙的人类大脑: 加里·马库斯所著书籍，论述人类大脑并非完美设计，而是充满妥协和缺陷的产物）》，中文译作《笨拙的人类大脑》。在这本书里，他花了很大力气证明人类大脑根本不是什么完美设计，而是一个充满了各种凑合设计的、漏洞百出的“草台班子”。这本书与另一本非常流行的《**Thinking Fast and Slow**（思考，快与慢: 诺贝尔经济学奖得主丹尼尔·卡尼曼所著书籍，探讨人类的两种思维系统——直觉系统和理性系统）》有异曲同工之妙。

这事是不是特别拧巴？他先花了十几年告诉全世界，人类别自恋了，脑子也就那样，充满了非理性。现在，他又调转枪口，对着全世界最火的AI技术天天喊：“你们这帮机器也太蠢了，连我们这个笨蛋人类的边都摸不着。”你可能会觉得他精神分裂，或者良心发现开始尊重人类了。其实都不是。今天我们就好好讲讲加里·马库斯的故事，他究竟是一个AI时代的先知，还是一个跟不上时代的**唐吉柯德**（Don Quixote: 西班牙文学作品中的人物，比喻脱离现实、盲目幻想的人）？这背后其实藏着AI最根本的秘密。

### 从儿童语言习得到AI的“阿克琉斯之踵”

要搞明白马库斯这个人，我们现在把时间往前倒，回到他还是个小伙子的时候。他不是半路出家搞AI的，他是根正苗红的学界大佬，心理学和神经科学的荣誉教授。他到底是什么时候开始跟AI杠上的？你绝对想不到，是他在写博士论文的时候就开始了，那是在1992年。他当时研究的是小孩子怎么学说话。这跟AI有什么关系呢？关系可大了去了。他当时发现一个特别有意思的现象，叫做**过度规则化**（Overregularization: 儿童在语言习得过程中，将普遍语法规则过度应用于不规则动词或名词的现象）。说白了，就是小孩会说出像“breaked”（正确的应该是broke）或“goed”（正确的应该是went）这样的词。你可以看到，小孩其实把语法的规则过度使用到了一些特殊情况下。

这说明什么呢？这说明小孩不是在死记硬背，他是在试图理解语言背后的规则，并且把这个规则用到了不该用的地方。这个小小的错误，一下子就让马库斯抓到了问题的核心。他在访谈中自己都说，他从这里学到了两点：第一，很多人喜欢根据一点点数据就开始瞎编理论；第二，也是最重要的，理解一个错误为何会发生，对于理解整个系统是如何工作的，极具启发性。

你听听这话说的，当一个系统表现正确的时候，你搞不清楚他是真懂还是恰巧蒙对了。但是当他犯错的时候，这个错误的模式恰恰暴露了他底层的运作机制。这就是马库斯所有思想的钥匙。从他研究一个三岁小孩怎么会说“goed”开始，他就一直在琢磨一件事情：一个系统，不论是人脑还是电脑，到底是怎么实现抽象和推理的？而当时的神经网络模型，连三岁小孩的语言能力都模拟不了。所以你看，他不是今天才开始批判AI的，他从上世纪90年代开始，就已经盯着神经网络的**阿克琉斯之踵**（Achilles' Heel: 源自希腊神话，指某人或某事物的致命弱点）了。这根刺在他心里扎了三十多年。

### 人类大脑的“漏洞大全”与AI的“轻信陷阱”

有了这个“抓bug”的底层逻辑，我们再看看他第一阶段，就是那个把人类说得一无是处的阶段。2008年的时候，他写了一本叫做《Kludge》的书。这本书说白了，就是一本人类大脑的“bug大全”。他告诉我们，我们的大脑并不是上帝精心设计的艺术品，而是进化过程中一路打补丁、一路凑合过来的产物，是一个“funny bag of tricks”（一袋子搞笑的戏法）。你想一下，我们的脊椎是不是经常疼？我们的呼吸系统和进食系统共用一个通道，是不是有时候会噎着？马库斯说，我们都愿意承认身体上的有些设计不完美，是局部最优，但是一提到我们的大脑和思维，很多人就不乐意了，总觉得自己是理性的化身。马库斯就在书里“啪啪打脸”，他说：“拉倒吧！什么**确认偏误**（Confirmation Bias: 人们倾向于寻找、解释和记忆支持自己已有信念的信息，而忽略或贬低与自己信念相悖的信息）啊，就是你总想找证据证明自己是对的；什么**动机性推理**（Motivated Reasoning: 人们为了维护自身信念或自尊，有选择性地寻找、解释或评估证据的心理过程）啊，为了保护我们脆弱的自尊心而找理由。”这些东西，本质上都是我们大脑这个“草台班子”为了走捷径、省能量而产生的bug。所以你看，在那个时候，马库斯扮演的角色就是一个毫不留情的**人类中心主义**（Anthropocentrism: 认为人类是宇宙中心或最重要的物种的观念）粉碎机。他告诉我们，别太把自己当回事儿，我们的理性既脆弱又有限。

好了，第一幕唱罢，大家是不是都觉得这哥们肯定是一个技术决定论者？既然人类这么不行，那肯定得靠机器来拯救世界了呗。结果谁也没想到，风水轮流转，到了最近几年，特别是**大语言模型**（Large Language Model, LLM: 一种基于深度学习的AI模型，通过分析海量文本数据来理解和生成人类语言）火了之后，马库斯摇身一变，又变成了AI的头号批评家了。他和他的合作者写了另一本书，叫做《**重启AI**（Rebooting AI: 加里·马库斯与厄尼斯特·戴维斯合著书籍，批判当前AI的局限性并提出未来发展方向）》。在这本书里，他火力全开，他是怎么形容现在的AI呢？“auto complete on steroids”（嗑了药的自动补全）。这个比喻太绝了，就是说你别看它能写诗能画画，本质上它就是在玩一个超级复杂的文字接龙游戏，根据概率来预测下一个最可能出现的词是什么，它根本不知道自己在说什么。

马库斯说，我们现在都陷入一个巨大的“轻信陷阱”，就是我们太容易高估机器的能力了。就像几十年前，麻省理工学院的一个叫做**ELIZA**（伊莉莎: 1960年代开发的早期自然语言处理计算机程序，通过模式匹配模拟人类对话）的简单程序，就让很多人都以为电脑真的跟人聊天一样。现在呢，只不过是这个骗局变得更加精致、更宏大了而已。他举了个例子，特别吓人，说有一个乔治城的律师被AI凭空污蔑，说他在阿拉斯加的一次旅行中性骚扰学生。AI还有鼻子有眼地说，这事是《**华盛顿邮报**（Washington Post: 美国一家知名报纸）》报道的。结果呢，《华盛顿邮报》自己去查，文章是假的，旅行是假的，什么都是假的，根本就是凭空捏造嘛！这就是所谓的**幻觉**（Hallucination: AI模型生成虚假、不准确或与事实不符信息的现象）。所以呢，马库斯的第二幕就告诉我们，别被AI的光鲜外表骗了，这玩意现在就是一个黑箱，是一个脆弱的、不可靠的、没有真正理解能力的“炼金术”。

### “人类是个低标准，机器甚至连这都达不到”

好了，戏唱到这里，矛盾就彻底摆在台面上了：一边是人类不行，一边是机器也不行，到底谁行呢？这不就成了一个死结吗？马库斯在访谈里提到一个堪称“名场面”的画面，完美地展现了这个矛盾的顶点。有一次，他和那个《Thinking Fast and Slow》的作者，诺贝尔奖得主**丹尼尔·卡尼曼**（Daniel Kahneman: 著名心理学家和经济学家，因其在前景理论方面的贡献而获得诺贝尔经济学奖）一起参加一个座谈会。大家都知道，卡尼曼这一辈子都在研究人类的**认知偏见**（Cognitive Bias: 人类在判断和决策过程中，因思维捷径或情感因素而产生的系统性偏差），是证明人类不靠谱的“祖师爷”。会上，卡尼曼就说了一句非常经典的话：“humans are a low bar”（人类是一个很低的标准）。这话什么意思呢？就是说我们人类自己这一堆毛病，所以要超越人类，这个门槛其实并不高。

此话一出，所有人都看着马库斯，怎么接啊？照理说呢，他作为《Kludge》的作者，应该点头如捣蒜对不对？结果呢，马库斯当场就怼回去了。他说了一句让全场都记住的话：“and it's sad that machine hasn't met it”（可悲的是，机器到现在还没有达到这个低标准）。你看这句话，就把所有的矛盾全都串联起来了。人类是个低标准，而机器甚至连这个低标准都达不到。这句话就是理解马库斯所有观点的“总钥匙”。

他到底想说什么呢？他不是在玩文字游戏，他想表达一个特别深刻的观点：人类和AI犯的错误类型根本就不一样。我们人类的“蠢”呢，是蠢在有各种认知偏见，很容易被情绪所左右，我们的记忆不靠谱，我们的推理有漏洞。但是呢，我们有一个巨大的优点，那就是灵活性。我们可以处理全新的问题，在没有见过的情况下举一反三，触类旁通。而AI呢，现在的AI它没有我们那些保护脆弱自尊心的毛病，它没有动机性推理。从这个角度来看呢，它确实比我们更理性。但问题是，它聪明是建立在海量数据喂养的模式匹配上的。一旦你把它扔到一个它没有见过的数据之外的环境，它就傻了。它缺乏真正的抽象推理能力。这就是马库斯的核心论点：人类的智慧是带有bug但灵活的智慧，而AI的智慧是僵化的、缺乏**泛化**（Generalization: AI模型将从训练数据中学到的知识应用于未见过的新数据的能力）能力的伪智慧。

### AI开发是“炼金术”而非科学工程

说到这里，可能就有人会说，有bug怕什么呢？修不就行了吗？我们用电脑，软件出了问题，厂商很快就会发个补丁。AI的bug为什么就修不好呢？马库斯说，问题就出在这里。现在AI开发根本不是科学，也不是工程，而是**炼金术**（Alchemy: 早期的一种化学实践，旨在将普通金属转化为黄金，在此处比喻AI开发缺乏科学理论指导，依赖反复尝试）。他举了一个漫画的例子，简直绝了。漫画里一个人问：“这是你的机器学习系统吗？”另一个人回答：“是啊，你把数据从一头输进去，然后我有一个线性代数的系统，你就可以在另一端收集这些回答了。”小人又问：“如果这些回答是错的怎么办？”他说：“那我就再把这一堆重新搅一搅，直到它们看起来像是对的。”那就是重新再训练嘛！

这其实就告诉你，现在的AI开发很大程度上就是这样。大家没有一个明确的理论能告诉你为什么这些模型会产生幻觉，或者为什么它会有偏见。大家能做的，就是“炼丹”，调整参数，增加数据量，再搅和搅和，然后祈祷下一次结果会好一些。马库斯说，这和传统的软件开发完全是两码事。传统软件，比如说你的银行系统，如果把大于号写成小于号，程序员可能像福尔摩斯一样顺藤摸瓜，找到那个出错的代码，把它改掉，问题就解决了。但是AI的幻觉呢，它不是一个可以精确定位的bug。幻觉和真相是由同一个机制产生的。你只要运营这个系统，它就必然会产生幻觉。这是它自动补全工作方式的固有属性。你没有办法像外科手术一样把它切掉。所以呢，当你听到“我们再过几个月就能解决幻觉问题”这种说法，在马库斯看来，全是硅谷的“希望与炒作”（Hope and Hype）。他觉得这帮人根本就没有找到病根，只是在给一个系统性的癌症贴创口贴。

### 泛化难题与硅谷的“文化之病”

为了把这个“炼金术”的问题说得更透彻，马库斯抛出了一个他职业生涯里最重要的发现，就是那些关于**泛化**（Generalization: AI模型将从训练数据中学到的知识应用于未见过的新数据的能力）的两种不同类型。这词听起来有点学术，但是说白了特别简单。一种呢，叫做“训练空间内的泛化”（within training space generalization）。什么意思呢？就是说我教你认识了100种不同的狗，然后给你看一个第101种你没有见过的狗，你也能认出来。现在的AI呢，在这方面做得其实还是不错的。但是还有第二种，叫做“训练空间外的泛化”。这是什么呢？就是我教了你100种狗，然后我给你看一只猫，问你这是什么。如果你能回答：“这不是狗，而是另一种毛茸茸的四脚动物”，这才叫真正的泛化。马库斯说，AI在这种泛化上简直就是一塌糊涂。它所有的能力都严重依赖于它吃进去的数据。只要你给它的问题稍微超出了它见过的那些数据的分布范围，它就立刻“翻车”。

他举了那个特斯拉的例子，简直经典中的经典。特斯拉有个功能叫做“召唤”（Summon），理论上能够让车自动过来找你。结果有个人在一个飞机展上用了这个功能。你想想，飞机展这玩意肯定不是在特斯拉常规训练数据里吧？这是一个典型的**边缘案例**（Edge Case: 在正常操作范围之外或极端条件下的特殊情况，往往难以被系统正确处理）。结果怎么着呢？那辆特斯拉对着一辆价值350万美元的私人飞机直接“duang”的一下撞上去了。它能够识别行人、识别自行车，但是它不理解飞机是什么东西，它系统里头就没有这个预案。所以呢，它就当成它不存在。这就是马库斯几十年来一直想告诉我们的：如果一个系统不能够处理好训练数据之外的意外情况，它就永远不值得我们真正的信任。而这个问题，从他1998年开始研究最简单的神经网络开始，直到今天最复杂的GPT，本质上一点都没有解决。

好了，技术上的硬伤说完了，马库斯直接把矛头对向了硅谷的这帮大佬们。他觉得这已经不是单纯的技术问题了，而是一种文化上的病。他点名批评了**埃隆·马斯克**（Elon Musk: 特斯拉和SpaceX的首席执行官，以其大胆的技术愿景和承诺而闻名）。他说马斯克承诺的全自动驾驶承诺多少年了？十年了吧快。他自己都记不清马斯克到底说了多少次“明年都能实现100万辆机器人出租车队”的这种话了。结果呢，马库斯一针见血地指出，这帮人完全低估了现实世界的复杂性，尤其是那个边缘案例的问题，也叫**长尾问题**（Long Tail Problem: 指在数据分布中，出现频率极低但种类繁多的事件或情况，对AI系统构成挑战）。你可以在加州阳光明媚的大道上跑得很好，但是你敢把车开到东北部下着暴雪和冻雨的乡间小路上吗？你敢把它开到路况混乱的孟买街头吗？他说，Waymo的人都知道，当你把车队的规模从100辆扩大到100万辆的时候，你每天遇到的奇葩意外事件会成指数级增长，多到你根本想象不到。这需要大量的人工远程干预，需要一套极其复杂和昂贵的基础设施来支持。而马斯克呢，似乎对这些真正的难题选择性无视。

除了马斯克，他还提到了OpenAI的**山姆·奥特曼**（Sam Altman: OpenAI的首席执行官，致力于推动通用人工智能的发展）。奥特曼总喜欢暗示一些非常宏大的愿景，比如说当AI解决了物理学难题，世界会变成怎么样？马库斯一听这话就来气，他说：“什么叫AI解决物理学啊？这根本就不是一个定义清晰的问题。这是典型的硅谷式的话术，用一个模糊而宏伟的承诺来掩盖当前技术能力的不足。”说白了就是“画大饼”。他觉得硅谷现在已经从一个交付产品的地方，变成了一个贩卖谎言的地方。而媒体和公众呢，还就吃这一套，被忽悠得一愣一愣的，缺乏足够的批判性思维。

### 将AI视为“新药”：呼吁FDA式监管

那么问题来了，既然技术有硬伤，文化有问题，我们普通人应该怎么办呢？就眼睁睁看这头被驯服的野兽横冲直撞吗？马库斯说，当然不行。他提出一个非常重要的类比，也就是他新书《**驯服硅谷**（Taming Silicon Valley: 加里·马库斯的新书，主张对科技巨头进行更严格的监管）》的核心观点。他说呢，我们应该把AI，特别是特别强大的**通用AI**（General AI, AGI: 能够像人类一样理解、学习和应用智能来解决任何问题的AI系统），当成一种“新药”，而不是一种“新软件”。

你想想这个类比有多妙！一款新药被研发出来的时候，我们敢直接就上市让所有人吃吗？不敢吧！我们要有**FDA**（美国食品药品监督管理局: 负责监管食品、药品、医疗器械等产品安全性的美国政府机构）这样的机构对它进行严格的临床实验，评估它的疗效，更重要的是评估它的副作用。万一这药吃死人怎么办？谁来负责？那现在AI呢，一个公司它自己训练了一个模型，说它通过内部的安全测试，然后就直接发布给全世界数亿人使用。我们知道它会产生虚假信息，知道它可能有偏见，知道它可能会被用来制造诈骗混乱。但是呢，没有任何一个独立的第三方权威机构对它进行上市前的强制审查。马库斯说这太疯狂了。

他举了**生物武器**（Bioweapon: 利用生物毒素或微生物作为武器，旨在造成疾病或死亡）的例子。OpenAI自己的报告也都承认，他们最新的模型有可能会增加生物武器研发的危险。结果呢，他们承认了风险，然后还是照样发布了。为什么呢？因为最终做决定的是山姆·奥特曼一个人。他脑子里想的都是商业利益，是竞争。全世界的安危呢，就这么被绑在一两个科技大佬的战车上了。所以马库斯呼吁，我们急需建立一个AI界FDA这样的机构，对于那些高风险的AI模型进行强制的、独立的、透明的审查，不能让开发者既当运动员又当裁判员。

### 人类智慧的“最后护城河”：抽象、因果与常识

聊了这么多AI的不是，我们回头看看人类自己。既然马库斯说我们是那个“很低的标准”，那我们这个低标准里头到底有些什么东西是现在AI死活都学不会的呢？这才是问题的关键。马库斯认为，我们人类虽然bug很多，但是我们掌握了一些AI目前完全不具备的核心能力。

比如**抽象和建立模型的能力**（Ability to abstract and model: 从具体事物中提取共同特征，构建概念框架的能力）。我们在商学院里学到什么？不是教你背案例，而是教你从案例中提取出来框架和模型：顺风时怎么做，逆风时怎么做，顺风转逆风时又该怎么做。这种从抽象到具体，再用抽象指导具体的能力，AI目前没有。

再比如**因果推理**（Causal Reasoning: 理解事物之间因果关系的能力，而非仅仅是相关性）。AI知道打雷和闪电总是一同出现，但是它不知道是闪电导致了打雷。它只能看到相关性，却没有办法理解因果性。而我们人类呢，天生就在寻找万事万物背后的“为什么”。

还有**常识**（Common Sense: 人们普遍认同的基本知识和判断力）。这个就更悬了。我们知道水是湿的，知道不能抓刀刃，知道乌龟跑不过兔子。这些看似简单的常识背后，是一个庞大的关于世界如何运作的物理和社会模型。AI没有这个模型，所以它会犯很多在我们看来匪夷所思的低级错误。

所以马库斯说，我们在学校里，尤其是商学院和研究生院，真正应该教的正是这些东西。不是教学生怎么用**ChatGPT**（ChatGPT: OpenAI开发的一款基于大型语言模型的聊天机器人）写报告，而是培养他们的批判性思维能力，教他们如何识别和挑战一个论点背后的所有假设，如何设计实验来证伪一个理论。这些才是短期内人类智慧相对于人工智能，最核心也是最后的**护城河**（Moat: 在商业领域指企业相对于竞争对手的竞争优势，在此处比喻人类智能的独特优势）。

### 马库斯的药方：神经符号混合AI

听到这你是不是觉得马库斯就是一个彻头彻尾的AI悲观主义者呢？大错特错！这可能是对外界对他最大的误解。马库斯最后表示，他不是不相信AI的未来，恰恰相反，他相信AI最终会给医学、科技等领域带来革命性的进步。他只是极度不看好当前这条单纯靠堆数据、堆算力的**深度学习**（Deep Learning: 机器学习的一个分支，通过多层神经网络从大量数据中学习复杂模式）路线。他认为正确的路线应该是什么呢？他提出一个概念，叫做**神经符号混合AI**（Neuro-symbolic AI: 结合了神经网络（擅长模式识别）和符号逻辑（擅长推理规划）的混合人工智能方法）。

这又是个术语，别怕，我给大家翻译一下。神经指的就是现在很火的神经网络、深度学习这一套。它擅长干什么呢？擅长处理模糊的模式识别类任务，就像我们大脑的“**系统一**（System 1: 丹尼尔·卡尼曼提出的概念，指人类快速、直觉、无意识的思维系统）”，直觉反应很快。符号指的是什么呢？指的是那种传统的、基于规则和逻辑的**老式AI**（Old-fashioned AI: 指基于符号逻辑和规则推理的传统人工智能方法）。它特别擅长干什么呢？擅长进行精确的一步步的推理和规划，就像我们大脑的“**系统二**（System 2: 丹尼尔·卡尼曼提出的概念，指人类缓慢、理性、有意识的思维系统）”，深思熟虑。马库斯认为，真正智能一定是这两者的结合。光靠直觉，神经网络没有**符号逻辑**（Symbolic Logic: 一种通过符号来表示和操作逻辑关系的推理方法，是传统AI的核心）系统，就会像现在这样漏洞百出。光有逻辑，没有直觉，又会显得非常僵化和脆弱。

他已经举了一个成功的例子，叫做**AlphaFold**（阿尔法折叠: DeepMind开发的人工智能程序，能够准确预测蛋白质的三维结构）。马库斯说，AlphaFold的巨大成功恰恰不是纯粹深度学习的胜利。它内部就包含了大量经典的、基于逻辑编程的老式AI技术。它是一个完美的混合系统的典范。所以你看，马库斯他不是在唱衰AI，他是在告诉大家：“你们走错路了！旁边这条小路，虽然现在人少，才是可能通往罗马的正道。”

### 智识上的坚持：马库斯的真正敌人

好，我们现在把所有的线索串起来，就还原一个真实的加里·马库斯。他真的是一个前后矛盾的人吗？不是。他是一个思想体系高度统一和连贯的学者。你看他学术生涯都在干一件事情：研究智能这个东西的本质，以及它在现实生活中是如何“掉链子”的。

第一步，他通过研究儿童语言和《Kludge》，深刻地揭示了人类智能不完美的本质。我们大脑不是一台完美的逻辑计算机，而是一个充满各种进化遗留bug、凑合能用的混合系统。

第二步，他把目光投向AI时，他发现当前主流的AI路径试图用一个纯粹的、大一统的神经网络模型来解决所有问题。这在他看来，是犯了方向性的错误。因为它完全忽视了我们大脑虽然有bug，但依然强大的部分，就是符号逻辑和抽象推理的能力。

第三步，所以他批判AI并不是为了否定AI，而是认为当前的AI发育畸形，是一个“偏科生”。它只模仿了人脑的系统一直觉，却没有建立起可靠的系统二审慎思维。

第四步，因此，他开出了药方：神经符号混合AI，以及建立严格的监管机制。这就顺理成章了。前者是在技术上治病，让AI显得更可靠、更强大；后者是为在社会层面治病，防止一个不成熟的技术对我们这个本来就充满bug的人类社会造成无法挽回的伤害。

所以你看，从头到尾他的逻辑都是自洽的。他不是墙头草，更不是为了博眼球。他只是在用一种刨根问底的、严谨的、甚至有点刻薄的科学精神，去审视两个不同的智能体——人类和机器。

所以加里·马库斯的真正敌人不是AI技术，也不是OpenAI或者谷歌这些公司。他真正反对的是几样东西：

第一是**智识上的懒惰**（Intellectual Laziness: 指在思考和学习过程中不愿深入探究、寻求捷径的倾向），就是那种“数据能解决一切，只要模型够大，智力就会涌现”这种“大力出奇迹”的思维定势。他认为这是在回避真正的难题。

第二就是商业上的贪婪和不负责任。明知道技术有缺陷有风险，但为了抢占市场，为了股价，为了融资，还是把它包装成无所不能的样子，急匆匆推向社会，把风险转嫁给所有人。

第三就是媒体和公众的盲目崇拜。就像我们前面说的“轻信陷阱”，我们被酷炫的效果所迷惑，放弃了思考和质疑，变成了科技公司宏大叙事的“韭菜”。

这几样东西加在一起，就构成了他眼中那个需要被驯服的狂野的硅谷巨兽。他扮演的角色，就像那个童话里说**皇帝没穿衣服的小孩**（The Emperor's New Clothes: 源自安徒生童话，比喻揭露虚伪或谎言的人）。这话不中听，甚至有点扫兴，但可能这才是我们现在需要听到的声音。

### 逆耳忠言的价值与清醒的智慧

好了，讲了这么多，来说说我个人的看法。在我看来，我觉得像加里·马库斯这样的人，在这个时代不是太多了，而是太少了。我们这个时代太需要逆耳的忠言了。当所有人都沉浸在一场技术狂欢里的时候，我们需要有人站出来泼一盆冷水，告诉我们：“嘿，等一等，我们先看看这酒里有没有毒。”

马库斯的价值不在于他每一个预测都100%准确。说实话，他倡导的这个神经符号混合路线到底能不能走通，什么时候能走通，也是一个未知数。他真正价值是它提供了一个制衡的力量。你想想，如果没有他这样的人天天在媒体上、在国会听证会上找茬，科技公司会不会更肆无忌惮呢？他们会不会更不愿意承认自己产品的缺陷呢？公众会不会更深地陷入到技术崇拜的迷雾里呢？他就像汽车里头的刹车系统。你平时开车的时候，可能觉得它没什么用，甚至有些碍事，你总想一脚油门踩到底。但是呢，一旦遇到紧急情况，这个刹车系统还是最能救命的。

而且我佩服他一点，就是他几十年如一日智识上的坚持。从他研究三岁小孩说话，到现在跟万亿市值的科技巨头叫板，他的核心观念始终都没变。这种坚持，在今天这个追逐风口、光速变脸的时代，显得尤为可贵。所以呢，你可以不同意他的所有观点，你甚至可以觉得他有点**杞人忧天**（Qǐ Rén Yōu Tiān: 中国成语，比喻不必要的或过度的担忧），但是我们必须捍卫他唱反调的权利。而且呢，他的这些观点其实在现在这个时刻反而被证明是对的，这个就非常有意思。之前很多人都在嘲讽马库斯，但是到GPT-5发布之后呢，很多人都认为：“哎，马库斯说的居然是对的！”

好了，今天关于加里·马库斯的故事就聊到这里了，但是他给我们的思考远远还没有结束。他其实告诉我们每个人一个问题，就是在人工智能这个不可逆转的时代浪潮面前，大家想要扮演一个什么样的角色？是做一个被动的、只会惊叹“哇，好厉害”的信徒，把自己的判断力全都交给科技公司和他们宣传机器？还是做一个主动的、清醒的、会用“为什么”和“万一呢”的用户，既享受科技带来的便利，又对它的局限性和风险保持一份警惕？马库斯选择的是后者。他用他自己整个职业生涯来告诉我们，真正的智慧不在于不出错，而在于理解错误、反思错误，并且在错误中学习的能力。这个道理呢，其实对人类适用，对AI也适用，对我们每个人都同样适用。别忘了，工具越强大，使用工具的人就更需要智慧，而这种智慧恰恰是任何AI都不能够给我们的。

那么最后呢，我还想讲一个跟马库斯的小故事。我听了他的节目，看了他的书之后，我去推特上联系他，给他发私信，我说我特别喜欢你的理论，我想采访你一下。然后他就回复我了，他说：“非常感谢你的邀请，但是最近确实邀请的人太多了，我已经overcommitted，我已经overbooked了，以后有机会再说。”我觉得他能够回我这样一个“小咖”，回我这样一个“nobody”的消息，其实还是挺让人惊讶的。我当时给他发消息的时候，只是抱着试试看的想法，但是他居然回我了，然后还回了很多话，我就觉得这个人确实挺不错的，就是并没有很高的EGO。我也会把他的书和他的这些访谈视频也放在本期节目的视频描述栏，感兴趣的朋友可以进一步去深度听一下他怎么说的。非常感谢大家观看，我们本期节目就录到这里了。