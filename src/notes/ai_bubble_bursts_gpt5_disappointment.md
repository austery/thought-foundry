---
title: AI泡沫破灭：聊聊GPT-5的失望与行业的未来
summary: 探讨AI泡沫破灭的现状，聚焦于GPT-5相较于前代版本令人失望的表现和日益严重的“幻觉”问题。对话深入分析了AI研发的巨额成本、通用人工智能（AGI）的夸大宣传与现实的差距，并展望了行业未来可能转向专用AI模型的发展趋势。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- agi
- ai-bubble
- large-language-model
people: []
companies_orgs: []
products_models:
- gpt-5
media_books: []
date: 2025-09-01
author: Lei
speaker: 北美王陆飞
draft: true
file_name: ai_bubble_bursts_gpt5_disappointment.md
guest: 老隐, 索隆
insight: null
layout: post.njk
series: null
source: null
status: evergreen
---
## GPT-5的初体验与失望

陆飞: 好的，我们直播开始了。今天我们的主题，就像标题上说的，“AI泡沫破灭了？聊聊ChatGPT-5”。我不知道老隐，你和索隆两个人，有没有经常用这个最新的GPT？

老隐: 那是经常用。我今天讲俄罗斯和楚国的更新时，最后也提到了GPT最近经常出幻觉，各种幻觉。

陆飞: 是吧。我不知道你们俩什么感觉，我是一个GPT的重度使用者，基本上每天早上起来就开始用GPT，然后一直用到晚上睡觉前。

索隆: 那你用GPT干嘛呢？当个虚拟情人谈恋爱是吗？

陆飞: 我就是有的时候，比如说我会有什么想法，我会跟他语音对话，跟他聊天。你知道那个语音功能挺好玩的，你可以不停地提问。你可以试一下，打开这个voice mode。

索隆: 你老婆OK吗？你确定你不是沉迷了吗？

陆飞: 没有沉迷。

索隆: 行行行，你怎么说咱们怎么信。

陆飞: 但是我必须得说，从GPT-4o，还有之前各种命名，一直升级到GPT-5，我就发现他这个5，没有之前给我那种眼前一亮的感觉。之前我不知道你们有没有经历，从3到4，4到4o这个阶段，那是一个非常质的飞跃，就让你眼前一亮那种感觉。

索隆: 当然是的，是这样的。

陆飞: 本来我对GPT-5期望很高的，因为Sam Altman天天说“万一我们要是把物理给解决了怎么办？”（What if we solve physics?）。我想，那你都把物理都给解决了，不是无敌了吗？

老隐: 他自己发的一个帖子，这个其实说的很不清楚。其实Sora里面的各种世界物理规则已经处理得比较好了。

陆飞: 对。所以现在就有很多怀疑，因为他自己其实也承认了，最新的GPT-5确实是炒作（hype）太严重了，给大家过高的期望。天天说**AGI**（通用人工智能：一种拥有与人类相当或更高智能水平的人工智能），然后说要把所有工程师都给淘汰了。结果5出来之后，很多人反映说，能不能给我换回之前的模型，我想要之前的4o。这就非常尴尬了。

老隐: 我就很想换回原来的模型。我在做观众老爷们催更的俄罗斯和楚国内容里面，GPT-5出现了幻觉，就是编造了很多本不存在的文字，而且编得特别像那么回事，我读过不少古文官职都没看出来，后来一查不对。

## AI幻觉的具体案例

陆飞: 我跟你说一个，我这次的这个幻觉太牛了。我这次回国之后，去西安参观碑林，还有兵马俑，历史感拉满，全都是先秦的小篆，完全看不懂。所以我就让GPT给我翻译。兵马俑博物馆的那个匾额，上面写的应该是叫“秦始皇兵马俑博物馆”，但他是用那个秦小篆写的。我就让GPT给我翻译，我说这个是什么字呀？GPT给我的答案是：“南澳服务区服务站”。它还一本正经地说，你现在是在一个高速公路服务区。我说行，这个可能小篆他看不懂，就没理他。

后来就去碑林，碑林上面有各种碑，那都是正楷。我就想让他介绍一下，比如说“大秦景教流行中国碑”，就是讲基督教在唐朝传播的碑文，这上面的碑文写的都是什么意思。因为古文是没有断句的，然后GPT开始给我一本正经的解释，解释得可好了，看完觉得挺好的。过了一会儿来了一个旅游团，人家有导游。我们就在那旁边想着，我已经懂了，说不定还能给这个导游指出一点他不懂的地方。我就在那听着，听了一会儿，我就发现，他跟我讲的跟GPT完全不是同一个东西。

后来我就在GPT里说，我刚才又听到了另外一个版本，这是为什么？他马上就说“对不起，我刚才说错了”，又给我重新说了一遍，但是他又是一本正经地说了一通瞎话。我就明白了，可能让他解读碑文也是太为难它了。

然后我们就继续往前走，去了一个叫“大唐不夜城”的地方。它就是一个仿古的步行街，非常现代，没有任何历史感了。但是它步行街中间，有一个很大的雕塑，是李世民骑着他的高头大马，然后下面应该写的是“贞观之治”四个字。这个时候我就给这个雕塑拍了一张照片，发给了GPT，我说你能不能给我讲讲上面是什么典故。这个GPT跟我说，这个典故叫做“昭君出塞”，讲的是王昭君在唐朝嫁给匈奴单于的故事。她说这个昭君骑在马上，就是要替国家去和亲了。

我说，请问你看不见那个字上面写的是“贞观之治”吗？昭君是汉朝的呀。你这关公战秦琼，汉朝的人物怎么安到了唐朝头上？这个GPT又说“哦”，下面一通解释，说是看成了“昭君出塞”。我说这个也不是秦小篆，这个是正楷写的呀。后来它就懒得解释了。

## AI的巨大成本与泡沫隐忧

陆飞: 我是觉得这个GPT-5出来以后，它的幻觉好像愈发严重了一些。

索隆: 变得更严重了是吧？因为它之前可是号称会把幻觉问题解决。Sam Altman说“我已经找到怎么制作AGI了”，让大家期望特别高，感觉GPT-5肯定是要吊打GPT-4的。结果发出来之后，大家就没有这种感觉。

陆飞: 然后其实还有另外一个问题。你们知道OpenAI每天为用户提供服务，就是你在上面问问题，一天要花多少钱吗？

老隐: 不知道，多少钱？几百万？

陆飞: 一天要烧掉70万美金。

索隆: 70万差不多。

老隐: 什么叫提问题的？

陆飞: 就是你花在算力上的钱。因为你每天在那个对话框上输入一个提示词（prompt），他都得在云端去做一系列的模型运算。这些模型本身全都是部署在云上的，你每次运用都需要花钱，就花这些算力的钱。他光每天就要烧掉70万美金。

老隐: 听起来还不是很多呢，我觉得。

陆飞: 但是这是一天。这还没算你训练模型、买**GPU**（图形处理器：专为执行复杂数学和几何计算而设计的电子电路，是AI训练的核心硬件）这些钱，只是每天让大家使用的**推理**（Inference：指使用已经训练好的AI模型来做预测或生成结果的过程）的钱。

另一方面大家也知道，作为美股的第一股王，英伟达股价已经是达到了4万亿的市值。

索隆: 4万亿的市值，超过了世界上100多个国家的GDP，这非常的夸张。

陆飞: 然后亚马逊投入了1050亿美元，但是他现在AI的收入预计只有50亿。你看到这些科技巨头，他投入和产出其实差别是非常大的，完全不成比例。关键是大家现在万众期待的AGI，就是说AI可以基本上取代工程师、会计等各行各业，你都不用上班了，因为AI就可以取代你的工作。这都已经喊了好长时间了，现在还是没有出现。

然后OpenAI的CEO在GPT-5发布之后，看到观众的反应都非常不好，他也承认GPT-5搞砸了，说我们之前给大家希望拉得太高，然后实际交付（deliver）非常糟糕。

## 各大AI模型的比较与未来趋势

陆飞: 我其实是各大公司的模型我都有。但是市场头部的，比如说像ChatGPT的Pro模型和谷歌Gemini付费的Ultra，这两个性能其实差别没有那么明显了。就是各大公司顶尖模型之间的性能已经越来越趋同了。那就说明，其实你很难存在一定的护城河。就是我如果OpenAI今天倒闭了，我有Gemina的话，其实我也没有觉得特别难用。

老隐: 是，特别是谷歌有数据的优势。所以如果你训练的方式什么的没有代差的话，那么像谷歌这种掌握了大量数据的，肯定是要占便宜的。我们私下里，我跟节目的策划老陈，他也更看好谷歌的双子座（Gemini），因为你的数据量更大。

陆飞: 而且我觉得谷歌他有一个天然优势，就是他这个模型训练出来，他不一定是光卖模型的订阅（subscription），他还可以整合（integrate）到自己的所有系统中。比如说邮件、NotebookLM这些他都可以用。

老隐: 是的，所以我这次做频道迁移，有一些问题也是直接在后台问谷歌的AI，省了不少事。

陆飞: OpenAI他其实现在一个很大的问题，就是说他的付费用户的转化率是非常低的。他这个名号在AI界其实非常强大，因为大家现在基本上说大语言模型，说的都是ChatGPT，这是一个非常强大的市场营销。但是，他实际付费用户的比例占的很小。

而且AI这个产业，他其实不是一个轻资产的产业，他其实是一个重资产、能源非常密集的产业。

老隐: 他是超重资产。

陆飞: 就是他其实要投入大量的钱，不停去买这种固定资产。一个很简单的事实，就是一个大型AI公司的数据中心（data center），它所需要的配套的一个电厂要达到吉瓦（GW）级别。一般的发电厂是满足不了它的，得是一个比较大型的核电站才能支撑。

老隐: 是的。所以我就记得为什么Meta正好是在我们德州，奥斯汀的北边大概40分钟车程的地方，开了一个数据中心。因为德州它有一个大核电站，正好近水楼台先得月。

## 关于AI护城河与泡沫的讨论

陆飞: 其实这里头就讨论到AI的护城河了。目前OpenAI之所以有这样一个领先的模型，就是因为它是走这种“大力出奇迹”的路径，就是不停地训练更大的模型，用更多的数据去喂它，这样的话就能够得到性能上提升。但是目前这样一个规模法则（scaling law）已经走到头了，你很难再继续获得这样显著的提升了。

索隆: 现在可能有一个新的名词，叫**AI泡沫**（AI bubble）。很多人认为它现在处于一个泡沫期，包括英伟达这种4万亿的市值。

陆飞: Meta最近有一个叫做“招聘狂潮”，花了上亿美金去签……

索隆: 上亿美金你太小看他了，他是花了140亿美金，好像是从OpenAI和Anthropic挖了18、19个顶尖的AI科学家。

陆飞: 非常夸张。扎克伯格也说，今年的目标是要花500亿美元。有人算过，这大概是3000个小目标。大家去这样砸钱，但是所取得的成果，我们看到GPT-5的成果已经远远不如GPT-4了。

索隆: 看来并不是在这个赛道上去疯狂的撒钱就行。因为一开始的时候，主流的声音就是两个：一个就是说我们马上就要实现AGI了，所有人就可以在家躺平了；另外一个就是说这个AI已经脱离了我们的掌控，会奴役我们人类。

陆飞: 还有Sam Altman说数据中心会自己造数据中心。

索隆: 对，会用我们人类的算力去提升它自己。事实上我们距离真正的AGI还有非常长远的距离，通过大语言模型来实现AGI看起来是不太可能的。

陆飞: 而且更搞笑的是，Meta刚刚发了一个新闻说，Meta的AI领导者在讨论要使用谷歌和OpenAI的模型。

索隆: 这就相当于承认自己的不行了。

陆飞: 其实你可以看到，现在模型之间的差距已经很小了，而且还有开源模型。就像Deepseek把自己的推理模型也都免费给大家用，其实竞争就会非常激烈。

老隐: 特别是Deepseek，它用的是一种叫**MoE**（混合专家模型，Mixture of Experts）的稀疏架构。原来其他的模型是整个大脑一块运行，你哪怕问一个专业领域的问题，它也是整个大脑一块运行。但是Deepseek就相当于把它划分成不同领域，你在问某个领域问题的时候，只是对应领域的电路被激活，所以能源消耗和训练成本会大大降低。这个技术我相信要么这一代，要么下一代，其他的AI肯定也都会运用了。

## AI的应用落地与挑战

陆飞: 之前All-in Podcast提到了一个关键概念，就是AI是一个概率性软件，你每次给出来的答案不一定是可靠的。而我们过去熟知的软件工程，它其实是一个决定性的系统。一个输入就会有一个输出。这种概率性导致了AI模型在落地时会遇到很多挑战。

比如说拿AI模型用到医疗上去，实际效果很糟糕，因为它经常出现幻觉，又不能达到百分之百的可靠。你做医疗诊断，要是把人给弄错了，这个成本是很大的。

索隆: 你得赔死。

陆飞: 这也是这种大语言模型本身概率性存在的一个强大的问题。

索隆: 说到这个我可以补充一下。之前很多人担心AI将来会取代人类的工作，但实际上我非常不同意这个观点，就是因为你刚才说的这个问题。AI它不是一个端到端的产品，它是一个中间值。它的任务的起点和终点都需要人类的参与。最开始，你需要人类来写prompt；最后，你需要人类来验证AI的结果，防止幻觉。

AI所做的只是中间这一部分。它不但不会减少人类的工作，反而会增加新的商业模式（business model）。比如说现在有一个职业叫提示词工程师（prompt engineering）。所以我觉得大家并不需要过于担心AI会取代人类的工作，至少我认为，谈这个问题还为时过早。

陆飞: 他可以省一些人工，但是省不了那么多。

索隆: 他在某些领域省人工，但是它又在其他的领域给你创造了其他的工作岗位。

陆飞: 那么还有一种说法，就是说AI可以取代谷歌的搜索。但是搜索这么容易做吗？从搜索中能赚到这么多钱的公司只有谷歌一家。因为谷歌不光是有自己的搜索引擎，它还有底层的基础设施，包括海底电缆，同时它还拥有一个广告的买方和卖方平台，有一个非常完整的商业闭环。OpenAI现在什么都没有，服务器用的是微软的，广告网络也没有，也没有庞大的销售团队。所以OpenAI想要去抢谷歌的钱，是很难的。

## AI发展的加特纳炒作周期

陆飞: 在All-in Podcast中，也将现在和2000年的互联网泡沫形成了一个对比。在90年代，大家对互联网无限憧憬，所有带.com的公司都能获得大量的投资和估值。电信公司疯狂地铺设光纤网络。泡沫破裂之后，无数公司倒闭。但是你回头看，互联网基础设施并没有失败，当时铺的这些光纤，为后来科技巨头的崛起都奠定了一个基础。它的价值实现，其实只是比预期晚了几年。

现在我们在AI其实是面对同样的一个问题，我们前期投入了大量钱，但是短期内其实找不到一个很好的、快速获得现金流的机会。这种情况下，很多小AI公司、讲故事的这些公司，可能资金链会断裂，然后倒闭。但是真正强大的应用，会在这些废墟上重建。

索隆: 这就有点类似于股票的回调过程，对于一个健康的市场来说，它不但不是坏事，反而是一个好事，一个大浪淘沙的过程。

陆飞: 最近有一个MIT的研究，调查了300多个企业，发现95%的企业级生成式AI的试点项目，最终都未能成功地投入生产。这背后失败的原因，首先有员工的抵制，还有AI输出质量差，但最核心的问题其实是资源错配。因为企业把70%的AI预算，都投到了销售和市场营销这些面子工程上，希望做出一些酷炫的工具来吸引顾客。但这些领域恰恰是AI最容易翻车、最难标准化、而且投资回报率低的地方。

那么哪些领域投资回报率会相对高一些呢？就是后台的自动化处理、内部流程优化。这些任务重复繁琐，但是规则非常明确，特别适合AI来提效。比如说个人创作者，有很多工作就可以交给AI做，这确实能够提高非常多的效率。这也是为什么很多人发现，大家对AI的体感是冰火两重天：高管吹得天花乱坠，一线员工用起来感觉不靠谱，因为你用错地方了。

## 对从业者与投资者的建议

陆飞: 我们现在正处在**加特纳炒作周期**（Gartner Hype Cycle）的哪个阶段？从曲线上来看，我们已经度过了萌芽期，也可能度过了期望膨胀的顶峰。媒体和资本疯狂炒作，各种不切实际的预期满天飞。下一步就应该是经历泡沫破裂的低谷期，技术无法达到预期，各种问题暴露，投资退潮。

我觉得AI现在处于一个蓬勃发展，但是明显是存在泡沫的。目前来说，继续“大力出奇迹”的路是走不通的，各家肯定要想办法降本增效了。

我们不要被什么AGI、超级智能这些宏大叙事所迷惑，要真正去看它到底解决哪些真实世界的问题，评估商业模式是否可持续。公司他花了这么多钱投固定资产，它产生的营收（revenue）到底是多少？因为营收不会骗人。

最后给大家一个实用指南。对于投资者，要关注应用而不是空谈。对于职场人，要拥抱工具而不是恐惧，主动学习使用这些工具，尽可能用AI提升你的效率和创造力。对于所有人，要保持怀疑，回归常识，质疑过于美好或者恐怖的AI言论。

## 俄罗斯与楚国：边缘政权的类比

老隐: 首先要特别感谢一下各位观众朋友们上礼拜的催更。我一个刚开频道三个月的小V，现在真是享受了大V才有的催更待遇。上次开一个脑洞，把俄罗斯这种麻烦制造者，和春秋战国时期的楚国作对比，他们的心态都是典型的边缘政权心态。我今天就跟大家说一下这个更新。

无论是俄罗斯还是楚国，它作为典型的边陲政权，他们的心态其实是很矛盾的，就是遵从与反抗并存。一方面你知道中央秩序是好的，但另一方面你有点叛逆，又忍不住想反抗它。这里面我举的例子就是楚国国君熊通称王。

他不是一上来就称王，说我跟周天子平起平坐。他是先派人向周天子请求，说你看我现在扩张，实力那么大，把南方的蛮夷都打服了，功劳杠杠的。但我现在的爵位是子爵，倒数第二等，配不上我的实力和功劳了，你能不能给我晋升一下？他是追求在体制内解决。结果当时周天子也很“客气”，说“滚”。

熊通就怒了，说你敬酒不吃吃罚酒，于是他就自立为楚武王。然后他就开始破罐子破摔，攻打随国。随国说我没罪你干嘛灭我？熊通回答说：“我，蛮夷也”。反正我是蛮夷，我打你需要理由吗？这就是楚国的这种遵从与反抗并存的心态。

他第一阶段是遵从与反抗并存，但第二阶段他就想要取而代之。随后的一百年，也就是公元前606年的时候，楚庄王问鼎中原。他已经打到了周朝的首都洛阳，然后就问周天子，说咱们这九鼎多重啊？意思就是，你是不是该退位了？我就要取代你成为天下的共主了。

周天子派的使者王孙满回答说：“在德不在鼎”。你想控制天下，要靠德政和仁政，而不是靠九鼎。这句话的后果，比历史书上写的要严重得多。他一句话，把九鼎的法统地位给取消了。从此以后，衡量政府合法性的KPI，从具象的、客观的九鼎，变成了抽象的、主观的“德”。这会刺激很多野心家，因为道德是主观的，谁都可以说自己更有德。

## AI的哲学与数学限制

老隐: 我再回应一下陆飞有关AI局限性的问题。AI的幻觉，其实是在于它混淆了**符号真实**（Symbolic Truth）和**经验真实**（Empirical Truth）。这是哲学家金观涛的体系。数学、逻辑推理，属于符号真实；而物理世界、艺术创作、个人情感体验，属于经验真实。AI的问题在于，它试图用处理经验真实的方式（概率、模式匹配）来处理符号真实的问题（如2+2=4）。你用经验真实去推符号真实，那2+2就不可能永远等于4。

大川: 我想补充几个数学上的有关AI的限制。

第一个是**P不等于NP问题**。简单来说，验证一个复杂问题的答案（NP），比从头解决这个问题（P）要容易得多。AI现在能做的，是给你一个“可行”的答案，但验证这个答案是否正确，甚至找到它在哪一步错了，可能比你自己重算一遍还要花时间。这就限制了它在解决高精尖问题上的效率。

第二个是**哥德尔不完全性定理**。任何一个逻辑体系内部，都存在该体系自身无法证明也无法证伪的命题。应用到AI上，就是一个单一的AI模型无法自我否定。它如果说错了，你再怎么追问，它也会一直顺着自己的逻辑去辩解，而不会承认错误。所以，你就必须要有另一个独立的AI体系来做事实核查（fact check）。这就意味着AI这个产业模型，从一开始就鼓励竞争，很难形成垄断。

第三个是**信息不对称性**，我用麻将和围棋来比喻。围棋是信息完全对称的游戏，双方所有信息都摆在台面上。所以AlphaGo可以穷举推演，达到超越人类的水平。但麻将是信息不对称的，你不知道别人的牌。AI可以做出一个胜率很高的麻将选手，但它做不到百分之百赢。因为这里面有运气成分。现实世界中的很多问题，比如舆论传播，信息不对称性比麻将还要复杂几万倍，AI就更难判断了。

## 对AI未来的展望

Eason: 我自己是一个在读的计算机科学博士，不是做AI的，但跟AI接触很多。我的感受是，不管是政府还是公司，对于传统计算机科学方向的投入越来越少，资源都被投入到大模型去了。感觉大家做的东西越来越水了。我们有个笑话，说现在大家都是“魔法师”，把大模型当作一个魔法水晶球，遇到解决不了的问题，就去摸一摸，相信它一定能给答案。这导致很多更基础的研究得不到支持。

陆飞: 我之前做过一期节目里提到一本书叫《AI帝国》（Empire of AI），作者也说了跟你一模一样的事情。很多做基础研究的博士发现经费拿不到了，钱全部拿去训练大模型了。这会导致一个结果：大家对AI的期望破灭后，又会很长一段时间资本不愿意投这个领域了，反而是把你们这些做基础研究的人给害了。

Eason: 我认为大模型本身这条路，它的能力天花板很明显已经到了。

小杜: 那AI更理想的应用模式是什么？

陆飞: 就像我们之前节目里专家讲的，要把不同的技术流派结合起来。不能只靠深度学习这一条路，也要结合传统的符号逻辑、专家系统。

小杜: 我认为不是问大语言模型的下一步，而是应该问算力的下一步往哪走。算力的第一代是挖比特币，第二代是训练大语言模型，那算力的第三代会是什么？现在很明显是一个算力的时代。

Roney: 我是做芯片这一行的。现在的感觉好像是AI这边的需求，并没有对硬件提出更多的挑战。另外，我觉得人的大脑和AI本质上区别没那么大。我们对一个概念的认知，也是通过感官建立各种联系。如果AI也能收集到触觉、味觉等所有数据，它应该也能建立起同样的联系。

陆飞: 这个我不是很认同。人脑能够抽象出规则，在内部形成逻辑模型。而现在的大语言模型，它没有这个能力。你让它下象棋，它还是会走出一些违反规则的步法，说明它内部并没有真正理解“象棋”这个模型。它只是一个高级的模式匹配器。

好的，我们今天直播就到这里了，非常感谢大家的观看和参与。