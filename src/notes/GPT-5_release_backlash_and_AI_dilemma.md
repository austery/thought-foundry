---
title: 深聊GPT-5发布：过度营销的反噬与AI技术突破的困局
summary: 探讨GPT-5发布的争议、技术方案与商业应用。分析其因过度营销和技术未达预期引发的失望，讨论Scaling Law瓶颈，并展望强化学习、多模态等未来AI突破方向。
area: null
category: null
project: []
tags:
- scaling-law
- 多模态
- 视频文稿
people: []
companies_orgs:
- openai
products_models:
- gpt-5
media_books: []
date: 2025-08-11
author: Lei
speaker: 陈茜
channel: ''
draft: true
file_name: GPT-5_release_backlash_and_AI_dilemma.md
guest: Bill Zhu
insight: ''
layout: post.njk
series: ''
source: ''
---
陈茜: 大家好，欢迎来到硅谷101，我是陈茜。

陈茜: GPT-5的发布在硅谷引发了不小的舆论争议。我身边大多数AI从业者和技术人员，本来都非常期待又一个**ChatGPT Moment**的出现，但看完发布会，基本上都一个表情：“就这？！”

陈茜: 除了诸多错误漏洞的发布会，包括错误的数据图、有bug的代码演示，还有翻车的科学原理解释等等，真正让大家失望的点在于，以目前的路径发展AI，大模型能力突破显著放缓，而GPT-5更是印证了这一点。然而，有一说一，虽然GPT-5的发布，是一次失败的技术突破，但不可否认的是，ChatGPT正在变成一款越来越好的产品，也正在打入更多的垂类领域，朝着一款“全能”AI **Superapp**（超级APP）进发。而一场抢占市场份额、争夺企业订单的价格战，也在头部大模型公司之间正式开打。

陈茜: 所以这一期视频，我们来从这几个方向入手，聊聊GPT-5的这场发布。第一我们会聊到 OpenAI发布了什么功能，出了什么错，为什么引发外界这么多的吐槽和失望。第二我们会聊到 ChatGPT作为AI产品，将会如何继续占领用户的心智，为什么编程、教育和健康医疗，是它要进攻的市场？第三 GPT-5开发的过程是怎么样的，中途遇到了什么技术瓶颈，最后选择了什么架构来攻克这些难点的？最后我们会聊， 当**Scaling Law**已经碰壁，后面的技术提升要靠什么技术来完成？框架的创新还是算法的创新？**强化学习**、**多模态**能力以及**世界模型**，又能如何让我们走出目前的大语言模型技术限制呢？

## 发布会的失望：功能、错误与争议

陈茜: 那我们先来讲讲这场drama（戏剧性）的发布会。说实话，外界对GPT-5的发布非常期待。原因很简单，GPT-4发布已经是两年半之前的事情了，而外界已经等新一代模型已经很久了。

陈茜: 但总结来说，GPT-3到GPT-4的能力跨越太过惊艳，所谓的“ChatGPT Moment”（ChatGPT时刻），这样的“Wow moment”（惊艳时刻），是这一轮生成式AI技术革命的基础。但GPT-4到GPT-5的能力跨越，却远没有达到外界的期待。

技术专家: 你要横向对比，就是GPT-4和当年GPT-3的对比，这个的是天和地的区别 对吧？那GPT-4跟GPT-5，如果你是以同样的标准来做对比的话，其实差距是没有那么大的。就是它可能是一个在我看来，是个refinement（改进），而不是一个step change（阶段性的变化）。

陈茜: 那GPT-5发布了个啥呢？首先，此前新闻爆料，GPT-5会成为一个“统一大模型”（unifying system），能强大地将推理、编码、语音、研究等能力，整合进单一模型，实现“既要”和“又要”的用户需求。将GPT系列和o系列的模型融合，这个单一模态架构，能自动调取相应的模型和能力，而不需要用户之后自己选择模型了。

陈茜: 虽然OpenAI目前还没有正式发布详细的GPT-5技术报告，但业内的技术专家们猜测，这其实不是一个端到端的超级大模型，而是由一个实时的“**路由器**”（Real-time Model Router）来“拼接”下面的不同子模型。其实这个技术路线，不是创新也不是突破，早在硅谷初创技术圈里就存在很久了。

技术专家: GPT-5就是一个典型的联合的系统。它是把已有的GPT-4、o3等等，Thinking和非thinking，推理和非推理的模型，给它串联到一起。我觉得它可能是因为商业化比较着急吧，我觉得更应该把它叫做GPT-4.99，因为它是在所有的历史上的一个聚合的方案。然后这个Router（路由器），其实并不是一个很新的东西。

陈茜: 这样路由器的方案，主要是一些初创公司在使用，大概有三个使用场景和原因。第一是在手机这样的设备端上，有端上的小模型，也有云端的大模型，简单的问题用本地模型，复杂的问题用云端模型，就需要有个路由器去帮你做选择。第二是初创公司们，做模型层之上的开发和应用的时候，把所有开源和闭源模型聚合起来，把不同的任务给不同的模型来调用。第三个原因是要去平衡系统的成本。比如说用户的一些高频又简单的提问，像“hello”和“thank you”，这种query（查询）量非常大，光是这种简单的问题，每天都在消耗OpenAI上百万美元的费用。所以这些典型问题，都可以直接分发给非常小的模型去解决。

陈茜: 所以，这些是之前初创企业们，因为要平衡系统成本，开发和应用时的主要三大使用场景。但如今被GPT-5作为主打技术突破，让外界不少人怀疑，一个端到端训练的超级大模型路线已经触顶，而OpenAI不得不开始用这些“取巧”的技术，来解决“产品层面”的问题，而不是AI大模型“智能飞跃”的问题。这是和外界的期待非常相悖的。

陈茜: 当然，**Real-time Model Router**（实时路由器）也没有那么好做，包括整合各种多模态也有很多技术上的挑战，也可能是发布延迟的原因之一。

技术专家: 有的模型擅长于数学，有的模型擅长于写作，有的模型擅长于编码。所以你要根据用户的意图、语言类型，各种各样的地域位置，包括它的语言偏好去分发模型。这其实是一个非常复杂的问题。因为不同的模态会有非常不同的计算需求，以及许多不同的推理需求。例如，如果是语音模块，对吧，它就会需要非常低的延时。因为如果延时太大，你和AI进行对话时就会变得很尴尬。而其他模块，比如深度推理或研究，可能会有两三分钟的延时，甚至更长，有时候我觉得都有30分钟。所以把所有这些模态整合在一起，还要确保产品不卡顿，这是一个相当大的技术挑战。

陈茜: 抛开这不是一个多么酷炫的技术不谈，说实话，单从用户角度来看，我本来觉得这点改进还挺好的。因为之前你在用ChatGPT的时候确实就像个大杂烩，有4o、o3、o4-mini、o4-mini-high, GPT-4.5, GPT-4.1, GPT-4.1-mini，旁边还有Codex、视频模型Sora，以及agent生态的GPTs，简直就是太乱了。所以如果GPT-5能自动为我挑选最适合的模型，其实在用户交互上是挺重要的。但这里的关键词是，你得能选对，且效果得比之前好。

陈茜: 然而，当OpenAI取消此前自选模式，在社交媒体上用户们却开始集体抗议。很多人认为GPT-5没有4o的亲切感，效果甚至不如4o，并且用户有种被剥夺了选择权的感受。所以在X上，非常多用户集体呼吁让4o回来，不然就注销ChatGPT账号。这也让OpenAI CEO Sam Altman，不得不在周末之前回应，保证将上线更多定制化的功能和内容，并持续对GPT-5进行改进。

陈茜: OpenAI在这次发布会中，一直在强调要给用户的，不是“more information（更多信息）”，“越多的的信息不一定是越好的”，而是要给“just right”的信息，“刚刚好的、适合”的信息。这个出发点看起来没有什么问题，但在技术上，怎么去定义“just right”，什么是“刚刚好”，这个还蛮有争议的。关于GPT-5的优化，我们也会继续关注。

## ChatGPT的产品化野心：进攻教育、医疗与编程市场

陈茜: 接下来，我们再聊聊这次发布会上，OpenAI展示的三个应用场景：教育、编程以及健康医疗。毫无疑问，这将是OpenAI进军商业化的主要三个战场。

陈茜: 在发布会上，OpenAI展示了用多模态学习韩语的场景，效果确实看上去挺丝滑的。语音模型进一步升级，可以实时加快放慢，感觉会是非常好的教育交互场景。GPT-5的玩法更加升级，你还可以让ChatGPT直接给你做个学法语的网页，或者小游戏应用。几分钟时间，记忆闪卡、单词测验、进度追踪等等功能，应有尽有。所以我们看到语言学习公司多邻国公司股价，在GPT-5发布会期间就开始大幅度震荡。本来因为财报非常好出现盘中大涨，但OpenAI发布会之后开始一路狂跌。也是市场在质疑，ChatGPT在之后会抢夺多少教育市场的份额。

技术专家: 我认为教育是OpenAI非常明确的一个垂直领域。ChatGPT刚推出时，基本上把Chegg给“干掉”了。对吧？Chegg是一家教育公司，学生主要用它从同伴那里抄作业。ChatGPT推出后，学生们就觉得，我们好像不再需要Chegg了。如果你看OpenAI模型在2023年初的早期用户，你会发现很多都是学生。而且在暑假期间，OpenAI的使用量会大幅下降。OpenAI最近推出了“学习”功能，我觉得这个功能更多是针对那些想随便学学或者是探索某个主题的人。就语言学习而言，我一直在用ChatGPT练习我的粤语，我感觉它效果非常好。我以前是用Duolingo，但我觉得OpenAI 比Duolingo自由度高得多，因为你可以用OpenAI探索任何话题。我认为OpenAI肯定会去切入这些（语言学习）公司的营收领域，因为在ChatGPT的原生环境下，复刻它们的模式实在太容易了。

陈茜: 另外 OpenAI强调的市场蛋糕，还有健康医疗领域。因为GPT-5号称有着PhD博士级别的能力，所以在医疗健康领域，也能够对专业的癌症诊断报告，做通俗易懂的解读。在发布会中，OpenAI请到一名女性癌症患者和她的家人，她分享到说，去年被诊断出癌症病情，收到的报告有许多医学术语，她让ChatGPT先帮助她厘清资讯，并与医生的评估进行比对，再做出关键决策。而她也形容说，GPT-5更快速、更完整，在整个治疗过程中，让她觉得有了一个“伙伴”。

陈茜: 其实这一点我也感触蛮深的。医疗领域其实是一个医生和患者知识差距巨大的行业。因为这样的知识差距，导致了两者关系的不平衡，患者通常没有选择。我最近身边有个好朋友进了重症监护室，陷入昏迷整整五天。她家人刚开始除了每天去医院求医生，感觉什么都做不了。但他们很快用上了AI，开始对病情和治疗方案各种学习和讨论，之后感觉和医生交流的时候障碍变小了很多，在做出一些关键决策的时候也心里更有底了。我觉得这就是技术的光明面，能赋能人们的自主权。而健康医疗行业占据美国GDP的18%左右，是巨大的市场，OpenAI不会放过这个市场。

陈茜: 同时，我们看到全球AI医疗市场也在井喷式发展。市场预测，全球AI医疗领域规模会从2024年的26.69亿美元，飙升至2030年的188.38亿美元，年复合增长率高达38.62%。包括OpenAI参与投资的，专注于利用AI减轻医疗专业人员行政负担的初创公司Ambience Healthcare，最近C轮融资2.43亿美元，迈进独角兽行列。所以我们接下来会看到OpenAI在医疗健康领域的进一步动作。

陈茜: 另外一个GPT-5要打的核心商业战争，就是编程市场了。无论是低提示词的非专业用户场景，还是专业编程场景，GPT-5都展现出代码能力的强势升级。同时，OpenAI还请到了最炙手可热的AI编程初创公司Cursor CEO到现场，分享如何用GPT-5打造出最高效的编程体验。这里能看出，自从Anthropic开启了Claude Code产品之后，AI coding初创公司就开始纷纷站队了。之前OpenAI本来想买Windsurf没买成，我们之前也出了视频跟大家讲了这个狗血的收购大瓜。现在Cursor明显站队OpenAI一起来打Claude，这是一轮新的**coding**（编程）市场争夺战。

技术专家: 它（Anthropic）其实做了很多很多事情，它在开发者社区的影响力，我觉得会大于GPT-5。GPT-5可能大家会做应用，各种东西，**PoC**（Proof of Concept, 概念验证），快速起步。但是一些专业的开发者可能还是比较喜欢Anthropic。所以它一定是各有所长。

陈茜: 但就算是OpenAI主打及自夸“世界最强”的编程场景，其实也让很多人失望。

技术专家: 我可能本来的预期可能在于，它单一模型可以把，比如说在代码领域它可以直接端到端，从架构到写每一个前端、后端代码，到它知道选择什么工具，到我怎么把这些东西都串联起来，然后自行测试。完成测试以后，可能回过头来再去改自己的代码。类似于有这样的一个端到端的能力，就从OpenAI的定义上面，超越它的（第三阶段）的那个定义，就是**agentic experience**（智能体体验）那个定义，再往上走一点的那种感觉。但目前看起来没有，就完全没有。总体来说是一个跟，在我看来，是跟Anthropic的Claude Opus差不多的能力范围。

## GPT-5的曲折研发路：技术瓶颈与架构选择

陈茜: 同时，这场发布会不得不吐槽的就是现场出的各种bug了，让这场万众期待的发布会显得特别“草台班子”。这个时候，OpenAI得感谢自己还没有上市。如果是谷歌的发布会出现这么多错误，可以想像股价早就蒸发上千亿美元了吧。

陈茜: 首先在发布会直播中，一张展示GPT-5在编程基准测试（SWE-bench）上性能的图表出现了严重错误。图上代表GPT-5（52.8%准确率）的柱状图，其高度竟明显超过了代表旧模型o3（69.1%准确率）的柱状图。另一款模型4o的柱状图，与o3的水平位置一模一样，标注的数字却是30.8%。这个错误低级到不敢让人相信是OpenAI的发布会。尽管OpenAI事后在官网上修正了图，Sam Altman也发文自嘲了，但这个图的火爆和出圈程度，直接秒杀Sam Altman之前铺垫的任何营销努力。而更严重的是，这显示出的不仅仅是匆忙和粗心，更是OpenAI团队试图在数据呈现上，营造出的“巨大进步”的假象。

陈茜: 同时 Benchmark“分数打榜”这件事情，其实也正变得更越来越不重要。

技术专家: 前两天（OpenAI）刚发布的 **open-source model**（开源模型），它在**Benchmark**（基准测试）上面的表现也还可以，但是它真正使用起来，它的代码能力其实挺拉胯的。它出现了很多的bug，然后很多代码都跑不通。

技术专家: 基准测试“已死”，但新形态的“基准测试”又会死灰复燃。所有这些实验室，都非常注重在基准测试表现上的提升。他们会为了在某个特定基准上提升3%或5%，而相互竞争。而且很多研究人员，也以模型在这些基准上的表现为傲。但作为用户，我的感受是，基准测试对用户来说毫无意义。所以我认为，下一个竞争前沿会主要转向用户体验。我觉得现在，很难靠原始性能来区分模型的优劣。

陈茜: 另外还有一个尴尬的细节，在演示过程中，GPT-5在解释“伯努利效应”时，错误地采用被主流物理学教材已经证伪的“等时通过理论”。前一秒Sam Altman还在说，GPT-5是属于“博士级别”的AI，后一秒就直接自己打脸，还挺尴尬的。这显示出，GPT-5完全没能识别过时的错误解释理论，让外界对这个新模型的理解和推理能力，有了更多的质疑。不过有一说一，在解释这个理论时自动产出高质量SVG动画，与可交互代码还真的挺酷炫的。感觉对我们的视频后期之后会非常有用，也说明OpenAI的多模态生成能力，确实还是很强的。

技术专家: 我的总体感觉是感觉OpenAI在尝试去，在那么多个（模型）发布之后，想要能够在这个阶段上面可以站住脚跟，把自己这个领先地位给占住。所以它必须要去做这么一个发布。

陈茜: 我们大概总结了GPT-5发布的重点，总结一下，就是GPT-5解决的都是产品层面的问题，并没有技术颠覆性的创新。这说明接下来一线大模型的技术差距，也能会进一步缩小。大家都用着差不多的方式，在把模型能力艰难地往前推。不过就是，堆算力+堆数据+高质量数据筛选+后训练+推理时长+工具使用 这几个方面。因此，我也看到一句话说OpenAI从“The One”变成了“One”，从“引领者”变成了前沿模型“之一”。

陈茜: 那么我下一个问题是，为什么GPT-5会这么拉胯呢？是不是**LLM**的发展路径真的已经碰壁了呢？其实GPT-5的训练从很早就开始了，但非常有意思的是，没有一个模型在OpenAI从第一天就被命名为GPT-5的。

技术专家: 我们都清楚，OpenAI一直在训练下一代模型，但肯定只有在达到一个重要的里程碑后，他们才会给模型正式命名 对吧？GPT-5自2024年以来一直在训练，但只有到达一个重大节点之后，OpenAI才会将这个模型命名为GPT-5。

陈茜: OpenAI在推出GPT-4的时候，所谓的“下一代大模型”就已经在训练当中了。但如果这个模型不够好，不够“wow”到大家，那它就注定不能被叫做“GPT-5”。比如说，在2023年年底就被曝出，OpenAI内部代号为“Q Star”或者“Project Q”的项目，但这个模型后来被称为“o1”。

技术专家: OpenAI在另外一个叫Project Q的项目上投入了很多精力，很多人也叫它Q star。这个项目在2023年11月左右，也就是Sam Altman那场（董事会）风波期间被泄露了出来，最终成为了o1系列，也就是o系列。这个项目非常重视思维链推理，想要打造推理模型，这个就是所谓的Q项目。

陈茜: 其实“O”系列模型还算成功，后来又更新了o3和o4-mini，但依然不能被称为GPT-5。为什么呢？The Information在GPT-5发布之前，出了一篇非常重磅的文章，爆料了OpenAI内部的这几次关键的GPT-5研发挫败。其中在谈到o系列的时候说，这样的推理模型似乎帮助OpenAI克服了预训练阶段性能增长放缓的问题。而且2024年年底的o3母模型（也称为教师模型），在理解各种科学领域及其他领域方面，相比o1的母模型取得了显著的进步。当然这个进步也是因为OpenAI用上了更强的英伟达芯片服务器。但奇怪的事情发生了，当OpenAI将o3母模型，转换为能让人们提问的ChatGPT版本（也称为学生模型）时，效果出现了显著下降，甚至比o1表现好不了多少。同样的效果下降也出现在了API的模型版本中。业界有猜测是因为，基于人类自然语言的聊天产品形态，拉低了模型的能力水平，限制了AI的发挥。

技术专家: 那就可以理解说大模型像是一个，理解这种高维度复杂内容的这样一个模型。但是最终它要跟我们人类交流，或者是要把它转换成人类理解的文字的时候，它需要通过这样降维的方式。那就相当于一个高等的生物需要降维，才能跟我们人类进行交流。这样在这个降维这个过程中，其实它会损失很多这种高维度的这个信息。包括我们自己其实也有一些各式各样这种潜意识，或者是高维度的这样的一些思考，那最终的话，我们要个人表达的时候，其实是要通过语言来表达。但是语言其实并不一定，真正能够把我们大脑中的所思所想，全部都能够去很清晰地表达出来，或者甚至说有些东西是没有办法去表达的。所以从这一点上来看的话，那当你去需要这个模型，通过语言来跟人交流的时候，在一定程度上其实也拉低了，模型自身的一个智能的一个表现。

陈茜: 除此之外 在o3之后，OpenAI内部有一个代号为“Orion”的项目，在今年2月份推出，但也没有掀起什么水花。估计OpenAI对它的信心也不大，所以也没有把GPT-5的名字给它，而是叫了“GPT-4.5”。

技术专家: 我个人认为最大的挑战仍然在于预训练，因为早在去年年底，甚至更早的时候，**Scaling Law**就已经碰壁，因为我们正在耗尽高质量，且多样化的人类生成的数据。（缺乏）数据是OpenAI的Orion项目延迟的最大因素。有些人会称这个项目失败了，有些人则会说是延期。但本质上，在OpenAI训练Orion系列模型时，他们就已经遇到了缺乏高质量，多样化数据的问题。他们最终是用由OpenAI的o1模型生成的合成数据来训练Orion系列，但结果仍然没有达到人们的预期。我觉得OpenAI 4.5（也就是Orion模型）会没那么成功，是因为它真的没有带来让人眼前一亮的突破，就好比几乎没有人特别关注4.5版本。

陈茜: 同时 The Information的报道中说，2024年下半年，Orion没能成功的部分原因，在于其预训练阶段的局限性。同时 OpenAI还发现对Orion模型做的优化，在模型较小的时候有效，但当模型规模增大时，这些优化就不再有效了。就感觉，模型训练的不确定性仍然非常大，有很多的因素会导致模型训练的失败。之前在硅谷101的播客录制中，我们的嘉宾Bill Zhu也跟我们分享了训练模型中，会出现很多模型崩溃的情况，甚至可能会在强化学习过程中，出现所谓的“灾难性遗忘”。

Bill Zhu: 模型本身，你的训练是不可以无限制对它训练的。就是你训练到某一个程度它就会崩溃。其实在**RL**领域之前很经常看到，叫**catastrophic forgetting**（灾难性遗忘）。就是说在你训练很久很久以后，它开始忘记所有过往的就学习到的知识，然后整个模型像疯了一样，它所有的原来的policy（决策策略）都消失。这是为什么你一开始模型要变得足够大，其实就像海绵一样，然后你往里面不停地注水，然后你注水注到一定程度它满了，那你再往里面注水会发生什么？就是它会流出来一些，但流出来的不一定是注入的水，很有可能是原来已经有的水。那如果原来已经有的一部分水是很重要的水，就像你大脑里面不停地灌输知识，然后到最后你过载了，然后把加减乘除忘了，那是不是剩下的所有的知识体系就直接崩溃？这个问题本身叫，**model plasticity**（模型可塑性），就是说它的可塑性到了某种程度就直接崩溃了。然后你要怎么去解决这个问题？叫**Continual Learning**（持续学习）。现在可能你有一天会人类生成1TB的数据，那10天是10个TB。那未来可能生成数据还会越来越多，那你怎么能够用一个模型无限地去训练它，让它仍然能够对未来的知识进行获取？这是不可能的。

## Scaling Law碰壁后：AI的未来在何方？

陈茜: 这样看来，以**Transformer**架构为基础的LLM模型发展，如今确实可能到了一个关键的时刻。或者我们需要一个完全不同的新架构，来帮助我们突破技术的壁垒。那我们跟身边的技术大牛聊了一圈，总结了一下，接下来，前沿的大模型继续优化方式会有三种：第一是**强化学习**，第二押注**多模态**能力提升带来的突破，而第三 是寻找其它的框架范式。

### 方案一：强化学习与通用验证器

Bill Zhu: 我先讲讲以**RL**为核心的训练机制，为了解决什么问题。就是说很多的任务是以目标驱动的，比如说写代码、比如说数学、物理、就金融机构的一些东西，然后再比如说城市规划，你做operations（执行） research（研究），supply chain（供应链）这些东西，它都是有明确目标的，世界机制也很完整。如果a发生了会出现b。那在这种情况下，**Pre-training**（预训练）就变得不是很有必要。

Bill Zhu: 第一，你这种专业型的目标为驱动的这些场景，你可以想象大多数都是没有任何的数据的。数学跟代码是唯一的两个，可能有相对比较多的数据点的一些场景。除此以外，我刚刚说的剩下的那些点，基本上都没什么数据。你很难在互联网上得到大量的数据去完成这个训练。

Bill Zhu: 第二，本质上它要解决的问题，是非常泛化的。而市面上已经出现的数据大多数，都是非常聚焦在一些经常会发生的编程问题和代码问题和数学问题。而那些非常高深难测那些数学问题，它是从来没有出现过的。那它就必须要通过一个 **counter factual**（反事实）的形式，就是我要生成一些这市面上从来没有出现过的代码、数学、物理规划等等的这种输出，然后靠一个 **ground truth**（真实数据）的**validator**（验证器）来告诉我做得对不对，然后去**self-train**（自我训练）。那这种训练方式是非常适合于，这种有ground truth（真实数据）能够做出精确判断的这种用例，然后去进行优化的。这个时候RL的最闪光的时候了。

Bill Zhu: 其实有很多研究在网上都说过，就是说其实现在最大的问题是**verification**（验证）。我如果能够找到一个好的**verifier**（验证器），那我可以认为问题解决了，因为可以通过RL去完成对于这个验证器的优化就可以了。

陈茜: 那Bill说的这个**verification**（验证），是RL中非常重要的关键，也是The Information爆料中，GPT-5在RL上的杀手锏。报道说，OpenAI一直在开发一个被称为“**universal verifier**”（通用验证器）的技术，让一个大语言模型使用各种来源的研究，来检查和评分另一个模型的答案，可以自动执行确保模型在强化学习过程中生成高质量答案的过程。

技术专家: 这个方向是就像我们当年看到AlphaZero打败人类一样，它所能够走出的一些路子，是跟人类正常想象当中想象不到的一些路子。可以通过这个机制，甚至于可以发现新的物理定理。它可能可以真正去发现人类所不拥有的知识，这个可能是下一步，我觉得真正迈向超级智能的一个关键点。但是目前还没有什么很好的一个突破。

### 方案二：多模态与世界模型

陈茜: 而接下来，需要各大模型公司去探索的第二条路，就是多模态。就像前面我们说到的，大语言模型的维度是非常有限的。而多模态，以及世界模型将对接下来AI的发展至关重要。

技术专家: 还有一个变量，我们要注意多模态。因为多模态一旦引入了的话，它就有非常复杂的**workflow**（工作流）。比如说你要用浏览器，你要用数学，你要用使用代码，你要使用各种复杂的工具。然后包括多模态的使用。比如说，你看GAIA，Facebook提出来的**Multi-agent**（多智能体）框架，它其实是非常复杂的任务，人类去完成都可能要6-15分钟。那如果AI不断地把时间降到6分钟以下，我觉得这个也是在学术界，包括创业公司一直在追求的。比如说我们在金融领域，去做很复杂的自动交易这种策略，包括给网红们去做这种发帖，其实这里面有非常复杂的步骤。你怎么样把它的**boundary**（能力上限）能够提高，我觉得两个层面，一个是在应用这样的**multi-agent**（多智能体）系统，不断去推高这个需求。另外一个是在某些能力层面，大家不断地去在螺旋式上升。自己训更大的模型，当模型因为算力和能源限制的时候，它就会去做**multi-model**（多模型）的组合。所以上面是**multi-agent**（多智能体），下面是**multi-model**（多模型）。我觉得这个是接下来，我比较看好的两到三年的一个发展路线图。

技术专家: 对于大方向的突破，我感觉应该肯定会发力在**Multi-modality**（多模态）上面，特别是在视频跟**world model**（世界模型）上面。人类的语言本身是一个非常大的压缩，它的信息搭载量和视频的信息是一个数量级的差异。这件事情我是同意Yann LeCun的说法，就是人类从视觉和听觉以及触觉各方面的这种多维度的信息吸收，整个数量级，是要比纯文字要高出大几个数量级的。

技术专家: 那文字训练的一个假设，就是说我如果能够通过一些简单的规则，就是比如说**reinforcement**（强化学习）、**fine tuning**（微调），或者**reward model**（奖励模型），都是说我通过一个简单规则，或者一个简单的判断方式，或者训练出来，或者写出来的判断方式，能够去判断一个模型的好坏，那它就能够告诉你说，我怎么去提升这个模型？它就相当于一个文字领域的世界模型。对吧？这个比较好理解。那比较复杂的点是，当你出现了多模态视频，可以**navigate environment**（导航环境）之后，它的这个评估的难度就会高很多。从纯像素的方式去做评估，这个是目前机器人领域肯定没有解决的问题。如果世界模型能有大幅度提升的话，那我们有一个很大的机会能够去训练，比如说视频理解的模型、机器人的基础模型，然后再比如说游戏的基础模型。这些基础模型诞生再给到一个机会，让我们去后面再去做**post-training**（后训练）。它可以在整个多模态的世界里面，创造**text-based model**（基于文字的模型）的一个同样的可以复制一个成就。然而在那些领域当中，它所代表的市场份额，或者整个市场的空间，其实比纯文字的市场空间要更大。它可以把一个纯文字交流式的，非常**compressing information**（压缩信息）的这种系统拓展成一个，或者是线上的非常丰富那种信息，或者说视觉的一些部分，或者听觉的部分、触觉的部分，或者直接线下的机器人的东西，它们的能够部署的这个领域，有一个非常大的延展。所以我觉得我刚刚说的像世界模型这个方向，视觉的方向，这一定是下一步最重要发力的方向。

陈茜: 而多模态之战确实在最近变得非常激烈。谷歌最近发布世界模型Genie 3，这在一些业内人士看来，重要性是要超过GPT-5的。我们硅谷101也在操作这个选题了，很快会放出来。

### 方案三：超越Transformer的新架构

陈茜: 此外，Bill提到的图灵奖得主Yann LeCun，近年来提出的核心研究方向，叫做**Joint Embedding Predictive Architecture**，简称**JEPA**，翻译过来是“联合嵌入预测架构”，旨在克服大语言模型的局限，推动AI向理解物理世界。

技术专家: 那**JEPA**本身，其实它是也是把所有这样模型的这个训练，放到浅层空间中去完成。它在浅层空间的话，对于你的输入是有一个抽象的表达，然后对于你的输出也是一个抽象表达。那这样你就可以再把输入、输出都同时放到这样的一个维度空间中去进行一个训练。然后再给到它不同的State（状态的量），然后让它可以在浅层空间中去预测，我下一个动作应该是怎么样的？或者我下一个应该预测的是怎样的一个状态？那它在这个过程中，就不是一帧或者是一个一个像素去预测的，而是它是把你**mask**（遮挡）了的某一块，可以整体地给预测出来。那像JEPA本身的话，它其实也分它的图像的JEPA，就是I-JEPA 和V-JEPA，video(视频）JEPA。然后最新发表这个文章其实也表现出，诶，我在预测一个整个视频中的这个事物的变化的时候，也取得了非常好的表现。

技术专家: 所以说我个人其实也是比较看好，一些非Transformer的一些构架，是否在未来可以说，给到我们一个真正的智能，更加接近或者是模拟我们人脑思考的一个方式？所以说我觉得Transformer的局限性是存在的，但是我们也有其他一些替代方案的这些架构，也有不同的这个团队在进行探索。所以说我觉得大家可能也需要去关注一些，非Transformer方面的这些模型，究竟是怎么样去模拟人类的这个智能。

## 过度营销的反噬与未来展望

陈茜: 最后还想说的一点是，这次GPT-5的翻车与Sam Altman之前过于浮夸的营销分不开。在发布会之前，他在X上的各种预热还有用词，一会儿在他弟弟的播客上，感叹自己相对于AI毫无用处，一会儿又是在X上，晒出与GPT-5的聊天截图，各种“暗示”，但又保持神秘吊足了公众的胃口。同时把期待值拉得太高，结果发布会出来，大家都愣了。所以，这次发布会的失利，也是被视为“营销鬼才”的Sam Altman太过度营销的一次反噬。

陈茜: 总结一下，长期来看，到达**AGI**之前，我们可能还有很多工作要做，还有很多技术壁垒需要突破。而这些突破需要脚踏实地研发和创新。但很遗憾的是，在人类的技术进步，能在进一步被推进之际，OpenAI等大模型公司，却开始在商业化上变得非常激进，包括发布GPT-5之际，正式开始打价格战来圈地、圈市场份额。这让不少人担心，会不会这次的GPT-5发布，会意味着AI泡沫破灭的开始？AI大模型的进展是否会就此停止呢？

技术专家: 我个人也是比较期待，类似像JEPA这样的一些新的构架能够出现，有更多人能进行探索。而不是大家因为说Transformer现在可以给我们带来很多经济利益、经济价值，就只是停留在这样的一个阶段，然后一直所有人都押注，Scaling Law能够继续持续下去。但是从GPT-5的发布来讲的话，我觉得大家也可以更好地去清醒地认识到，Transformer本身的局限，然后可能也有更多人，可以去关注其他的一些替代方案，能够帮助整个AI或者人工智能，得到一个更深远的一个发展。

陈茜: 最后，虽然我们这个视频，说了OpenAI和GPT-5这么多“坏话”，我个人其实还是非常非常喜欢这款产品，以及我是一个忠实用户，基本上工作生活都离不开ChatGPT了。这场发布会让我看到了ChatGPT朝着一个更好的AI全能Superapp（超级应用）的迈进。很多功能，在我看来，都将会让我的生活和工作更加的高效。而看上去OpenAI还会继续优化GPT-5的各种性能，到时候我们也会为大家跟进AI发展的进一步分析。所以不要忘了关注我们的账号哦。

陈茜: 这就是本期的视频全部内容了。真是赶了整个周末的时间出的视频，非常辛苦团队。所以，你们的留言、转发和点赞是支持我们硅谷101做好深度科技和商业内容的最佳动力。那我们就下期视频再见啦！