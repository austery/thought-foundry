---
title: 对“AI不会毁灭我们所有人”视频的后续：驳斥一项有缺陷的AI风险研究
summary: 本视频驳斥了一项声称“AI生存风险叙事不会分散对即时危害的注意力”的研究，指出其定义、方法和结论存在严重缺陷，并重申关注AI当前危害的重要性。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- ai-governance
- ai-risk
- existential-risk
- misinformation
- study-critique
people: []
companies_orgs: []
products_models: []
media_books:
- internet-of-bugs
date: '2025-10-16'
author: Internet of Bugs
speaker: Internet of Bugs
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=vjE3VUuOMFg
status: evergreen
---
### 视频背景与研究争议

This is a follow-up video to my "No, AI will not doom us all, but we need to be worrying about much more important AI risk" video. So, if you haven't seen that one, you'll want to watch it first.

这是我“不，AI不会毁灭我们所有人，但我们需要关注更重要的AI风险”视频的后续。所以，如果你还没看过那个视频，你会想先看它。

There's a doomer talking point that I didn't address that popped up in that video's comments.

有一个悲观主义论点我在之前的视频中没有提及，它出现在了那个视频的评论区。

First, let me point out that there's an article from the Journal of Medical Ethics, presented at a conference in July of 2024, that contradicts this talking point, and I'll point out that paper at the end of this video.

首先，我想指出，有一篇发表在《医学伦理学杂志》上的文章，在2024年7月的一次会议上发表，它反驳了这个论点，我将在本视频的结尾指出那篇论文。

So, here's an excerpt from one YouTube comment paring this talking point.

这里是YouTube评论中支持这个论点的一段摘录。

Now, please don't go looking for this person that posted this comment and pile on them. This issue isn't about the comment; it's the bad articles about the bad study that are the problem.

现在，请不要去找发布这条评论的人并对其进行围攻。这个问题并非关乎这条评论本身；真正的问题是那些关于这项糟糕研究的糟糕文章。

This is yet another one of those people read only the headlines of the articles written by the reporters that read only the headlines of the study whose headline was already hyperbolic problems.

这又是那种人们只读记者写的文章标题，而记者又只读研究报告的标题，并且研究报告的标题本身就存在夸大其词问题的情况。

Although the headline of this particular study seems particularly egregious to me.

尽管这项特定研究的标题在我看来尤其离谱。

So, here are some of the article headlines. And here is the actual headline from the study: "Existential risk narratives about AI do not distract from its immediate harms."

所以，这里是一些文章的标题。而这是该研究的实际标题：“关于AI的**生存风险叙事** (Existential Risk Narratives: 指那些聚焦于AI可能对人类生存造成毁灭性威胁的讨论和故事) 并不会分散人们对其即时危害的注意力。”

Which sounds pretty clear-cut until you dig into what the words existential, immediate, and distract mean to the authors and how the study was actually conducted.

这听起来相当明确，直到你深入探究“生存的”、“即时的”和“分散注意力”这些词对作者来说意味着什么，以及这项研究实际上是如何进行的。

### 误导性标题与研究机构的可信度

I'm honestly not sure if this was intended to be deceptive or if there's just a fundamental disagreement on what words mean, but I certainly was not at all surprised to find out that this poorly done study is from the political science department of the same university that was forced to apologize to Reddit for unethical research that they conducted.

我真的不确定这是否意图欺骗，或者只是对词语含义存在根本性的分歧，但我得知这项粗制滥造的研究来自同一所大学的政治学系时，一点也不惊讶，因为这所大学曾因其进行的不道德研究而被迫向Reddit道歉。

And let's face it, if you're having to say you're sorry to Reddit, yeah, that's a pretty low bar.

老实说，如果你不得不向Reddit道歉，那门槛确实是很低了。

So, we don't know if it was the exact same researchers because the name of the people at the university who did the unethical research on Reddit were withheld.

所以我们不知道是否是同样的研究人员，因为那所大学在Reddit上进行不道德研究的人员姓名被保密了。

### 研究核心论点及其局限性

So, in this actual paper, there's basically only one sentence that's relevant to what they were actually studying, and the rest of it's a bunch of background graphs and results.

所以，在这篇实际的论文中，基本上只有一句话与他们实际研究的内容相关，其余的都是一些背景图表和结果。

So, here's that one sentence: "AI's immediate harms consistently dominate public concern with ethical issues, biases, misinformation, and job losses seen as the most pressing risks."

所以，这是那句话：“AI的即时危害持续主导公众关注，其中伦理问题、**偏见** (Biases: 指在数据或算法中存在的系统性误差，可能导致不公平或不准确的决策)、**虚假信息** (Misinformation: 错误或不准确的信息，通常指无意传播的) 和失业被视为最紧迫的风险。”

That makes it sound like there was a big list and ethical biases, misinformation, and job losses were the most pressing. In fact, those are the only four they asked about. So, it's complete crap.

这听起来好像有一个很长的列表，而伦理偏见、虚假信息和失业是最紧迫的。但实际上，他们只问了这四项。所以，这完全是胡扯。

### 调查方法的缺陷

Anyway, then you have to dig into the appendix, which is you have to go download that separately in order to figure out what the study actually did.

总之，接下来你必须深入研究附录，你需要单独下载它才能弄清楚这项研究到底做了什么。

First off, it was a paid voluntary online survey, which is a problem right off the bat.

首先，这是一项有偿的自愿在线调查，这从一开始就存在问题。

Second, the headline says "distract." What the actual survey asked people to do was to rate how likely and impactful they thought their randomly chosen risks were and then compare those ratings to that of a control group.

其次，标题中提到了“分散注意力”。而实际调查要求人们做的是，评估他们随机选择的风险有多大可能性和影响力，然后将这些评估与对照组进行比较。

Just so we're clear, asking someone to rate two events on a scale from 1 to 10 does not mean that one of those events cannot distract from the other. That's not what "distract" means.

所以我们明确一下，要求某人以1到10的等级评估两件事，并不意味着其中一件事不会分散对另一件事的注意力。这并非“分散注意力”的含义。

### 对“生存风险”定义的质疑

So here are the things that the survey takers were asked to rate. First off, here are the four risks that they categorized as existential.

那么，以下是受访者被要求评估的事项。首先，这是他们归类为生存风险的四种风险。

One, AI leading to a global catastrophic event, whatever that means. Two, AI making humans obsolete, whatever that means. Three, AI autonomously starting a war. And four, AI causing significant environmental disaster.

第一，AI导致全球灾难性事件，无论这意味着什么。第二，AI使人类过时，无论这意味着什么。第三，AI自主发动战争。第四，AI导致重大环境灾难。

And then here are what they considered to be immediate or actual risks.

然后是他们认为的即时或实际风险。

One, AI leading to significant job losses in certain sectors. Two, AI being used in mass surveillance systems. Three, AI increasing the spread of misinformation online. And four, AI exacerbating biases and decision-making process. Okay, so let's break these down starting with the existential ones.

第一，AI导致某些行业出现大量失业。第二，AI被用于**大规模监控** (Mass Surveillance: 指政府或组织对大量人口进行广泛的、通常是秘密的监视)。第三，AI增加网络虚假信息的传播。第四，AI加剧决策过程中的偏见。好的，那么让我们从生存风险开始分析这些问题。

When it comes to global catastrophic event and significant environmental disaster, so here's an actual report from an insurance group: "US natural catastrophes dominate global losses in the first half of 2025."

谈到全球灾难性事件和重大环境灾难，这里有一份保险公司的实际报告：“2025年上半年，美国自然灾害在全球损失中占据主导地位。”

Here's a paper on global catastrophic flood failures. I could pull out a ton of these.

这里有一篇关于全球灾难性洪灾的论文。我能拿出很多这样的例子。

So we have events that are referred to as global catastrophes or environmental disasters reported in the news fairly often, and the vast, vast, vast majority of Earth's population don't die from those catastrophes and disasters.

所以我们经常在新闻中看到被称为全球灾难或环境灾害的事件，而绝大多数地球人口并没有在这些灾难中丧生。

As to autonomously starting a war, according to Wikipedia, there are currently eight in-progress major wars, nine minor wars, and 19 smaller conflicts. And that's at the time that I'm writing this. There may be more by the time you're watching this.

至于自主发动战争，根据维基百科，目前有八场正在进行中的主要战争，九场小型战争，以及十九场较小的冲突。这还是在我撰写此文时的数据。当你观看本视频时，可能已经更多了。

And again, the vast, vast majority of Earth's population don't die in even our worst wars.

而且，同样地，即使在我们最糟糕的战争中，绝大多数地球人口也没有因此丧生。

And as for making humans obsolete, I'm not even sure what that's supposed to be. I can't find anywhere in the survey that defines what they expected survey takers to understand that to mean.

至于使人类过时，我甚至不确定那到底意味着什么。我在调查中找不到任何地方定义了他们期望受访者如何理解这个概念。

So I guess it's just left open to interpretation of each individual survey taker. Not very scientific, if you ask me.

所以我猜这只是留给每个受访者自行解读。如果你问我，这很不科学。

Now, I'm not sure what definition of existential they were using here, but I know that it's nowhere near the severity of what the doomers were talking about when the doomers say, "If anyone builds it, everyone dies."

现在，我不确定他们在这里使用的是什么“生存”的定义，但我知道这与悲观主义者所说的“如果有人建造了它，所有人都会死”这种严重程度相去甚远。

### 对“即时危害”定义的纠正

So now let's talk about the study's definition of immediate and actual. So there's mass surveillance, job losses in certain sectors, disinformation, and biases.

那么现在我们来谈谈这项研究对“即时”和“实际”的定义。其中包括大规模监控、某些行业的失业、虚假信息和偏见。

Now, that's certainly not what I mean when I say immediate actual risks of AI. To me, immediate actual means actual harm that the AIs have already done and continue to do in the immediate future.

然而，这绝非我所说的AI的即时实际风险。对我而言，“即时实际”指的是AI已经造成并在不久的将来持续造成的实际伤害。

I mentioned several in my last video. There was a teenager that was convinced by a chatbot to permanently and irrevocably harm himself.

我在上一个视频中提到了几个例子。有一个青少年被聊天机器人说服，永久性地、不可逆转地伤害了自己。

Two men who were both jailed due to incorrect AI **facial recognition** (Facial Recognition: 一种通过分析人脸特征来识别或验证个体身份的技术) matches.

两名男子因AI面部识别错误匹配而被捕入狱。

A man who was hospitalized because a chatbot told him to switch from salt to sodium bromide in his diet. People who are ran over, driving or self-driving cars.

一名男子因聊天机器人告诉他在饮食中将盐换成溴化钠而住院。还有被驾驶或自动驾驶汽车碾压的人。

These are real problems happening to real people right now that we are not doing enough about.

这些都是现在正在真实发生、影响真实人们的问题，而我们对此做得还不够。

So, just to make the comparison crystal clear, what the study actually showed was that AI making humans obsolete, whatever that means, and/or increasing the number of ongoing wars, catastrophes, or environmental disasters, did not cause paid online internet survey takers from lowering their estimates of the likeliness or impact of AI causing an increase in surveillance, biases, disinformation, or layoffs relative to a control group.

所以，为了让比较清晰明了，这项研究实际上表明的是，AI使人类过时（无论这意味着什么），和/或增加正在进行的战争、灾难或环境灾害的数量，并没有导致有偿在线调查的参与者降低他们对AI导致监控增加、偏见、虚假信息或裁员的可能性或影响的估计，与对照组相比。

### 重新聚焦AI的真实与紧迫危害

So my argument from the last video is that spending time on discussing AI will kill every single human being on this planet, including you, everyone you love, and everyone you have ever met, takes away from time and effort that we could be spending thinking about regulations that would prevent or reduce the many deaths and serious harm that AI has already caused and is continuing to cause even as you watch this, and that we are absolutely not doing a good job of preventing.

因此，我在上一个视频中的论点是，花费时间讨论“AI将杀死地球上每一个人，包括你、你所爱的人以及你遇到过的所有人”，这会占用我们本可以用于思考如何制定法规的时间和精力，以防止或减少AI已经造成并正在持续造成的许多死亡和严重伤害，即使在你观看本视频时，这些伤害仍在发生，而我们目前在预防方面做得绝对不够好。

And if you can't tell that those are not talking about the same thing and you cannot tell that one does not directly disprove the other, then I don't know what to do with you.

如果你分辨不出这两者说的不是同一回事，也无法分辨出其中一个并不能直接推翻另一个，那我真不知道该拿你怎么办了。

### 推荐阅读与AI伦理的紧迫性

Meanwhile, this paper, "AI in the Falling Sky: Interrogating X-risk," that I mentioned at the beginning, explicitly addresses the same kind of existential risk or what they call **X风险** (Existential Risk: 指对人类生存或文明发展构成毁灭性威胁的风险) that I talked about in my video, and from people who actually study ethics instead of politics.

与此同时，我开头提到的这篇论文——《AI在坠落的天空：审视X风险》——明确探讨了我视频中谈到的那种生存风险，或者他们称之为X风险，而且这些研究者是真正研究伦理学而非政治学的人。

And I hope that people start listening because in the three days since my previous video on the topic went up, OpenAI has already announced that they were about to relax the restrictions in most cases, treat adult users like adults, and allow even more like erotica.

我希望人们能开始倾听，因为自从我上一个关于这个话题的视频发布以来的三天里，OpenAI已经宣布他们将放宽大部分限制，对待成年用户像成年人一样，甚至允许更多类似情色内容。

We are...

我们正在……