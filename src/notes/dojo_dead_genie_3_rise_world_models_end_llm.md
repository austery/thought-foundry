---
title: Dojo已死，Genie 3当立：世界模型将终结大语言模型？
summary: 本文深入探讨了特斯拉突然终止Dojo项目的决策，分析了其从自研芯片向采用英伟达方案的战略转变。对话进一步延伸至当前大语言模型的局限性，并重点讨论了以Google
  Genie 3为代表的“世界模型”作为下一代AI架构的巨大潜力，尤其是在具身智能和机器人领域的应用前景。
area: null
category: null
project: []
tags:
- genie-3
- 世界模型
- 大语言模型
- 视频文稿
people: []
companies_orgs:
- 特斯拉
products_models:
- dojo
media_books: []
date: 2025-08-17
author: Lei
speaker: 主持人
channel: ''
draft: true
file_name: dojo_dead_genie_3_rise_world_models_end_llm.md
guest: 老修, 闲哥
insight: null
layout: post.njk
series: ''
source: ''
---
## 特斯拉Dojo项目终结：战略聚焦还是撤退？

主持人: 马斯克突然宣布把**Dojo**团队全部裁撤，这个项目直接关掉了，这是一个相当震撼的新闻。老修，作为特斯拉的股东，你要不要出来讲两句？这是战略聚焦还是战略撤退？

老修: 我都听说有人要告他了。因为他在7月份的第二季度财报会议上，还特意强调**Dojo**有多重要，结果转眼间整个团队都解散了，很多人都走了。

闲哥: 是的，我第一感觉也以为是假新闻。毕竟之前的投入可能都快百亿美金了，这是一个很高的投入。他自己说，是相当于跑到了一个进化的死胡同里面去了。

老修: 其实应该是他的整个战略上发生了重大改变。以前**Dojo**的思路是“一锅端”，从头到尾全部自研，特斯拉做最后的大脑。那现在，这里应该发生了一个深刻的变化，就是大脑可能要转一转，变成大脑跟端侧分开处理的模式。尤其是从他整个商业帝国来看，**xAI**那边不是购买了大量的英伟达的卡嘛，所以这些卡应该都是能用起来的。

主持人: 对，还有英伟达的投资。你看，我昨天跟老邱（老修）还在讲，训练跟推理，一开始从产品模型端分离，现在从硬件端也分离了。最后在特斯拉这里，你看到了一个答案，就是直接把原本的**Dojo**超算给解散掉了。我在想，闲哥，有没有这样一种可能？是不是马斯克已经有了**xAI**，融了那么多钱，投了那么多在训练芯片上，他回头一想，自己搞这个**Dojo**好几年了，还不如直接让**xAI**来帮我训练这个大脑就好了。会不会有这么一个算账的逻辑在里面？

闲哥: 我感觉真不是。用一个特别形象的比喻，就是“中年男人不小心丢了一个肾”，得有多疼。这个项目，我查的数据可能没有上百亿，但也有数十亿了。而且之前的投行估值，光**Dojo**就可以估到5000亿，说未来可以支撑起非常高的价值。从2018年筹备，2021年正式启动，每一季度的财报里都把**Dojo**说成是重要的核心投入。花了这么多钱，寄予了这么高的厚望，结果突然一下全砍了，而且是在二季度财报里还在说它多重要的一个月后。这就是丢了个肾的概念，虽然少了一个肾还能正常工作，但你永远会觉得自己少了个肾。这对他长期的人设是一个巨大的损失。

## 训练与推理的分离：从硬件到架构的转变

老修: 也不一定是打水漂那么悲观，甚至都不能叫及时止损，我觉得应该是花钱买的教训。因为整个行业技术变得太快了，快到有时候觉得马斯克也不一定跟得上。他的意识可能跟得上，但是组织的惯性或者能力不一定跟得上。英伟达的进步速度跟**Dojo**的进步速度完全是两条不一样的曲线，完全不可同日而语。英伟达的芯片迭代速度太快了，特斯拉自己做硬件实在是跟不上。

闲哥: 我了解到的信息是，**Dojo**跟英伟达应该有4倍的性能代差。如果是4倍的代差，我肯定也是租用而不是自建了。

老修: 对，而且现在这个节点做这个决断，虽然出乎意料，但也情理之中，这又跟他“该断则断”的人设对上了。以特斯拉以前积累的数据而言，它的预训练模型其实已经做得很不错了。现在的问题就是，你怎么样能够在端侧，也就是所谓的边缘计算，在那些正在路上跑的汽车，包括未来的机器人身上，去真正地跟真实世界收集数据，然后再把反馈给到预训练那边去形成闭环。把预训练跟端侧直接分开，现在其实是一个很好的节点。

闲哥: 以前可能是幼儿园阶段全托，大脑跟四肢都在幼儿园里练。但现在不一样了，现在可能是大脑要出去上奥数班，而四肢要去上专门的体育课、搏击课。

老修: 对，我更觉得他这是个理性的决定。因为你看到现在这一代的**FSD**，可以证明他的大脑已经可以了，这套端到端的技术路线也是成立的。现在可能更多地要放在对真实世界感知的这一部分数据上，也就是边缘推理。就像把人扔到水里才能学会游泳一样。

闲哥: 不开玩笑地讲，我觉得端侧的数据，包括他现在数百万辆特斯拉在路上跑来跑去收集的这些数据，从端侧进行训练，比强化大脑训练的效率更高。而且大脑训练他在做**Dojo**的时候是在做芯片研发，这个领域的代差太大了，真的是造不如买。

## 大语言模型的瓶颈与世界模型的兴起

老修: 其实，我们最近一直在聊推理，现在很明确一个节点，就是推理跟预训练好像已经实现了分离。老马有**xAI**那么大的集群在做预训练，**Dojo**的优势可能还没有**xAI**强，那为什么还要自己去做一个封闭的集群呢？没必要。而且在他这个版图里面，**xAI**其实就是马斯克商业帝国的大脑，专门负责练脑。而特斯拉则专注于“练身体”，发展户外能力。

主持人: 从技术上讲，最近有很多地方可以提炼出一个观点，就是**大语言模型**现在遇到了瓶颈。比如GPT-5的发布，并没有像3.5到4那样带来飞跃级的提升。现在大家的能力已经基本都够用了，真正要胜出，是后面要能够去真实世界里找到更多适合你大脑的数据。而这些数据，得用大脑驱动的**Agent**（智能体）去真实世界里跑去收集。大脑的抽象和总结能力，是最适合现在**大语言模型**的，但把它放到手脚（**Agent**）上去，就有很多问题。

闲哥: 我最近看到世界机器人大会上，王兴有一个观点，他觉得具身智能或者人形机器人，现阶段硬件已经完全够用，数据也不是最大的问题，最大的问题是在机器人端的模型上面。你预训练做的那些数据，对端侧的模型没有任何作用。你训练得再多，它也用不上，因为它对数据的理解和模型架构，跟现在的**大语言模型**完全不一样。所以他的观点，也能佐证今天马斯克做的这个决定。

老修: 这和阿里云的创始人王坚在世界人工智能大会上讲的是能对上的。机器人实际上是一个多学科交叉的东西，它的手、脚、平衡、规划，都是由不同的模型来做的，根本不是一个**大语言模型**能搞定的。它需要去跟物理世界采集数据，根本不是现在**大语言模型**能搞定的事情。

## Genie 3：通向虚拟世界与具身智能的桥梁？

主持人: 我最近在想一个问题，上周谷歌发布了**Genie 3**，所谓的**世界模型**。像**Genie 3**这样一种新的**世界模型**架构，对于特斯拉或者具身智能来讲，是不是一个潜在的架构上的突破？

老修: 我觉得有关联，但不是强关联。最终大家都会走到**世界模型**和现有模型（无论是端侧模型还是**大语言模型**）互补的关系，而不是谁替代谁。**Genie 3**的表现有点像打游戏，你可以在一个世界里逐帧地、自由地移动和观察，而且有惊人的一致性。你在墙上做的涂鸦，出去看一会风景再回来，涂鸦也还在。而且它做了大量的无监督学习，通过看别的视频就能自学成才。这一代已经完全是数据驱动，自己去学习了，比较像**AlphaGo**和**AlphaZero**的关系。

闲哥: 我在节目里一直在说，我个人坚信**世界模型**在未来6到12个月，将成为超越**大语言模型**的下一个爆点。我始终觉得语言模型只是AI模型的一部分。**大语言模型**无论在ToC还是ToB的应用都会见顶，而且这个顶可能很快就到。但是**世界模型**刚刚方兴未艾。就像李飞飞说的，“世界是三维的”。光靠语言去学习，是无法跟我们所身处的真实物理世界做共情的。而机器人，是需要在真实的物理世界中存在的。

主持人: 你像**Genie 3**这种**世界模型**，它还是基于数据驱动的。但我们原本做的一些像仿真、数字孪生，是基于物理定律去做的。数据驱动的肯定更容易规模化（scale），但物理驱动的可能成本更高、更精确。你真的让**Genie 3**用在工业领域，我觉得严谨性肯定跟原本那种物理定律模拟的有非常大的差别。

老修: 这里要补充一个很重要的角度，大家可能忘了英伟达。他一直在做物理的**世界模型**。就在昨天，英伟达发布了一个叫Cosmo的模型，就是面向机器人做的，提供了一整套基础设施、工具和平台，专门解决物理AI应用的机器人设计。他已经和亚马逊合作，在工业环境中训练高精度的机器人动作了。他们强调用“模拟优先”的方式，依托强大的工具和算力，做审计级别的数字孪生，让机器人在虚拟工厂里先训练，再去实际的工业环境里干活。

## 算力之争：新架构对芯片产业的影响

主持人: 很多网友都在问，这件事到底会不会利好台积电？今天我们聊的话题，确实是一个超大算力驱动的事情。

闲哥: 我觉得短期内一定是利好。但长期来讲，没有任何一个行业能形成绝对的垄断。以前全球有一个台积电、一个英伟达就够了。现在有这么大的算力需求，无论是**大语言模型**还是**世界模型**，都需要巨大算力，那凭什么只有一个台积电，只有一个英伟达呢？所以短期内利好，但长期能否持续垄断，我持怀疑态度。

老修: 这个市场大了以后，应该是会更多样化。如果真的做到了我们刚才讲的**世界模型**的程度，那应该会更需要像台积电这样基础的芯片需求。这里就不得不提OpenAI，它最近的做法很像AI界的苹果，开始“卡内存”了。它现在开始卡你的上下文长度，Plus会员的上下文窗口变成了原来的四分之一，免费版更惨，只有8K。你要想聊得爽，就得交钱。所以如果OpenAI以后一直这么搞，把上下文卖得越来越贵，那到最后还是利好了一众做硬件的厂商。

主持人: 我觉得现在越来越明显地看到，训练和推理在分化。训练的芯片和推理的芯片，训练的架构和推理的架构，完全不同了。像特斯拉就是一个很好的例子，他把预训练这一块交给了英伟达的体系。但像苹果、谷歌、特斯拉自己也都在做推理端的自研芯片。所以对于台积电这样的客户来讲，可能只是把钱从预训练挪到了推理，客户从训练的几家大厂，变成了更多做推理的客户，市场变得更大了。

## 结语

主持人: 好的，那我们这一期就快速地碰头到这里结束。我们最近也是换了一种形式，以碰头会的形式来跟大家聊一些最近关心的话题。如果你有感兴趣的话题，也直接在评论区留言给我们。

闲哥: 是的，关于**世界模型**这件事我还是没聊尽兴，希望有机会咱们再有什么新闻，可以再继续聊。

老修: 希望网友多给你提点问题，问题驱动最带劲。

主持人: 好，那我们这期节目到这里结束，谢谢大家的收听。

嘉宾: 感谢大家收听，期待大家的问题，拜拜。