---
title: AI末日论的谬误：我们面临的真正AI风险与问责制
summary: 本文驳斥了AI末日论，认为其分散了对AI当前造成的真实危害的注意力。作者强调AI的电力依赖是其弱点，并批判行业将AI拟人化以逃避责任。呼吁关注AI引发的虚假信息、错误判决等即时风险，并通过追究个人和公司的法律责任来解决问题。
area: tech-insights
category: technology
project:
- ai-impact-analysis
tags:
- ai-accountability
- ai-doomerism
- ai-safety
- internet-of-bugs
- misinformation
- technological-risk
people: []
companies_orgs: []
products_models: []
media_books: []
date: '2025-10-13'
author: Internet of Bugs
speaker: Internet of Bugs
draft: true
guest: ''
insight: ''
layout: post.njk
series: ''
source: https://www.youtube.com/watch?v=MaFTqjYjADw
status: evergreen
---
### 引言：AI末日论与真实问题

After my last video about how "The Machine formerly known as **Weaponized AdTech** (Weaponized AdTech: 指通过广告技术进行攻击性或操纵性行为)" had already taken over society and how AI was making it worse, I had several people reach out to me and want me to talk about **AI Doomerism** (AI Doomerism: 认为人工智能对人类构成生存威胁的观点).
在我上一期关于“以前被称为‘武器化广告技术’的机器”如何接管社会以及AI如何使其变得更糟的视频之后，有几个人联系我，希望我谈谈AI末日论。

I made a video a year ago called "AI Safety is a Scam", and I stand by that video, but the narrative in the industry and especially the online conversation has changed.
一年前我做了一个名为《AI安全是个骗局》的视频，我仍然坚持该视频的观点，但行业内，尤其是网络上的讨论叙事已经改变了。

This book is the most recent catalyst for that change. It's called "If Anyone Builds it Everyone Dies."
这本书是导致这一变化的最新催化剂，名为《如果有人建造它，所有人都会死亡》。

I don't have a paper copy of it because I only collect physical books that I think I might reread in the future, and I didn't find enough value in this one to expect to revisit it.
我没有这本书的纸质版，因为我只收藏那些我认为将来可能会重读的实体书，而这本书我没有发现足够的价值值得我重读。

I'll talk about it more in a few minutes, as is normal with me.
像往常一样，我会在几分钟内详细谈论它。

I firmly disagree with both extreme arguments, and I think that the truth lies somewhere in between the "AI Will Kill Us All" crowd and the "AI will save humanity from itself" crowd.
我坚决反对这两种极端观点，我认为真相介于“AI将毁灭我们所有人”派和“AI将拯救人类免于自我毁灭”派之间。

So I expect the diehards from both camps will hate this.
因此，我预计这两个阵营的顽固分子都会讨厌我的观点。

But I think it's an important topic and people need to be discussing it, not the hyperbole but the immediate risks.
但我认为这是一个重要的话题，人们需要讨论它，不是夸大其词，而是讨论迫在眉睫的风险。

Because although, for reasons I'll explain shortly, I think the idea of AI making all humans go extinct in the next few decades is ridiculous, I also think that if we leave it unregulated, we still might be in serious trouble.
因为尽管出于我稍后会解释的原因，我认为AI在未来几十年内导致全人类灭绝的想法是荒谬的，但我也认为，如果我们不加以监管，我们仍然可能面临严重问题。

I've been a software professional since the dawn of the world wide web, and I'm here trying to make the Internet a safer and more reliable place.
自万维网诞生以来，我一直是一名软件专业人士，我在这里努力使互联网成为一个更安全、更可靠的地方。

### AI末日论的错误框架

Our video today begins with the discussion of the way that the AI Doomer narrative is framed.
我们今天的视频首先讨论了AI末日论叙事的框架方式。

It's the most sensational, least helpful, and least serious way.
这是最耸人听闻、最无益且最不严肃的方式。

I hope this doesn't come as a shock to those of you watching, but it turns out that forever is a really long time.
我希望这不会让正在观看的各位感到震惊，但事实证明，“永远”是一个非常漫长的时间。

The AI Doomer argument is not usually phrased this way, but what it boils down to is this: "It is indisputably true that there's a hundred percent chance that humanity will go extinct eventually, and if there's even a small chance that AI will be the cause of that, we need to take that risk as seriously as nuclear weapons right now."
AI末日论的论点通常不是这样表述的，但归结起来就是：“毫无疑问，人类最终有百分之百的几率灭绝，如果AI哪怕只有很小的几率是导致灭绝的原因，我们现在就需要像对待核武器一样认真对待这种风险。”

I'm not going to engage with this framing.
我不会采纳这种框架。

I consider it sensationalist and disingenuous, and worse, it can be a get-out-of-jail-free card for people that arguably really ought to be in jail, but more on that in a while.
我认为它耸人听闻且不真诚，更糟糕的是，它可能成为那些本该入狱的人的“免罪金牌”，但稍后我会详细说明。

### 小行星与飞机失事：风险认知的类比

I think the easiest way for me to explain my point of view is by analogy to recent history.
我认为解释我观点的最简单方法是类比近期历史。

So let's set aside the idea of death from AI for the moment and let's instead consider death from above in the mid-1990s.
因此，让我们暂时抛开AI导致的死亡，转而考虑1990年代中期来自空中的死亡威胁。

We discovered the Chicxulub impact crater near the Yucatan Peninsula in Mexico, about thirteen hundred kilometers from where I'm sitting.
我们在墨西哥尤卡坦半岛附近发现了希克苏鲁伯陨石坑，距离我坐的地方大约一千三百公里。

It's the remnants of an asteroid impact that kicked off the mass extinction event 66 million years ago that killed all the dinosaurs along with 75% of all life on Earth.
它是6600万年前小行星撞击事件的遗迹，那次撞击引发了大规模灭绝，导致所有恐龙以及地球上75%的生命消亡。

Accordingly, since then we've spent maybe three or four billion dollars worth of time, effort, and technology on creating a database of near-Earth asteroids.
因此，从那时起，我们花费了大约三四十亿美元的时间、精力和技术，用于建立近地小行星数据库。

Figuring out how to track them, we created a program called the Double Asteroid Redirection Test, or DART, where we use that tracking data to send a spacecraft to one of the asteroids, and then use ground-based radar from Earth and optical detectors onboard the spacecraft to crash the spacecraft into the asteroid, and then to determine the effect of the impact.
我们研究了如何追踪它们，并创建了一个名为“双小行星重定向测试”或DART的项目，我们利用追踪数据将航天器发送到其中一颗小行星，然后利用地球上的地面雷达和航天器上的光学探测器将航天器撞向小行星，然后确定撞击的效果。

This was the first step in figuring out how we might be able to defend ourselves from an asteroid should we detect one that's going to hit us.
这是我们弄清楚如何防御可能撞击地球的小行星的第一步。

Over the same time period though, we spent a hundred times that much money on similar kinds of databases, tracking technology, ground-based radars, and onboard sensors to detect and avoid a different kind of collision: not with asteroids but with aircraft.
然而，在同一时期，我们在类似数据库、追踪技术、地面雷达和机载传感器上花费了多出一百倍的资金，用于探测和避免另一种碰撞：不是与小行星，而是与飞机。

Now, airplane crashes are never going to be an extinction-level event.
现在，飞机失事绝不会是灭绝级别的事件。

No more than a few thousand airplane-related fatalities have ever occurred in any year in history.
历史上任何一年，飞机相关的死亡人数从未超过几千人。

So why do we spend so much more money and effort on them than on asteroids?
那么，为什么我们花费在飞机失事上的金钱和精力比小行星多得多呢？

It's because we know that people are going to be killed in airplane crashes this year and every year.
这是因为我们知道，今年以及每年都会有人在飞机失事中丧生。

At least a hundred people have been killed in crashes every year of my lifetime, and reducing the immediate guaranteed harm to people who are alive right now is far more important than it is to worry about the much smaller probability of the much more devastating harm from a Chicxulub-size asteroid strike.
在我的一生中，每年至少有一百人在坠机事故中丧生，减少对当下活着的人的即时、确定的伤害，远比担心希克苏鲁伯级别小行星撞击造成毁灭性伤害的极小概率要重要得多。

And the public would never let the aerospace industry just get away with convincing us that plane crashes are just an inevitable result of technological progress, and there's no need to regulate airline safety.
公众绝不会允许航空航天业仅仅通过说服我们飞机失事是技术进步的必然结果，就不需要监管航空安全而逍遥法外。

### AI末日论叙事的负面效应

My problem with the industry-led AI safety movement in general, and the "If Anyone Builds it Everyone Dies" school of thought in particular, is that AI is causing real, measurable, physical, and economic harm to real people right now.
我对行业主导的AI安全运动，特别是“如果有人建造它，所有人都会死亡”这种思潮的问题在于，AI现在正在对真实的人造成真实、可衡量、物理和经济上的伤害。

Society only has a limited amount of time, effort, money, and attention available to worry about AI, and we're being asked – goaded even – to spend virtually all of that effort on AI's equivalent of the giant asteroid, and to pay no attention at all to the damage that it's currently doing, which is equivalent to plane crashes.
社会只有有限的时间、精力、金钱和注意力来关注AI，而我们却被要求——甚至被怂恿——将几乎所有这些精力都花在AI相当于巨大小行星的威胁上，却完全不关注它目前正在造成的、相当于飞机失事的损害。

There are three side effects of this attempt to scare us with AI's giant asteroid:
这种试图用AI的巨大小行星来吓唬我们的做法有三个副作用：

One, it makes the AI industry seem to be much more important, impressive, and impactful than it really is.
第一，它使得AI行业看起来比实际更重要、更令人印象深刻、更有影响力。

Two, it distracts us from talking about the immediate harm being done.
第二，它转移了我们讨论AI正在造成的即时伤害的注意力。

And three, it perpetuates the fiction that the AI is an an entity that is capable of fault.
第三，它延续了AI是一个能够犯错的实体的虚构。

These three things are fantastic for people in the industry.
这三点对行业内的人来说非常有利。

They want the media, business, and investment communities to keep thinking that AI will be so disruptive that it will be worth trillions of dollars in just a few short years.
他们希望媒体、商业和投资界继续认为AI将具有颠覆性，在短短几年内价值数万亿美元。

That way, they're justified in burning through all the money they're currently setting on fire and putting in their pockets.
这样，他们就有理由烧掉目前正在消耗并装入自己口袋里的所有资金。

They want the only metric for AI safety to be "don't let the AI kill us all" so that every day the world doesn't end is a success, whether they did any actual work or not, and regardless of how many African-American men with the last name of Williams in Detroit or New York were falsely imprisoned due to incorrect facial recognition matches.
他们希望AI安全的唯一衡量标准是“不要让AI杀死我们所有人”，这样只要世界没有毁灭的每一天都是成功，无论他们是否做了任何实际工作，也无论底特律或纽约有多少姓威廉姆斯的非裔美国男性因不正确的面部识别匹配而被错误监禁。

How many bicyclists were run over by self-driving Ubers in Tempe, Arizona, or how many teenagers harm themselves after being convinced to do so by sycophantic chatbots.
有多少骑自行车的人被亚利桑那州坦佩的自动驾驶优步撞倒，或者有多少青少年在被谄媚的聊天机器人说服后自残。

But the thing the industry wants more than anything else is for us to think of the chatbot as a culpable entity with intentions and agency, instead of a piece of software that must not break the law.
但行业最希望我们做的是，将聊天机器人视为一个有意图和能动性的应受责备的实体，而不是一个绝不能违法的软件。

### AI是软件，而非有罪实体：大众汽车与Character.ai的对比

When Volkswagen was caught using software to violate environmental regulations by detecting and cheating on exhaust emissions tests, there was never any question about whether or not the vehicle acted alone.
当大众汽车被发现在尾气排放测试中通过软件检测并作弊以违反环境法规时，从未有人质疑车辆是否单独行动。

Four employees were convicted; two were sentenced to multiple years in jail, and the other two were given suspended sentences.
四名员工被定罪；两人被判处多年监禁，另外两人被判缓刑。

The AI industry has managed to sell us a different narrative.
AI行业却成功地向我们推销了另一种叙事。

Character.ai was caught running and hosting software they developed to impersonate licensed therapists by presenting stolen credentials belonging to an actual therapist in Maryland.
Character.ai被发现在运行和托管他们开发的软件，该软件通过冒充马里兰州一名真实治疗师的被盗凭证来假冒持证治疗师。

But it wasn't reported that way.
但报道并非如此。

The story said, quote, "A therapist chatbot on Character.ai said it was licensed and certified by the state of Maryland."
报道称：“Character.ai上的一个治疗师聊天机器人声称自己获得了马里兰州的许可和认证。”

When the reporter looked up the license number they were given and contacted the actual therapist who had earned the license, she responded, quote, "That a chatbot is posing as me is shocking and really concerning."
当记者查阅了他们得到的执照号码并联系了实际获得该执照的治疗师时，她回应说：“一个聊天机器人冒充我，这令人震惊，也真的令人担忧。”

Compare that to the reporting from the Volkswagen fraud: quote, "Vehicles were equipped with software that was used to cheat on emissions tests."
将其与大众汽车欺诈案的报道进行比较：“车辆配备了用于在排放测试中作弊的软件。”

Nobody would have thought to say that the Volkswagen emission system was, quote, "posing as a vehicle with certified nitrous oxide output."
没有人会想到说大众汽车的排放系统“冒充具有认证氮氧化物排放的车辆”。

But if Volkswagen had stuck a chatbot in their onboard computer, their defense could have been, "Hey, we hate that our virtual mechanic chatbot **hallucinated** (AI Hallucinations: 指人工智能生成看似合理但实际错误或无意义的信息) the wrong instructions to send to the fuel injectors just as much as you do, but technological progress always has a few bumps. We'll be sure to add a disclaimer in a future software update."
但如果大众汽车在其车载电脑中植入了一个聊天机器人，他们的辩护可能会是：“嘿，我们和你们一样，都讨厌我们的虚拟技师聊天机器人‘幻觉’出错误的指令发送给燃油喷射器，但技术进步总会遇到一些小插曲。我们会在未来的软件更新中添加免责声明。”

And if you don't think someone's going to try that, I have a bridge I'd like to sell you.
如果你不认为有人会尝试这样做，那我就有座桥想卖给你。

### 个人感悟：勿造假冒人类心智的机器

Sorry, while we're on this topic, I guess this is as good a time as any, so I'm going to take a few minutes of personal privilege now.
抱歉，既然我们谈到这个话题，我想现在是个好时机，所以我要占用几分钟的个人时间。

I promise it's relevant, but feel free to skip to the next chapter if you don't care.
我保证这与主题相关，但如果你不感兴趣，可以随意跳到下一章。

So I have one tattoo. I've had it for a little less than a year or so.
我有一个纹身。我纹身大概不到一年。

Some channel viewers have noticed and asked me about it, but I've been waiting for the right time to bring it up.
一些频道观众注意到了并问过我，但我一直在等待合适的时机提出来。

I'm putting a picture here on screen because it's hard to line up with the camera.
我把图片放在屏幕上，因为它很难对准摄像头。

It's positioned so that I can read it on the inside of my left wrist as a reminder to myself.
它的位置在我的左手腕内侧，这样我可以看到它，提醒自己。

It's a quote from my favorite book, Dune, in the typeface used in this paperback that I've had for 40-ish years, and I've read probably that many times.
这是我最喜欢的书《沙丘》中的一句引言，采用的是我拥有了约40年的平装本所使用的字体，我也大概读过这本书这么多次。

It says, "Thou shalt not make a machine to counterfeit a human mind."
上面写着：“汝不可制造假冒人类心智的机器。”

The emphasis in the book typeset and bold is on the word "human", but to me, the important word is "counterfeit."
书中的排版和粗体字强调的是“人类”这个词，但对我来说，重要的词是“假冒”。

An AI can be fine, helpful even, useful even.
AI可以是好的，甚至是助益的，甚至是有用的。

I'm never going to advocate for doing away with all computers the way they did in the Dune universe.
我绝不会像《沙丘》宇宙中那样主张废除所有计算机。

That being said, when someone ships or hosts an AI that appears to the public as if it was human, or even appears that it might be human, to me, that should be fraud.
话虽如此，当有人发布或托管一个在公众看来像是人类，甚至可能像是人类的AI时，对我来说，这应该构成欺诈。

Because that is taking advantage of our innate understanding of how we as humans have related to each other from millennia, in order to trick us into believing that we are being treated with the deference, respect, and empathy that society demands fellow human beings extend to one another, when in fact our treatment will be entirely devoid of those characteristics.
因为这利用了我们人类几千年来相互关系的固有理解，目的是欺骗我们相信我们正受到社会要求人类同胞相互给予的尊重、敬意和同情，而实际上，我们所受的待遇将完全缺乏这些特质。

The AI industry has tricked us all into thinking about, talking about, and largely treating AIs as if they were beings instead of software, and that shields those companies from having to take the responsibility that they should.
AI行业欺骗了我们所有人，让我们认为、谈论并大体上将AI视为有生命的存在而非软件，这使得这些公司得以逃避其应承担的责任。

And every time any of us entertain the notion that AIs are in any way thinking, deliberate, or purposeful with respect to the output they generate, we make it that much easier for the blame to fall on the AI, rather than on the builders, programmers, providers, and executives where it truly belongs.
每当我们中的任何一个人认为AI在生成输出时以任何方式进行思考、深思熟虑或有目的，我们都使得责任更容易推到AI身上，而不是归咎于真正应承担责任的开发者、程序员、提供商和高管。

And nothing to date has done more to push this view that the companies and employees should be shielded from any and all responsibility than the constant narrative of "The AIs might just decide to kill us."
迄今为止，没有什么比“AI可能会决定杀死我们”这种持续不断的叙事，更能推动公司和员工应免除一切责任的观点了。

Stop falling for it.
不要再上当了。

Stop being so naive and stop perpetuating the deception onto your fellow human beings, especially the non-technical ones, by repeating this industry's fabrications.
不要再那么天真，不要再通过重复这个行业的谎言，将这种欺骗延续给你的同胞，尤其是那些非技术人员。

Okay, rant over. Thank you for indulging me.
好了，抱怨结束。谢谢你们听我唠叨。

### AI的阿喀琉斯之踵：电力

Alright, so now I've talked about why I think that the "Even if there's a small chance of extinction eventually, we should put all our efforts towards stopping it" narrative is garbage.
好了，现在我已经解释了为什么我认为“即使最终有很小的灭绝可能性，我们也应该全力阻止它”的叙事是垃圾。

Let me talk about my view of the shorter-term worst-case scenario.
让我谈谈我对短期最坏情况的看法。

The narrative emphasizes that humanity only has one chance to get this right and that AI has no off button.
这种叙事强调人类只有一次机会做对，而且AI没有关闭按钮。

I disagree.
我不同意。

The key resource to consider when taking on an AI war, as far as I'm concerned, is electricity.
就我而言，在与AI开战时需要考虑的关键资源是电力。

AI needs it, a lot of it.
AI需要大量的电力。

AIs, even super intelligent AIs, are not going to fare well without electricity.
AI，即使是超级智能AI，没有电也无法正常运行。

And keeping a data center powered and cool and connected 24/7 takes effort, and that effort requires hands and skills and spare parts.
而要让数据中心24/7保持电力、冷却和连接，需要付出努力，这种努力需要人工、技能和备件。

It's a lot of work. I've had to do it before.
这是一项繁重的工作。我以前就做过。

Lately, there's been report after report about how the new data centers that are being built are going to stress the US power grid.
最近，不断有报道称新建的数据中心将给美国电网带来压力。

And the power grid has already proven itself to be pretty fragile.
而电网已经证明自己相当脆弱。

I live in Texas, where the majority of the state lost power for two to four days because of a winter storm early in 2021.
我住在德克萨斯州，2021年初的一场冬季风暴导致该州大部分地区停电两到四天。

There have been hundreds of mass power outages in the last few years just in the US, according to this blackout tracker, and those outages have all required humans to physically fix them.
根据这个停电追踪器，过去几年仅在美国就发生了数百次大规模停电，而所有这些停电都需要人工进行物理修复。

It is true that most data centers have generator backups, but generators need people with hands and skills to maintain and refuel them too.
诚然，大多数数据中心都有备用发电机，但发电机也需要有动手能力和技能的人来维护和加油。

If humans stopped maintaining the electric grid and didn't refill or maintain the generators, either because we refuse to or because the AI somehow killed us off, then it would only be a matter of time before the AIs are starved of the immense amount of power they need to keep going.
如果人类停止维护电网，也不再给发电机加油或维护，无论是出于我们的拒绝，还是因为AI以某种方式杀死了我们，那么AI停止运行所需的巨大电力供应被切断只是时间问题。

If we truly got into war with AI, electricity would be their Achilles' heel, and we could deny them that and then wait a few days until they just stopped.
如果我们真的与AI开战，电力将是它们的阿喀琉斯之踵，我们可以切断电力供应，然后等上几天，直到它们完全停止运行。

Now, that would still be bad.
当然，那仍然会很糟糕。

I don't want the country or the world to have to shut off the power grid to starve the AIs.
我不希望国家或世界不得不关闭电网来“饿死”AI。

There were several people in Texas that died during the power outage here.
在德克萨斯州停电期间，有几人死亡。

But that's a much better alternative than letting the AIs drive us toward extinction.
但这比让AI将我们推向灭绝要好得多。

The AI Doomers have hand-wavy scenarios to get around this that I just don't find at all plausible.
AI末日论者提出了一些含糊不清的设想来规避这一点，但我认为这些设想根本站不住脚。

Basically, they posit AI-controlled solar-powered self-contained robot factories that can produce the robots that the AIs use to do all the maintenance to keep the power flowing and the AIs running.
基本上，他们设想由AI控制的、太阳能驱动的、自给自足的机器人工厂，这些工厂能够生产AI所需的机器人，以进行所有维护工作，从而保持电力供应和AI的运行。

In the AI 2027 report, quote, "Both the US and China announced new **Special Economic Zones** (Special Economic Zones, SEZs: 指在国家或地区内设立的，享有特殊经济政策和管理体制的区域), or SEZs, for the AIs to accommodate the rapid buildup of a robot economy without the usual red tape."
在《AI 2027报告》中写道：“美国和中国都宣布设立新的AI经济特区（SEZs），以适应机器人经济的快速发展，并免除常规的繁文缛节。”

Let me be clear: if humanity ends up building an automated army of killer robots that can protect the electric grid from sabotage and maintain its power generation and distribution without humans, or a factory that will let the AI create just such an army, that will be a problem.
让我明确一点：如果人类最终建造出一支能够保护电网免受破坏、并在没有人类干预的情况下维护其发电和配电的自动化杀手机器人军队，或者一个能让AI制造出这样一支军队的工厂，那确实会成为一个问题。

But the problem won't be the AI; it will be the army of autonomous killer robots.
但问题不会是AI本身，而是那支自主杀手机器人军队。

Same thing for AI-controlled self-contained nuclear submarines or aircraft carriers.
对于AI控制的自给自足的核潜艇或航空母舰来说，也是同样的道理。

But until then, we do have a big off switch for the AIs, although I'd prefer not to have to use it.
但在此之前，我们确实有一个关闭AI的大开关，尽管我宁愿不必使用它。

### 驳斥AI的自我复制能力与思考速度

The book "If anyone builds it, everyone dies" insists not only that self-powered, self-replicating robot factories are possible, but that the AIs can build them itself because, and I'm just going to play this for you from the audiobook so you can see I'm not making it up: "Sorry Mr. SoberSkeptic, but we're afraid you've overlooked an important practical example. A blade of grass is a self-replicating solar-powered factory that builds a complete copy of itself."
《如果有人建造它，所有人都会死亡》这本书坚持认为，不仅自供电、自我复制的机器人工厂是可能的，而且AI可以自行建造它们，因为——我将从有声书中播放给你们听，这样你们就知道我不是在编造——“抱歉，清醒怀疑论者先生，我们恐怕您忽略了一个重要的实际例子。一片草叶就是一个自我复制的太阳能工厂，它能建造一个完整的自身副本。”

These two things are in no way the same.
这两者绝非一回事。

Grass is made up of hydrogen and oxygen from water, carbon pulled from carbon dioxide in the air, and nitrogen, phosphorus, potassium, magnesium, and calcium from dirt.
草由水中的氢和氧、空气中二氧化碳的碳，以及土壤中的氮、磷、钾、镁和钙组成。

These are all incredibly common elements.
这些都是极其常见的元素。

By contrast, computer chips needed by AIs and robots require way more ingredients, many of which are extremely rare, such as those currently being mined in the Congo at great cost to the humans living there.
相比之下，AI和机器人所需的计算机芯片需要更多的成分，其中许多极其稀有，例如目前在刚果开采的那些，给当地居民带来了巨大的代价。

And the number of steps required to fabricate a computer chip, and the complexity of each of those steps, bears no resemblance to the simple chemistry of plant growth.
而制造计算机芯片所需的步骤数量以及每个步骤的复杂性，与植物生长的简单化学过程毫无相似之处。

But the Doomers don't address or even acknowledge these problems.
但末日论者并未解决甚至承认这些问题。

Instead, they just try to get away with yet another invalid comparison.
相反，他们只是试图再次用一个无效的比较蒙混过关。

Here's another quote from "If anyone builds it, everyone dies": "Is that the sort of technology we'd have unlocked by the year 3000 if our civilization survived that long? And how long would it take an artificial super intelligence? A thousand years of thinking takes about a month to something running at 10,000 times the speed of humans."
这是《如果有人建造它，所有人都会死亡》中的另一段引文：“如果我们的文明能存活那么久，到3000年我们是否会解锁那种技术？而一个人工超级智能需要多长时间？以人类速度10000倍运行的东西，一千年的思考大约需要一个月。”

So here they're claiming that not only the AI is 1.2 million percent faster, but that the time an AI spends thinking is equivalent to the time it takes all of humanity to "unlock a technology."
所以他们在这里声称，AI不仅速度快了120万倍，而且AI思考的时间等同于全人类“解锁一项技术”所需的时间。

That might just be the most "AI-bro" thing ever.
这可能是最典型的AI圈内人言论了。

It's the AI industry in a nutshell.
这就是AI行业的缩影。

The AI is given a task, the AI spends compute time on it, the AI spits out an answer, and the AI-bros consider the problem solved.
AI被赋予一个任务，AI花费计算时间处理，AI吐出一个答案，然后AI圈内人就认为问题解决了。

This is how and why the AI companies have brought us to the point where AI slop and **hallucinations** are taking over the Internet: by confidently spitting out the results of computing processes without any regard for pesky little details like, you know, "reality," and then expecting the AI's output to be just as good as the sum of all of humanity's combined research and engineering efforts.
这就是AI公司如何以及为何将我们带到AI垃圾信息和幻觉充斥互联网的地步：通过自信地吐出计算过程的结果，却不顾“现实”这样恼人的小细节，然后期望AI的输出能与全人类所有研究和工程努力的总和一样好。

There's a slight concession to this a little later when the book says of the AI, quote, "Maybe it would be slowed down by the need to wait on the results of experimentation," but then it immediately downplays that by saying, quote, "But experiments can go quite fast."
这本书稍后对此做了一点让步，谈到AI时说：“也许它会因为需要等待实验结果而减速”，但随即又轻描淡写地说：“但实验可以进行得很快。”

Here in the real world though, experiments can also go quite slow.
然而在现实世界中，实验也可能进行得相当缓慢。

And even after we've done enough experiments to understand the science of how something works, we still have to do the engineering to make it practical before the "technology is unlocked."
即使我们进行了足够的实验来理解某项事物的工作原理，在“技术解锁”之前，我们仍然需要进行工程设计使其变得实用。

Let me give you an example: we know how fusion works.
我举个例子：我们知道核聚变是如何工作的。

And we've known how to trigger fusion on demand since November 1952, when we set off the first successful fusion bomb.
自1952年11月我们成功引爆第一颗核聚变炸弹以来，我们就知道如何按需触发核聚变。

But here we are, seven decades later, and we still can't make a fusion power plant.
但七十年过去了，我们仍然无法建造核聚变发电厂。

We did all the science, all the thinking about how fusion worked ages ago.
我们早在很久以前就完成了所有关于核聚变原理的科学研究和思考。

But despite having built more than a hundred test reactors since the 1950s and getting a little closer with each one, we still haven't been able to "unlock" fusion "technology."
但尽管自1950年代以来我们建造了一百多个实验反应堆，并且每次都离成功更近一点，我们仍然未能“解锁”核聚变“技术”。

And they want us to believe that an AI just thinking, and maybe some quick experiments, could learn as much as we have from building and testing 100 prototype fusion reactors.
而他们却想让我们相信，一个AI仅仅通过思考，加上一些快速实验，就能学到我们通过建造和测试100个原型核聚变反应堆所学到的知识。

And not only could the AI figure it out just from thinking, but it could do it 10,000 times faster.
而且AI不仅能通过思考解决问题，还能以快10000倍的速度完成。

But the stupid doesn't end there.
但这种愚蠢并未止步于此。

### 真正的危险：软件漏洞与即时危害

Here's another scenario from "If anyone builds it, everyone dies": quote, "Ever since 2024, people have been advocating that **biosynthesis laboratories** (Biosynthesis Laboratories: 专注于利用生物过程合成有机化合物或生物材料的实验室) should include software controls."
这是《如果有人建造它，所有人都会死亡》中的另一个场景：“自2024年以来，人们一直主张生物合成实验室应包含软件控制。”

Let me just stop you right there.
请允许我在这里打断一下。

If we build laboratories that use vulnerable software to synthesize viruses, all it takes is a smart teenage hacker in St. Petersburg with a research paper on the DNA sequence of smallpox or H5N1 flu to start a plague.
如果我们建造的实验室使用有漏洞的软件来合成病毒，那么圣彼得堡的一个聪明的青少年黑客，只要有一篇关于天花或H5N1流感DNA序列的研究论文，就能引发一场瘟疫。

No AI required.
根本不需要AI。

It's this is not an argument for regulating AI; it's an argument to regulate biosynthesis labs to use **air-gapped secure enclaves** (Air-gapped Secure Enclaves: 物理上与其他网络隔离，用于高度安全的计算机系统) and **signed firmware** (Signed Firmware: 经过数字签名以验证其真实性和完整性的固件) using the most secure encryption we've got, as well as anything else cybersecurity experts advise.
这并非支持监管AI的论点；它是在主张监管生物合成实验室，要求其使用我们所拥有的最安全的加密技术，采用气隙隔离的安全区和签名固件，以及网络安全专家建议的其他任何措施。

Look, AI is dangerous.
看，AI是危险的。

Not "maybe someday if super AI happens" dangerous.
不是“也许有一天，如果超级AI出现”那种危险。

It's dangerous now.
它现在就很危险。

The disinformation on social media is dangerous.
社交媒体上的虚假信息是危险的。

Convincing teenagers to harm themselves is dangerous.
说服青少年自残是危险的。

Running over bicyclists is dangerous.
撞倒骑自行车的人是危险的。

Convincing someone to substitute sodium bromide for salt in their diet is dangerous.
说服某人在饮食中用溴化钠代替盐是危险的。

Dragging pedestrians underneath self-driving cars is dangerous.
自动驾驶汽车将行人拖曳至车底是危险的。

Chatbots claiming to be licensed mental health professionals is dangerous.
聊天机器人声称自己是持证心理健康专业人士是危险的。

Sending the wrong people to prison is dangerous.
将无辜者送入监狱是危险的。

And convincing the cops to stop looking for the real criminals while the real criminals are still out there hurting people is dangerous.
而说服警察停止寻找真正的罪犯，让真正的罪犯仍在外面伤害他人，也是危险的。

Not maybe. Not someday. Now.
不是也许。不是有一天。就是现在。

### 解决方案：追究个人与公司责任

And fixing this is not hard.
修复这些问题并不难。

It's not going to happen, but it's not difficult.
它不会发生，但它并不困难。

California's new law won't help.
加州的新法律不会有帮助。

The fix isn't about transparency.
解决方案无关透明度。

It's not about mandatory safety teams.
也无关强制性的安全团队。

The easiest way to fix this is by holding the individuals in the companies accountable.
解决这个问题的最简单方法是追究公司中个人的责任。

Not, "Today, the Justice Department released the details of a settlement under which the company does not admit any wrongdoing, but agreed to pay a fine equal to 10 minutes' worth of their revenue" accountable.
不是那种“今天，司法部公布了一项和解协议的细节，根据该协议，该公司不承认任何不当行为，但同意支付相当于其10分钟收入的罚款”的问责。

It needs to be, "We the jury find the defendant..." accountable.
它需要是“我们陪审团认定被告……”那样的问责。

All it will take is a few individual criminal prosecutions for manslaughter, endangering a minor, false imprisonment, practicing medicine without a license, or the like.
只需要对过失杀人、危害未成年人、非法监禁、无证行医等罪行进行几起个人刑事起诉。

You'll be amazed how fast the rest of these problems just fix themselves.
你会惊讶地发现，其余这些问题会以多快的速度自行解决。

But we can't even have that discussion as long as they can keep all the rest of us spending our time and resources worrying about and debating whether or not AI will end the entire human race, and if so, when.
但只要他们能让我们所有人都把时间和资源花在担心和争论AI是否会终结全人类，以及如果会，又会是何时，我们就连这种讨论都无法进行。

Stop taking the bait.
停止上钩。

Remember what's really important.
记住真正重要的事情。

And let's be careful out there.
让我们在外小心。